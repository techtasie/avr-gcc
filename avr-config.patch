diff --git a/gcc-12.1.0/gcc/config/avr/avr-arch.h b/gcc-12.1.0/gcc/config/avr/avr-arch.h
index 7b253559388..29834f473f3 100644
--- a/gcc-12.1.0/gcc/config/avr/avr-arch.h
+++ b/gcc-12.1.0/gcc/config/avr/avr-arch.h
@@ -1,6 +1,6 @@
 /* Definitions of types that are used to store AVR architecture and
    device information.
-   Copyright (C) 2012-2022 Free Software Foundation, Inc.
+   Copyright (C) 2012-2021 Free Software Foundation, Inc.
    Contributed by Georg-Johann Lay (avr@gjlay.de)
 
 This file is part of GCC.
diff --git a/gcc-12.1.0/gcc/config/avr/avr-c.c b/gcc-12.1.0/gcc/config/avr/avr-c.c
new file mode 100644
index 00000000000..fda56edcd56
--- /dev/null
+++ b/gcc-12.1.0/gcc/config/avr/avr-c.c
@@ -0,0 +1,509 @@
+/* Copyright (C) 2009-2021 Free Software Foundation, Inc.
+   Contributed by Anatoly Sokolov (aesok@post.ru)
+
+   This file is part of GCC.
+
+   GCC is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 3, or (at your option)
+   any later version.
+   
+   GCC is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+   
+   You should have received a copy of the GNU General Public License
+   along with GCC; see the file COPYING3.  If not see
+   <http://www.gnu.org/licenses/>.  */
+
+/* Not included in avr.c since this requires C front end.  */
+
+#define IN_TARGET_CODE 1
+
+#include "config.h"
+#include "system.h"
+#include "coretypes.h"
+#include "target.h"
+#include "c-family/c-common.h"
+#include "stor-layout.h"
+#include "langhooks.h"
+#include "memmodel.h"
+#include "tm_p.h"
+
+/* IDs for all the AVR builtins.  */
+
+enum avr_builtin_id
+  {
+#define DEF_BUILTIN(NAME, N_ARGS, TYPE, CODE, LIBNAME)  \
+    AVR_BUILTIN_ ## NAME,
+#include "builtins.def"
+#undef DEF_BUILTIN
+
+    AVR_BUILTIN_COUNT
+  };
+
+
+/* Implement `TARGET_RESOLVE_OVERLOADED_PLUGIN'.  */
+
+static tree
+avr_resolve_overloaded_builtin (unsigned int iloc, tree fndecl, void *vargs)
+{
+  tree type0, type1, fold = NULL_TREE;
+  enum avr_builtin_id id = AVR_BUILTIN_COUNT;
+  location_t loc = (location_t) iloc;
+  vec<tree, va_gc> &args = * (vec<tree, va_gc>*) vargs;
+
+  switch (DECL_MD_FUNCTION_CODE (fndecl))
+    {
+    default:
+      break;
+
+    case AVR_BUILTIN_ABSFX:
+      if (args.length() != 1)
+        {
+          error_at (loc, "%qs expects 1 argument but %d given",
+                    "absfx", (int) args.length());
+
+          fold = error_mark_node;
+          break;
+        }
+
+      type0 = TREE_TYPE (args[0]);
+
+      if (!FIXED_POINT_TYPE_P (type0))
+        {
+          error_at (loc, "%qs expects a fixed-point value as argument",
+                    "absfx");
+
+          fold = error_mark_node;
+        }
+
+      switch (TYPE_MODE (type0))
+        {
+        case E_QQmode: id = AVR_BUILTIN_ABSHR; break;
+        case E_HQmode: id = AVR_BUILTIN_ABSR; break;
+        case E_SQmode: id = AVR_BUILTIN_ABSLR; break;
+        case E_DQmode: id = AVR_BUILTIN_ABSLLR; break;
+
+        case E_HAmode: id = AVR_BUILTIN_ABSHK; break;
+        case E_SAmode: id = AVR_BUILTIN_ABSK; break;
+        case E_DAmode: id = AVR_BUILTIN_ABSLK; break;
+        case E_TAmode: id = AVR_BUILTIN_ABSLLK; break;
+
+        case E_UQQmode:
+        case E_UHQmode:
+        case E_USQmode:
+        case E_UDQmode:
+        case E_UHAmode:
+        case E_USAmode:
+        case E_UDAmode:
+        case E_UTAmode:
+          warning_at (loc, 0, "using %qs with unsigned type has no effect",
+                      "absfx");
+          return args[0];
+
+        default:
+          error_at (loc, "no matching fixed-point overload found for %qs",
+                    "absfx");
+
+          fold = error_mark_node;
+          break;
+        }
+
+      fold = targetm.builtin_decl (id, true);
+
+      if (fold != error_mark_node)
+        fold = build_function_call_vec (loc, vNULL, fold, &args, NULL);
+
+      break; // absfx
+
+    case AVR_BUILTIN_ROUNDFX:
+      if (args.length() != 2)
+        {
+          error_at (loc, "%qs expects 2 arguments but %d given",
+                    "roundfx", (int) args.length());
+
+          fold = error_mark_node;
+          break;
+        }
+
+      type0 = TREE_TYPE (args[0]);
+      type1 = TREE_TYPE (args[1]);
+
+      if (!FIXED_POINT_TYPE_P (type0))
+        {
+          error_at (loc, "%qs expects a fixed-point value as first argument",
+                    "roundfx");
+
+          fold = error_mark_node;
+        }
+
+      if (!INTEGRAL_TYPE_P (type1))
+        {
+          error_at (loc, "%qs expects an integer value as second argument",
+                    "roundfx");
+
+          fold = error_mark_node;
+        }
+
+      switch (TYPE_MODE (type0))
+        {
+        case E_QQmode: id = AVR_BUILTIN_ROUNDHR; break;
+        case E_HQmode: id = AVR_BUILTIN_ROUNDR; break;
+        case E_SQmode: id = AVR_BUILTIN_ROUNDLR; break;
+        case E_DQmode: id = AVR_BUILTIN_ROUNDLLR; break;
+
+        case E_UQQmode: id = AVR_BUILTIN_ROUNDUHR; break;
+        case E_UHQmode: id = AVR_BUILTIN_ROUNDUR; break;
+        case E_USQmode: id = AVR_BUILTIN_ROUNDULR; break;
+        case E_UDQmode: id = AVR_BUILTIN_ROUNDULLR; break;
+
+        case E_HAmode: id = AVR_BUILTIN_ROUNDHK; break;
+        case E_SAmode: id = AVR_BUILTIN_ROUNDK; break;
+        case E_DAmode: id = AVR_BUILTIN_ROUNDLK; break;
+        case E_TAmode: id = AVR_BUILTIN_ROUNDLLK; break;
+
+        case E_UHAmode: id = AVR_BUILTIN_ROUNDUHK; break;
+        case E_USAmode: id = AVR_BUILTIN_ROUNDUK; break;
+        case E_UDAmode: id = AVR_BUILTIN_ROUNDULK; break;
+        case E_UTAmode: id = AVR_BUILTIN_ROUNDULLK; break;
+
+        default:
+          error_at (loc, "no matching fixed-point overload found for %qs",
+                    "roundfx");
+
+          fold = error_mark_node;
+          break;
+        }
+
+      fold = targetm.builtin_decl (id, true);
+
+      if (fold != error_mark_node)
+        fold = build_function_call_vec (loc, vNULL, fold, &args, NULL);
+
+      break; // roundfx
+
+    case AVR_BUILTIN_COUNTLSFX:
+      if (args.length() != 1)
+        {
+          error_at (loc, "%qs expects 1 argument but %d given",
+                    "countlsfx", (int) args.length());
+
+          fold = error_mark_node;
+          break;
+        }
+
+      type0 = TREE_TYPE (args[0]);
+
+      if (!FIXED_POINT_TYPE_P (type0))
+        {
+          error_at (loc, "%qs expects a fixed-point value as first argument",
+                    "countlsfx");
+
+          fold = error_mark_node;
+        }
+
+      switch (TYPE_MODE (type0))
+        {
+        case E_QQmode: id = AVR_BUILTIN_COUNTLSHR; break;
+        case E_HQmode: id = AVR_BUILTIN_COUNTLSR; break;
+        case E_SQmode: id = AVR_BUILTIN_COUNTLSLR; break;
+        case E_DQmode: id = AVR_BUILTIN_COUNTLSLLR; break;
+
+        case E_UQQmode: id = AVR_BUILTIN_COUNTLSUHR; break;
+        case E_UHQmode: id = AVR_BUILTIN_COUNTLSUR; break;
+        case E_USQmode: id = AVR_BUILTIN_COUNTLSULR; break;
+        case E_UDQmode: id = AVR_BUILTIN_COUNTLSULLR; break;
+
+        case E_HAmode: id = AVR_BUILTIN_COUNTLSHK; break;
+        case E_SAmode: id = AVR_BUILTIN_COUNTLSK; break;
+        case E_DAmode: id = AVR_BUILTIN_COUNTLSLK; break;
+        case E_TAmode: id = AVR_BUILTIN_COUNTLSLLK; break;
+
+        case E_UHAmode: id = AVR_BUILTIN_COUNTLSUHK; break;
+        case E_USAmode: id = AVR_BUILTIN_COUNTLSUK; break;
+        case E_UDAmode: id = AVR_BUILTIN_COUNTLSULK; break;
+        case E_UTAmode: id = AVR_BUILTIN_COUNTLSULLK; break;
+
+        default:
+          error_at (loc, "no matching fixed-point overload found for %qs",
+                    "countlsfx");
+
+          fold = error_mark_node;
+          break;
+        }
+
+      fold = targetm.builtin_decl (id, true);
+
+      if (fold != error_mark_node)
+        fold = build_function_call_vec (loc, vNULL, fold, &args, NULL);
+
+      break; // countlsfx
+    }
+
+  return fold;
+}
+  
+
+/* Implement `REGISTER_TARGET_PRAGMAS'.  */
+
+void
+avr_register_target_pragmas (void)
+{
+  gcc_assert (ADDR_SPACE_GENERIC == ADDR_SPACE_RAM);
+
+  /* Register address spaces.  The order must be the same as in the respective
+     enum from avr.h (or designated initializers must be used in avr.c).
+     We always register all address spaces even if some of them make no
+     sense for some targets.  Diagnose for non-supported spaces will be
+     emit by TARGET_ADDR_SPACE_DIAGNOSE_USAGE.  */
+
+  for (int i = 0; i < ADDR_SPACE_COUNT; i++)
+    {
+      gcc_assert (i == avr_addrspace[i].id);
+
+      if (!ADDR_SPACE_GENERIC_P (i))
+        c_register_addr_space (avr_addrspace[i].name, avr_addrspace[i].id);
+    }
+
+  targetm.resolve_overloaded_builtin = avr_resolve_overloaded_builtin;
+}
+
+
+/* Transform LO into uppercase and write the result to UP.
+   You must provide enough space for UP.  Return UP.  */
+
+static char*
+avr_toupper (char *up, const char *lo)
+{
+  char *up0 = up;
+
+  for (; *lo; lo++, up++)
+    *up = TOUPPER (*lo);
+
+  *up = '\0';
+
+  return up0;
+}
+
+/* Worker function for TARGET_CPU_CPP_BUILTINS.  */
+
+void
+avr_cpu_cpp_builtins (struct cpp_reader *pfile)
+{
+  builtin_define_std ("AVR");
+
+  /* __AVR_DEVICE_NAME__ and  avr_mcu_types[].macro like __AVR_ATmega8__
+     are defined by -D command option, see device-specs file.  */
+
+  if (avr_arch->macro)
+    cpp_define_formatted (pfile, "__AVR_ARCH__=%s", avr_arch->macro);
+  if (AVR_HAVE_RAMPD)    cpp_define (pfile, "__AVR_HAVE_RAMPD__");
+  if (AVR_HAVE_RAMPX)    cpp_define (pfile, "__AVR_HAVE_RAMPX__");
+  if (AVR_HAVE_RAMPY)    cpp_define (pfile, "__AVR_HAVE_RAMPY__");
+  if (AVR_HAVE_RAMPZ)    cpp_define (pfile, "__AVR_HAVE_RAMPZ__");
+  if (AVR_HAVE_ELPM)     cpp_define (pfile, "__AVR_HAVE_ELPM__");
+  if (AVR_HAVE_ELPMX)    cpp_define (pfile, "__AVR_HAVE_ELPMX__");
+  if (AVR_HAVE_MOVW)     cpp_define (pfile, "__AVR_HAVE_MOVW__");
+  if (AVR_HAVE_LPMX)     cpp_define (pfile, "__AVR_HAVE_LPMX__");
+
+  if (avr_arch->asm_only)
+    cpp_define (pfile, "__AVR_ASM_ONLY__");
+  if (AVR_HAVE_MUL)
+    {
+      cpp_define (pfile, "__AVR_ENHANCED__");
+      cpp_define (pfile, "__AVR_HAVE_MUL__");
+    }
+
+  if (AVR_HAVE_JMP_CALL)
+    cpp_define (pfile, "__AVR_HAVE_JMP_CALL__");
+
+  if (avr_arch->have_jmp_call)
+    cpp_define (pfile, "__AVR_MEGA__");
+
+  if (AVR_SHORT_CALLS)
+    cpp_define (pfile, "__AVR_SHORT_CALLS__");
+
+  if (AVR_XMEGA)
+    cpp_define (pfile, "__AVR_XMEGA__");
+
+  if (AVR_TINY)
+    {
+      cpp_define (pfile, "__AVR_TINY__");
+
+      /* Define macro "__AVR_TINY_PM_BASE_ADDRESS__" with mapped program memory
+         start address.  This macro shall be used where mapped program
+         memory is accessed, eg. copying data section (__do_copy_data)
+         contents to data memory region.
+         NOTE:
+         Program memory of AVR_TINY devices cannot be accessed directly,
+         it has been mapped to the data memory.  For AVR_TINY devices
+         (ATtiny4/5/9/10/20 and 40) mapped program memory starts at 0x4000. */
+
+      cpp_define_formatted (pfile, "__AVR_TINY_PM_BASE_ADDRESS__=0x%x",
+                            avr_arch->flash_pm_offset);
+    }
+
+  if (avr_arch->flash_pm_offset)
+    cpp_define_formatted (pfile, "__AVR_PM_BASE_ADDRESS__=0x%x",
+                          avr_arch->flash_pm_offset);
+
+  if (AVR_HAVE_EIJMP_EICALL)
+    {
+      cpp_define (pfile, "__AVR_HAVE_EIJMP_EICALL__");
+      cpp_define (pfile, "__AVR_3_BYTE_PC__");
+    }
+  else
+    {
+      cpp_define (pfile, "__AVR_2_BYTE_PC__");
+    }
+
+  if (AVR_HAVE_8BIT_SP)
+    cpp_define (pfile, "__AVR_HAVE_8BIT_SP__");
+  else
+    cpp_define (pfile, "__AVR_HAVE_16BIT_SP__");
+
+  if (AVR_HAVE_SPH)
+    cpp_define (pfile, "__AVR_HAVE_SPH__");
+  else
+    cpp_define (pfile, "__AVR_SP8__");
+
+  if (TARGET_NO_INTERRUPTS)
+    cpp_define (pfile, "__NO_INTERRUPTS__");
+
+  if (TARGET_SKIP_BUG)
+    {
+      cpp_define (pfile, "__AVR_ERRATA_SKIP__");
+
+      if (AVR_HAVE_JMP_CALL)
+        cpp_define (pfile, "__AVR_ERRATA_SKIP_JMP_CALL__");
+    }
+
+  if (TARGET_RMW)
+    cpp_define (pfile, "__AVR_ISA_RMW__");
+
+  cpp_define_formatted (pfile, "__AVR_SFR_OFFSET__=0x%x",
+                        avr_arch->sfr_offset);
+
+#ifdef WITH_AVRLIBC
+  cpp_define (pfile, "__WITH_AVRLIBC__");
+#endif /* WITH_AVRLIBC */
+
+  // From configure --with-libf7={|libgcc|math|math-symbols|yes|no}
+
+#ifdef WITH_LIBF7_LIBGCC
+  cpp_define (pfile, "__WITH_LIBF7_LIBGCC__");
+#endif /* WITH_LIBF7_LIBGCC */
+
+#ifdef WITH_LIBF7_MATH
+  cpp_define (pfile, "__WITH_LIBF7_MATH__");
+#endif /* WITH_LIBF7_MATH */
+
+#ifdef WITH_LIBF7_MATH_SYMBOLS
+  cpp_define (pfile, "__WITH_LIBF7_MATH_SYMBOLS__");
+#endif /* WITH_LIBF7_MATH_SYMBOLS */
+
+  // From configure --with-double={|32|32,64|64,32|64}
+
+#ifdef HAVE_DOUBLE_MULTILIB
+  cpp_define (pfile, "__HAVE_DOUBLE_MULTILIB__");
+#endif
+
+#ifdef HAVE_DOUBLE64
+  cpp_define (pfile, "__HAVE_DOUBLE64__");
+#endif
+
+#ifdef HAVE_DOUBLE32
+  cpp_define (pfile, "__HAVE_DOUBLE32__");
+#endif
+
+#if defined (WITH_DOUBLE64)
+  cpp_define (pfile, "__DEFAULT_DOUBLE__=64");
+#elif defined (WITH_DOUBLE32)
+  cpp_define (pfile, "__DEFAULT_DOUBLE__=32");
+#else
+#error "align this with config.gcc"
+#endif
+
+  // From configure --with-long-double={|32|32,64|64,32|64|double}
+
+#ifdef HAVE_LONG_DOUBLE_MULTILIB
+  cpp_define (pfile, "__HAVE_LONG_DOUBLE_MULTILIB__");
+#endif
+
+#ifdef HAVE_LONG_DOUBLE64
+  cpp_define (pfile, "__HAVE_LONG_DOUBLE64__");
+#endif
+
+#ifdef HAVE_LONG_DOUBLE32
+  cpp_define (pfile, "__HAVE_LONG_DOUBLE32__");
+#endif
+
+#ifdef HAVE_LONG_DOUBLE_IS_DOUBLE
+  cpp_define (pfile, "__HAVE_LONG_DOUBLE_IS_DOUBLE__");
+#endif
+
+#if defined (WITH_LONG_DOUBLE64)
+  cpp_define (pfile, "__DEFAULT_LONG_DOUBLE__=64");
+#elif defined (WITH_LONG_DOUBLE32)
+  cpp_define (pfile, "__DEFAULT_LONG_DOUBLE__=32");
+#else
+#error "align this with config.gcc"
+#endif
+
+  // From configure --with-double-comparison={2|3} --with-libf7.
+
+#if defined (WITH_DOUBLE_COMPARISON)
+#if WITH_DOUBLE_COMPARISON == 2 || WITH_DOUBLE_COMPARISON == 3
+  /* The number of states a DFmode comparison libcall might take and
+     reflects what avr.c:FLOAT_LIB_COMPARE_RETURNS_BOOL returns for
+     DFmode.  GCC's default is 3-state, but some libraries like LibF7
+     implement true / false (2-state).  */
+  cpp_define_formatted (pfile, "__WITH_DOUBLE_COMPARISON__=%d",
+			WITH_DOUBLE_COMPARISON);
+#else
+#error "align this with config.gcc"
+#endif
+#else
+#error "align this with config.gcc"
+#endif
+
+  /* Define builtin macros so that the user can easily query whether
+     non-generic address spaces (and which) are supported or not.
+     This is only supported for C.  For C++, a language extension is needed
+     (as mentioned in ISO/IEC DTR 18037; Annex F.2) which is not
+     implemented in GCC up to now.  */
+
+  if (lang_GNU_C ())
+    {
+      for (int i = 0; i < ADDR_SPACE_COUNT; i++)
+        if (!ADDR_SPACE_GENERIC_P (i)
+            /* Only supply __FLASH<n> macro if the address space is reasonable
+               for this target.  The address space qualifier itself is still
+               supported, but using it will throw an error.  */
+            && avr_addr_space_supported_p ((addr_space_t) i))
+          {
+            const char *name = avr_addrspace[i].name;
+            char *Name = (char*) alloca (1 + strlen (name));
+
+            cpp_define (pfile, avr_toupper (Name, name));
+          }
+    }
+
+  /* Define builtin macros so that the user can easily query whether or
+     not a specific builtin is available. */
+
+#define DEF_BUILTIN(NAME, N_ARGS, TYPE, CODE, LIBNAME)  \
+  cpp_define (pfile, "__BUILTIN_AVR_" #NAME);
+#include "builtins.def"
+#undef DEF_BUILTIN
+
+  /* Builtin macros for the __int24 and __uint24 type.  */
+
+  cpp_define_formatted (pfile, "__INT24_MAX__=8388607%s",
+                        INT_TYPE_SIZE == 8 ? "LL" : "L");
+  cpp_define (pfile, "__INT24_MIN__=(-__INT24_MAX__-1)");
+  cpp_define_formatted (pfile, "__UINT24_MAX__=16777215%s",
+                        INT_TYPE_SIZE == 8 ? "ULL" : "UL");
+}
diff --git a/gcc-12.1.0/gcc/config/avr/avr-devices.c b/gcc-12.1.0/gcc/config/avr/avr-devices.c
new file mode 100644
index 00000000000..60efc3a6de2
--- /dev/null
+++ b/gcc-12.1.0/gcc/config/avr/avr-devices.c
@@ -0,0 +1,156 @@
+/* Copyright (C) 2009-2021 Free Software Foundation, Inc.
+   Contributed by Anatoly Sokolov (aesok@post.ru)
+
+   This file is part of GCC.
+
+   GCC is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 3, or (at your option)
+   any later version.
+   
+   GCC is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+   
+   You should have received a copy of the GNU General Public License
+   along with GCC; see the file COPYING3.  If not see
+   <http://www.gnu.org/licenses/>.  */
+
+#ifndef IN_GEN_AVR_MMCU_TEXI
+#define IN_TARGET_CODE 1
+
+#include "config.h"
+#include "system.h"
+#include "coretypes.h"
+#include "tm.h"
+#include "diagnostic.h"
+#endif /* IN_GEN_AVR_MMCU_TEXI */
+
+#include "avr-arch.h"
+
+/* List of all known AVR MCU architectures.
+   Order as of enum avr_arch from avr.h.  */
+
+const avr_arch_t
+avr_arch_types[] =
+{
+  /* unknown device specified */
+  { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0x0060, 0,      32, NULL, AVR_MMCU_DEFAULT },
+  /*
+    A  M  J  LM E  E  E  X  R  T  d S     FPO     S O   A
+    S  U  M  PO L  L  I  M  A  I  a t     lMff    F ff  r
+    M  L  P  MV P  P  J  E  M  N  t a     a s     R s   c
+             XW M  M  M  G  P  Y  a r     s e       e   h
+                   X  P  A  D       t     h t       t   ID   */
+  { 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0x0060, 0,      32, "1",   "avr1"  },
+  { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0x0060, 0,      32, "2",   "avr2"  },
+  { 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0x0060, 0,      32, "25",  "avr25" },
+  { 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0x0060, 0,      32, "3",   "avr3"  },
+  { 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0x0060, 0,      32, "31",  "avr31" },
+  { 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0x0060, 0,      32, "35",  "avr35" },
+  { 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0x0060, 0,      32, "4",   "avr4"  },
+  { 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0x0060, 0,      32, "5",   "avr5"  },
+  { 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0x0060, 0,      32, "51",  "avr51" },
+  { 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0x0060, 0,      32, "6",   "avr6"  },
+
+  { 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0x0040, 0x4000, 0, "100", "avrtiny" },
+  { 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0x2000, 0,      0, "102", "avrxmega2" },
+  { 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0x2000, 0x8000, 0, "103", "avrxmega3" },
+  { 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0x2000, 0,      0, "104", "avrxmega4" },
+  { 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0x2000, 0,      0, "105", "avrxmega5" },
+  { 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0x2000, 0,      0, "106", "avrxmega6" },
+  { 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0x2000, 0,      0, "107", "avrxmega7" }
+};
+
+const avr_arch_info_t
+avr_texinfo[] =
+{
+  { ARCH_AVR1,
+    "This ISA is implemented by the minimal AVR core and supported "
+    "for assembler only." },
+  { ARCH_AVR2,
+    "``Classic'' devices with up to 8@tie{}KiB of program memory." },
+  { ARCH_AVR25,
+    "``Classic'' devices with up to 8@tie{}KiB of program memory and with "
+    "the @code{MOVW} instruction." },
+  { ARCH_AVR3,
+    "``Classic'' devices with 16@tie{}KiB up to 64@tie{}KiB of "
+    "program memory." },
+  { ARCH_AVR31,
+    "``Classic'' devices with 128@tie{}KiB of program memory." },
+  { ARCH_AVR35,
+    "``Classic'' devices with 16@tie{}KiB up to 64@tie{}KiB of "
+    "program memory and with the @code{MOVW} instruction." },
+  { ARCH_AVR4,
+    "``Enhanced'' devices with up to 8@tie{}KiB of program memory." },
+  { ARCH_AVR5,
+    "``Enhanced'' devices with 16@tie{}KiB up to 64@tie{}KiB of "
+    "program memory." },
+  { ARCH_AVR51,
+    "``Enhanced'' devices with 128@tie{}KiB of program memory." },
+  { ARCH_AVR6,
+    "``Enhanced'' devices with 3-byte PC, i.e.@: with more than 128@tie{}KiB "
+    "of program memory." },
+  { ARCH_AVRTINY,
+    "``TINY'' Tiny core devices with 512@tie{}B up to 4@tie{}KiB of "
+    "program memory." },
+  { ARCH_AVRXMEGA2,
+    "``XMEGA'' devices with more than 8@tie{}KiB and up to 64@tie{}KiB "
+    "of program memory." },
+  { ARCH_AVRXMEGA3,
+    "``XMEGA'' devices with up to 64@tie{}KiB of combined program memory "
+    "and RAM, and with program memory visible in the RAM address space." },
+  { ARCH_AVRXMEGA4,
+    "``XMEGA'' devices with more than 64@tie{}KiB and up to 128@tie{}KiB "
+    "of program memory." },
+  { ARCH_AVRXMEGA5,
+    "``XMEGA'' devices with more than 64@tie{}KiB and up to 128@tie{}KiB "
+    "of program memory and more than 64@tie{}KiB of RAM." },
+  { ARCH_AVRXMEGA6,
+    "``XMEGA'' devices with more than 128@tie{}KiB of program memory." },
+  { ARCH_AVRXMEGA7,
+    "``XMEGA'' devices with more than 128@tie{}KiB of program memory "
+    "and more than 64@tie{}KiB of RAM." }
+};
+
+const avr_mcu_t
+avr_mcu_types[] =
+{
+#define AVR_MCU(NAME, ARCH, DEV_ATTRIBUTE, MACRO, DATA_SEC, TEXT_SEC, FLASH_SIZE, PMOFF) \
+  { NAME, ARCH, DEV_ATTRIBUTE, MACRO, DATA_SEC, TEXT_SEC, FLASH_SIZE, PMOFF },
+#include "avr-mcus.def"
+#undef AVR_MCU
+    /* End of list.  */
+  { NULL, ARCH_UNKNOWN, AVR_ISA_NONE, NULL, 0, 0, 0, 0 }
+};
+
+
+
+
+#ifndef IN_GEN_AVR_MMCU_TEXI
+
+static char*
+avr_archs_str (void)
+{
+  char *archs = concat ("", NULL);
+
+  // Build of core architectures' names.
+
+  for (const avr_mcu_t *mcu = avr_mcu_types; mcu->name; mcu++)
+    if (!mcu->macro)
+      archs = concat (archs, " ", avr_arch_types[mcu->arch_id].name, NULL);
+
+  return archs;
+}
+
+  
+void
+avr_inform_core_architectures (void)
+{
+  char *archs = avr_archs_str ();
+  inform (input_location, "supported core architectures:%s", archs);
+  free (archs);
+}
+
+#endif // IN_GEN_AVR_MMCU_TEXI
diff --git a/gcc-12.1.0/gcc/config/avr/avr-dimode.md b/gcc-12.1.0/gcc/config/avr/avr-dimode.md
index 6e491336915..1817c16fb10 100644
--- a/gcc-12.1.0/gcc/config/avr/avr-dimode.md
+++ b/gcc-12.1.0/gcc/config/avr/avr-dimode.md
@@ -1,6 +1,6 @@
 ;;   Machine description for GNU compiler,
 ;;   for Atmel AVR micro controllers.
-;;   Copyright (C) 1998-2022 Free Software Foundation, Inc.
+;;   Copyright (C) 1998-2021 Free Software Foundation, Inc.
 ;;   Contributed by Georg Lay (avr@gjlay.de)
 ;;
 ;; This file is part of GCC.
@@ -95,77 +95,39 @@
 ;; "adddq3_insn" "addudq3_insn"
 ;; "addda3_insn" "adduda3_insn"
 ;; "addta3_insn" "adduta3_insn"
-(define_insn_and_split "add<mode>3_insn"
+(define_insn "add<mode>3_insn"
   [(set (reg:ALL8 ACC_A)
         (plus:ALL8 (reg:ALL8 ACC_A)
                    (reg:ALL8 ACC_B)))]
   "avr_have_dimode"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL8 ACC_A)
-                   (plus:ALL8 (reg:ALL8 ACC_A)
-                              (reg:ALL8 ACC_B)))
-   (clobber (reg:CC REG_CC))])])
-
-(define_insn "*add<mode>3_insn"
-  [(set (reg:ALL8 ACC_A)
-        (plus:ALL8 (reg:ALL8 ACC_A)
-                   (reg:ALL8 ACC_B)))
-   (clobber (reg:CC REG_CC))]
-  "avr_have_dimode && reload_completed"
   "%~call __adddi3"
-  [(set_attr "adjust_len" "call")])
+  [(set_attr "adjust_len" "call")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "adddi3_const8_insn"
+(define_insn "adddi3_const8_insn"
   [(set (reg:DI ACC_A)
         (plus:DI (reg:DI ACC_A)
                  (sign_extend:DI (reg:QI REG_X))))]
   "avr_have_dimode"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:DI ACC_A)
-                   (plus:DI (reg:DI ACC_A)
-                            (sign_extend:DI (reg:QI REG_X))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*adddi3_const8_insn"
-  [(set (reg:DI ACC_A)
-        (plus:DI (reg:DI ACC_A)
-                 (sign_extend:DI (reg:QI REG_X))))
-   (clobber (reg:CC REG_CC))]
-  "avr_have_dimode && reload_completed"
   "%~call __adddi3_s8"
-  [(set_attr "adjust_len" "call")])
+  [(set_attr "adjust_len" "call")
+   (set_attr "cc" "clobber")])
 
 ;; "adddi3_const_insn"
 ;; "adddq3_const_insn" "addudq3_const_insn"
 ;; "addda3_const_insn" "adduda3_const_insn"
 ;; "addta3_const_insn" "adduta3_const_insn"
-(define_insn_and_split "add<mode>3_const_insn"
+(define_insn "add<mode>3_const_insn"
   [(set (reg:ALL8 ACC_A)
         (plus:ALL8 (reg:ALL8 ACC_A)
                    (match_operand:ALL8 0 "const_operand" "n Ynn")))]
   "avr_have_dimode
    && !s8_operand (operands[0], VOIDmode)"
-   "#"
-   "&& reload_completed"
-   [(parallel [(set (reg:ALL8 ACC_A)
-                    (plus:ALL8 (reg:ALL8 ACC_A)
-                               (match_dup 0)))
-               (clobber (reg:CC REG_CC))])])
-
-(define_insn "*add<mode>3_const_insn"
-  [(set (reg:ALL8 ACC_A)
-        (plus:ALL8 (reg:ALL8 ACC_A)
-                   (match_operand:ALL8 0 "const_operand" "n Ynn")))
-   (clobber (reg:CC REG_CC))]
-  "avr_have_dimode
-   && !s8_operand (operands[0], VOIDmode)
-   && reload_completed"
   {
     return avr_out_plus (insn, operands);
   }
-  [(set_attr "adjust_len" "plus")])
+  [(set_attr "adjust_len" "plus")
+   (set_attr "cc" "clobber")])
 
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
@@ -205,53 +167,29 @@
 ;; "subdq3_insn" "subudq3_insn"
 ;; "subda3_insn" "subuda3_insn"
 ;; "subta3_insn" "subuta3_insn"
-(define_insn_and_split "sub<mode>3_insn"
+(define_insn "sub<mode>3_insn"
   [(set (reg:ALL8 ACC_A)
         (minus:ALL8 (reg:ALL8 ACC_A)
                     (reg:ALL8 ACC_B)))]
   "avr_have_dimode"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL8 ACC_A)
-                   (minus:ALL8 (reg:ALL8 ACC_A)
-                               (reg:ALL8 ACC_B)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*sub<mode>3_insn"
-  [(set (reg:ALL8 ACC_A)
-        (minus:ALL8 (reg:ALL8 ACC_A)
-                    (reg:ALL8 ACC_B)))
-   (clobber (reg:CC REG_CC))]
-  "avr_have_dimode && reload_completed"
   "%~call __subdi3"
-  [(set_attr "adjust_len" "call")])
+  [(set_attr "adjust_len" "call")
+   (set_attr "cc" "set_czn")])
 
 ;; "subdi3_const_insn"
 ;; "subdq3_const_insn" "subudq3_const_insn"
 ;; "subda3_const_insn" "subuda3_const_insn"
 ;; "subta3_const_insn" "subuta3_const_insn"
-(define_insn_and_split "sub<mode>3_const_insn"
+(define_insn "sub<mode>3_const_insn"
   [(set (reg:ALL8 ACC_A)
         (minus:ALL8 (reg:ALL8 ACC_A)
                     (match_operand:ALL8 0 "const_operand" "n Ynn")))]
   "avr_have_dimode"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL8 ACC_A)
-                   (minus:ALL8 (reg:ALL8 ACC_A)
-                               (match_dup 0)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*sub<mode>3_const_insn"
-  [(set (reg:ALL8 ACC_A)
-        (minus:ALL8 (reg:ALL8 ACC_A)
-                    (match_operand:ALL8 0 "const_operand" "n Ynn")))
-   (clobber (reg:CC REG_CC))]
-  "avr_have_dimode && reload_completed"
   {
     return avr_out_plus (insn, operands);
   }
-  [(set_attr "adjust_len" "plus")])
+  [(set_attr "adjust_len" "plus")
+   (set_attr "cc" "clobber")])
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
 ;; Signed Saturating Addition and Subtraction
@@ -282,49 +220,25 @@
     DONE;
   })
 
-(define_insn_and_split "<code_stdname><mode>3_insn"
+(define_insn "<code_stdname><mode>3_insn"
   [(set (reg:ALL8S ACC_A)
         (ss_addsub:ALL8S (reg:ALL8S ACC_A)
                          (reg:ALL8S ACC_B)))]
   "avr_have_dimode"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL8S ACC_A)
-                   (ss_addsub:ALL8S (reg:ALL8S ACC_A)
-                                    (reg:ALL8S ACC_B)))
-             (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<code_stdname><mode>3_insn"
-  [(set (reg:ALL8S ACC_A)
-        (ss_addsub:ALL8S (reg:ALL8S ACC_A)
-                         (reg:ALL8S ACC_B)))
-   (clobber (reg:CC REG_CC))]
-  "avr_have_dimode && reload_completed"
   "%~call __<code_stdname><mode>3"
-  [(set_attr "adjust_len" "call")])
+  [(set_attr "adjust_len" "call")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "<code_stdname><mode>3_const_insn"
+(define_insn "<code_stdname><mode>3_const_insn"
   [(set (reg:ALL8S ACC_A)
         (ss_addsub:ALL8S (reg:ALL8S ACC_A)
                          (match_operand:ALL8S 0 "const_operand" "n Ynn")))]
   "avr_have_dimode"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL8S ACC_A)
-                   (ss_addsub:ALL8S (reg:ALL8S ACC_A)
-                                    (match_dup 0)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<code_stdname><mode>3_const_insn"
-  [(set (reg:ALL8S ACC_A)
-        (ss_addsub:ALL8S (reg:ALL8S ACC_A)
-                         (match_operand:ALL8S 0 "const_operand" "n Ynn")))
-   (clobber (reg:CC REG_CC))]
-  "avr_have_dimode && reload_completed"
   {
     return avr_out_plus (insn, operands);
   }
-  [(set_attr "adjust_len" "plus")])
+  [(set_attr "adjust_len" "plus")
+   (set_attr "cc" "clobber")])
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
 ;; Unsigned Saturating Addition and Subtraction
@@ -355,49 +269,25 @@
     DONE;
   })
 
-(define_insn_and_split "<code_stdname><mode>3_insn"
+(define_insn "<code_stdname><mode>3_insn"
   [(set (reg:ALL8U ACC_A)
         (us_addsub:ALL8U (reg:ALL8U ACC_A)
                          (reg:ALL8U ACC_B)))]
   "avr_have_dimode"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL8U ACC_A)
-                   (us_addsub:ALL8U (reg:ALL8U ACC_A)
-                                    (reg:ALL8U ACC_B)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<code_stdname><mode>3_insn"
-  [(set (reg:ALL8U ACC_A)
-        (us_addsub:ALL8U (reg:ALL8U ACC_A)
-                         (reg:ALL8U ACC_B)))
-   (clobber (reg:CC REG_CC))]
-  "avr_have_dimode && reload_completed"
   "%~call __<code_stdname><mode>3"
-  [(set_attr "adjust_len" "call")])
+  [(set_attr "adjust_len" "call")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "<code_stdname><mode>3_const_insn"
+(define_insn "<code_stdname><mode>3_const_insn"
   [(set (reg:ALL8U ACC_A)
         (us_addsub:ALL8U (reg:ALL8U ACC_A)
                          (match_operand:ALL8U 0 "const_operand" "n Ynn")))]
   "avr_have_dimode"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL8U ACC_A)
-                   (us_addsub:ALL8U (reg:ALL8U ACC_A)
-                                    (match_operand:ALL8U 0 "const_operand" "n Ynn")))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<code_stdname><mode>3_const_insn"
-  [(set (reg:ALL8U ACC_A)
-        (us_addsub:ALL8U (reg:ALL8U ACC_A)
-                         (match_operand:ALL8U 0 "const_operand" "n Ynn")))
-   (clobber (reg:CC REG_CC))]
-  "avr_have_dimode && reload_completed"
   {
     return avr_out_plus (insn, operands);
   }
-  [(set_attr "adjust_len" "plus")])
+  [(set_attr "adjust_len" "plus")
+   (set_attr "cc" "clobber")])
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
 ;; Negation
@@ -416,23 +306,13 @@
     DONE;
   })
 
-(define_insn_and_split "negdi2_insn"
+(define_insn "negdi2_insn"
   [(set (reg:DI ACC_A)
         (neg:DI (reg:DI ACC_A)))]
   "avr_have_dimode"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:DI ACC_A)
-                   (neg:DI (reg:DI ACC_A)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*negdi2_insn"
-  [(set (reg:DI ACC_A)
-        (neg:DI (reg:DI ACC_A)))
-   (clobber (reg:CC REG_CC))]
-  "avr_have_dimode && reload_completed"
   "%~call __negdi2"
-  [(set_attr "adjust_len" "call")])
+  [(set_attr "adjust_len" "call")
+   (set_attr "cc" "clobber")])
 
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
@@ -442,7 +322,7 @@
 (define_expand "conditional_jump"
   [(set (pc)
         (if_then_else
-         (match_operator 0 "ordered_comparison_operator" [(reg:CC REG_CC)
+         (match_operator 0 "ordered_comparison_operator" [(cc0)
                                                           (const_int 0)])
          (label_ref (match_operand 1 "" ""))
          (pc)))]
@@ -453,14 +333,13 @@
 ;; "cbranchda4" "cbranchuda4"
 ;; "cbranchta4" "cbranchuta4"
 (define_expand "cbranch<mode>4"
-  [(set (pc)
-        (if_then_else (match_operator 0 "ordered_comparison_operator"
-                        [(match_operand:ALL8 1 "register_operand"  "")
-                         (match_operand:ALL8 2 "nonmemory_operand" "")])
-         (label_ref (match_operand 3 "" ""))
-         (pc)))]
+  [(parallel [(match_operand:ALL8 1 "register_operand" "")
+              (match_operand:ALL8 2 "nonmemory_operand" "")
+              (match_operator 0 "ordered_comparison_operator" [(cc0)
+                                                               (const_int 0)])
+              (label_ref (match_operand 3 "" ""))])]
   "avr_have_dimode"
-   {
+  {
     rtx acc_a = gen_rtx_REG (<MODE>mode, ACC_A);
 
     avr_fix_inputs (operands, 1 << 2, regmask (<MODE>mode, ACC_A));
@@ -469,36 +348,19 @@
     if (s8_operand (operands[2], VOIDmode))
       {
         emit_move_insn (gen_rtx_REG (QImode, REG_X), operands[2]);
-        emit_jump_insn (gen_cbranch_const8_di2_split (operands[0], operands[3]));
+        emit_insn (gen_compare_const8_di2 ());
       }
     else if (const_operand (operands[2], GET_MODE (operands[2])))
       {
-        emit_jump_insn (gen_cbranch_const_<mode>2_split (operands[0],
-                                                         operands[2],
-                                                         operands[3]));
+        emit_insn (gen_compare_const_<mode>2 (operands[2]));
       }
     else
       {
         emit_move_insn (gen_rtx_REG (<MODE>mode, ACC_B), operands[2]);
-        emit_jump_insn (gen_cbranch_<mode>2_split (operands[0], operands[3]));
+        emit_insn (gen_compare_<mode>2 ());
       }
-    DONE;
-   })
 
-(define_insn_and_split "cbranch_<mode>2_split"
-  [(set (pc)
-        (if_then_else (match_operator 0 "ordered_comparison_operator"
-                        [(reg:ALL8 ACC_A)
-                         (reg:ALL8 ACC_B)])
-         (label_ref (match_operand 1 "" ""))
-         (pc)))]
-  "avr_have_dimode"
-  "#"
-  "&& reload_completed"
-  [(const_int 0)]
-  {
-    emit_insn (gen_compare_<mode>2 ());
-    emit_jump_insn (gen_conditional_jump (operands[0], operands[1]));
+    emit_jump_insn (gen_conditional_jump (operands[0], operands[3]));
     DONE;
   })
 
@@ -507,74 +369,39 @@
 ;; "compare_da2" "compare_uda2"
 ;; "compare_ta2" "compare_uta2"
 (define_insn "compare_<mode>2"
-  [(set (reg:CC REG_CC)
-        (compare:CC (reg:ALL8 ACC_A)
-                    (reg:ALL8 ACC_B)))]
-  "reload_completed && avr_have_dimode"
-  "%~call __cmpdi2"
-  [(set_attr "adjust_len" "call")])
-
-(define_insn_and_split "cbranch_const8_di2_split"
-  [(set (pc)
-        (if_then_else (match_operator 0 "ordered_comparison_operator"
-                        [(reg:DI ACC_A)
-                         (sign_extend:DI (reg:QI REG_X))])
-         (label_ref (match_operand 1 "" ""))
-         (pc)))]
+  [(set (cc0)
+        (compare (reg:ALL8 ACC_A)
+                 (reg:ALL8 ACC_B)))]
   "avr_have_dimode"
-  "#"
-  "&& reload_completed"
-  [(const_int 0)]
-  {
-    emit_insn (gen_compare_const8_di2 ());
-    emit_jump_insn (gen_conditional_jump (operands[0], operands[1]));
-    DONE;
-  })
+  "%~call __cmpdi2"
+  [(set_attr "adjust_len" "call")
+   (set_attr "cc" "compare")])
 
 (define_insn "compare_const8_di2"
-  [(set (reg:CC REG_CC)
-        (compare:CC (reg:DI ACC_A)
-                    (sign_extend:DI (reg:QI REG_X))))]
-  "reload_completed && avr_have_dimode"
+  [(set (cc0)
+        (compare (reg:DI ACC_A)
+                 (sign_extend:DI (reg:QI REG_X))))]
+  "avr_have_dimode"
   "%~call __cmpdi2_s8"
-  [(set_attr "adjust_len" "call")])
-
-(define_insn_and_split "cbranch_const_<mode>2_split"
-  [(set (pc)
-        (if_then_else (match_operator 0 "ordered_comparison_operator"
-                        [(reg:ALL8 ACC_A)
-                         (match_operand:ALL8 1 "const_operand" "n Ynn")])
-         (label_ref (match_operand 2 "" ""))
-         (pc)))
-   (clobber (match_scratch:QI 3 "=&d"))]
-  "avr_have_dimode
-   && !s8_operand (operands[1], VOIDmode)"
-  "#"
-  "&& reload_completed"
-  [(const_int 0)]
-  {
-    emit_insn (gen_compare_const_<mode>2 (operands[1], operands[3]));
-    emit_jump_insn (gen_conditional_jump (operands[0], operands[2]));
-    DONE;
-  })
-
+  [(set_attr "adjust_len" "call")
+   (set_attr "cc" "compare")])
 
 ;; "compare_const_di2"
 ;; "compare_const_dq2" "compare_const_udq2"
 ;; "compare_const_da2" "compare_const_uda2"
 ;; "compare_const_ta2" "compare_const_uta2"
 (define_insn "compare_const_<mode>2"
-  [(set (reg:CC REG_CC)
-        (compare:CC (reg:ALL8 ACC_A)
-                    (match_operand:ALL8 0 "const_operand" "n Ynn")))
-   (clobber (match_operand:QI 1 "register_operand" "=&d"))]
-  "reload_completed
-   && avr_have_dimode
+  [(set (cc0)
+        (compare (reg:ALL8 ACC_A)
+                 (match_operand:ALL8 0 "const_operand" "n Ynn")))
+   (clobber (match_scratch:QI 1 "=&d"))]
+  "avr_have_dimode
    && !s8_operand (operands[0], VOIDmode)"
   {
     return avr_out_compare64 (insn, operands, NULL);
   }
-  [(set_attr "adjust_len" "compare64")])
+  [(set_attr "adjust_len" "compare64")
+   (set_attr "cc" "compare")])
 
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
@@ -617,26 +444,14 @@
 ;; "ashludq3_insn"  "ashrudq3_insn"  "lshrudq3_insn"  "rotludq3_insn"
 ;; "ashluda3_insn"  "ashruda3_insn"  "lshruda3_insn"  "rotluda3_insn"
 ;; "ashluta3_insn"  "ashruta3_insn"  "lshruta3_insn"  "rotluta3_insn"
-(define_insn_and_split "<code_stdname><mode>3_insn"
+(define_insn "<code_stdname><mode>3_insn"
   [(set (reg:ALL8 ACC_A)
         (di_shifts:ALL8 (reg:ALL8 ACC_A)
                         (reg:QI 16)))]
   "avr_have_dimode"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL8 ACC_A)
-                   (di_shifts:ALL8 (reg:ALL8 ACC_A)
-                                   (reg:QI 16)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<code_stdname><mode>3_insn"
-  [(set (reg:ALL8 ACC_A)
-        (di_shifts:ALL8 (reg:ALL8 ACC_A)
-                        (reg:QI 16)))
-   (clobber (reg:CC REG_CC))]
-  "avr_have_dimode && reload_completed"
   "%~call __<code_stdname>di3"
-  [(set_attr "adjust_len" "call")])
+  [(set_attr "adjust_len" "call")
+   (set_attr "cc" "clobber")])
 
 ;; "umulsidi3"
 ;; "mulsidi3"
@@ -660,8 +475,7 @@
 
 ;; "umulsidi3_insn"
 ;; "mulsidi3_insn"
-
-(define_insn_and_split "<extend_u>mulsidi3_insn"
+(define_insn "<extend_u>mulsidi3_insn"
   [(set (reg:DI ACC_A)
         (mult:DI (any_extend:DI (reg:SI 18))
                  (any_extend:DI (reg:SI 22))))
@@ -669,24 +483,6 @@
    (clobber (reg:HI REG_Z))]
   "avr_have_dimode
    && AVR_HAVE_MUL"
-   "#"
-   "&& reload_completed"
-   [(parallel [(set (reg:DI ACC_A)
-                    (mult:DI (any_extend:DI (reg:SI 18))
-                             (any_extend:DI (reg:SI 22))))
-               (clobber (reg:HI REG_X))
-               (clobber (reg:HI REG_Z))
-               (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<extend_u>mulsidi3_insn"
-  [(set (reg:DI ACC_A)
-        (mult:DI (any_extend:DI (reg:SI 18))
-                 (any_extend:DI (reg:SI 22))))
-   (clobber (reg:HI REG_X))
-   (clobber (reg:HI REG_Z))
-   (clobber (reg:CC REG_CC))]
-  "avr_have_dimode
-   && AVR_HAVE_MUL
-   && reload_completed"
   "%~call __<extend_u>mulsidi3"
-  [(set_attr "adjust_len" "call")])
+  [(set_attr "adjust_len" "call")
+   (set_attr "cc" "clobber")])
diff --git a/gcc-12.1.0/gcc/config/avr/avr-fixed.md b/gcc-12.1.0/gcc/config/avr/avr-fixed.md
index 542d92e1c13..a3b49d57913 100644
--- a/gcc-12.1.0/gcc/config/avr/avr-fixed.md
+++ b/gcc-12.1.0/gcc/config/avr/avr-fixed.md
@@ -1,6 +1,6 @@
 ;;   This file contains instructions that support fixed-point operations
 ;;   for Atmel AVR micro controllers.
-;;   Copyright (C) 2012-2022 Free Software Foundation, Inc.
+;;   Copyright (C) 2012-2021 Free Software Foundation, Inc.
 ;;
 ;;   Contributed by Sean D'Epagnier  (sean@depagnier.com)
 ;;                  Georg-Johann Lay (avr@gjlay.de)
@@ -56,53 +56,27 @@
    TA UTA
    QI HI SI DI])
 
-(define_insn_and_split "fract<FIXED_B:mode><FIXED_A:mode>2"
+(define_insn "fract<FIXED_B:mode><FIXED_A:mode>2"
   [(set (match_operand:FIXED_A 0 "register_operand" "=r")
         (fract_convert:FIXED_A
          (match_operand:FIXED_B 1 "register_operand" "r")))]
   "<FIXED_B:MODE>mode != <FIXED_A:MODE>mode"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (fract_convert:FIXED_A
-                    (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*fract<FIXED_B:mode><FIXED_A:mode>2"
-  [(set (match_operand:FIXED_A 0 "register_operand" "=r")
-        (fract_convert:FIXED_A
-         (match_operand:FIXED_B 1 "register_operand" "r")))
-   (clobber (reg:CC REG_CC))]
-  "<FIXED_B:MODE>mode != <FIXED_A:MODE>mode
-   && reload_completed"
   {
     return avr_out_fract (insn, operands, true, NULL);
   }
-  [(set_attr "adjust_len" "sfract")])
+  [(set_attr "cc" "clobber")
+   (set_attr "adjust_len" "sfract")])
 
-(define_insn_and_split "fractuns<FIXED_B:mode><FIXED_A:mode>2"
+(define_insn "fractuns<FIXED_B:mode><FIXED_A:mode>2"
   [(set (match_operand:FIXED_A 0 "register_operand" "=r")
         (unsigned_fract_convert:FIXED_A
          (match_operand:FIXED_B 1 "register_operand" "r")))]
   "<FIXED_B:MODE>mode != <FIXED_A:MODE>mode"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (unsigned_fract_convert:FIXED_A
-                    (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*fractuns<FIXED_B:mode><FIXED_A:mode>2"
-  [(set (match_operand:FIXED_A 0 "register_operand" "=r")
-        (unsigned_fract_convert:FIXED_A
-         (match_operand:FIXED_B 1 "register_operand" "r")))
-   (clobber (reg:CC REG_CC))]
-  "<FIXED_B:MODE>mode != <FIXED_A:MODE>mode
-   && reload_completed"
   {
     return avr_out_fract (insn, operands, false, NULL);
   }
-  [(set_attr "adjust_len" "ufract")])
+  [(set_attr "cc" "clobber")
+   (set_attr "adjust_len" "ufract")])
 
 ;******************************************************************************
 ;** Saturated Addition and Subtraction
@@ -118,59 +92,35 @@
 
 ;; "ssaddqq3"  "ssaddhq3"  "ssaddha3"  "ssaddsq3"  "ssaddsa3"
 ;; "sssubqq3"  "sssubhq3"  "sssubha3"  "sssubsq3"  "sssubsa3"
-(define_insn_and_split "<code_stdname><mode>3"
+(define_insn "<code_stdname><mode>3"
   [(set (match_operand:ALL124S 0 "register_operand"                          "=??d,d")
         (ss_addsub:ALL124S (match_operand:ALL124S 1 "register_operand" "<abelian>0,0")
                            (match_operand:ALL124S 2 "nonmemory_operand"         "r,Ynn")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ss_addsub:ALL124S (match_dup 1)
-                                      (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<code_stdname><mode>3"
-  [(set (match_operand:ALL124S 0 "register_operand"                          "=??d,d")
-        (ss_addsub:ALL124S (match_operand:ALL124S 1 "register_operand" "<abelian>0,0")
-                           (match_operand:ALL124S 2 "nonmemory_operand"         "r,Ynn")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_plus (insn, operands);
   }
-  [(set_attr "adjust_len" "plus")])
+  [(set_attr "cc" "clobber")
+   (set_attr "adjust_len" "plus")])
 
 ;; "usadduqq3"  "usadduhq3"  "usadduha3" "usaddusq3"  "usaddusa3"
 ;; "ussubuqq3"  "ussubuhq3"  "ussubuha3" "ussubusq3"  "ussubusa3"
-(define_insn_and_split "<code_stdname><mode>3"
+(define_insn "<code_stdname><mode>3"
   [(set (match_operand:ALL124U 0 "register_operand"                          "=??r,d")
         (us_addsub:ALL124U (match_operand:ALL124U 1 "register_operand" "<abelian>0,0")
                            (match_operand:ALL124U 2 "nonmemory_operand"         "r,Ynn")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (us_addsub:ALL124U (match_dup 1)
-                                      (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<code_stdname><mode>3"
-  [(set (match_operand:ALL124U 0 "register_operand"                          "=??r,d")
-        (us_addsub:ALL124U (match_operand:ALL124U 1 "register_operand" "<abelian>0,0")
-                           (match_operand:ALL124U 2 "nonmemory_operand"         "r,Ynn")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_plus (insn, operands);
   }
-  [(set_attr "adjust_len" "plus")])
+  [(set_attr "cc" "clobber")
+   (set_attr "adjust_len" "plus")])
 
 ;******************************************************************************
 ;** Saturated Negation and Absolute Value
 ;******************************************************************************
 
-;; Fixme: This will always result in 0.  Dunno why simplify-rtx.cc says
+;; Fixme: This will always result in 0.  Dunno why simplify-rtx.c says
 ;;   "unknown" on how to optimize this.  libgcc call would be in order,
 ;;   but the performance is *PLAIN* *HORROR* because the optimizers don't
 ;;   manage to optimize out MEMCPY that's sprincled all over fixed-bit.c  */
@@ -184,41 +134,21 @@
     DONE;
   })
 
-(define_insn_and_split "ssnegqq2"
+(define_insn "ssnegqq2"
   [(set (match_operand:QQ 0 "register_operand"            "=r")
         (ss_neg:QQ (match_operand:QQ 1 "register_operand"  "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ss_neg:QQ (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*ssnegqq2"
-  [(set (match_operand:QQ 0 "register_operand"            "=r")
-        (ss_neg:QQ (match_operand:QQ 1 "register_operand"  "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "neg %0\;brvc 0f\;dec %0\;0:"
-  [(set_attr "length" "3")])
+  [(set_attr "cc" "clobber")
+   (set_attr "length" "3")])
 
-(define_insn_and_split "ssabsqq2"
+(define_insn "ssabsqq2"
   [(set (match_operand:QQ 0 "register_operand"            "=r")
         (ss_abs:QQ (match_operand:QQ 1 "register_operand"  "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ss_abs:QQ (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*ssabsqq2"
-  [(set (match_operand:QQ 0 "register_operand"            "=r")
-        (ss_abs:QQ (match_operand:QQ 1 "register_operand"  "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "sbrc %0,7\;neg %0\;sbrc %0,7\;dec %0"
-  [(set_attr "length" "4")])
+  [(set_attr "cc" "clobber")
+   (set_attr "length" "4")])
 
 ;; "ssneghq2"  "ssnegha2"  "ssnegsq2"  "ssnegsa2"
 ;; "ssabshq2"  "ssabsha2"  "ssabssq2"  "ssabssa2"
@@ -236,43 +166,23 @@
 
 ;; "*ssneghq2"  "*ssnegha2"
 ;; "*ssabshq2"  "*ssabsha2"
-(define_insn_and_split "*<code_stdname><mode>2_split"
+(define_insn "*<code_stdname><mode>2"
   [(set (reg:ALL2S 24)
         (ss_abs_neg:ALL2S (reg:ALL2S 24)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL2S 24)
-                   (ss_abs_neg:ALL2S (reg:ALL2S 24)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<code_stdname><mode>2"
-  [(set (reg:ALL2S 24)
-        (ss_abs_neg:ALL2S (reg:ALL2S 24)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __<code_stdname>_2"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;; "*ssnegsq2"  "*ssnegsa2"
 ;; "*ssabssq2"  "*ssabssa2"
-(define_insn_and_split "*<code_stdname><mode>2_split"
+(define_insn "*<code_stdname><mode>2"
   [(set (reg:ALL4S 22)
         (ss_abs_neg:ALL4S (reg:ALL4S 22)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL4S 22)
-                   (ss_abs_neg:ALL4S (reg:ALL4S 22)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<code_stdname><mode>2"
-  [(set (reg:ALL4S 22)
-        (ss_abs_neg:ALL4S (reg:ALL4S 22)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __<code_stdname>_4"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;******************************************************************************
 ; mul
@@ -290,47 +200,23 @@
     DONE;
   })
 
-(define_insn_and_split "mulqq3_enh"
+(define_insn "mulqq3_enh"
   [(set (match_operand:QQ 0 "register_operand"         "=r")
         (mult:QQ (match_operand:QQ 1 "register_operand" "a")
                  (match_operand:QQ 2 "register_operand" "a")))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (mult:QQ (match_dup 1)
-                            (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*mulqq3_enh"
-  [(set (match_operand:QQ 0 "register_operand"         "=r")
-        (mult:QQ (match_operand:QQ 1 "register_operand" "a")
-                 (match_operand:QQ 2 "register_operand" "a")))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "fmuls %1,%2\;dec r1\;brvs 0f\;inc r1\;0:\;mov %0,r1\;clr __zero_reg__"
-  [(set_attr "length" "6")])
+  [(set_attr "length" "6")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "muluqq3_enh"
+(define_insn "muluqq3_enh"
   [(set (match_operand:UQQ 0 "register_operand"          "=r")
         (mult:UQQ (match_operand:UQQ 1 "register_operand" "r")
                   (match_operand:UQQ 2 "register_operand" "r")))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (mult:UQQ (match_dup 1)
-                             (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*muluqq3_enh"
-  [(set (match_operand:UQQ 0 "register_operand"          "=r")
-        (mult:UQQ (match_operand:UQQ 1 "register_operand" "r")
-                  (match_operand:UQQ 2 "register_operand" "r")))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "mul %1,%2\;mov %0,r1\;clr __zero_reg__"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "clobber")])
 
 (define_expand "mulqq3_nomul"
   [(set (reg:QQ 24)
@@ -369,32 +255,16 @@
     avr_fix_inputs (operands, 1 << 2, regmask (UQQmode, 22));
   })
 
-(define_insn_and_split "*mulqq3.call_split"
+(define_insn "*mulqq3.call"
   [(set (reg:QQ 23)
         (mult:QQ (reg:QQ 24)
                  (reg:QQ 25)))
    (clobber (reg:QI 22))
    (clobber (reg:HI 24))]
   "!AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:QQ 23)
-                   (mult:QQ (reg:QQ 24)
-                            (reg:QQ 25)))
-              (clobber (reg:QI 22))
-              (clobber (reg:HI 24))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*mulqq3.call"
-  [(set (reg:QQ 23)
-        (mult:QQ (reg:QQ 24)
-                 (reg:QQ 25)))
-   (clobber (reg:QI 22))
-   (clobber (reg:HI 24))
-   (clobber (reg:CC REG_CC))]
-  "!AVR_HAVE_MUL && reload_completed"
   "%~call __mulqq3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 
 ;; "mulhq3" "muluhq3"
@@ -418,29 +288,15 @@
 
 ;; "*mulhq3.call"  "*muluhq3.call"
 ;; "*mulha3.call"  "*muluha3.call"
-(define_insn_and_split "*mul<mode>3.call_split"
+(define_insn "*mul<mode>3.call"
   [(set (reg:ALL2QA 24)
         (mult:ALL2QA (reg:ALL2QA 18)
                      (reg:ALL2QA 26)))
    (clobber (reg:HI 22))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL2QA 24)
-                   (mult:ALL2QA (reg:ALL2QA 18)
-                                (reg:ALL2QA 26)))
-              (clobber (reg:HI 22))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*mul<mode>3.call"
-  [(set (reg:ALL2QA 24)
-        (mult:ALL2QA (reg:ALL2QA 18)
-                     (reg:ALL2QA 26)))
-   (clobber (reg:HI 22))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "%~call __mul<mode>3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 
 ;; On the enhanced core, don't clobber either input and use a separate output
@@ -462,26 +318,14 @@
   })
 
 ;; "*mulsa3.call" "*mulusa3.call"
-(define_insn_and_split "*mul<mode>3.call_split"
+(define_insn "*mul<mode>3.call"
   [(set (reg:ALL4A 24)
         (mult:ALL4A (reg:ALL4A 16)
                     (reg:ALL4A 20)))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL4A 24)
-                   (mult:ALL4A (reg:ALL4A 16)
-                               (reg:ALL4A 20)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*mul<mode>3.call"
-  [(set (reg:ALL4A 24)
-        (mult:ALL4A (reg:ALL4A 16)
-                    (reg:ALL4A 20)))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "%~call __mul<mode>3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ; / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / /
 ; div
@@ -507,29 +351,15 @@
 
 
 ;; "*divqq3.call" "*udivuqq3.call"
-(define_insn_and_split "*<code><mode>3.call_split"
+(define_insn "*<code><mode>3.call"
   [(set (reg:ALL1Q 24)
         (usdiv:ALL1Q (reg:ALL1Q 25)
                      (reg:ALL1Q 22)))
    (clobber (reg:QI 25))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL1Q 24)
-                   (usdiv:ALL1Q (reg:ALL1Q 25)
-                                (reg:ALL1Q 22)))
-              (clobber (reg:QI 25))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<code><mode>3.call"
-  [(set (reg:ALL1Q 24)
-        (usdiv:ALL1Q (reg:ALL1Q 25)
-                     (reg:ALL1Q 22)))
-   (clobber (reg:QI 25))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __<code><mode>3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;; "divhq3" "udivuhq3"
 ;; "divha3" "udivuha3"
@@ -552,32 +382,16 @@
 
 ;; "*divhq3.call" "*udivuhq3.call"
 ;; "*divha3.call" "*udivuha3.call"
-(define_insn_and_split "*<code><mode>3.call_split"
+(define_insn "*<code><mode>3.call"
   [(set (reg:ALL2QA 24)
         (usdiv:ALL2QA (reg:ALL2QA 26)
                       (reg:ALL2QA 22)))
    (clobber (reg:HI 26))
    (clobber (reg:QI 21))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL2QA 24)
-                   (usdiv:ALL2QA (reg:ALL2QA 26)
-                                 (reg:ALL2QA 22)))
-              (clobber (reg:HI 26))
-              (clobber (reg:QI 21))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<code><mode>3.call"
-  [(set (reg:ALL2QA 24)
-        (usdiv:ALL2QA (reg:ALL2QA 26)
-                      (reg:ALL2QA 22)))
-   (clobber (reg:HI 26))
-   (clobber (reg:QI 21))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __<code><mode>3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;; Note the first parameter gets passed in already offset by 2 bytes
 
@@ -600,32 +414,16 @@
   })
 
 ;; "*divsa3.call" "*udivusa3.call"
-(define_insn_and_split "*<code><mode>3.call_split"
+(define_insn "*<code><mode>3.call"
   [(set (reg:ALL4A 22)
         (usdiv:ALL4A (reg:ALL4A 24)
                      (reg:ALL4A 18)))
    (clobber (reg:HI 26))
    (clobber (reg:HI 30))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL4A 22)
-                   (usdiv:ALL4A (reg:ALL4A 24)
-                                (reg:ALL4A 18)))
-              (clobber (reg:HI 26))
-              (clobber (reg:HI 30))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<code><mode>3.call"
-  [(set (reg:ALL4A 22)
-        (usdiv:ALL4A (reg:ALL4A 24)
-                     (reg:ALL4A 18)))
-   (clobber (reg:HI 26))
-   (clobber (reg:HI 30))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __<code><mode>3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 
 ;******************************************************************************
@@ -676,109 +474,51 @@
 ;; "roundqq3_const"  "rounduqq3_const"
 ;; "roundhq3_const"  "rounduhq3_const"  "roundha3_const"  "rounduha3_const"
 ;; "roundsq3_const"  "roundusq3_const"  "roundsa3_const"  "roundusa3_const"
-(define_insn_and_split "round<mode>3_const"
+(define_insn "round<mode>3_const"
   [(set (match_operand:ALL124QA 0 "register_operand"                  "=d")
         (unspec:ALL124QA [(match_operand:ALL124QA 1 "register_operand" "0")
                           (match_operand:HI 2 "const_int_operand"      "n")
                           (const_int 0)]
                          UNSPEC_ROUND))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (unspec:ALL124QA [(match_dup 1)
-                                     (match_dup 2)
-                                     (const_int 0)]
-                                    UNSPEC_ROUND))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*round<mode>3_const"
-  [(set (match_operand:ALL124QA 0 "register_operand"                  "=d")
-        (unspec:ALL124QA [(match_operand:ALL124QA 1 "register_operand" "0")
-                          (match_operand:HI 2 "const_int_operand"      "n")
-                          (const_int 0)]
-                         UNSPEC_ROUND))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_round (insn, operands);
   }
-  [(set_attr "adjust_len" "round")])
+  [(set_attr "cc" "clobber")
+   (set_attr "adjust_len" "round")])
 
 
 ;; "*roundqq3.libgcc"  "*rounduqq3.libgcc"
-(define_insn_and_split "*round<mode>3.libgcc_split"
+(define_insn "*round<mode>3.libgcc"
   [(set (reg:ALL1Q 24)
         (unspec:ALL1Q [(reg:ALL1Q 22)
                        (reg:QI 24)] UNSPEC_ROUND))
    (clobber (reg:ALL1Q 22))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL1Q 24)
-                   (unspec:ALL1Q [(reg:ALL1Q 22)
-                                  (reg:QI 24)] UNSPEC_ROUND))
-              (clobber (reg:ALL1Q 22))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*round<mode>3.libgcc"
-  [(set (reg:ALL1Q 24)
-        (unspec:ALL1Q [(reg:ALL1Q 22)
-                       (reg:QI 24)] UNSPEC_ROUND))
-   (clobber (reg:ALL1Q 22))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __round<mode>3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;; "*roundhq3.libgcc"  "*rounduhq3.libgcc"
 ;; "*roundha3.libgcc"  "*rounduha3.libgcc"
-(define_insn_and_split "*round<mode>3.libgcc_split"
+(define_insn "*round<mode>3.libgcc"
   [(set (reg:ALL2QA 24)
         (unspec:ALL2QA [(reg:ALL2QA 22)
                         (reg:QI 24)] UNSPEC_ROUND))
    (clobber (reg:ALL2QA 22))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL2QA 24)
-                   (unspec:ALL2QA [(reg:ALL2QA 22)
-                                   (reg:QI 24)] UNSPEC_ROUND))
-              (clobber (reg:ALL2QA 22))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*round<mode>3.libgcc"
-  [(set (reg:ALL2QA 24)
-        (unspec:ALL2QA [(reg:ALL2QA 22)
-                        (reg:QI 24)] UNSPEC_ROUND))
-   (clobber (reg:ALL2QA 22))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __round<mode>3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;; "*roundsq3.libgcc"  "*roundusq3.libgcc"
 ;; "*roundsa3.libgcc"  "*roundusa3.libgcc"
-(define_insn_and_split "*round<mode>3.libgcc_split"
+(define_insn "*round<mode>3.libgcc"
   [(set (reg:ALL4QA 22)
         (unspec:ALL4QA [(reg:ALL4QA 18)
                         (reg:QI 24)] UNSPEC_ROUND))
    (clobber (reg:ALL4QA 18))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:ALL4QA 22)
-                   (unspec:ALL4QA [(reg:ALL4QA 18)
-                                   (reg:QI 24)] UNSPEC_ROUND))
-              (clobber (reg:ALL4QA 18))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*round<mode>3.libgcc"
-  [(set (reg:ALL4QA 22)
-        (unspec:ALL4QA [(reg:ALL4QA 18)
-                        (reg:QI 24)] UNSPEC_ROUND))
-   (clobber (reg:ALL4QA 18))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __round<mode>3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
diff --git a/gcc-12.1.0/gcc/config/avr/avr-log.c b/gcc-12.1.0/gcc/config/avr/avr-log.c
new file mode 100644
index 00000000000..a4dc0f66ebe
--- /dev/null
+++ b/gcc-12.1.0/gcc/config/avr/avr-log.c
@@ -0,0 +1,325 @@
+/* Subroutines for log output for Atmel AVR back end.
+   Copyright (C) 2011-2021 Free Software Foundation, Inc.
+   Contributed by Georg-Johann Lay (avr@gjlay.de)
+
+   This file is part of GCC.
+
+   GCC is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 3, or (at your option)
+   any later version.
+   
+   GCC is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+   
+   You should have received a copy of the GNU General Public License
+   along with GCC; see the file COPYING3.  If not see
+   <http://www.gnu.org/licenses/>.  */
+
+#define IN_TARGET_CODE 1
+
+#include "config.h"
+#include "system.h"
+#include "coretypes.h"
+#include "tm.h"
+#include "function.h"
+#include "rtl.h"
+#include "tree.h"
+#include "tree-pass.h"	/* for current_pass */
+#include "memmodel.h"
+#include "tm_p.h"
+#include "print-tree.h"
+
+/* This file supplies some functions for AVR back-end developers
+   with a printf-like interface.  The functions are called through
+   macros `avr_dump', `avr_edump' or `avr_fdump' from avr-protos.h:
+
+   avr_fdump (FILE *stream, const char *fmt, ...);
+   avr_edump (fmt, ...) is a shortcut for avr_fdump (stderr, fmt, ...)
+   avr_dump (fmt, ...)  is a shortcut for avr_fdump (dump_file, fmt, ...)
+
+  == known %-codes ==
+
+  b: bool
+  r: rtx
+  t: tree
+  T: tree (brief)
+  C: enum rtx_code
+  m: machine_mode
+  R: enum reg_class
+  L: insn list
+  H: location_t
+
+  == no arguments ==
+
+  A: call abort()
+  f: current_function_name()
+  F: caller (via __FUNCTION__)
+  P: Pass name and number
+  ?: Print caller, current function and pass info
+  !: Ditto, but only print if in a pass with static pass number,
+     else return.
+
+  == same as printf ==
+
+  %: %
+  c: char
+  s: string
+  d: int (decimal)
+  x: int (hex)
+*/
+
+/* Set according to -mlog= option.  */
+avr_log_t avr_log;
+
+/* The worker function implementing the %-codes */
+static void avr_log_vadump (FILE*, const char*, va_list);
+
+/* Wrapper for avr_log_vadump.  If STREAM is NULL we are called by avr_dump,
+   i.e. output to dump_file if available.  The 2nd argument is __FUNCTION__.
+   The 3rd argument is the format string. */
+
+int
+avr_vdump (FILE *stream, const char *caller, ...)
+{
+  va_list ap;
+        
+  if (stream == NULL && dump_file)
+    stream = dump_file;
+
+  va_start (ap, caller);
+  if (stream)
+    avr_log_vadump (stream, caller, ap);
+  va_end (ap);
+
+  return 1;
+}
+
+
+/* Worker function implementing the %-codes and forwarding to
+   respective print/dump function.  */
+
+static void
+avr_log_vadump (FILE *file, const char *caller, va_list ap)
+{
+  char bs[3] = {'\\', '?', '\0'};
+
+  /* 3rd proper argument is always the format string.  */
+  const char *fmt = va_arg (ap, const char*);
+
+  while (*fmt)
+    {
+      switch (*fmt++)
+        {
+        default:
+          fputc (*(fmt-1), file);
+          break;
+
+        case '\\':
+          bs[1] = *fmt++;
+          fputs (bs, file);
+          break;
+
+        case '%':
+          switch (*fmt++)
+            {
+            case '%':
+              fputc ('%', file);
+              break;
+
+            case 't':
+              {
+                tree t = va_arg (ap, tree);
+                if (NULL_TREE == t)
+                  fprintf (file, "<NULL-TREE>");
+                else
+                  {
+                    if (stderr == file)
+                      debug_tree (t);
+                    else
+                      {
+                        print_node (file, "", t, 0);
+                        putc ('\n', file);
+                      }
+                  }
+                break;
+              }
+
+            case 'T':
+              {
+                tree t = va_arg (ap, tree);
+                if (NULL_TREE == t)
+                  fprintf (file, "<NULL-TREE>");
+                else
+                  print_node_brief (file, "", t, 3);
+              }
+              break;
+
+            case 'd':
+              fprintf (file, "%d", va_arg (ap, int));
+              break;
+
+            case 'x':
+              fprintf (file, "%x", va_arg (ap, int));
+              break;
+
+            case 'b':
+              fprintf (file, "%s", va_arg (ap, int) ? "true" : "false");
+              break;
+
+            case 'c':
+              fputc (va_arg (ap, int), file);
+              break;
+
+            case 'r':
+              print_inline_rtx (file, va_arg (ap, rtx), 0);
+              break;
+
+            case 'L':
+              {
+                rtx_insn *insn = safe_as_a <rtx_insn *> (va_arg (ap, rtx));
+
+                while (insn)
+                  {
+                    print_inline_rtx (file, insn, 0);
+                    fprintf (file, "\n");
+                    insn = NEXT_INSN (insn);
+                  }
+                break;
+              }
+
+            case 'f':
+              if (cfun && cfun->decl)
+                fputs (current_function_name(), file);
+              break;
+
+            case 's':
+              {
+                const char *str = va_arg (ap, char*);
+                fputs (str ? str : "(null)", file);
+              }
+              break;
+
+            case 'm':
+              fputs (GET_MODE_NAME ((machine_mode) va_arg (ap, int)),
+                     file);
+              break;
+
+            case 'C':
+              fputs (rtx_name[va_arg (ap, int)], file);
+              break;
+
+            case 'R':
+              fputs (reg_class_names[va_arg (ap, int)], file);
+              break;
+
+            case 'F':
+              fputs (caller, file);
+              break;
+
+            case 'H':
+              {
+                location_t loc = va_arg (ap, location_t);
+
+                if (BUILTINS_LOCATION == loc)
+                  fprintf (file, "<BUILTIN-LOCATION>");
+                else if (UNKNOWN_LOCATION == loc)
+                  fprintf (file, "<UNKNOWN-LOCATION>");
+                else
+                  fprintf (file, "%s:%d",
+                           LOCATION_FILE (loc), LOCATION_LINE (loc));
+
+                break;
+              }
+
+            case '!':
+              if (!current_pass)
+                return;
+              /* FALLTHRU */
+
+            case '?':
+              avr_vdump (file, caller, "%F[%f:%P]");
+              break;
+
+            case 'P':
+              if (current_pass)
+                fprintf (file, "%s(%d)",
+                         current_pass->name,
+                         current_pass->static_pass_number);
+              else
+                fprintf (file, "pass=?");
+
+              break;
+
+            case 'A':
+              fflush (file);
+              abort();
+
+            default:
+              /* Unknown %-code: Stop printing */
+
+              fprintf (file, "??? %%%c ???%s\n", *(fmt-1), fmt);
+              fmt = "";
+
+              break;
+            }
+          break; /* % */
+        }
+    }
+
+  fflush (file);
+}
+
+
+/* Called from avr.c:avr_option_override().
+   Parse argument of -mlog= and set respective fields in avr_log.  */
+
+void
+avr_log_set_avr_log (void)
+{
+  bool all = TARGET_ALL_DEBUG != 0;
+
+  if (all)
+    avr_log_details = "all";
+	
+  if (all || avr_log_details)
+    {
+      /* Adding , at beginning and end of string makes searching easier.  */
+
+      char *str = (char*) alloca (3 + strlen (avr_log_details));
+      bool info;
+
+      str[0] = ',';
+      strcat (stpcpy (str+1, avr_log_details), ",");
+
+      all |= strstr (str, ",all,") != NULL;
+      info = strstr (str, ",?,") != NULL;
+
+      if (info)
+        fprintf (stderr, "\n-mlog=");
+
+#define SET_DUMP_DETAIL(S)                                       \
+      do {                                                       \
+	avr_log.S = (all || strstr (str, "," #S ",") != NULL);   \
+        if (info)                                                \
+          fprintf (stderr, #S ",");                              \
+      } while (0)
+
+      SET_DUMP_DETAIL (address_cost);
+      SET_DUMP_DETAIL (builtin);
+      SET_DUMP_DETAIL (constraints);
+      SET_DUMP_DETAIL (insn_addresses);
+      SET_DUMP_DETAIL (legitimate_address_p);
+      SET_DUMP_DETAIL (legitimize_address);
+      SET_DUMP_DETAIL (legitimize_reload_address);
+      SET_DUMP_DETAIL (progmem);
+      SET_DUMP_DETAIL (rtx_costs);
+
+#undef SET_DUMP_DETAIL
+
+      if (info)
+        fprintf (stderr, "?\n\n");
+    }
+}
diff --git a/gcc-12.1.0/gcc/config/avr/avr-mcus.def b/gcc-12.1.0/gcc/config/avr/avr-mcus.def
index 1e12ab30170..37e4e9b317f 100644
--- a/gcc-12.1.0/gcc/config/avr/avr-mcus.def
+++ b/gcc-12.1.0/gcc/config/avr/avr-mcus.def
@@ -1,5 +1,5 @@
 /* AVR MCUs.
-   Copyright (C) 2009-2022 Free Software Foundation, Inc.
+   Copyright (C) 2009-2021 Free Software Foundation, Inc.
 
    This file is part of GCC.
 
@@ -40,7 +40,7 @@
    where the arguments are the fields of avr_mcu_t:
    
 	NAME	Name of the device as specified by -mmcu=<NAME>.  Also
-		used by DRIVER_SELF_SPECS and gen-avr-mmcu-specs.cc for
+		used by DRIVER_SELF_SPECS and gen-avr-mmcu-specs.c for
 		- the name of the device specific specs file
 		  in -specs=device-specs/spec-<NAME>
 		- the name of the startup file crt<NAME>.o
@@ -207,7 +207,6 @@ AVR_MCU ("atmega323",        ARCH_AVR5, AVR_ISA_NONE, "__AVR_ATmega323__",
 AVR_MCU ("atmega324a",       ARCH_AVR5, AVR_ISA_NONE, "__AVR_ATmega324A__",        0x0100, 0x0, 0x8000, 0)
 AVR_MCU ("atmega324p",       ARCH_AVR5, AVR_ISA_NONE, "__AVR_ATmega324P__",        0x0100, 0x0, 0x8000, 0)
 AVR_MCU ("atmega324pa",      ARCH_AVR5, AVR_ISA_NONE, "__AVR_ATmega324PA__",       0x0100, 0x0, 0x8000, 0)
-AVR_MCU ("atmega324pb",      ARCH_AVR5, AVR_ISA_NONE, "__AVR_ATmega324PB__",       0x0100, 0x0, 0x8000, 0)
 AVR_MCU ("atmega325",        ARCH_AVR5, AVR_ISA_NONE, "__AVR_ATmega325__",         0x0100, 0x0, 0x8000, 0)
 AVR_MCU ("atmega325a",       ARCH_AVR5, AVR_ISA_NONE, "__AVR_ATmega325A__",        0x0100, 0x0, 0x8000, 0)
 AVR_MCU ("atmega325p",       ARCH_AVR5, AVR_ISA_NONE, "__AVR_ATmega325P__",        0x0100, 0x0, 0x8000, 0)
diff --git a/gcc-12.1.0/gcc/config/avr/avr-modes.def b/gcc-12.1.0/gcc/config/avr/avr-modes.def
index 0e7117300b0..9a09317ee63 100644
--- a/gcc-12.1.0/gcc/config/avr/avr-modes.def
+++ b/gcc-12.1.0/gcc/config/avr/avr-modes.def
@@ -1,4 +1,4 @@
-/* Copyright (C) 2012-2022 Free Software Foundation, Inc.
+/* Copyright (C) 2012-2021 Free Software Foundation, Inc.
 
    This file is part of GCC.
 
@@ -20,7 +20,7 @@ FRACTIONAL_INT_MODE (PSI, 24, 3);
 
 /* Make TA and UTA 64 bits wide.
    128 bit wide modes would be insane on a 8-bit machine.
-   This needs special treatment in avr.cc and avr-lib.h.  */
+   This needs special treatment in avr.c and avr-lib.h.  */
 
 ADJUST_BYTESIZE  (TA, 8);
 ADJUST_ALIGNMENT (TA, 1);
diff --git a/gcc-12.1.0/gcc/config/avr/avr-passes.def b/gcc-12.1.0/gcc/config/avr/avr-passes.def
index d8630151090..7c76e435042 100644
--- a/gcc-12.1.0/gcc/config/avr/avr-passes.def
+++ b/gcc-12.1.0/gcc/config/avr/avr-passes.def
@@ -1,5 +1,5 @@
 /* Description of target passes for AVR.
-   Copyright (C) 2016-2022 Free Software Foundation, Inc. */
+   Copyright (C) 2016-2021 Free Software Foundation, Inc. */
 
 /* This file is part of GCC.
 
@@ -24,7 +24,7 @@
 INSERT_PASS_BEFORE (pass_thread_prologue_and_epilogue, 1, avr_pass_pre_proep);
 
 /* This avr-specific pass (re)computes insn notes, in particular REG_DEAD
-   notes which are used by `avr.cc::reg_unused_after' and branch offset
+   notes which are used by `avr.c::reg_unused_after' and branch offset
    computations.  These notes must be correct, i.e. there must be no
    dangling REG_DEAD notes; otherwise wrong code might result, cf. PR64331.
 
diff --git a/gcc-12.1.0/gcc/config/avr/avr-protos.h b/gcc-12.1.0/gcc/config/avr/avr-protos.h
index 6023b33bcfe..999994586aa 100644
--- a/gcc-12.1.0/gcc/config/avr/avr-protos.h
+++ b/gcc-12.1.0/gcc/config/avr/avr-protos.h
@@ -1,6 +1,6 @@
-/* Prototypes for exported functions defined in avr.cc
+/* Prototypes for exported functions defined in avr.c
    
-   Copyright (C) 2000-2022 Free Software Foundation, Inc.
+   Copyright (C) 2000-2021 Free Software Foundation, Inc.
    Contributed by Denis Chertykov (chertykov@gmail.com)
 
    This file is part of GCC.
@@ -161,7 +161,7 @@ extern rtl_opt_pass *make_avr_pass_pre_proep (gcc::context *);
 extern rtl_opt_pass *make_avr_pass_recompute_notes (gcc::context *);
 extern rtl_opt_pass *make_avr_pass_casesi (gcc::context *);
 
-/* From avr-log.cc */
+/* From avr-log.c */
 
 #define avr_dump(...) avr_vdump (NULL, __FUNCTION__, __VA_ARGS__)
 #define avr_edump(...) avr_vdump (stderr, __FUNCTION__, __VA_ARGS__)
diff --git a/gcc-12.1.0/gcc/config/avr/avr-stdint.h b/gcc-12.1.0/gcc/config/avr/avr-stdint.h
index cd26281eb36..2f876e1812c 100644
--- a/gcc-12.1.0/gcc/config/avr/avr-stdint.h
+++ b/gcc-12.1.0/gcc/config/avr/avr-stdint.h
@@ -1,5 +1,5 @@
 /* Definitions for <stdint.h> types on systems using newlib.
-   Copyright (C) 2012-2022 Free Software Foundation, Inc.
+   Copyright (C) 2012-2021 Free Software Foundation, Inc.
 
 This file is part of GCC.
 
diff --git a/gcc-12.1.0/gcc/config/avr/avr.c b/gcc-12.1.0/gcc/config/avr/avr.c
new file mode 100644
index 00000000000..3a250dfb960
--- /dev/null
+++ b/gcc-12.1.0/gcc/config/avr/avr.c
@@ -0,0 +1,14778 @@
+/* Subroutines for insn-output.c for ATMEL AVR micro controllers
+   Copyright (C) 1998-2021 Free Software Foundation, Inc.
+   Contributed by Denis Chertykov (chertykov@gmail.com)
+
+   This file is part of GCC.
+
+   GCC is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 3, or (at your option)
+   any later version.
+   
+   GCC is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+   
+   You should have received a copy of the GNU General Public License
+   along with GCC; see the file COPYING3.  If not see
+   <http://www.gnu.org/licenses/>.  */
+
+#define IN_TARGET_CODE 1
+
+#include "config.h"
+#include "system.h"
+#include "intl.h"
+#include "coretypes.h"
+#include "backend.h"
+#include "target.h"
+#include "rtl.h"
+#include "tree.h"
+#include "stringpool.h"
+#include "attribs.h"
+#include "cgraph.h"
+#include "c-family/c-common.h"
+#include "cfghooks.h"
+#include "df.h"
+#include "memmodel.h"
+#include "tm_p.h"
+#include "optabs.h"
+#include "regs.h"
+#include "emit-rtl.h"
+#include "recog.h"
+#include "conditions.h"
+#include "insn-attr.h"
+#include "reload.h"
+#include "varasm.h"
+#include "calls.h"
+#include "stor-layout.h"
+#include "output.h"
+#include "explow.h"
+#include "expr.h"
+#include "langhooks.h"
+#include "cfgrtl.h"
+#include "builtins.h"
+#include "context.h"
+#include "tree-pass.h"
+#include "print-rtl.h"
+#include "rtl-iter.h"
+
+/* This file should be included last.  */
+#include "target-def.h"
+
+/* Maximal allowed offset for an address in the LD command */
+#define MAX_LD_OFFSET(MODE) (64 - (signed)GET_MODE_SIZE (MODE))
+
+/* Return true if STR starts with PREFIX and false, otherwise.  */
+#define STR_PREFIX_P(STR,PREFIX) (strncmp (STR, PREFIX, strlen (PREFIX)) == 0)
+
+/* The 4 bits starting at SECTION_MACH_DEP are reserved to store the
+   address space where data is to be located.
+   As the only non-generic address spaces are all located in flash,
+   this can be used to test if data shall go into some .progmem* section.
+   This must be the rightmost field of machine dependent section flags.  */
+#define AVR_SECTION_PROGMEM (0xf * SECTION_MACH_DEP)
+
+/* Similar 4-bit region for SYMBOL_REF_FLAGS.  */
+#define AVR_SYMBOL_FLAG_PROGMEM (0xf * SYMBOL_FLAG_MACH_DEP)
+
+/* Similar 4-bit region in SYMBOL_REF_FLAGS:
+   Set address-space AS in SYMBOL_REF_FLAGS of SYM  */
+#define AVR_SYMBOL_SET_ADDR_SPACE(SYM,AS)                       \
+  do {                                                          \
+    SYMBOL_REF_FLAGS (sym) &= ~AVR_SYMBOL_FLAG_PROGMEM;         \
+    SYMBOL_REF_FLAGS (sym) |= (AS) * SYMBOL_FLAG_MACH_DEP;      \
+  } while (0)
+
+/* Read address-space from SYMBOL_REF_FLAGS of SYM  */
+#define AVR_SYMBOL_GET_ADDR_SPACE(SYM)                          \
+  ((SYMBOL_REF_FLAGS (sym) & AVR_SYMBOL_FLAG_PROGMEM)           \
+   / SYMBOL_FLAG_MACH_DEP)
+
+/* (AVR_TINY only): Symbol has attribute progmem */
+#define AVR_SYMBOL_FLAG_TINY_PM \
+  (SYMBOL_FLAG_MACH_DEP << 7)
+
+/* (AVR_TINY only): Symbol has attribute absdata */
+#define AVR_SYMBOL_FLAG_TINY_ABSDATA \
+  (SYMBOL_FLAG_MACH_DEP << 8)
+
+#define TINY_ADIW(REG1, REG2, I)                                \
+    "subi " #REG1 ",lo8(-(" #I "))" CR_TAB                      \
+    "sbci " #REG2 ",hi8(-(" #I "))"
+
+#define TINY_SBIW(REG1, REG2, I)                                \
+    "subi " #REG1 ",lo8((" #I "))" CR_TAB                       \
+    "sbci " #REG2 ",hi8((" #I "))"
+
+#define AVR_TMP_REGNO (AVR_TINY ? TMP_REGNO_TINY : TMP_REGNO)
+#define AVR_ZERO_REGNO (AVR_TINY ? ZERO_REGNO_TINY : ZERO_REGNO)
+
+/* Known address spaces.  The order must be the same as in the respective
+   enum from avr.h (or designated initialized must be used).  */
+const avr_addrspace_t avr_addrspace[ADDR_SPACE_COUNT] =
+{
+  { ADDR_SPACE_RAM,  0, 2, "", 0, NULL },
+  { ADDR_SPACE_FLASH,  1, 2, "__flash",   0, ".progmem.data" },
+  { ADDR_SPACE_FLASH1, 1, 2, "__flash1",  1, ".progmem1.data" },
+  { ADDR_SPACE_FLASH2, 1, 2, "__flash2",  2, ".progmem2.data" },
+  { ADDR_SPACE_FLASH3, 1, 2, "__flash3",  3, ".progmem3.data" },
+  { ADDR_SPACE_FLASH4, 1, 2, "__flash4",  4, ".progmem4.data" },
+  { ADDR_SPACE_FLASH5, 1, 2, "__flash5",  5, ".progmem5.data" },
+  { ADDR_SPACE_MEMX, 1, 3, "__memx",  0, ".progmemx.data" },
+};
+
+
+/* Holding RAM addresses of some SFRs used by the compiler and that
+   are unique over all devices in an architecture like 'avr4'.  */
+
+typedef struct
+{
+  /* SREG: The processor status */
+  int sreg;
+
+  /* RAMPX, RAMPY, RAMPD and CCP of XMEGA */
+  int ccp;
+  int rampd;
+  int rampx;
+  int rampy;
+
+  /* RAMPZ: The high byte of 24-bit address used with ELPM */
+  int rampz;
+
+  /* SP: The stack pointer and its low and high byte */
+  int sp_l;
+  int sp_h;
+} avr_addr_t;
+
+static avr_addr_t avr_addr;
+
+
+/* Prototypes for local helper functions.  */
+
+static const char* out_movqi_r_mr (rtx_insn *, rtx[], int*);
+static const char* out_movhi_r_mr (rtx_insn *, rtx[], int*);
+static const char* out_movsi_r_mr (rtx_insn *, rtx[], int*);
+static const char* out_movqi_mr_r (rtx_insn *, rtx[], int*);
+static const char* out_movhi_mr_r (rtx_insn *, rtx[], int*);
+static const char* out_movsi_mr_r (rtx_insn *, rtx[], int*);
+
+static int get_sequence_length (rtx_insn *insns);
+static int sequent_regs_live (void);
+static const char *ptrreg_to_str (int);
+static const char *cond_string (enum rtx_code);
+static int avr_num_arg_regs (machine_mode, const_tree);
+static int avr_operand_rtx_cost (rtx, machine_mode, enum rtx_code,
+                                 int, bool);
+static void output_reload_in_const (rtx*, rtx, int*, bool);
+static struct machine_function * avr_init_machine_status (void);
+
+
+/* Prototypes for hook implementors if needed before their implementation.  */
+
+static bool avr_rtx_costs (rtx, machine_mode, int, int, int*, bool);
+
+
+/* Allocate registers from r25 to r8 for parameters for function calls.  */
+#define FIRST_CUM_REG 26
+
+/* Last call saved register */
+#define LAST_CALLEE_SAVED_REG (AVR_TINY ? 19 : 17)
+
+/* Implicit target register of LPM instruction (R0) */
+extern GTY(()) rtx lpm_reg_rtx;
+rtx lpm_reg_rtx;
+
+/* (Implicit) address register of LPM instruction (R31:R30 = Z) */
+extern GTY(()) rtx lpm_addr_reg_rtx;
+rtx lpm_addr_reg_rtx;
+
+/* Temporary register RTX (reg:QI TMP_REGNO) */
+extern GTY(()) rtx tmp_reg_rtx;
+rtx tmp_reg_rtx;
+
+/* Zeroed register RTX (reg:QI ZERO_REGNO) */
+extern GTY(()) rtx zero_reg_rtx;
+rtx zero_reg_rtx;
+
+/* RTXs for all general purpose registers as QImode */
+extern GTY(()) rtx all_regs_rtx[32];
+rtx all_regs_rtx[32];
+
+/* SREG, the processor status */
+extern GTY(()) rtx sreg_rtx;
+rtx sreg_rtx;
+
+/* RAMP* special function registers */
+extern GTY(()) rtx rampd_rtx;
+extern GTY(()) rtx rampx_rtx;
+extern GTY(()) rtx rampy_rtx;
+extern GTY(()) rtx rampz_rtx;
+rtx rampd_rtx;
+rtx rampx_rtx;
+rtx rampy_rtx;
+rtx rampz_rtx;
+
+/* RTX containing the strings "" and "e", respectively */
+static GTY(()) rtx xstring_empty;
+static GTY(()) rtx xstring_e;
+
+/* Current architecture.  */
+const avr_arch_t *avr_arch;
+
+/* Unnamed sections associated to __attribute__((progmem)) aka. PROGMEM
+   or to address space __flash* or __memx.  Only used as singletons inside
+   avr_asm_select_section, but it must not be local there because of GTY.  */
+static GTY(()) section *progmem_section[ADDR_SPACE_COUNT];
+
+/* Condition for insns/expanders from avr-dimode.md.  */
+bool avr_have_dimode = true;
+
+/* To track if code will use .bss and/or .data.  */
+bool avr_need_clear_bss_p = false;
+bool avr_need_copy_data_p = false;
+
+
+/* Transform UP into lowercase and write the result to LO.
+   You must provide enough space for LO.  Return LO.  */
+
+static char*
+avr_tolower (char *lo, const char *up)
+{
+  char *lo0 = lo;
+
+  for (; *up; up++, lo++)
+    *lo = TOLOWER (*up);
+
+  *lo = '\0';
+
+  return lo0;
+}
+
+
+/* Constraint helper function.  XVAL is a CONST_INT or a CONST_DOUBLE.
+   Return true if the least significant N_BYTES bytes of XVAL all have a
+   popcount in POP_MASK and false, otherwise.  POP_MASK represents a subset
+   of integers which contains an integer N iff bit N of POP_MASK is set.  */
+
+bool
+avr_popcount_each_byte (rtx xval, int n_bytes, int pop_mask)
+{
+  machine_mode mode = GET_MODE (xval);
+
+  if (VOIDmode == mode)
+    mode = SImode;
+
+  for (int i = 0; i < n_bytes; i++)
+    {
+      rtx xval8 = simplify_gen_subreg (QImode, xval, mode, i);
+      unsigned int val8 = UINTVAL (xval8) & GET_MODE_MASK (QImode);
+
+      if ((pop_mask & (1 << popcount_hwi (val8))) == 0)
+        return false;
+    }
+
+  return true;
+}
+
+
+/* Access some RTX as INT_MODE.  If X is a CONST_FIXED we can get
+   the bit representation of X by "casting" it to CONST_INT.  */
+
+rtx
+avr_to_int_mode (rtx x)
+{
+  machine_mode mode = GET_MODE (x);
+
+  return VOIDmode == mode
+    ? x
+    : simplify_gen_subreg (int_mode_for_mode (mode).require (), x, mode, 0);
+}
+
+namespace {
+
+static const pass_data avr_pass_data_recompute_notes =
+{
+  RTL_PASS,      // type
+  "",            // name (will be patched)
+  OPTGROUP_NONE, // optinfo_flags
+  TV_DF_SCAN,    // tv_id
+  0,             // properties_required
+  0,             // properties_provided
+  0,             // properties_destroyed
+  0,             // todo_flags_start
+  TODO_df_finish | TODO_df_verify // todo_flags_finish
+};
+
+
+class avr_pass_recompute_notes : public rtl_opt_pass
+{
+public:
+  avr_pass_recompute_notes (gcc::context *ctxt, const char *name)
+    : rtl_opt_pass (avr_pass_data_recompute_notes, ctxt)
+  {
+    this->name = name;
+  }
+
+  virtual unsigned int execute (function*)
+  {
+    df_note_add_problem ();
+    df_analyze ();
+
+    return 0;
+  }
+}; // avr_pass_recompute_notes
+
+static const pass_data avr_pass_data_casesi =
+{
+  RTL_PASS,      // type
+  "",            // name (will be patched)
+  OPTGROUP_NONE, // optinfo_flags
+  TV_DF_SCAN,    // tv_id
+  0,             // properties_required
+  0,             // properties_provided
+  0,             // properties_destroyed
+  0,             // todo_flags_start
+  0              // todo_flags_finish
+};
+
+
+class avr_pass_casesi : public rtl_opt_pass
+{
+public:
+  avr_pass_casesi (gcc::context *ctxt, const char *name)
+    : rtl_opt_pass (avr_pass_data_casesi, ctxt)
+  {
+    this->name = name;
+  }
+
+  void avr_rest_of_handle_casesi (function*);
+
+  virtual bool gate (function*) { return optimize > 0; }
+
+  virtual unsigned int execute (function *func)
+  {
+    avr_rest_of_handle_casesi (func);
+
+    return 0;
+  }
+}; // avr_pass_casesi
+
+} // anon namespace
+
+rtl_opt_pass*
+make_avr_pass_recompute_notes (gcc::context *ctxt)
+{
+  return new avr_pass_recompute_notes (ctxt, "avr-notes-free-cfg");
+}
+
+rtl_opt_pass*
+make_avr_pass_casesi (gcc::context *ctxt)
+{
+  return new avr_pass_casesi (ctxt, "avr-casesi");
+}
+
+
+/* Make one parallel insn with all the patterns from insns i[0]..i[5].  */
+
+static rtx_insn*
+avr_parallel_insn_from_insns (rtx_insn *i[6])
+{
+  rtvec vec = gen_rtvec (6, PATTERN (i[0]), PATTERN (i[1]), PATTERN (i[2]),
+                         PATTERN (i[3]), PATTERN (i[4]), PATTERN (i[5]));
+  start_sequence();
+  emit (gen_rtx_PARALLEL (VOIDmode, vec));
+  rtx_insn *insn = get_insns();
+  end_sequence();
+
+  return insn;
+}
+
+
+/* Return true if we see an insn stream generated by casesi expander together
+   with an extension to SImode of the switch value.
+
+   If this is the case, fill in the insns from casesi to INSNS[1..5] and
+   the SImode extension to INSNS[0].  Moreover, extract the operands of
+   pattern casesi_<mode>_sequence forged from the sequence to recog_data.  */
+
+static bool
+avr_is_casesi_sequence (basic_block bb, rtx_insn *insn, rtx_insn *insns[6])
+{
+  rtx set_5, set_0;
+
+  /* A first and quick test for a casesi sequences.  As a side effect of
+     the test, harvest respective insns to INSNS[0..5].  */
+
+  if (!(JUMP_P (insns[5] = insn)
+        // casesi is the only insn that comes up with UNSPEC_INDEX_JMP,
+        // hence the following test ensures that we are actually dealing
+        // with code from casesi.
+        && (set_5 = single_set (insns[5]))
+        && UNSPEC == GET_CODE (SET_SRC (set_5))
+        && UNSPEC_INDEX_JMP == XINT (SET_SRC (set_5), 1)
+
+        && (insns[4] = prev_real_insn (insns[5]))
+        && (insns[3] = prev_real_insn (insns[4]))
+        && (insns[2] = prev_real_insn (insns[3]))
+        && (insns[1] = prev_real_insn (insns[2]))
+
+        // Insn prior to casesi.
+        && (insns[0] = prev_real_insn (insns[1]))
+        && (set_0 = single_set (insns[0]))
+        && extend_operator (SET_SRC (set_0), SImode)))
+    {
+      return false;
+    }
+
+  if (dump_file)
+    {
+      fprintf (dump_file, ";; Sequence from casesi in "
+               "[bb %d]:\n\n", bb->index);
+      for (int i = 0; i < 6; i++)
+        print_rtl_single (dump_file, insns[i]);
+    }
+
+  /* We have to deal with quite some operands.  Extracting them by hand
+     would be tedious, therefore wrap the insn patterns into a parallel,
+     run recog against it and then use insn extract to get the operands. */
+
+  rtx_insn *xinsn = avr_parallel_insn_from_insns (insns);
+
+  INSN_CODE (xinsn) = recog (PATTERN (xinsn), xinsn, NULL /* num_clobbers */);
+
+  /* Failing to recognize means that someone changed the casesi expander or
+     that some passes prior to this one performed some unexpected changes.
+     Gracefully drop such situations instead of aborting.  */
+
+  if (INSN_CODE (xinsn) < 0)
+    {
+      if (dump_file)
+        fprintf (dump_file, ";; Sequence not recognized, giving up.\n\n");
+
+      return false;
+    }
+
+  gcc_assert (CODE_FOR_casesi_qi_sequence == INSN_CODE (xinsn)
+              || CODE_FOR_casesi_hi_sequence == INSN_CODE (xinsn));
+
+  extract_insn (xinsn);
+
+  // Assert on the anatomy of xinsn's operands we are going to work with.
+
+  gcc_assert (recog_data.n_operands == 11);
+  gcc_assert (recog_data.n_dups == 4);
+
+  if (dump_file)
+    {
+      fprintf (dump_file, ";; Operands extracted:\n");
+      for (int i = 0; i < recog_data.n_operands; i++)
+        avr_fdump (dump_file, ";; $%d = %r\n", i, recog_data.operand[i]);
+      fprintf (dump_file, "\n");
+    }
+
+  return true;
+}
+
+
+/* Perform some extra checks on operands of casesi_<mode>_sequence.
+   Not all operand dependencies can be described by means of predicates.
+   This function performs left over checks and should always return true.
+   Returning false means that someone changed the casesi expander but did
+   not adjust casesi_<mode>_sequence.  */
+
+bool
+avr_casei_sequence_check_operands (rtx *xop)
+{
+  rtx sub_5 = NULL_RTX;
+
+  if (AVR_HAVE_EIJMP_EICALL
+      // The last clobber op of the tablejump.
+      && xop[8] == all_regs_rtx[24])
+    {
+      // $6 is: (subreg:SI ($5) 0)
+      sub_5 = xop[6];
+    }
+
+  if (!AVR_HAVE_EIJMP_EICALL
+      // $6 is: (plus:HI (subreg:SI ($5) 0)
+      //                 (label_ref ($3)))
+      && PLUS == GET_CODE (xop[6])
+      && LABEL_REF == GET_CODE (XEXP (xop[6], 1))
+      && rtx_equal_p (xop[3], XEXP (XEXP (xop[6], 1), 0))
+      // The last clobber op of the tablejump.
+      && xop[8] == const0_rtx)
+    {
+      sub_5 = XEXP (xop[6], 0);
+    }
+
+  if (sub_5
+      && SUBREG_P (sub_5)
+      && SUBREG_BYTE (sub_5) == 0
+      && rtx_equal_p (xop[5], SUBREG_REG (sub_5)))
+    return true;
+
+  if (dump_file)
+    fprintf (dump_file, "\n;; Failed condition for casesi_<mode>_sequence\n\n");
+
+  return false;
+}
+
+
+/* INSNS[1..5] is a sequence as generated by casesi and INSNS[0] is an
+   extension of an 8-bit or 16-bit integer to SImode.  XOP contains the
+   operands of INSNS as extracted by insn_extract from pattern
+   casesi_<mode>_sequence:
+
+      $0: SImode reg switch value as result of $9.
+      $1: Negative of smallest index in switch.
+      $2: Number of entries in switch.
+      $3: Label to table.
+      $4: Label if out-of-bounds.
+      $5: $0 + $1.
+      $6: 3-byte PC: subreg:HI ($5) + label_ref ($3)
+          2-byte PC: subreg:HI ($5)
+      $7: HI reg index into table (Z or pseudo)
+      $8: R24 or const0_rtx (to be clobbered)
+      $9: Extension to SImode of an 8-bit or 16-bit integer register $10.
+      $10: QImode or HImode register input of $9.
+
+   Try to optimize this sequence, i.e. use the original HImode / QImode
+   switch value instead of SImode.  */
+
+static void
+avr_optimize_casesi (rtx_insn *insns[6], rtx *xop)
+{
+  // Original mode of the switch value; this is QImode or HImode.
+  machine_mode mode = GET_MODE (xop[10]);
+
+  // How the original switch value was extended to SImode; this is
+  // SIGN_EXTEND or ZERO_EXTEND.
+  enum rtx_code code = GET_CODE (xop[9]);
+
+  // Lower index, upper index (plus one) and range of case calues.
+  HOST_WIDE_INT low_idx = -INTVAL (xop[1]);
+  HOST_WIDE_INT num_idx = INTVAL (xop[2]);
+  HOST_WIDE_INT hig_idx = low_idx + num_idx;
+
+  // Maximum ranges of (un)signed QImode resp. HImode.
+  unsigned umax = QImode == mode ? 0xff : 0xffff;
+  int imax = QImode == mode ? 0x7f : 0x7fff;
+  int imin = -imax - 1;
+
+  // Testing the case range and whether it fits into the range of the
+  // (un)signed mode.  This test should actually always pass because it
+  // makes no sense to have case values outside the mode range.  Notice
+  // that case labels which are unreachable because they are outside the
+  // mode of the switch value (e.g. "case -1" for uint8_t) have already
+  // been thrown away by the middle-end.
+
+  if (SIGN_EXTEND == code
+      && low_idx >= imin
+      && hig_idx <= imax)
+    {
+      // ok
+    }
+  else if (ZERO_EXTEND == code
+           && low_idx >= 0
+           && (unsigned) hig_idx <= umax)
+    {
+      // ok
+    }
+  else
+    {
+      if (dump_file)
+        fprintf (dump_file, ";; Case ranges too big, giving up.\n\n");
+      return;
+    }
+
+  // Do normalization of switch value $10 and out-of-bound check in its
+  // original mode instead of in SImode.  Use a newly created pseudo.
+  // This will replace insns[1..2].
+
+  start_sequence();
+
+  rtx_insn *seq1, *seq2, *last1, *last2;
+
+  rtx reg = copy_to_mode_reg (mode, xop[10]);
+
+  rtx (*gen_add)(rtx,rtx,rtx) = QImode == mode ? gen_addqi3 : gen_addhi3;
+  rtx (*gen_cmp)(rtx,rtx) = QImode == mode ? gen_cmpqi3 : gen_cmphi3;
+
+  emit_insn (gen_add (reg, reg, gen_int_mode (-low_idx, mode)));
+  emit_insn (gen_cmp (reg, gen_int_mode (num_idx, mode)));
+
+  seq1 = get_insns();
+  last1 = get_last_insn();
+  end_sequence();
+
+  emit_insn_before (seq1, insns[1]);
+
+  // After the out-of-bounds test and corresponding branch, use a
+  // 16-bit index.  If QImode is used, extend it to HImode first.
+  // This will replace insns[4].
+
+  start_sequence();
+
+  if (QImode == mode)
+    reg = force_reg (HImode, gen_rtx_fmt_e (code, HImode, reg));
+
+  rtx pat_4 = AVR_3_BYTE_PC
+    ? gen_movhi (xop[7], reg)
+    : gen_addhi3 (xop[7], reg, gen_rtx_LABEL_REF (VOIDmode, xop[3]));
+
+  emit_insn (pat_4);
+
+  seq2 = get_insns();
+  last2 = get_last_insn();
+  end_sequence();
+
+  emit_insn_after (seq2, insns[4]);
+
+  if (dump_file)
+    {
+      fprintf (dump_file, ";; New insns: ");
+
+      for (rtx_insn *insn = seq1; ; insn = NEXT_INSN (insn))
+        {
+          fprintf (dump_file, "%d, ", INSN_UID (insn));
+          if (insn == last1)
+            break;
+        }
+      for (rtx_insn *insn = seq2; ; insn = NEXT_INSN (insn))
+        {
+          fprintf (dump_file, "%d%s", INSN_UID (insn),
+                   insn == last2 ? ".\n\n" : ", ");
+          if (insn == last2)
+            break;
+        }
+
+      fprintf (dump_file, ";; Deleting insns: %d, %d, %d.\n\n",
+               INSN_UID (insns[1]), INSN_UID (insns[2]), INSN_UID (insns[4]));
+    }
+
+  // Pseudodelete the SImode and subreg of SImode insns.  We don't care
+  // about the extension insns[0]: Its result is now unused and other
+  // passes will clean it up.
+
+  SET_INSN_DELETED (insns[1]);
+  SET_INSN_DELETED (insns[2]);
+  SET_INSN_DELETED (insns[4]);
+}
+
+
+void
+avr_pass_casesi::avr_rest_of_handle_casesi (function *func)
+{
+  basic_block bb;
+
+  FOR_EACH_BB_FN (bb, func)
+    {
+      rtx_insn *insn, *insns[6];
+
+      FOR_BB_INSNS (bb, insn)
+        {
+          if (avr_is_casesi_sequence (bb, insn, insns))
+            {
+              avr_optimize_casesi (insns, recog_data.operand);
+            }
+        }
+    }
+}
+
+
+/* Set `avr_arch' as specified by `-mmcu='.
+   Return true on success.  */
+
+static bool
+avr_set_core_architecture (void)
+{
+  /* Search for mcu core architecture.  */
+
+  if (!avr_mmcu)
+    avr_mmcu = AVR_MMCU_DEFAULT;
+
+  avr_arch = &avr_arch_types[0];
+
+  for (const avr_mcu_t *mcu = avr_mcu_types; ; mcu++)
+    {
+      if (mcu->name == NULL)
+        {
+          /* Reached the end of `avr_mcu_types'.  This should actually never
+             happen as options are provided by device-specs.  It could be a
+             typo in a device-specs or calling the compiler proper directly
+             with -mmcu=<device>. */
+
+          error ("unknown core architecture %qs specified with %qs",
+                 avr_mmcu, "-mmcu=");
+          avr_inform_core_architectures ();
+          break;
+        }
+      else if (strcmp (mcu->name, avr_mmcu) == 0
+               // Is this a proper architecture ?
+	       && mcu->macro == NULL)
+        {
+          avr_arch = &avr_arch_types[mcu->arch_id];
+          if (avr_n_flash < 0)
+            avr_n_flash = 1 + (mcu->flash_size - 1) / 0x10000;
+
+          return true;
+        }
+    }
+
+  return false;
+}
+
+
+/* Implement `TARGET_OPTION_OVERRIDE'.  */
+
+static void
+avr_option_override (void)
+{
+  /* caller-save.c looks for call-clobbered hard registers that are assigned
+     to pseudos that cross calls and tries so save-restore them around calls
+     in order to reduce the number of stack slots needed.
+
+     This might lead to situations where reload is no more able to cope
+     with the challenge of AVR's very few address registers and fails to
+     perform the requested spills.  */
+
+  if (avr_strict_X)
+    flag_caller_saves = 0;
+
+  /* Unwind tables currently require a frame pointer for correctness,
+     see toplev.c:process_options().  */
+
+  if ((flag_unwind_tables
+       || flag_non_call_exceptions
+       || flag_asynchronous_unwind_tables)
+      && !ACCUMULATE_OUTGOING_ARGS)
+    {
+      flag_omit_frame_pointer = 0;
+    }
+
+  if (flag_pic == 1)
+    warning (OPT_fpic, "%<-fpic%> is not supported");
+  if (flag_pic == 2)
+    warning (OPT_fPIC, "%<-fPIC%> is not supported");
+  if (flag_pie == 1)
+    warning (OPT_fpie, "%<-fpie%> is not supported");
+  if (flag_pie == 2)
+    warning (OPT_fPIE, "%<-fPIE%> is not supported");
+
+#if !defined (HAVE_AS_AVR_MGCCISR_OPTION)
+  avr_gasisr_prologues = 0;
+#endif
+
+  if (!avr_set_core_architecture())
+    return;
+
+  /* Sould be set by avr-common.c */
+  gcc_assert (avr_long_double >= avr_double && avr_double >= 32);
+
+  /* RAM addresses of some SFRs common to all devices in respective arch. */
+
+  /* SREG: Status Register containing flags like I (global IRQ) */
+  avr_addr.sreg = 0x3F + avr_arch->sfr_offset;
+
+  /* RAMPZ: Address' high part when loading via ELPM */
+  avr_addr.rampz = 0x3B + avr_arch->sfr_offset;
+
+  avr_addr.rampy = 0x3A + avr_arch->sfr_offset;
+  avr_addr.rampx = 0x39 + avr_arch->sfr_offset;
+  avr_addr.rampd = 0x38 + avr_arch->sfr_offset;
+  avr_addr.ccp = (AVR_TINY ? 0x3C : 0x34) + avr_arch->sfr_offset;
+
+  /* SP: Stack Pointer (SP_H:SP_L) */
+  avr_addr.sp_l = 0x3D + avr_arch->sfr_offset;
+  avr_addr.sp_h = avr_addr.sp_l + 1;
+
+  init_machine_status = avr_init_machine_status;
+
+  avr_log_set_avr_log();
+}
+
+/* Function to set up the backend function structure.  */
+
+static struct machine_function *
+avr_init_machine_status (void)
+{
+  return ggc_cleared_alloc<machine_function> ();
+}
+
+
+/* Implement `INIT_EXPANDERS'.  */
+/* The function works like a singleton.  */
+
+void
+avr_init_expanders (void)
+{
+  for (int regno = 0; regno < 32; regno ++)
+    all_regs_rtx[regno] = gen_rtx_REG (QImode, regno);
+
+  lpm_reg_rtx  = all_regs_rtx[LPM_REGNO];
+  tmp_reg_rtx  = all_regs_rtx[AVR_TMP_REGNO];
+  zero_reg_rtx = all_regs_rtx[AVR_ZERO_REGNO];
+
+  lpm_addr_reg_rtx = gen_rtx_REG (HImode, REG_Z);
+
+  sreg_rtx = gen_rtx_MEM (QImode, GEN_INT (avr_addr.sreg));
+  rampd_rtx = gen_rtx_MEM (QImode, GEN_INT (avr_addr.rampd));
+  rampx_rtx = gen_rtx_MEM (QImode, GEN_INT (avr_addr.rampx));
+  rampy_rtx = gen_rtx_MEM (QImode, GEN_INT (avr_addr.rampy));
+  rampz_rtx = gen_rtx_MEM (QImode, GEN_INT (avr_addr.rampz));
+
+  xstring_empty = gen_rtx_CONST_STRING (VOIDmode, "");
+  xstring_e = gen_rtx_CONST_STRING (VOIDmode, "e");
+
+  /* TINY core does not have regs r10-r16, but avr-dimode.md expects them
+     to be present */
+  if (AVR_TINY)
+    avr_have_dimode = false;
+}
+
+
+/* Implement `REGNO_REG_CLASS'.  */
+/* Return register class for register R.  */
+
+enum reg_class
+avr_regno_reg_class (int r)
+{
+  static const enum reg_class reg_class_tab[] =
+    {
+      R0_REG,
+      /* r1 - r15 */
+      NO_LD_REGS, NO_LD_REGS, NO_LD_REGS,
+      NO_LD_REGS, NO_LD_REGS, NO_LD_REGS, NO_LD_REGS,
+      NO_LD_REGS, NO_LD_REGS, NO_LD_REGS, NO_LD_REGS,
+      NO_LD_REGS, NO_LD_REGS, NO_LD_REGS, NO_LD_REGS,
+      /* r16 - r23 */
+      SIMPLE_LD_REGS, SIMPLE_LD_REGS, SIMPLE_LD_REGS, SIMPLE_LD_REGS,
+      SIMPLE_LD_REGS, SIMPLE_LD_REGS, SIMPLE_LD_REGS, SIMPLE_LD_REGS,
+      /* r24, r25 */
+      ADDW_REGS, ADDW_REGS,
+      /* X: r26, 27 */
+      POINTER_X_REGS, POINTER_X_REGS,
+      /* Y: r28, r29 */
+      POINTER_Y_REGS, POINTER_Y_REGS,
+      /* Z: r30, r31 */
+      POINTER_Z_REGS, POINTER_Z_REGS,
+      /* SP: SPL, SPH */
+      STACK_REG, STACK_REG
+    };
+
+  if (r <= 33)
+    return reg_class_tab[r];
+
+  return ALL_REGS;
+}
+
+
+/* Implement `TARGET_SCALAR_MODE_SUPPORTED_P'.  */
+
+static bool
+avr_scalar_mode_supported_p (scalar_mode mode)
+{
+  if (ALL_FIXED_POINT_MODE_P (mode))
+    return true;
+
+  if (PSImode == mode)
+    return true;
+
+  return default_scalar_mode_supported_p (mode);
+}
+
+
+/* Return TRUE if DECL is a VAR_DECL located in flash and FALSE, otherwise.  */
+
+static bool
+avr_decl_flash_p (tree decl)
+{
+  if (TREE_CODE (decl) != VAR_DECL
+      || TREE_TYPE (decl) == error_mark_node)
+    {
+      return false;
+    }
+
+  return !ADDR_SPACE_GENERIC_P (TYPE_ADDR_SPACE (TREE_TYPE (decl)));
+}
+
+
+/* Return TRUE if DECL is a VAR_DECL located in the 24-bit flash
+   address space and FALSE, otherwise.  */
+
+static bool
+avr_decl_memx_p (tree decl)
+{
+  if (TREE_CODE (decl) != VAR_DECL
+      || TREE_TYPE (decl) == error_mark_node)
+    {
+      return false;
+    }
+
+  return (ADDR_SPACE_MEMX == TYPE_ADDR_SPACE (TREE_TYPE (decl)));
+}
+
+
+/* Return TRUE if X is a MEM rtx located in flash and FALSE, otherwise.  */
+
+bool
+avr_mem_flash_p (rtx x)
+{
+  return (MEM_P (x)
+          && !ADDR_SPACE_GENERIC_P (MEM_ADDR_SPACE (x)));
+}
+
+
+/* Return TRUE if X is a MEM rtx located in the 24-bit flash
+   address space and FALSE, otherwise.  */
+
+bool
+avr_mem_memx_p (rtx x)
+{
+  return (MEM_P (x)
+          && ADDR_SPACE_MEMX == MEM_ADDR_SPACE (x));
+}
+
+
+/* A helper for the subsequent function attribute used to dig for
+   attribute 'name' in a FUNCTION_DECL or FUNCTION_TYPE */
+
+static inline int
+avr_lookup_function_attribute1 (const_tree func, const char *name)
+{
+  if (FUNCTION_DECL == TREE_CODE (func))
+    {
+      if (NULL_TREE != lookup_attribute (name, DECL_ATTRIBUTES (func)))
+        {
+          return true;
+        }
+
+      func = TREE_TYPE (func);
+    }
+
+  gcc_assert (TREE_CODE (func) == FUNCTION_TYPE
+              || TREE_CODE (func) == METHOD_TYPE);
+
+  return NULL_TREE != lookup_attribute (name, TYPE_ATTRIBUTES (func));
+}
+
+/* Return nonzero if FUNC is a naked function.  */
+
+static int
+avr_naked_function_p (tree func)
+{
+  return avr_lookup_function_attribute1 (func, "naked");
+}
+
+/* Return nonzero if FUNC is an interrupt function as specified
+   by the "interrupt" attribute.  */
+
+static int
+avr_interrupt_function_p (tree func)
+{
+  return avr_lookup_function_attribute1 (func, "interrupt");
+}
+
+/* Return nonzero if FUNC is a signal function as specified
+   by the "signal" attribute.  */
+
+static int
+avr_signal_function_p (tree func)
+{
+  return avr_lookup_function_attribute1 (func, "signal");
+}
+
+/* Return nonzero if FUNC is an OS_task function.  */
+
+static int
+avr_OS_task_function_p (tree func)
+{
+  return avr_lookup_function_attribute1 (func, "OS_task");
+}
+
+/* Return nonzero if FUNC is an OS_main function.  */
+
+static int
+avr_OS_main_function_p (tree func)
+{
+  return avr_lookup_function_attribute1 (func, "OS_main");
+}
+
+
+/* Return nonzero if FUNC is a no_gccisr function as specified
+   by the "no_gccisr" attribute.  */
+
+static int
+avr_no_gccisr_function_p (tree func)
+{
+  return avr_lookup_function_attribute1 (func, "no_gccisr");
+}
+
+/* Implement `TARGET_SET_CURRENT_FUNCTION'.  */
+/* Sanity cheching for above function attributes.  */
+
+static void
+avr_set_current_function (tree decl)
+{
+  if (decl == NULL_TREE
+      || current_function_decl == NULL_TREE
+      || current_function_decl == error_mark_node
+      || ! cfun->machine
+      || cfun->machine->attributes_checked_p)
+    return;
+
+  location_t loc = DECL_SOURCE_LOCATION (decl);
+
+  cfun->machine->is_naked = avr_naked_function_p (decl);
+  cfun->machine->is_signal = avr_signal_function_p (decl);
+  cfun->machine->is_interrupt = avr_interrupt_function_p (decl);
+  cfun->machine->is_OS_task = avr_OS_task_function_p (decl);
+  cfun->machine->is_OS_main = avr_OS_main_function_p (decl);
+  cfun->machine->is_no_gccisr = avr_no_gccisr_function_p (decl);
+
+  const char *isr = cfun->machine->is_interrupt ? "interrupt" : "signal";
+
+  /* Too much attributes make no sense as they request conflicting features. */
+
+  if (cfun->machine->is_OS_task
+      && (cfun->machine->is_signal || cfun->machine->is_interrupt))
+    error_at (loc, "function attributes %qs and %qs are mutually exclusive",
+              "OS_task", isr);
+
+  if (cfun->machine->is_OS_main
+      && (cfun->machine->is_signal || cfun->machine->is_interrupt))
+    error_at (loc, "function attributes %qs and %qs are mutually exclusive",
+              "OS_main", isr);
+
+  if (cfun->machine->is_interrupt || cfun->machine->is_signal)
+    {
+      tree args = TYPE_ARG_TYPES (TREE_TYPE (decl));
+      tree ret = TREE_TYPE (TREE_TYPE (decl));
+      const char *name;
+
+      name = DECL_ASSEMBLER_NAME_SET_P (decl)
+        ? IDENTIFIER_POINTER (DECL_ASSEMBLER_NAME (decl))
+        : IDENTIFIER_POINTER (DECL_NAME (decl));
+
+      /* Skip a leading '*' that might still prefix the assembler name,
+         e.g. in non-LTO runs.  */
+
+      name = default_strip_name_encoding (name);
+
+      /* Interrupt handlers must be  void __vector (void)  functions.  */
+
+      if (args && TREE_CODE (TREE_VALUE (args)) != VOID_TYPE)
+        error_at (loc, "%qs function cannot have arguments", isr);
+
+      if (TREE_CODE (ret) != VOID_TYPE)
+        error_at (loc, "%qs function cannot return a value", isr);
+
+#if defined WITH_AVRLIBC
+      /* Silently ignore 'signal' if 'interrupt' is present.  AVR-LibC startet
+         using this when it switched from SIGNAL and INTERRUPT to ISR.  */
+
+      if (cfun->machine->is_interrupt)
+        cfun->machine->is_signal = 0;
+
+      /* If the function has the 'signal' or 'interrupt' attribute, ensure
+         that the name of the function is "__vector_NN" so as to catch
+         when the user misspells the vector name.  */
+
+      if (!STR_PREFIX_P (name, "__vector"))
+        warning_at (loc, OPT_Wmisspelled_isr, "%qs appears to be a misspelled "
+                    "%qs handler, missing %<__vector%> prefix", name, isr);
+#endif // AVR-LibC naming conventions
+    }
+
+#if defined WITH_AVRLIBC
+  // Common problem is using "ISR" without first including avr/interrupt.h.
+  const char *name = IDENTIFIER_POINTER (DECL_NAME (decl));
+  name = default_strip_name_encoding (name);
+  if (strcmp ("ISR", name) == 0
+      || strcmp ("INTERRUPT", name) == 0
+      || strcmp ("SIGNAL", name) == 0)
+    {
+      warning_at (loc, OPT_Wmisspelled_isr, "%qs is a reserved identifier"
+                  " in AVR-LibC.  Consider %<#include <avr/interrupt.h>%>"
+                  " before using the %qs macro", name, name);
+    }
+#endif // AVR-LibC naming conventions
+
+  /* Don't print the above diagnostics more than once.  */
+
+  cfun->machine->attributes_checked_p = 1;
+}
+
+
+/* Implement `ACCUMULATE_OUTGOING_ARGS'.  */
+
+int
+avr_accumulate_outgoing_args (void)
+{
+  if (!cfun)
+    return TARGET_ACCUMULATE_OUTGOING_ARGS;
+
+  /* FIXME: For setjmp and in avr_builtin_setjmp_frame_value we don't know
+        what offset is correct.  In some cases it is relative to
+        virtual_outgoing_args_rtx and in others it is relative to
+        virtual_stack_vars_rtx.  For example code see
+            gcc.c-torture/execute/built-in-setjmp.c
+            gcc.c-torture/execute/builtins/sprintf-chk.c   */
+
+  return (TARGET_ACCUMULATE_OUTGOING_ARGS
+          && !(cfun->calls_setjmp
+               || cfun->has_nonlocal_label));
+}
+
+
+/* Report contribution of accumulated outgoing arguments to stack size.  */
+
+static inline int
+avr_outgoing_args_size (void)
+{
+  return (ACCUMULATE_OUTGOING_ARGS
+	  ? (HOST_WIDE_INT) crtl->outgoing_args_size : 0);
+}
+
+
+/* Implement TARGET_STARTING_FRAME_OFFSET.  */
+/* This is the offset from the frame pointer register to the first stack slot
+   that contains a variable living in the frame.  */
+
+static HOST_WIDE_INT
+avr_starting_frame_offset (void)
+{
+  return 1 + avr_outgoing_args_size ();
+}
+
+
+/* Return the number of hard registers to push/pop in the prologue/epilogue
+   of the current function, and optionally store these registers in SET.  */
+
+static int
+avr_regs_to_save (HARD_REG_SET *set)
+{
+  int count;
+  int int_or_sig_p = cfun->machine->is_interrupt || cfun->machine->is_signal;
+
+  if (set)
+    CLEAR_HARD_REG_SET (*set);
+  count = 0;
+
+  /* No need to save any registers if the function never returns or
+     has the "OS_task" or "OS_main" attribute.  */
+
+  if (TREE_THIS_VOLATILE (current_function_decl)
+      || cfun->machine->is_OS_task
+      || cfun->machine->is_OS_main)
+    return 0;
+
+  for (int reg = 0; reg < 32; reg++)
+    {
+      /* Do not push/pop __tmp_reg__, __zero_reg__, as well as
+         any global register variables.  */
+
+      if (fixed_regs[reg])
+        continue;
+
+      if ((int_or_sig_p && !crtl->is_leaf && call_used_or_fixed_reg_p (reg))
+          || (df_regs_ever_live_p (reg)
+              && (int_or_sig_p || !call_used_or_fixed_reg_p (reg))
+              /* Don't record frame pointer registers here.  They are treated
+                 indivitually in prologue.  */
+              && !(frame_pointer_needed
+                   && (reg == REG_Y || reg == REG_Y + 1))))
+        {
+          if (set)
+            SET_HARD_REG_BIT (*set, reg);
+          count++;
+        }
+    }
+  return count;
+}
+
+
+/* Implement `TARGET_ALLOCATE_STACK_SLOTS_FOR_ARGS' */
+
+static bool
+avr_allocate_stack_slots_for_args (void)
+{
+  return !cfun->machine->is_naked;
+}
+
+
+/* Return true if register FROM can be eliminated via register TO.  */
+
+static bool
+avr_can_eliminate (const int from ATTRIBUTE_UNUSED, const int to)
+{
+  return ((frame_pointer_needed && to == FRAME_POINTER_REGNUM)
+          || !frame_pointer_needed);
+}
+
+
+/* Implement `TARGET_WARN_FUNC_RETURN'.  */
+
+static bool
+avr_warn_func_return (tree decl)
+{
+  /* Naked functions are implemented entirely in assembly, including the
+     return sequence, so suppress warnings about this.  */
+
+  return !avr_naked_function_p (decl);
+}
+
+/* Compute offset between arg_pointer and frame_pointer.  */
+
+int
+avr_initial_elimination_offset (int from, int to)
+{
+  if (from == FRAME_POINTER_REGNUM && to == STACK_POINTER_REGNUM)
+    return 0;
+  else
+    {
+      int offset = frame_pointer_needed ? 2 : 0;
+      int avr_pc_size = AVR_HAVE_EIJMP_EICALL ? 3 : 2;
+
+      // If FROM is ARG_POINTER_REGNUM, we are not in an ISR as ISRs
+      // might not have arguments.  Hence the following is not affected
+      // by gasisr prologues.
+      offset += avr_regs_to_save (NULL);
+      return (get_frame_size () + avr_outgoing_args_size()
+              + avr_pc_size + 1 + offset);
+    }
+}
+
+
+/* Helper for the function below.  */
+
+static void
+avr_adjust_type_node (tree *node, machine_mode mode, int sat_p)
+{
+  *node = make_node (FIXED_POINT_TYPE);
+  TYPE_SATURATING (*node) = sat_p;
+  TYPE_UNSIGNED (*node) = UNSIGNED_FIXED_POINT_MODE_P (mode);
+  TYPE_IBIT (*node) = GET_MODE_IBIT (mode);
+  TYPE_FBIT (*node) = GET_MODE_FBIT (mode);
+  TYPE_PRECISION (*node) = GET_MODE_BITSIZE (mode);
+  SET_TYPE_ALIGN (*node, 8);
+  SET_TYPE_MODE (*node, mode);
+
+  layout_type (*node);
+}
+
+
+/* Implement `TARGET_BUILD_BUILTIN_VA_LIST'.  */
+
+static tree
+avr_build_builtin_va_list (void)
+{
+  /* avr-modes.def adjusts [U]TA to be 64-bit modes with 48 fractional bits.
+     This is more appropriate for the 8-bit machine AVR than 128-bit modes.
+     The ADJUST_IBIT/FBIT are handled in toplev:init_adjust_machine_modes()
+     which is auto-generated by genmodes, but the compiler assigns [U]DAmode
+     to the long long accum modes instead of the desired [U]TAmode.
+
+     Fix this now, right after node setup in tree.c:build_common_tree_nodes().
+     This must run before c-cppbuiltin.c:builtin_define_fixed_point_constants()
+     which built-in defines macros like __ULLACCUM_FBIT__ that are used by
+     libgcc to detect IBIT and FBIT.  */
+
+  avr_adjust_type_node (&ta_type_node, TAmode, 0);
+  avr_adjust_type_node (&uta_type_node, UTAmode, 0);
+  avr_adjust_type_node (&sat_ta_type_node, TAmode, 1);
+  avr_adjust_type_node (&sat_uta_type_node, UTAmode, 1);
+
+  unsigned_long_long_accum_type_node = uta_type_node;
+  long_long_accum_type_node = ta_type_node;
+  sat_unsigned_long_long_accum_type_node = sat_uta_type_node;
+  sat_long_long_accum_type_node = sat_ta_type_node;
+
+  /* Dispatch to the default handler.  */
+
+  return std_build_builtin_va_list ();
+}
+
+
+/* Return contents of MEM at frame pointer + stack size + 1 (+2 if 3-byte PC).
+   This is return address of function.  */
+
+rtx
+avr_return_addr_rtx (int count, rtx tem)
+{
+  rtx r;
+
+  /* Can only return this function's return address. Others not supported.  */
+  if (count)
+    return NULL;
+
+  if (AVR_3_BYTE_PC)
+    {
+      r = gen_rtx_SYMBOL_REF (Pmode, ".L__stack_usage+2");
+      warning (0, "%<builtin_return_address%> contains only 2 bytes"
+               " of address");
+    }
+  else
+    r = gen_rtx_SYMBOL_REF (Pmode, ".L__stack_usage+1");
+
+  cfun->machine->use_L__stack_usage = 1;
+
+  r = gen_rtx_PLUS (Pmode, tem, r);
+  r = gen_frame_mem (Pmode, memory_address (Pmode, r));
+  r = gen_rtx_ROTATE (HImode, r, GEN_INT (8));
+  return r;
+}
+
+/* Return 1 if the function epilogue is just a single "ret".  */
+
+int
+avr_simple_epilogue (void)
+{
+  return (! frame_pointer_needed
+          && get_frame_size () == 0
+          && avr_outgoing_args_size() == 0
+          && avr_regs_to_save (NULL) == 0
+          && ! cfun->machine->is_interrupt
+          && ! cfun->machine->is_signal
+          && ! cfun->machine->is_naked
+          && ! TREE_THIS_VOLATILE (current_function_decl));
+}
+
+/* This function checks sequence of live registers.  */
+
+static int
+sequent_regs_live (void)
+{
+  int live_seq = 0;
+  int cur_seq = 0;
+
+  for (int reg = 0; reg <= LAST_CALLEE_SAVED_REG; ++reg)
+    {
+      if (fixed_regs[reg])
+        {
+          /* Don't recognize sequences that contain global register
+             variables.  */
+
+          if (live_seq != 0)
+            return 0;
+          else
+            continue;
+        }
+
+      if (!call_used_or_fixed_reg_p (reg))
+        {
+          if (df_regs_ever_live_p (reg))
+            {
+              ++live_seq;
+              ++cur_seq;
+            }
+          else
+            cur_seq = 0;
+        }
+    }
+
+  if (!frame_pointer_needed)
+    {
+      if (df_regs_ever_live_p (REG_Y))
+        {
+          ++live_seq;
+          ++cur_seq;
+        }
+      else
+        cur_seq = 0;
+
+      if (df_regs_ever_live_p (REG_Y + 1))
+        {
+          ++live_seq;
+          ++cur_seq;
+        }
+      else
+        cur_seq = 0;
+    }
+  else
+    {
+      cur_seq += 2;
+      live_seq += 2;
+    }
+  return (cur_seq == live_seq) ? live_seq : 0;
+}
+
+namespace {
+static const pass_data avr_pass_data_pre_proep =
+{
+  RTL_PASS,      // type
+  "",            // name (will be patched)
+  OPTGROUP_NONE, // optinfo_flags
+  TV_DF_SCAN,    // tv_id
+  0,             // properties_required
+  0,             // properties_provided
+  0,             // properties_destroyed
+  0,             // todo_flags_start
+  0              // todo_flags_finish
+};
+
+
+class avr_pass_pre_proep : public rtl_opt_pass
+{
+public:
+  avr_pass_pre_proep (gcc::context *ctxt, const char *name)
+    : rtl_opt_pass (avr_pass_data_pre_proep, ctxt)
+  {
+    this->name = name;
+  }
+
+  void compute_maybe_gasisr (function*);
+
+  virtual unsigned int execute (function *fun)
+  {
+    if (avr_gasisr_prologues
+        // Whether this function is an ISR worth scanning at all.
+        && !fun->machine->is_no_gccisr
+        && (fun->machine->is_interrupt
+            || fun->machine->is_signal)
+        && !cfun->machine->is_naked
+        // Paranoia: Non-local gotos and labels that might escape.
+        && !cfun->calls_setjmp
+        && !cfun->has_nonlocal_label
+        && !cfun->has_forced_label_in_static)
+      {
+        compute_maybe_gasisr (fun);
+      }
+
+    return 0;
+  }
+
+}; // avr_pass_pre_proep
+
+} // anon namespace
+
+rtl_opt_pass*
+make_avr_pass_pre_proep (gcc::context *ctxt)
+{
+  return new avr_pass_pre_proep (ctxt, "avr-pre-proep");
+}
+
+
+/* Set fun->machine->gasisr.maybe provided we don't find anything that
+   prohibits GAS generating parts of ISR prologues / epilogues for us.  */
+
+void
+avr_pass_pre_proep::compute_maybe_gasisr (function *fun)
+{
+  // Don't use BB iterators so that we see JUMP_TABLE_DATA.
+
+  for (rtx_insn *insn = get_insns (); insn; insn = NEXT_INSN (insn))
+    {
+      // Transparent calls always use [R]CALL and are filtered out by GAS.
+      // ISRs don't use -mcall-prologues, hence what remains to be filtered
+      // out are open coded (tail) calls.
+
+      if (CALL_P (insn))
+        return;
+
+      // __tablejump2__ clobbers something and is targeted by JMP so
+      // that GAS won't see its usage.
+
+      if (AVR_HAVE_JMP_CALL
+          && JUMP_TABLE_DATA_P (insn))
+        return;
+
+      // Non-local gotos not seen in *FUN.
+
+      if (JUMP_P (insn)
+          && find_reg_note (insn, REG_NON_LOCAL_GOTO, NULL_RTX))
+        return;
+    }
+
+  fun->machine->gasisr.maybe = 1;
+}
+
+
+/* Obtain the length sequence of insns.  */
+
+int
+get_sequence_length (rtx_insn *insns)
+{
+  int length = 0;
+
+  for (rtx_insn *insn = insns; insn; insn = NEXT_INSN (insn))
+    length += get_attr_length (insn);
+
+  return length;
+}
+
+
+/*  Implement `INCOMING_RETURN_ADDR_RTX'.  */
+
+rtx
+avr_incoming_return_addr_rtx (void)
+{
+  /* The return address is at the top of the stack.  Note that the push
+     was via post-decrement, which means the actual address is off by one.  */
+  return gen_frame_mem (HImode, plus_constant (Pmode, stack_pointer_rtx, 1));
+}
+
+
+/* Unset a bit in *SET.  If successful, return the respective bit number.
+   Otherwise, return -1 and *SET is unaltered.  */
+
+static int
+avr_hregs_split_reg (HARD_REG_SET *set)
+{
+  for (int regno = 0; regno < 32; regno++)
+    if (TEST_HARD_REG_BIT (*set, regno))
+      {
+        // Don't remove a register from *SET which might indicate that
+        // some RAMP* register might need ISR prologue / epilogue treatment.
+
+        if (AVR_HAVE_RAMPX
+            && (REG_X == regno || REG_X + 1 == regno)
+            && TEST_HARD_REG_BIT (*set, REG_X)
+            && TEST_HARD_REG_BIT (*set, REG_X + 1))
+          continue;
+
+        if (AVR_HAVE_RAMPY
+            && !frame_pointer_needed
+            && (REG_Y == regno || REG_Y + 1 == regno)
+            && TEST_HARD_REG_BIT (*set, REG_Y)
+            && TEST_HARD_REG_BIT (*set, REG_Y + 1))
+          continue;
+
+        if (AVR_HAVE_RAMPZ
+            && (REG_Z == regno || REG_Z + 1 == regno)
+            && TEST_HARD_REG_BIT (*set, REG_Z)
+            && TEST_HARD_REG_BIT (*set, REG_Z + 1))
+          continue;
+            
+        CLEAR_HARD_REG_BIT (*set, regno);
+        return regno;
+      }
+
+  return -1;
+}
+
+
+/*  Helper for expand_prologue.  Emit a push of a byte register.  */
+
+static void
+emit_push_byte (unsigned regno, bool frame_related_p)
+{
+  rtx mem, reg;
+  rtx_insn *insn;
+
+  mem = gen_rtx_POST_DEC (HImode, stack_pointer_rtx);
+  mem = gen_frame_mem (QImode, mem);
+  reg = gen_rtx_REG (QImode, regno);
+
+  insn = emit_insn (gen_rtx_SET (mem, reg));
+  if (frame_related_p)
+    RTX_FRAME_RELATED_P (insn) = 1;
+
+  cfun->machine->stack_usage++;
+}
+
+
+/*  Helper for expand_prologue.  Emit a push of a SFR via register TREG.
+    SFR is a MEM representing the memory location of the SFR.
+    If CLR_P then clear the SFR after the push using zero_reg.  */
+
+static void
+emit_push_sfr (rtx sfr, bool frame_related_p, bool clr_p, int treg)
+{
+  rtx_insn *insn;
+
+  gcc_assert (MEM_P (sfr));
+
+  /* IN treg, IO(SFR) */
+  insn = emit_move_insn (all_regs_rtx[treg], sfr);
+  if (frame_related_p)
+    RTX_FRAME_RELATED_P (insn) = 1;
+
+  /* PUSH treg */
+  emit_push_byte (treg, frame_related_p);
+
+  if (clr_p)
+    {
+      /* OUT IO(SFR), __zero_reg__ */
+      insn = emit_move_insn (sfr, const0_rtx);
+      if (frame_related_p)
+        RTX_FRAME_RELATED_P (insn) = 1;
+    }
+}
+
+static void
+avr_prologue_setup_frame (HOST_WIDE_INT size, HARD_REG_SET set)
+{
+  rtx_insn *insn;
+  bool isr_p = cfun->machine->is_interrupt || cfun->machine->is_signal;
+  int live_seq = sequent_regs_live ();
+
+  HOST_WIDE_INT size_max
+    = (HOST_WIDE_INT) GET_MODE_MASK (AVR_HAVE_8BIT_SP ? QImode : Pmode);
+
+  bool minimize = (TARGET_CALL_PROLOGUES
+                   && size < size_max
+                   && live_seq
+                   && !isr_p
+                   && !cfun->machine->is_OS_task
+                   && !cfun->machine->is_OS_main
+                   && !AVR_TINY);
+
+  if (minimize
+      && (frame_pointer_needed
+          || avr_outgoing_args_size() > 8
+          || (AVR_2_BYTE_PC && live_seq > 6)
+          || live_seq > 7))
+    {
+      rtx pattern;
+      int first_reg, reg, offset;
+
+      emit_move_insn (gen_rtx_REG (HImode, REG_X),
+                      gen_int_mode (size, HImode));
+
+      pattern = gen_call_prologue_saves (gen_int_mode (live_seq, HImode),
+                                         gen_int_mode (live_seq+size, HImode));
+      insn = emit_insn (pattern);
+      RTX_FRAME_RELATED_P (insn) = 1;
+
+      /* Describe the effect of the unspec_volatile call to prologue_saves.
+         Note that this formulation assumes that add_reg_note pushes the
+         notes to the front.  Thus we build them in the reverse order of
+         how we want dwarf2out to process them.  */
+
+      /* The function does always set frame_pointer_rtx, but whether that
+         is going to be permanent in the function is frame_pointer_needed.  */
+
+      add_reg_note (insn, REG_CFA_ADJUST_CFA,
+                    gen_rtx_SET ((frame_pointer_needed
+				  ? frame_pointer_rtx
+				  : stack_pointer_rtx),
+                                 plus_constant (Pmode, stack_pointer_rtx,
+                                                -(size + live_seq))));
+
+      /* Note that live_seq always contains r28+r29, but the other
+         registers to be saved are all below 18.  */
+
+      first_reg = (LAST_CALLEE_SAVED_REG + 1) - (live_seq - 2);
+
+      for (reg = 29, offset = -live_seq + 1;
+           reg >= first_reg;
+           reg = (reg == 28 ? LAST_CALLEE_SAVED_REG : reg - 1), ++offset)
+        {
+          rtx m, r;
+
+          m = gen_rtx_MEM (QImode, plus_constant (Pmode, stack_pointer_rtx,
+                                                  offset));
+          r = gen_rtx_REG (QImode, reg);
+          add_reg_note (insn, REG_CFA_OFFSET, gen_rtx_SET (m, r));
+        }
+
+      cfun->machine->stack_usage += size + live_seq;
+    }
+  else /* !minimize */
+    {
+      for (int reg = 0; reg < 32; ++reg)
+        if (TEST_HARD_REG_BIT (set, reg))
+          emit_push_byte (reg, true);
+
+      if (frame_pointer_needed
+          && (!(cfun->machine->is_OS_task || cfun->machine->is_OS_main)))
+        {
+          /* Push frame pointer.  Always be consistent about the
+             ordering of pushes -- epilogue_restores expects the
+             register pair to be pushed low byte first.  */
+
+          emit_push_byte (REG_Y, true);
+          emit_push_byte (REG_Y + 1, true);
+        }
+
+      if (frame_pointer_needed
+          && size == 0)
+        {
+          insn = emit_move_insn (frame_pointer_rtx, stack_pointer_rtx);
+          RTX_FRAME_RELATED_P (insn) = 1;
+        }
+
+      if (size != 0)
+        {
+          /*  Creating a frame can be done by direct manipulation of the
+              stack or via the frame pointer. These two methods are:
+                  fp =  sp
+                  fp -= size
+                  sp =  fp
+              or
+                  sp -= size
+                  fp =  sp    (*)
+              the optimum method depends on function type, stack and
+              frame size.  To avoid a complex logic, both methods are
+              tested and shortest is selected.
+
+              There is also the case where SIZE != 0 and no frame pointer is
+              needed; this can occur if ACCUMULATE_OUTGOING_ARGS is on.
+              In that case, insn (*) is not needed in that case.
+              We use the X register as scratch. This is save because in X
+              is call-clobbered.
+                 In an interrupt routine, the case of SIZE != 0 together with
+              !frame_pointer_needed can only occur if the function is not a
+              leaf function and thus X has already been saved.  */
+
+          int irq_state = -1;
+          HOST_WIDE_INT size_cfa = size, neg_size;
+          rtx_insn *fp_plus_insns;
+          rtx fp, my_fp;
+
+          gcc_assert (frame_pointer_needed
+                      || !isr_p
+                      || !crtl->is_leaf);
+
+          fp = my_fp = (frame_pointer_needed
+                        ? frame_pointer_rtx
+                        : gen_rtx_REG (Pmode, REG_X));
+
+          if (AVR_HAVE_8BIT_SP)
+            {
+              /* The high byte (r29) does not change:
+                 Prefer SUBI (1 cycle) over SBIW (2 cycles, same size).  */
+
+              my_fp = all_regs_rtx[FRAME_POINTER_REGNUM];
+            }
+
+          /* Cut down size and avoid size = 0 so that we don't run
+             into ICE like PR52488 in the remainder.  */
+
+          if (size > size_max)
+            {
+              /* Don't error so that insane code from newlib still compiles
+                 and does not break building newlib.  As PR51345 is implemented
+                 now, there are multilib variants with -msp8.
+
+                 If user wants sanity checks he can use -Wstack-usage=
+                 or similar options.
+
+                 For CFA we emit the original, non-saturated size so that
+                 the generic machinery is aware of the real stack usage and
+                 will print the above diagnostic as expected.  */
+
+              size = size_max;
+            }
+
+          size = trunc_int_for_mode (size, GET_MODE (my_fp));
+          neg_size = trunc_int_for_mode (-size, GET_MODE (my_fp));
+
+          /************  Method 1: Adjust frame pointer  ************/
+
+          start_sequence ();
+
+          /* Normally, the dwarf2out frame-related-expr interpreter does
+             not expect to have the CFA change once the frame pointer is
+             set up.  Thus, we avoid marking the move insn below and
+             instead indicate that the entire operation is complete after
+             the frame pointer subtraction is done.  */
+
+          insn = emit_move_insn (fp, stack_pointer_rtx);
+          if (frame_pointer_needed)
+            {
+              RTX_FRAME_RELATED_P (insn) = 1;
+              add_reg_note (insn, REG_CFA_ADJUST_CFA,
+                            gen_rtx_SET (fp, stack_pointer_rtx));
+            }
+
+          insn = emit_move_insn (my_fp, plus_constant (GET_MODE (my_fp),
+                                                       my_fp, neg_size));
+
+          if (frame_pointer_needed)
+            {
+              RTX_FRAME_RELATED_P (insn) = 1;
+              add_reg_note (insn, REG_CFA_ADJUST_CFA,
+                            gen_rtx_SET (fp, plus_constant (Pmode, fp,
+							    -size_cfa)));
+            }
+
+          /* Copy to stack pointer.  Note that since we've already
+             changed the CFA to the frame pointer this operation
+             need not be annotated if frame pointer is needed.
+             Always move through unspec, see PR50063.
+             For meaning of irq_state see movhi_sp_r insn.  */
+
+          if (cfun->machine->is_interrupt)
+            irq_state = 1;
+
+          if (TARGET_NO_INTERRUPTS
+              || cfun->machine->is_signal
+              || cfun->machine->is_OS_main)
+            irq_state = 0;
+
+          if (AVR_HAVE_8BIT_SP)
+            irq_state = 2;
+
+          insn = emit_insn (gen_movhi_sp_r (stack_pointer_rtx,
+                                            fp, GEN_INT (irq_state)));
+          if (!frame_pointer_needed)
+            {
+              RTX_FRAME_RELATED_P (insn) = 1;
+              add_reg_note (insn, REG_CFA_ADJUST_CFA,
+                            gen_rtx_SET (stack_pointer_rtx,
+                                         plus_constant (Pmode,
+                                                        stack_pointer_rtx,
+                                                        -size_cfa)));
+            }
+
+          fp_plus_insns = get_insns ();
+          end_sequence ();
+
+          /************  Method 2: Adjust Stack pointer  ************/
+
+          /* Stack adjustment by means of RCALL . and/or PUSH __TMP_REG__
+             can only handle specific offsets.  */
+
+          int n_rcall = size / (AVR_3_BYTE_PC ? 3 : 2);
+
+          if (avr_sp_immediate_operand (gen_int_mode (-size, HImode), HImode)
+              // Don't use more than 3 RCALLs.
+              && n_rcall <= 3)
+            {
+              rtx_insn *sp_plus_insns;
+
+              start_sequence ();
+
+              insn = emit_move_insn (stack_pointer_rtx,
+                                     plus_constant (Pmode, stack_pointer_rtx,
+                                                    -size));
+              RTX_FRAME_RELATED_P (insn) = 1;
+              add_reg_note (insn, REG_CFA_ADJUST_CFA,
+                            gen_rtx_SET (stack_pointer_rtx,
+                                         plus_constant (Pmode,
+                                                        stack_pointer_rtx,
+                                                        -size_cfa)));
+              if (frame_pointer_needed)
+                {
+                  insn = emit_move_insn (fp, stack_pointer_rtx);
+                  RTX_FRAME_RELATED_P (insn) = 1;
+                }
+
+              sp_plus_insns = get_insns ();
+              end_sequence ();
+
+              /************ Use shortest method  ************/
+
+              emit_insn (get_sequence_length (sp_plus_insns)
+                         < get_sequence_length (fp_plus_insns)
+                         ? sp_plus_insns
+                         : fp_plus_insns);
+            }
+          else
+            {
+              emit_insn (fp_plus_insns);
+            }
+
+          cfun->machine->stack_usage += size_cfa;
+        } /* !minimize && size != 0 */
+    } /* !minimize */
+}
+
+
+/*  Output function prologue.  */
+
+void
+avr_expand_prologue (void)
+{
+  HARD_REG_SET set;
+  HOST_WIDE_INT size;
+
+  size = get_frame_size() + avr_outgoing_args_size();
+
+  cfun->machine->stack_usage = 0;
+
+  /* Prologue: naked.  */
+  if (cfun->machine->is_naked)
+    {
+      return;
+    }
+
+  avr_regs_to_save (&set);
+
+  if (cfun->machine->is_interrupt || cfun->machine->is_signal)
+    {
+      int treg = AVR_TMP_REGNO;
+      /* Enable interrupts.  */
+      if (cfun->machine->is_interrupt)
+        emit_insn (gen_enable_interrupt ());
+
+      if (cfun->machine->gasisr.maybe)
+        {
+          /* Let GAS PR21472 emit prologue preamble for us which handles SREG,
+             ZERO_REG and TMP_REG and one additional, optional register for
+             us in an optimal way.  This even scans through inline asm.  */
+
+          cfun->machine->gasisr.yes = 1;
+
+          // The optional reg or TMP_REG if we don't need one.  If we need one,
+          // remove that reg from SET so that it's not puhed / popped twice.
+          // We also use it below instead of TMP_REG in some places.
+
+          treg = avr_hregs_split_reg (&set);
+          if (treg < 0)
+            treg = AVR_TMP_REGNO;
+          cfun->machine->gasisr.regno = treg;
+
+          // The worst case of pushes.  The exact number can be inferred
+          // at assembly time by magic expression __gcc_isr.n_pushed.
+          cfun->machine->stack_usage += 3 + (treg != AVR_TMP_REGNO);
+
+          // Emit a Prologue chunk.  Epilogue chunk(s) might follow.
+          // The final Done chunk is emit by final postscan.
+          emit_insn (gen_gasisr (GEN_INT (GASISR_Prologue), GEN_INT (treg)));
+        }
+      else // !TARGET_GASISR_PROLOGUES: Classic, dumb prologue preamble.
+        {
+          /* Push zero reg.  */
+          emit_push_byte (AVR_ZERO_REGNO, true);
+
+          /* Push tmp reg.  */
+          emit_push_byte (AVR_TMP_REGNO, true);
+
+          /* Push SREG.  */
+          /* ??? There's no dwarf2 column reserved for SREG.  */
+          emit_push_sfr (sreg_rtx, false, false /* clr */, AVR_TMP_REGNO);
+
+          /* Clear zero reg.  */
+          emit_move_insn (zero_reg_rtx, const0_rtx);
+
+          /* Prevent any attempt to delete the setting of ZERO_REG!  */
+          emit_use (zero_reg_rtx);
+        }
+
+      /* Push and clear RAMPD/X/Y/Z if present and low-part register is used.
+         ??? There are no dwarf2 columns reserved for RAMPD/X/Y/Z.  */
+
+      if (AVR_HAVE_RAMPD)
+        emit_push_sfr (rampd_rtx, false /* frame */, true /* clr */, treg);
+
+      if (AVR_HAVE_RAMPX
+          && TEST_HARD_REG_BIT (set, REG_X)
+          && TEST_HARD_REG_BIT (set, REG_X + 1))
+        {
+          emit_push_sfr (rampx_rtx, false /* frame */, true /* clr */, treg);
+        }
+
+      if (AVR_HAVE_RAMPY
+          && (frame_pointer_needed
+              || (TEST_HARD_REG_BIT (set, REG_Y)
+                  && TEST_HARD_REG_BIT (set, REG_Y + 1))))
+        {
+          emit_push_sfr (rampy_rtx, false /* frame */, true /* clr */, treg);
+        }
+
+      if (AVR_HAVE_RAMPZ
+          && TEST_HARD_REG_BIT (set, REG_Z)
+          && TEST_HARD_REG_BIT (set, REG_Z + 1))
+        {
+          emit_push_sfr (rampz_rtx, false /* frame */, AVR_HAVE_RAMPD, treg);
+        }
+    }  /* is_interrupt is_signal */
+
+  avr_prologue_setup_frame (size, set);
+
+  if (flag_stack_usage_info)
+    current_function_static_stack_size
+      = cfun->machine->stack_usage + INCOMING_FRAME_SP_OFFSET;
+}
+
+
+/* Implement `TARGET_ASM_FUNCTION_END_PROLOGUE'.  */
+/* Output summary at end of function prologue.  */
+
+static void
+avr_asm_function_end_prologue (FILE *file)
+{
+  if (cfun->machine->is_naked)
+    {
+      fputs ("/* prologue: naked */\n", file);
+    }
+  else
+    {
+      if (cfun->machine->is_interrupt)
+        {
+          fputs ("/* prologue: Interrupt */\n", file);
+        }
+      else if (cfun->machine->is_signal)
+        {
+          fputs ("/* prologue: Signal */\n", file);
+        }
+      else
+        fputs ("/* prologue: function */\n", file);
+    }
+
+  if (ACCUMULATE_OUTGOING_ARGS)
+    fprintf (file, "/* outgoing args size = %d */\n",
+             avr_outgoing_args_size());
+
+  fprintf (file, "/* frame size = " HOST_WIDE_INT_PRINT_DEC " */\n",
+           (HOST_WIDE_INT) get_frame_size());
+
+  if (!cfun->machine->gasisr.yes)
+    {
+      fprintf (file, "/* stack size = %d */\n", cfun->machine->stack_usage);
+      // Create symbol stack offset so all functions have it. Add 1 to stack
+      // usage for offset so that SP + .L__stack_offset = return address.
+      fprintf (file, ".L__stack_usage = %d\n", cfun->machine->stack_usage);
+    }
+  else
+    {
+      int used_by_gasisr = 3 + (cfun->machine->gasisr.regno != AVR_TMP_REGNO);
+      int to = cfun->machine->stack_usage;
+      int from = to - used_by_gasisr;
+      // Number of pushed regs is only known at assembly-time.
+      fprintf (file, "/* stack size = %d...%d */\n", from , to);
+      fprintf (file, ".L__stack_usage = %d + __gcc_isr.n_pushed\n", from);
+    }
+}
+
+
+/* Implement `EPILOGUE_USES'.  */
+
+int
+avr_epilogue_uses (int regno ATTRIBUTE_UNUSED)
+{
+  if (reload_completed
+      && cfun->machine
+      && (cfun->machine->is_interrupt || cfun->machine->is_signal))
+    return 1;
+  return 0;
+}
+
+/*  Helper for avr_expand_epilogue.  Emit a pop of a byte register.  */
+
+static void
+emit_pop_byte (unsigned regno)
+{
+  rtx mem, reg;
+
+  mem = gen_rtx_PRE_INC (HImode, stack_pointer_rtx);
+  mem = gen_frame_mem (QImode, mem);
+  reg = gen_rtx_REG (QImode, regno);
+
+  emit_insn (gen_rtx_SET (reg, mem));
+}
+
+/*  Output RTL epilogue.  */
+
+void
+avr_expand_epilogue (bool sibcall_p)
+{
+  int live_seq;
+  HARD_REG_SET set;
+  int minimize;
+  HOST_WIDE_INT size;
+  bool isr_p = cfun->machine->is_interrupt || cfun->machine->is_signal;
+
+  size = get_frame_size() + avr_outgoing_args_size();
+
+  /* epilogue: naked  */
+  if (cfun->machine->is_naked)
+    {
+      gcc_assert (!sibcall_p);
+
+      emit_jump_insn (gen_return ());
+      return;
+    }
+
+  avr_regs_to_save (&set);
+  live_seq = sequent_regs_live ();
+
+  minimize = (TARGET_CALL_PROLOGUES
+              && live_seq
+              && !isr_p
+              && !cfun->machine->is_OS_task
+              && !cfun->machine->is_OS_main
+              && !AVR_TINY);
+
+  if (minimize
+      && (live_seq > 4
+          || frame_pointer_needed
+          || size))
+    {
+      /*  Get rid of frame.  */
+
+      if (!frame_pointer_needed)
+        {
+          emit_move_insn (frame_pointer_rtx, stack_pointer_rtx);
+        }
+
+      if (size)
+        {
+          emit_move_insn (frame_pointer_rtx,
+                          plus_constant (Pmode, frame_pointer_rtx, size));
+        }
+
+      emit_insn (gen_epilogue_restores (gen_int_mode (live_seq, HImode)));
+      return;
+    }
+
+  if (size)
+    {
+      /* Try two methods to adjust stack and select shortest.  */
+
+      int irq_state = -1;
+      rtx fp, my_fp;
+      rtx_insn *fp_plus_insns;
+      HOST_WIDE_INT size_max;
+
+      gcc_assert (frame_pointer_needed
+                  || !isr_p
+                  || !crtl->is_leaf);
+
+      fp = my_fp = (frame_pointer_needed
+                    ? frame_pointer_rtx
+                    : gen_rtx_REG (Pmode, REG_X));
+
+      if (AVR_HAVE_8BIT_SP)
+        {
+          /* The high byte (r29) does not change:
+             Prefer SUBI (1 cycle) over SBIW (2 cycles).  */
+
+          my_fp = all_regs_rtx[FRAME_POINTER_REGNUM];
+        }
+
+      /* For rationale see comment in prologue generation.  */
+
+      size_max = (HOST_WIDE_INT) GET_MODE_MASK (GET_MODE (my_fp));
+      if (size > size_max)
+        size = size_max;
+      size = trunc_int_for_mode (size, GET_MODE (my_fp));
+
+      /********** Method 1: Adjust fp register  **********/
+
+      start_sequence ();
+
+      if (!frame_pointer_needed)
+        emit_move_insn (fp, stack_pointer_rtx);
+
+      emit_move_insn (my_fp, plus_constant (GET_MODE (my_fp), my_fp, size));
+
+      /* Copy to stack pointer.  */
+
+      if (TARGET_NO_INTERRUPTS)
+        irq_state = 0;
+
+      if (AVR_HAVE_8BIT_SP)
+        irq_state = 2;
+
+      emit_insn (gen_movhi_sp_r (stack_pointer_rtx, fp,
+                                 GEN_INT (irq_state)));
+
+      fp_plus_insns = get_insns ();
+      end_sequence ();
+
+      /********** Method 2: Adjust Stack pointer  **********/
+
+      if (avr_sp_immediate_operand (gen_int_mode (size, HImode), HImode))
+        {
+          rtx_insn *sp_plus_insns;
+
+          start_sequence ();
+
+          emit_move_insn (stack_pointer_rtx,
+                          plus_constant (Pmode, stack_pointer_rtx, size));
+
+          sp_plus_insns = get_insns ();
+          end_sequence ();
+
+          /************ Use shortest method  ************/
+
+          emit_insn (get_sequence_length (sp_plus_insns)
+                     < get_sequence_length (fp_plus_insns)
+                     ? sp_plus_insns
+                     : fp_plus_insns);
+        }
+      else
+        emit_insn (fp_plus_insns);
+    } /* size != 0 */
+
+  if (frame_pointer_needed
+      && !(cfun->machine->is_OS_task || cfun->machine->is_OS_main))
+    {
+      /* Restore previous frame_pointer.  See avr_expand_prologue for
+         rationale for not using pophi.  */
+
+      emit_pop_byte (REG_Y + 1);
+      emit_pop_byte (REG_Y);
+    }
+
+  /* Restore used registers.  */
+
+  int treg = AVR_TMP_REGNO;
+
+  if (isr_p
+      && cfun->machine->gasisr.yes)
+    {
+      treg = cfun->machine->gasisr.regno;
+      CLEAR_HARD_REG_BIT (set, treg);
+    }
+
+  for (int reg = 31; reg >= 0; --reg)
+    if (TEST_HARD_REG_BIT (set, reg))
+      emit_pop_byte (reg);
+
+  if (isr_p)
+    {
+      /* Restore RAMPZ/Y/X/D using tmp_reg as scratch.
+         The conditions to restore them must be tha same as in prologue.  */
+
+      if (AVR_HAVE_RAMPZ
+          && TEST_HARD_REG_BIT (set, REG_Z)
+          && TEST_HARD_REG_BIT (set, REG_Z + 1))
+        {
+          emit_pop_byte (treg);
+          emit_move_insn (rampz_rtx, all_regs_rtx[treg]);
+        }
+
+      if (AVR_HAVE_RAMPY
+          && (frame_pointer_needed
+              || (TEST_HARD_REG_BIT (set, REG_Y)
+                  && TEST_HARD_REG_BIT (set, REG_Y + 1))))
+        {
+          emit_pop_byte (treg);
+          emit_move_insn (rampy_rtx, all_regs_rtx[treg]);
+        }
+
+      if (AVR_HAVE_RAMPX
+          && TEST_HARD_REG_BIT (set, REG_X)
+          && TEST_HARD_REG_BIT (set, REG_X + 1))
+        {
+          emit_pop_byte (treg);
+          emit_move_insn (rampx_rtx, all_regs_rtx[treg]);
+        }
+
+      if (AVR_HAVE_RAMPD)
+        {
+          emit_pop_byte (treg);
+          emit_move_insn (rampd_rtx, all_regs_rtx[treg]);
+        }
+
+      if (cfun->machine->gasisr.yes)
+        {
+          // Emit an Epilogue chunk.
+          emit_insn (gen_gasisr (GEN_INT (GASISR_Epilogue),
+                                 GEN_INT (cfun->machine->gasisr.regno)));
+        }
+      else // !TARGET_GASISR_PROLOGUES
+        {
+          /* Restore SREG using tmp_reg as scratch.  */
+
+          emit_pop_byte (AVR_TMP_REGNO);
+          emit_move_insn (sreg_rtx, tmp_reg_rtx);
+
+          /* Restore tmp REG.  */
+          emit_pop_byte (AVR_TMP_REGNO);
+
+          /* Restore zero REG.  */
+          emit_pop_byte (AVR_ZERO_REGNO);
+        }
+    }
+
+  if (!sibcall_p)
+    emit_jump_insn (gen_return ());
+}
+
+
+/* Implement `TARGET_ASM_FUNCTION_BEGIN_EPILOGUE'.  */
+
+static void
+avr_asm_function_begin_epilogue (FILE *file)
+{
+  app_disable();
+  fprintf (file, "/* epilogue start */\n");
+}
+
+
+/* Implement `TARGET_CANNOT_MODITY_JUMPS_P'.  */
+
+static bool
+avr_cannot_modify_jumps_p (void)
+{
+  /* Naked Functions must not have any instructions after
+     their epilogue, see PR42240 */
+
+  if (reload_completed
+      && cfun->machine
+      && cfun->machine->is_naked)
+    {
+      return true;
+    }
+
+  return false;
+}
+
+
+/* Implement `TARGET_MODE_DEPENDENT_ADDRESS_P'.  */
+
+static bool
+avr_mode_dependent_address_p (const_rtx addr ATTRIBUTE_UNUSED, addr_space_t as)
+{
+  /* FIXME:  Non-generic addresses are not mode-dependent in themselves.
+       This hook just serves to hack around PR rtl-optimization/52543 by
+       claiming that non-generic addresses were mode-dependent so that
+       lower-subreg.c will skip these addresses.  lower-subreg.c sets up fake
+       RTXes to probe SET and MEM costs and assumes that MEM is always in the
+       generic address space which is not true.  */
+
+  return !ADDR_SPACE_GENERIC_P (as);
+}
+
+
+/* Return true if rtx X is a CONST_INT, CONST or SYMBOL_REF
+   address with the `absdata' variable attribute, i.e. respective
+   data can be read / written by LDS / STS instruction.
+   This is used only for AVR_TINY.  */
+
+static bool
+avr_address_tiny_absdata_p (rtx x, machine_mode mode)
+{
+  if (CONST == GET_CODE (x))
+    x = XEXP (XEXP (x, 0), 0);
+
+  if (SYMBOL_REF_P (x))
+    return SYMBOL_REF_FLAGS (x) & AVR_SYMBOL_FLAG_TINY_ABSDATA;
+
+  if (CONST_INT_P (x)
+      && IN_RANGE (INTVAL (x), 0, 0xc0 - GET_MODE_SIZE (mode)))
+    return true;
+
+  return false;
+}
+
+
+/* Helper function for `avr_legitimate_address_p'.  */
+
+static inline bool
+avr_reg_ok_for_addr_p (rtx reg, addr_space_t as,
+                       RTX_CODE outer_code, bool strict)
+{
+  return (REG_P (reg)
+          && (avr_regno_mode_code_ok_for_base_p (REGNO (reg), QImode,
+                                                 as, outer_code, UNKNOWN)
+              || (!strict
+                  && REGNO (reg) >= FIRST_PSEUDO_REGISTER)));
+}
+
+
+/* Return nonzero if X (an RTX) is a legitimate memory address on the target
+   machine for a memory operand of mode MODE.  */
+
+static bool
+avr_legitimate_address_p (machine_mode mode, rtx x, bool strict)
+{
+  bool ok = CONSTANT_ADDRESS_P (x);
+
+  switch (GET_CODE (x))
+    {
+    case REG:
+      ok = avr_reg_ok_for_addr_p (x, ADDR_SPACE_GENERIC,
+                                  MEM, strict);
+
+      if (strict
+          && GET_MODE_SIZE (mode) > 4
+          && REG_X == REGNO (x))
+        {
+          ok = false;
+        }
+      break;
+
+    case POST_INC:
+    case PRE_DEC:
+      ok = avr_reg_ok_for_addr_p (XEXP (x, 0), ADDR_SPACE_GENERIC,
+                                  GET_CODE (x), strict);
+      break;
+
+    case PLUS:
+      {
+        rtx reg = XEXP (x, 0);
+        rtx op1 = XEXP (x, 1);
+
+        if (REG_P (reg)
+            && CONST_INT_P (op1)
+            && INTVAL (op1) >= 0)
+          {
+            bool fit = IN_RANGE (INTVAL (op1), 0, MAX_LD_OFFSET (mode));
+
+            if (fit)
+              {
+                ok = (! strict
+                      || avr_reg_ok_for_addr_p (reg, ADDR_SPACE_GENERIC,
+                                                PLUS, strict));
+
+                if (reg == frame_pointer_rtx
+                    || reg == arg_pointer_rtx)
+                  {
+                    ok = true;
+                  }
+              }
+            else if (frame_pointer_needed
+                     && reg == frame_pointer_rtx)
+              {
+                ok = true;
+              }
+          }
+      }
+      break;
+
+    default:
+      break;
+    }
+
+  if (AVR_TINY
+      && CONSTANT_ADDRESS_P (x))
+    {
+      /* avrtiny's load / store instructions only cover addresses 0..0xbf:
+         IN / OUT range is 0..0x3f and LDS / STS can access 0x40..0xbf.  */
+
+      ok = avr_address_tiny_absdata_p (x, mode);
+    }
+
+  if (avr_log.legitimate_address_p)
+    {
+      avr_edump ("\n%?: ret=%d, mode=%m strict=%d "
+                 "reload_completed=%d reload_in_progress=%d %s:",
+                 ok, mode, strict, reload_completed, reload_in_progress,
+                 reg_renumber ? "(reg_renumber)" : "");
+
+      if (GET_CODE (x) == PLUS
+          && REG_P (XEXP (x, 0))
+          && CONST_INT_P (XEXP (x, 1))
+          && IN_RANGE (INTVAL (XEXP (x, 1)), 0, MAX_LD_OFFSET (mode))
+          && reg_renumber)
+        {
+          avr_edump ("(r%d ---> r%d)", REGNO (XEXP (x, 0)),
+                     true_regnum (XEXP (x, 0)));
+        }
+
+      avr_edump ("\n%r\n", x);
+    }
+
+  return ok;
+}
+
+
+/* Former implementation of TARGET_LEGITIMIZE_ADDRESS,
+   now only a helper for avr_addr_space_legitimize_address.  */
+/* Attempts to replace X with a valid
+   memory address for an operand of mode MODE  */
+
+static rtx
+avr_legitimize_address (rtx x, rtx oldx, machine_mode mode)
+{
+  bool big_offset_p = false;
+
+  x = oldx;
+
+  if (AVR_TINY)
+    {
+      if (CONSTANT_ADDRESS_P (x)
+          && ! avr_address_tiny_absdata_p (x, mode))
+        {
+          x = force_reg (Pmode, x);
+        }
+    }
+
+  if (GET_CODE (oldx) == PLUS
+      && REG_P (XEXP (oldx, 0)))
+    {
+      if (REG_P (XEXP (oldx, 1)))
+        x = force_reg (GET_MODE (oldx), oldx);
+      else if (CONST_INT_P (XEXP (oldx, 1)))
+        {
+          int offs = INTVAL (XEXP (oldx, 1));
+          if (frame_pointer_rtx != XEXP (oldx, 0)
+              && offs > MAX_LD_OFFSET (mode))
+            {
+              big_offset_p = true;
+              x = force_reg (GET_MODE (oldx), oldx);
+            }
+        }
+    }
+
+  if (avr_log.legitimize_address)
+    {
+      avr_edump ("\n%?: mode=%m\n %r\n", mode, oldx);
+
+      if (x != oldx)
+        avr_edump (" %s --> %r\n", big_offset_p ? "(big offset)" : "", x);
+    }
+
+  return x;
+}
+
+
+/* Implement `LEGITIMIZE_RELOAD_ADDRESS'.  */
+/* This will allow register R26/27 to be used where it is no worse than normal
+   base pointers R28/29 or R30/31.  For example, if base offset is greater
+   than 63 bytes or for R++ or --R addressing.  */
+
+rtx
+avr_legitimize_reload_address (rtx *px, machine_mode mode,
+                               int opnum, int type, int addr_type,
+                               int ind_levels ATTRIBUTE_UNUSED,
+                               rtx (*mk_memloc)(rtx,int))
+{
+  rtx x = *px;
+
+  if (avr_log.legitimize_reload_address)
+    avr_edump ("\n%?:%m %r\n", mode, x);
+
+  if (1 && (GET_CODE (x) == POST_INC
+            || GET_CODE (x) == PRE_DEC))
+    {
+      push_reload (XEXP (x, 0), XEXP (x, 0), &XEXP (x, 0), &XEXP (x, 0),
+                   POINTER_REGS, GET_MODE (x), GET_MODE (x), 0, 0,
+                   opnum, RELOAD_OTHER);
+
+      if (avr_log.legitimize_reload_address)
+        avr_edump (" RCLASS.1 = %R\n IN = %r\n OUT = %r\n",
+                   POINTER_REGS, XEXP (x, 0), XEXP (x, 0));
+
+      return x;
+    }
+
+  if (GET_CODE (x) == PLUS
+      && REG_P (XEXP (x, 0))
+      && reg_equiv_constant (REGNO (XEXP (x, 0))) == 0
+      && CONST_INT_P (XEXP (x, 1))
+      && INTVAL (XEXP (x, 1)) >= 1)
+    {
+      bool fit = INTVAL (XEXP (x, 1)) <= MAX_LD_OFFSET (mode);
+
+      if (fit)
+        {
+          if (reg_equiv_address (REGNO (XEXP (x, 0))) != 0)
+            {
+              int regno = REGNO (XEXP (x, 0));
+              rtx mem = mk_memloc (x, regno);
+
+              push_reload (XEXP (mem, 0), NULL_RTX, &XEXP (mem, 0), NULL,
+                           POINTER_REGS, Pmode, VOIDmode, 0, 0,
+                           1, (enum reload_type) addr_type);
+
+              if (avr_log.legitimize_reload_address)
+                avr_edump (" RCLASS.2 = %R\n IN = %r\n OUT = %r\n",
+                           POINTER_REGS, XEXP (mem, 0), NULL_RTX);
+
+              push_reload (mem, NULL_RTX, &XEXP (x, 0), NULL,
+                           BASE_POINTER_REGS, GET_MODE (x), VOIDmode, 0, 0,
+                           opnum, (enum reload_type) type);
+
+              if (avr_log.legitimize_reload_address)
+                avr_edump (" RCLASS.2 = %R\n IN = %r\n OUT = %r\n",
+                           BASE_POINTER_REGS, mem, NULL_RTX);
+
+              return x;
+            }
+        }
+      else if (! (frame_pointer_needed
+                  && XEXP (x, 0) == frame_pointer_rtx))
+        {
+          push_reload (x, NULL_RTX, px, NULL,
+                       POINTER_REGS, GET_MODE (x), VOIDmode, 0, 0,
+                       opnum, (enum reload_type) type);
+
+          if (avr_log.legitimize_reload_address)
+            avr_edump (" RCLASS.3 = %R\n IN = %r\n OUT = %r\n",
+                       POINTER_REGS, x, NULL_RTX);
+
+          return x;
+        }
+    }
+
+  return NULL_RTX;
+}
+
+
+/* Helper function to print assembler resp. track instruction
+   sequence lengths.  Always return "".
+
+   If PLEN == NULL:
+       Output assembler code from template TPL with operands supplied
+       by OPERANDS.  This is just forwarding to output_asm_insn.
+
+   If PLEN != NULL:
+       If N_WORDS >= 0  Add N_WORDS to *PLEN.
+       If N_WORDS < 0   Set *PLEN to -N_WORDS.
+       Don't output anything.
+*/
+
+static const char*
+avr_asm_len (const char* tpl, rtx* operands, int* plen, int n_words)
+{
+  if (plen == NULL)
+    output_asm_insn (tpl, operands);
+  else
+    {
+      if (n_words < 0)
+        *plen = -n_words;
+      else
+        *plen += n_words;
+    }
+
+  return "";
+}
+
+
+/* Return a pointer register name as a string.  */
+
+static const char*
+ptrreg_to_str (int regno)
+{
+  switch (regno)
+    {
+    case REG_X: return "X";
+    case REG_Y: return "Y";
+    case REG_Z: return "Z";
+    default:
+      output_operand_lossage ("address operand requires constraint for"
+                              " X, Y, or Z register");
+    }
+  return NULL;
+}
+
+/* Return the condition name as a string.
+   Used in conditional jump constructing  */
+
+static const char*
+cond_string (enum rtx_code code)
+{
+  switch (code)
+    {
+    case NE:
+      return "ne";
+    case EQ:
+      return "eq";
+    case GE:
+      if (cc_prev_status.flags & CC_OVERFLOW_UNUSABLE)
+        return "pl";
+      else
+        return "ge";
+    case LT:
+      if (cc_prev_status.flags & CC_OVERFLOW_UNUSABLE)
+        return "mi";
+      else
+        return "lt";
+    case GEU:
+      return "sh";
+    case LTU:
+      return "lo";
+    default:
+      gcc_unreachable ();
+    }
+
+  return "";
+}
+
+
+/* Return true if rtx X is a CONST or SYMBOL_REF with progmem.
+   This must be used for AVR_TINY only because on other cores
+   the flash memory is not visible in the RAM address range and
+   cannot be read by, say,  LD instruction.  */
+
+static bool
+avr_address_tiny_pm_p (rtx x)
+{
+  if (CONST == GET_CODE (x))
+    x = XEXP (XEXP (x, 0), 0);
+
+  if (SYMBOL_REF_P (x))
+    return SYMBOL_REF_FLAGS (x) & AVR_SYMBOL_FLAG_TINY_PM;
+
+  return false;
+}
+
+/* Implement `TARGET_PRINT_OPERAND_ADDRESS'.  */
+/* Output ADDR to FILE as address.  */
+
+static void
+avr_print_operand_address (FILE *file, machine_mode /*mode*/, rtx addr)
+{
+  if (AVR_TINY
+      && avr_address_tiny_pm_p (addr))
+    {
+      addr = plus_constant (Pmode, addr, avr_arch->flash_pm_offset);
+    }
+
+  switch (GET_CODE (addr))
+    {
+    case REG:
+      fprintf (file, "%s", ptrreg_to_str (REGNO (addr)));
+      break;
+
+    case PRE_DEC:
+      fprintf (file, "-%s", ptrreg_to_str (REGNO (XEXP (addr, 0))));
+      break;
+
+    case POST_INC:
+      fprintf (file, "%s+", ptrreg_to_str (REGNO (XEXP (addr, 0))));
+      break;
+
+    default:
+      if (CONSTANT_ADDRESS_P (addr)
+          && text_segment_operand (addr, VOIDmode))
+        {
+          rtx x = addr;
+          if (GET_CODE (x) == CONST)
+            x = XEXP (x, 0);
+          if (GET_CODE (x) == PLUS && CONST_INT_P (XEXP (x, 1)))
+            {
+              /* Assembler gs() will implant word address.  Make offset
+                 a byte offset inside gs() for assembler.  This is
+                 needed because the more logical (constant+gs(sym)) is not
+                 accepted by gas.  For 128K and smaller devices this is ok.
+                 For large devices it will create a trampoline to offset
+                 from symbol which may not be what the user really wanted.  */
+
+              fprintf (file, "gs(");
+              output_addr_const (file, XEXP (x, 0));
+              fprintf (file, "+" HOST_WIDE_INT_PRINT_DEC ")",
+                       2 * INTVAL (XEXP (x, 1)));
+              if (AVR_3_BYTE_PC)
+                if (warning (0, "pointer offset from symbol maybe incorrect"))
+                  {
+                    output_addr_const (stderr, addr);
+                    fprintf (stderr, "\n");
+                  }
+            }
+          else
+            {
+              fprintf (file, "gs(");
+              output_addr_const (file, addr);
+              fprintf (file, ")");
+            }
+        }
+      else
+        output_addr_const (file, addr);
+    }
+}
+
+
+/* Implement `TARGET_PRINT_OPERAND_PUNCT_VALID_P'.  */
+
+static bool
+avr_print_operand_punct_valid_p (unsigned char code)
+{
+  return code == '~' || code == '!';
+}
+
+
+/* Implement `TARGET_PRINT_OPERAND'.  */
+/* Output X as assembler operand to file FILE.
+   For a description of supported %-codes, see top of avr.md.  */
+
+static void
+avr_print_operand (FILE *file, rtx x, int code)
+{
+  int abcd = 0, ef = 0, ij = 0;
+
+  if (code >= 'A' && code <= 'D')
+    abcd = code - 'A';
+  else if (code == 'E' || code == 'F')
+    ef = code - 'E';
+  else if (code == 'I' || code == 'J')
+    ij = code - 'I';
+
+  if (code == '~')
+    {
+      if (!AVR_HAVE_JMP_CALL)
+        fputc ('r', file);
+    }
+  else if (code == '!')
+    {
+      if (AVR_HAVE_EIJMP_EICALL)
+        fputc ('e', file);
+    }
+  else if (code == 't'
+           || code == 'T')
+    {
+      static int t_regno = -1;
+      static int t_nbits = -1;
+
+      if (REG_P (x) && t_regno < 0 && code == 'T')
+        {
+          t_regno = REGNO (x);
+          t_nbits = GET_MODE_BITSIZE (GET_MODE (x));
+        }
+      else if (CONST_INT_P (x) && t_regno >= 0
+               && IN_RANGE (INTVAL (x), 0, t_nbits - 1))
+        {
+          int bpos = INTVAL (x);
+
+          fprintf (file, "%s", reg_names[t_regno + bpos / 8]);
+          if (code == 'T')
+            fprintf (file, ",%d", bpos % 8);
+
+          t_regno = -1;
+        }
+      else
+        fatal_insn ("operands to %T/%t must be reg + const_int:", x);
+    }
+  else if (code == 'E' || code == 'F')
+    {
+      rtx op = XEXP (x, 0);
+      fprintf (file, "%s", reg_names[REGNO (op) + ef]);
+    }
+  else if (code == 'I' || code == 'J')
+    {
+      rtx op = XEXP (XEXP (x, 0), 0);
+      fprintf (file, "%s", reg_names[REGNO (op) + ij]);
+    }
+  else if (REG_P (x))
+    {
+      if (x == zero_reg_rtx)
+        fprintf (file, "__zero_reg__");
+      else if (code == 'r' && REGNO (x) < 32)
+        fprintf (file, "%d", (int) REGNO (x));
+      else
+        fprintf (file, "%s", reg_names[REGNO (x) + abcd]);
+    }
+  else if (CONST_INT_P (x))
+    {
+      HOST_WIDE_INT ival = INTVAL (x);
+
+      if ('i' != code)
+        fprintf (file, HOST_WIDE_INT_PRINT_DEC, ival + abcd);
+      else if (low_io_address_operand (x, VOIDmode)
+               || high_io_address_operand (x, VOIDmode))
+        {
+          if (AVR_HAVE_RAMPZ && ival == avr_addr.rampz)
+            fprintf (file, "__RAMPZ__");
+          else if (AVR_HAVE_RAMPY && ival == avr_addr.rampy)
+            fprintf (file, "__RAMPY__");
+          else if (AVR_HAVE_RAMPX && ival == avr_addr.rampx)
+            fprintf (file, "__RAMPX__");
+          else if (AVR_HAVE_RAMPD && ival == avr_addr.rampd)
+            fprintf (file, "__RAMPD__");
+          else if ((AVR_XMEGA || AVR_TINY) && ival == avr_addr.ccp)
+            fprintf (file, "__CCP__");
+          else if (ival == avr_addr.sreg)   fprintf (file, "__SREG__");
+          else if (ival == avr_addr.sp_l)   fprintf (file, "__SP_L__");
+          else if (ival == avr_addr.sp_h)   fprintf (file, "__SP_H__");
+          else
+            {
+              fprintf (file, HOST_WIDE_INT_PRINT_HEX,
+                       ival - avr_arch->sfr_offset);
+            }
+        }
+      else
+        fatal_insn ("bad address, not an I/O address:", x);
+    }
+  else if (MEM_P (x))
+    {
+      rtx addr = XEXP (x, 0);
+
+      if (code == 'm')
+        {
+          if (!CONSTANT_P (addr))
+            fatal_insn ("bad address, not a constant:", addr);
+          /* Assembler template with m-code is data - not progmem section */
+          if (text_segment_operand (addr, VOIDmode))
+            if (warning (0, "accessing data memory with"
+                         " program memory address"))
+              {
+                output_addr_const (stderr, addr);
+                fprintf(stderr,"\n");
+              }
+          output_addr_const (file, addr);
+        }
+      else if (code == 'i')
+        {
+          avr_print_operand (file, addr, 'i');
+        }
+      else if (code == 'o')
+        {
+          if (GET_CODE (addr) != PLUS)
+            fatal_insn ("bad address, not (reg+disp):", addr);
+
+          avr_print_operand (file, XEXP (addr, 1), 0);
+        }
+      else if (code == 'b')
+        {
+          if (GET_CODE (addr) != PLUS)
+            fatal_insn ("bad address, not (reg+disp):", addr);
+
+          avr_print_operand_address (file, VOIDmode, XEXP (addr, 0));
+        }
+      else if (code == 'p' || code == 'r')
+        {
+          if (GET_CODE (addr) != POST_INC && GET_CODE (addr) != PRE_DEC)
+            fatal_insn ("bad address, not post_inc or pre_dec:", addr);
+
+          if (code == 'p')
+            /* X, Y, Z */
+            avr_print_operand_address (file, VOIDmode, XEXP (addr, 0));
+          else
+            avr_print_operand (file, XEXP (addr, 0), 0);  /* r26, r28, r30 */
+        }
+      else if (GET_CODE (addr) == PLUS)
+        {
+          avr_print_operand_address (file, VOIDmode, XEXP (addr, 0));
+          if (REGNO (XEXP (addr, 0)) == REG_X)
+            fatal_insn ("internal compiler error.  Bad address:"
+                        ,addr);
+          fputc ('+', file);
+          avr_print_operand (file, XEXP (addr, 1), code);
+        }
+      else
+        avr_print_operand_address (file, VOIDmode, addr);
+    }
+  else if (code == 'i')
+    {
+      if (SYMBOL_REF_P (x) && (SYMBOL_REF_FLAGS (x) & SYMBOL_FLAG_IO))
+	avr_print_operand_address
+	  (file, VOIDmode, plus_constant (HImode, x, -avr_arch->sfr_offset));
+      else
+	fatal_insn ("bad address, not an I/O address:", x);
+    }
+  else if (code == 'x')
+    {
+      /* Constant progmem address - like used in jmp or call */
+      if (text_segment_operand (x, VOIDmode) == 0)
+        if (warning (0, "accessing program memory"
+                     " with data memory address"))
+          {
+            output_addr_const (stderr, x);
+            fprintf(stderr,"\n");
+          }
+      /* Use normal symbol for direct address no linker trampoline needed */
+      output_addr_const (file, x);
+    }
+  else if (CONST_FIXED_P (x))
+    {
+      HOST_WIDE_INT ival = INTVAL (avr_to_int_mode (x));
+      if (code != 0)
+        output_operand_lossage ("Unsupported code '%c' for fixed-point:",
+                                code);
+      fprintf (file, HOST_WIDE_INT_PRINT_DEC, ival);
+    }
+  else if (CONST_DOUBLE_P (x))
+    {
+      long val;
+      if (GET_MODE (x) != SFmode)
+        fatal_insn ("internal compiler error.  Unknown mode:", x);
+      REAL_VALUE_TO_TARGET_SINGLE (*CONST_DOUBLE_REAL_VALUE (x), val);
+      fprintf (file, "0x%lx", val);
+    }
+  else if (GET_CODE (x) == CONST_STRING)
+    fputs (XSTR (x, 0), file);
+  else if (code == 'j')
+    fputs (cond_string (GET_CODE (x)), file);
+  else if (code == 'k')
+    fputs (cond_string (reverse_condition (GET_CODE (x))), file);
+  else
+    avr_print_operand_address (file, VOIDmode, x);
+}
+
+
+/* Implement TARGET_USE_BY_PIECES_INFRASTRUCTURE_P.  */
+
+/* Prefer sequence of loads/stores for moves of size upto
+   two - two pairs of load/store instructions are always better
+   than the 5 instruction sequence for a loop (1 instruction
+   for loop counter setup, and 4 for the body of the loop). */
+
+static bool
+avr_use_by_pieces_infrastructure_p (unsigned HOST_WIDE_INT size,
+                                    unsigned int align ATTRIBUTE_UNUSED,
+                                    enum by_pieces_operation op,
+                                    bool speed_p)
+{
+  if (op != MOVE_BY_PIECES
+      || (speed_p && size > MOVE_MAX_PIECES))
+    return default_use_by_pieces_infrastructure_p (size, align, op, speed_p);
+
+  return size <= MOVE_MAX_PIECES;
+}
+
+
+/* Worker function for `NOTICE_UPDATE_CC'.  */
+/* Update the condition code in the INSN.  */
+
+void
+avr_notice_update_cc (rtx body ATTRIBUTE_UNUSED, rtx_insn *insn)
+{
+  rtx set;
+  enum attr_cc cc = get_attr_cc (insn);
+
+  switch (cc)
+    {
+    default:
+      break;
+
+    case CC_PLUS:
+    case CC_LDI:
+      {
+        rtx *op = recog_data.operand;
+        int len_dummy, icc;
+
+        /* Extract insn's operands.  */
+        extract_constrain_insn_cached (insn);
+
+        switch (cc)
+          {
+          default:
+            gcc_unreachable();
+
+          case CC_PLUS:
+            avr_out_plus (insn, op, &len_dummy, &icc);
+            cc = (enum attr_cc) icc;
+            break;
+
+          case CC_LDI:
+
+            cc = (op[1] == CONST0_RTX (GET_MODE (op[0]))
+                  && reg_overlap_mentioned_p (op[0], zero_reg_rtx))
+              /* Loading zero-reg with 0 uses CLR and thus clobbers cc0.  */
+              ? CC_CLOBBER
+              /* Any other "r,rL" combination does not alter cc0.  */
+              : CC_NONE;
+
+            break;
+          } /* inner switch */
+
+        break;
+      }
+    } /* outer swicth */
+
+  switch (cc)
+    {
+    default:
+      /* Special values like CC_OUT_PLUS from above have been
+         mapped to "standard" CC_* values so we never come here.  */
+
+      gcc_unreachable();
+      break;
+
+    case CC_NONE:
+      /* Insn does not affect CC at all, but it might set some registers
+         that are stored in cc_status.  If such a register is affected by
+         the current insn, for example by means of a SET or a CLOBBER,
+         then we must reset cc_status; cf. PR77326.
+
+         Unfortunately, set_of cannot be used as reg_overlap_mentioned_p
+         will abort on COMPARE (which might be found in cc_status.value1/2).
+         Thus work out the registers set by the insn and regs mentioned
+         in cc_status.value1/2.  */
+
+      if (cc_status.value1
+          || cc_status.value2)
+        {
+          HARD_REG_SET regs_used;
+          HARD_REG_SET regs_set;
+          CLEAR_HARD_REG_SET (regs_used);
+
+          if (cc_status.value1
+              && !CONSTANT_P (cc_status.value1))
+            {
+              find_all_hard_regs (cc_status.value1, &regs_used);
+            }
+
+          if (cc_status.value2
+              && !CONSTANT_P (cc_status.value2))
+            {
+              find_all_hard_regs (cc_status.value2, &regs_used);
+            }
+
+          find_all_hard_reg_sets (insn, &regs_set, false);
+
+          if (hard_reg_set_intersect_p (regs_used, regs_set))
+            {
+              CC_STATUS_INIT;
+            }
+        }
+
+      break; // CC_NONE
+
+    case CC_SET_N:
+      CC_STATUS_INIT;
+      break;
+
+    case CC_SET_ZN:
+      set = single_set (insn);
+      CC_STATUS_INIT;
+      if (set)
+        {
+          cc_status.flags |= CC_NO_OVERFLOW;
+          cc_status.value1 = SET_DEST (set);
+        }
+      break;
+
+    case CC_SET_VZN:
+      /* Insn like INC, DEC, NEG that set Z,N,V.  We currently don't make use
+         of this combination, cf. also PR61055.  */
+      CC_STATUS_INIT;
+      break;
+
+    case CC_SET_CZN:
+      /* Insn sets the Z,N,C flags of CC to recog_operand[0].
+         The V flag may or may not be known but that's ok because
+         alter_cond will change tests to use EQ/NE.  */
+      set = single_set (insn);
+      CC_STATUS_INIT;
+      if (set)
+        {
+          cc_status.value1 = SET_DEST (set);
+          cc_status.flags |= CC_OVERFLOW_UNUSABLE;
+        }
+      break;
+
+    case CC_COMPARE:
+      set = single_set (insn);
+      CC_STATUS_INIT;
+      if (set)
+        cc_status.value1 = SET_SRC (set);
+      break;
+
+    case CC_CLOBBER:
+      /* Insn doesn't leave CC in a usable state.  */
+      CC_STATUS_INIT;
+      break;
+    }
+}
+
+/* Choose mode for jump insn:
+   1 - relative jump in range -63 <= x <= 62 ;
+   2 - relative jump in range -2046 <= x <= 2045 ;
+   3 - absolute jump (only for ATmega[16]03).  */
+
+int
+avr_jump_mode (rtx x, rtx_insn *insn)
+{
+  int dest_addr = INSN_ADDRESSES (INSN_UID (GET_CODE (x) == LABEL_REF
+                                            ? XEXP (x, 0) : x));
+  int cur_addr = INSN_ADDRESSES (INSN_UID (insn));
+  int jump_distance = cur_addr - dest_addr;
+
+  if (IN_RANGE (jump_distance, -63, 62))
+    return 1;
+  else if (IN_RANGE (jump_distance, -2046, 2045))
+    return 2;
+  else if (AVR_HAVE_JMP_CALL)
+    return 3;
+
+  return 2;
+}
+
+/* Return an AVR condition jump commands.
+   X is a comparison RTX.
+   LEN is a number returned by avr_jump_mode function.
+   If REVERSE nonzero then condition code in X must be reversed.  */
+
+const char*
+ret_cond_branch (rtx x, int len, int reverse)
+{
+  RTX_CODE cond = reverse ? reverse_condition (GET_CODE (x)) : GET_CODE (x);
+
+  switch (cond)
+    {
+    case GT:
+      if (cc_prev_status.flags & CC_OVERFLOW_UNUSABLE)
+	return (len == 1 ? ("breq .+2" CR_TAB
+			    "brpl %0") :
+		len == 2 ? ("breq .+4" CR_TAB
+			    "brmi .+2" CR_TAB
+			    "rjmp %0") :
+		("breq .+6" CR_TAB
+		 "brmi .+4" CR_TAB
+		 "jmp %0"));
+
+      else
+	return (len == 1 ? ("breq .+2" CR_TAB
+			    "brge %0") :
+		len == 2 ? ("breq .+4" CR_TAB
+			    "brlt .+2" CR_TAB
+			    "rjmp %0") :
+		("breq .+6" CR_TAB
+		 "brlt .+4" CR_TAB
+		 "jmp %0"));
+    case GTU:
+      return (len == 1 ? ("breq .+2" CR_TAB
+                          "brsh %0") :
+              len == 2 ? ("breq .+4" CR_TAB
+                          "brlo .+2" CR_TAB
+                          "rjmp %0") :
+              ("breq .+6" CR_TAB
+               "brlo .+4" CR_TAB
+               "jmp %0"));
+    case LE:
+      if (cc_prev_status.flags & CC_OVERFLOW_UNUSABLE)
+	return (len == 1 ? ("breq %0" CR_TAB
+			    "brmi %0") :
+		len == 2 ? ("breq .+2" CR_TAB
+			    "brpl .+2" CR_TAB
+			    "rjmp %0") :
+		("breq .+2" CR_TAB
+		 "brpl .+4" CR_TAB
+		 "jmp %0"));
+      else
+	return (len == 1 ? ("breq %0" CR_TAB
+			    "brlt %0") :
+		len == 2 ? ("breq .+2" CR_TAB
+			    "brge .+2" CR_TAB
+			    "rjmp %0") :
+		("breq .+2" CR_TAB
+		 "brge .+4" CR_TAB
+		 "jmp %0"));
+    case LEU:
+      return (len == 1 ? ("breq %0" CR_TAB
+                          "brlo %0") :
+              len == 2 ? ("breq .+2" CR_TAB
+                          "brsh .+2" CR_TAB
+			  "rjmp %0") :
+              ("breq .+2" CR_TAB
+               "brsh .+4" CR_TAB
+	       "jmp %0"));
+    default:
+      if (reverse)
+	{
+	  switch (len)
+	    {
+	    case 1:
+	      return "br%k1 %0";
+	    case 2:
+	      return ("br%j1 .+2" CR_TAB
+		      "rjmp %0");
+	    default:
+	      return ("br%j1 .+4" CR_TAB
+		      "jmp %0");
+	    }
+	}
+      else
+        {
+          switch (len)
+            {
+            case 1:
+              return "br%j1 %0";
+            case 2:
+              return ("br%k1 .+2" CR_TAB
+                      "rjmp %0");
+            default:
+              return ("br%k1 .+4" CR_TAB
+                      "jmp %0");
+            }
+        }
+    }
+  return "";
+}
+
+
+/* Worker function for `FINAL_PRESCAN_INSN'.  */
+/* Output insn cost for next insn.  */
+
+void
+avr_final_prescan_insn (rtx_insn *insn, rtx *operand ATTRIBUTE_UNUSED,
+                        int num_operands ATTRIBUTE_UNUSED)
+{
+  if (avr_log.rtx_costs)
+    {
+      rtx set = single_set (insn);
+
+      if (set)
+        fprintf (asm_out_file, "/* DEBUG: cost = %d.  */\n",
+                 set_src_cost (SET_SRC (set), GET_MODE (SET_DEST (set)),
+			       optimize_insn_for_speed_p ()));
+      else
+        fprintf (asm_out_file, "/* DEBUG: pattern-cost = %d.  */\n",
+                 rtx_cost (PATTERN (insn), VOIDmode, INSN, 0,
+                           optimize_insn_for_speed_p()));
+    }
+
+  if (avr_log.insn_addresses)
+    fprintf (asm_out_file, ";; ADDR = %d\n",
+             (int) INSN_ADDRESSES (INSN_UID (insn)));
+}
+
+
+/* Implement `TARGET_ASM_FINAL_POSTSCAN_INSN'.  */
+/* When GAS generates (parts of) ISR prologue / epilogue for us, we must
+   hint GAS about the end of the code to scan.  There migh be code located
+   after the last epilogue.  */
+
+static void
+avr_asm_final_postscan_insn (FILE *stream, rtx_insn *insn, rtx*, int)
+{
+  if (cfun->machine->gasisr.yes
+      && !next_real_insn (insn))
+    {
+      app_disable();
+      fprintf (stream, "\t__gcc_isr %d,r%d\n", GASISR_Done,
+               cfun->machine->gasisr.regno);
+    }
+}
+
+
+/* Return 0 if undefined, 1 if always true or always false.  */
+
+int
+avr_simplify_comparison_p (machine_mode mode, RTX_CODE op, rtx x)
+{
+  unsigned int max = (mode == QImode ? 0xff :
+                      mode == HImode ? 0xffff :
+                      mode == PSImode ? 0xffffff :
+                      mode == SImode ? 0xffffffff : 0);
+  if (max && op && CONST_INT_P (x))
+    {
+      if (unsigned_condition (op) != op)
+        max >>= 1;
+
+      if (max != (INTVAL (x) & max)
+          && INTVAL (x) != 0xff)
+        return 1;
+    }
+  return 0;
+}
+
+
+/* Worker function for `FUNCTION_ARG_REGNO_P'.  */
+/* Returns nonzero if REGNO is the number of a hard
+   register in which function arguments are sometimes passed.  */
+
+int
+avr_function_arg_regno_p (int r)
+{
+  return AVR_TINY ? IN_RANGE (r, 20, 25) : IN_RANGE (r, 8, 25);
+}
+
+
+/* Worker function for `INIT_CUMULATIVE_ARGS'.  */
+/* Initializing the variable cum for the state at the beginning
+   of the argument list.  */
+
+void
+avr_init_cumulative_args (CUMULATIVE_ARGS *cum, tree fntype, rtx libname,
+                          tree fndecl ATTRIBUTE_UNUSED)
+{
+  cum->nregs = AVR_TINY ? 6 : 18;
+  cum->regno = FIRST_CUM_REG;
+  if (!libname && stdarg_p (fntype))
+    cum->nregs = 0;
+
+  /* Assume the calle may be tail called */
+
+  cfun->machine->sibcall_fails = 0;
+}
+
+/* Returns the number of registers to allocate for a function argument.  */
+
+static int
+avr_num_arg_regs (machine_mode mode, const_tree type)
+{
+  int size;
+
+  if (mode == BLKmode)
+    size = int_size_in_bytes (type);
+  else
+    size = GET_MODE_SIZE (mode);
+
+  /* Align all function arguments to start in even-numbered registers.
+     Odd-sized arguments leave holes above them.  */
+
+  return (size + 1) & ~1;
+}
+
+
+/* Implement `TARGET_FUNCTION_ARG'.  */
+/* Controls whether a function argument is passed
+   in a register, and which register.  */
+
+static rtx
+avr_function_arg (cumulative_args_t cum_v, const function_arg_info &arg)
+{
+  CUMULATIVE_ARGS *cum = get_cumulative_args (cum_v);
+  int bytes = avr_num_arg_regs (arg.mode, arg.type);
+
+  if (cum->nregs && bytes <= cum->nregs)
+    return gen_rtx_REG (arg.mode, cum->regno - bytes);
+
+  return NULL_RTX;
+}
+
+
+/* Implement `TARGET_FUNCTION_ARG_ADVANCE'.  */
+/* Update the summarizer variable CUM to advance past an argument
+   in the argument list.  */
+
+static void
+avr_function_arg_advance (cumulative_args_t cum_v,
+			  const function_arg_info &arg)
+{
+  CUMULATIVE_ARGS *cum = get_cumulative_args (cum_v);
+  int bytes = avr_num_arg_regs (arg.mode, arg.type);
+
+  cum->nregs -= bytes;
+  cum->regno -= bytes;
+
+  /* A parameter is being passed in a call-saved register.  As the original
+     contents of these regs has to be restored before leaving the function,
+     a function must not pass arguments in call-saved regs in order to get
+     tail-called.  */
+
+  if (cum->regno >= 8
+      && cum->nregs >= 0
+      && !call_used_or_fixed_reg_p (cum->regno))
+    {
+      /* FIXME: We ship info on failing tail-call in struct machine_function.
+         This uses internals of calls.c:expand_call() and the way args_so_far
+         is used.  targetm.function_ok_for_sibcall() needs to be extended to
+         pass &args_so_far, too.  At present, CUMULATIVE_ARGS is target
+         dependent so that such an extension is not wanted.  */
+
+      cfun->machine->sibcall_fails = 1;
+    }
+
+  /* Test if all registers needed by the ABI are actually available.  If the
+     user has fixed a GPR needed to pass an argument, an (implicit) function
+     call will clobber that fixed register.  See PR45099 for an example.  */
+
+  if (cum->regno >= 8
+      && cum->nregs >= 0)
+    {
+      for (int regno = cum->regno; regno < cum->regno + bytes; regno++)
+        if (fixed_regs[regno])
+          warning (0, "fixed register %s used to pass parameter to function",
+                   reg_names[regno]);
+    }
+
+  if (cum->nregs <= 0)
+    {
+      cum->nregs = 0;
+      cum->regno = FIRST_CUM_REG;
+    }
+}
+
+/* Implement `TARGET_FUNCTION_OK_FOR_SIBCALL' */
+/* Decide whether we can make a sibling call to a function.  DECL is the
+   declaration of the function being targeted by the call and EXP is the
+   CALL_EXPR representing the call.  */
+
+static bool
+avr_function_ok_for_sibcall (tree decl_callee, tree exp_callee)
+{
+  tree fntype_callee;
+
+  /* Tail-calling must fail if callee-saved regs are used to pass
+     function args.  We must not tail-call when `epilogue_restores'
+     is used.  Unfortunately, we cannot tell at this point if that
+     actually will happen or not, and we cannot step back from
+     tail-calling.  Thus, we inhibit tail-calling with -mcall-prologues.  */
+
+  if (cfun->machine->sibcall_fails
+      || TARGET_CALL_PROLOGUES)
+    {
+      return false;
+    }
+
+  fntype_callee = TREE_TYPE (CALL_EXPR_FN (exp_callee));
+
+  if (decl_callee)
+    {
+      decl_callee = TREE_TYPE (decl_callee);
+    }
+  else
+    {
+      decl_callee = fntype_callee;
+
+      while (FUNCTION_TYPE != TREE_CODE (decl_callee)
+             && METHOD_TYPE != TREE_CODE (decl_callee))
+        {
+          decl_callee = TREE_TYPE (decl_callee);
+        }
+    }
+
+  /* Ensure that caller and callee have compatible epilogues */
+
+  if (cfun->machine->is_interrupt
+      || cfun->machine->is_signal
+      || cfun->machine->is_naked
+      || avr_naked_function_p (decl_callee))
+    {
+      return false;
+    }
+
+  return true;
+}
+
+/***********************************************************************
+  Functions for outputting various mov's for a various modes
+************************************************************************/
+
+/* Return true if a value of mode MODE is read from flash by
+   __load_* function from libgcc.  */
+
+bool
+avr_load_libgcc_p (rtx op)
+{
+  machine_mode mode = GET_MODE (op);
+  int n_bytes = GET_MODE_SIZE (mode);
+
+  return (n_bytes > 2
+          && !AVR_HAVE_LPMX
+          && avr_mem_flash_p (op));
+}
+
+/* Return true if a value of mode MODE is read by __xload_* function.  */
+
+bool
+avr_xload_libgcc_p (machine_mode mode)
+{
+  int n_bytes = GET_MODE_SIZE (mode);
+
+  return (n_bytes > 1
+          || avr_n_flash > 1);
+}
+
+
+/* Fixme: This is a hack because secondary reloads don't works as expected.
+
+   Find an unused d-register to be used as scratch in INSN.
+   EXCLUDE is either NULL_RTX or some register. In the case where EXCLUDE
+   is a register, skip all possible return values that overlap EXCLUDE.
+   The policy for the returned register is similar to that of
+   `reg_unused_after', i.e. the returned register may overlap the SET_DEST
+   of INSN.
+
+   Return a QImode d-register or NULL_RTX if nothing found.  */
+
+static rtx
+avr_find_unused_d_reg (rtx_insn *insn, rtx exclude)
+{
+  bool isr_p = (avr_interrupt_function_p (current_function_decl)
+                || avr_signal_function_p (current_function_decl));
+
+  for (int regno = 16; regno < 32; regno++)
+    {
+      rtx reg = all_regs_rtx[regno];
+
+      if ((exclude
+           && reg_overlap_mentioned_p (exclude, reg))
+          || fixed_regs[regno])
+        {
+          continue;
+        }
+
+      /* Try non-live register */
+
+      if (!df_regs_ever_live_p (regno)
+          && (TREE_THIS_VOLATILE (current_function_decl)
+              || cfun->machine->is_OS_task
+              || cfun->machine->is_OS_main
+              || (!isr_p && call_used_or_fixed_reg_p (regno))))
+        {
+          return reg;
+        }
+
+      /* Any live register can be used if it is unused after.
+         Prologue/epilogue will care for it as needed.  */
+
+      if (df_regs_ever_live_p (regno)
+          && reg_unused_after (insn, reg))
+        {
+          return reg;
+        }
+    }
+
+  return NULL_RTX;
+}
+
+
+/* Helper function for the next function in the case where only restricted
+   version of LPM instruction is available.  */
+
+static const char*
+avr_out_lpm_no_lpmx (rtx_insn *insn, rtx *xop, int *plen)
+{
+  rtx dest = xop[0];
+  rtx addr = xop[1];
+  int n_bytes = GET_MODE_SIZE (GET_MODE (dest));
+  int regno_dest;
+
+  regno_dest = REGNO (dest);
+
+  /* The implicit target register of LPM.  */
+  xop[3] = lpm_reg_rtx;
+
+  switch (GET_CODE (addr))
+    {
+    default:
+      gcc_unreachable();
+
+    case REG:
+
+      gcc_assert (REG_Z == REGNO (addr));
+
+      switch (n_bytes)
+        {
+        default:
+          gcc_unreachable();
+
+        case 1:
+          avr_asm_len ("%4lpm", xop, plen, 1);
+
+          if (regno_dest != LPM_REGNO)
+            avr_asm_len ("mov %0,%3", xop, plen, 1);
+
+          return "";
+
+        case 2:
+          if (REGNO (dest) == REG_Z)
+            return avr_asm_len ("%4lpm"      CR_TAB
+                                "push %3"    CR_TAB
+                                "adiw %2,1"  CR_TAB
+                                "%4lpm"      CR_TAB
+                                "mov %B0,%3" CR_TAB
+                                "pop %A0", xop, plen, 6);
+
+          avr_asm_len ("%4lpm"      CR_TAB
+                       "mov %A0,%3" CR_TAB
+                       "adiw %2,1"  CR_TAB
+                       "%4lpm"      CR_TAB
+                       "mov %B0,%3", xop, plen, 5);
+
+          if (!reg_unused_after (insn, addr))
+            avr_asm_len ("sbiw %2,1", xop, plen, 1);
+
+          break; /* 2 */
+        }
+
+      break; /* REG */
+
+    case POST_INC:
+
+      gcc_assert (REG_Z == REGNO (XEXP (addr, 0))
+                  && n_bytes <= 4);
+
+      if (regno_dest == LPM_REGNO)
+        avr_asm_len ("%4lpm"      CR_TAB
+                     "adiw %2,1", xop, plen, 2);
+      else
+        avr_asm_len ("%4lpm"      CR_TAB
+                     "mov %A0,%3" CR_TAB
+                     "adiw %2,1", xop, plen, 3);
+
+      if (n_bytes >= 2)
+        avr_asm_len ("%4lpm"      CR_TAB
+                     "mov %B0,%3" CR_TAB
+                     "adiw %2,1", xop, plen, 3);
+
+      if (n_bytes >= 3)
+        avr_asm_len ("%4lpm"      CR_TAB
+                     "mov %C0,%3" CR_TAB
+                     "adiw %2,1", xop, plen, 3);
+
+      if (n_bytes >= 4)
+        avr_asm_len ("%4lpm"      CR_TAB
+                     "mov %D0,%3" CR_TAB
+                     "adiw %2,1", xop, plen, 3);
+
+      break; /* POST_INC */
+
+    } /* switch CODE (addr) */
+
+  return "";
+}
+
+
+/* If PLEN == NULL: Ouput instructions to load a value from a memory location
+   OP[1] in AS1 to register OP[0].
+   If PLEN != 0 set *PLEN to the length in words of the instruction sequence.
+   Return "".  */
+
+const char*
+avr_out_lpm (rtx_insn *insn, rtx *op, int *plen)
+{
+  rtx xop[7];
+  rtx dest = op[0];
+  rtx src = SET_SRC (single_set (insn));
+  rtx addr;
+  int n_bytes = GET_MODE_SIZE (GET_MODE (dest));
+  int segment;
+  RTX_CODE code;
+  addr_space_t as = MEM_ADDR_SPACE (src);
+
+  if (plen)
+    *plen = 0;
+
+  if (MEM_P (dest))
+    {
+      warning (0, "writing to address space %qs not supported",
+               avr_addrspace[MEM_ADDR_SPACE (dest)].name);
+
+      return "";
+    }
+
+  addr = XEXP (src, 0);
+  code = GET_CODE (addr);
+
+  gcc_assert (REG_P (dest));
+  gcc_assert (REG == code || POST_INC == code);
+
+  xop[0] = dest;
+  xop[1] = addr;
+  xop[2] = lpm_addr_reg_rtx;
+  xop[4] = xstring_empty;
+  xop[5] = tmp_reg_rtx;
+  xop[6] = XEXP (rampz_rtx, 0);
+
+  segment = avr_addrspace[as].segment;
+
+  /* Set RAMPZ as needed.  */
+
+  if (segment)
+    {
+      xop[4] = GEN_INT (segment);
+      xop[3] = avr_find_unused_d_reg (insn, lpm_addr_reg_rtx);
+
+      if (xop[3] != NULL_RTX)
+        {
+          avr_asm_len ("ldi %3,%4" CR_TAB
+                       "out %i6,%3", xop, plen, 2);
+        }
+      else if (segment == 1)
+        {
+          avr_asm_len ("clr %5" CR_TAB
+                       "inc %5" CR_TAB
+                       "out %i6,%5", xop, plen, 3);
+        }
+      else
+        {
+          avr_asm_len ("mov %5,%2"   CR_TAB
+                       "ldi %2,%4"   CR_TAB
+                       "out %i6,%2"  CR_TAB
+                       "mov %2,%5", xop, plen, 4);
+        }
+
+      xop[4] = xstring_e;
+
+      if (!AVR_HAVE_ELPMX)
+        return avr_out_lpm_no_lpmx (insn, xop, plen);
+    }
+  else if (!AVR_HAVE_LPMX)
+    {
+      return avr_out_lpm_no_lpmx (insn, xop, plen);
+    }
+
+  /* We have [E]LPMX: Output reading from Flash the comfortable way.  */
+
+  switch (GET_CODE (addr))
+    {
+    default:
+      gcc_unreachable();
+
+    case REG:
+
+      gcc_assert (REG_Z == REGNO (addr));
+
+      switch (n_bytes)
+        {
+        default:
+          gcc_unreachable();
+
+        case 1:
+          avr_asm_len ("%4lpm %0,%a2", xop, plen, 1);
+          break;
+
+        case 2:
+          if (REGNO (dest) == REG_Z)
+            avr_asm_len ("%4lpm %5,%a2+" CR_TAB
+                         "%4lpm %B0,%a2" CR_TAB
+                         "mov %A0,%5", xop, plen, 3);
+          else
+            {
+              avr_asm_len ("%4lpm %A0,%a2+" CR_TAB
+                           "%4lpm %B0,%a2", xop, plen, 2);
+
+              if (!reg_unused_after (insn, addr))
+                avr_asm_len ("sbiw %2,1", xop, plen, 1);
+            }
+
+          break; /* 2 */
+
+        case 3:
+
+          avr_asm_len ("%4lpm %A0,%a2+" CR_TAB
+                       "%4lpm %B0,%a2+" CR_TAB
+                       "%4lpm %C0,%a2", xop, plen, 3);
+
+          if (!reg_unused_after (insn, addr))
+            avr_asm_len ("sbiw %2,2", xop, plen, 1);
+
+          break; /* 3 */
+
+        case 4:
+
+          avr_asm_len ("%4lpm %A0,%a2+" CR_TAB
+                       "%4lpm %B0,%a2+", xop, plen, 2);
+
+          if (REGNO (dest) == REG_Z - 2)
+            avr_asm_len ("%4lpm %5,%a2+" CR_TAB
+                         "%4lpm %C0,%a2" CR_TAB
+                         "mov %D0,%5", xop, plen, 3);
+          else
+            {
+              avr_asm_len ("%4lpm %C0,%a2+" CR_TAB
+                           "%4lpm %D0,%a2", xop, plen, 2);
+
+              if (!reg_unused_after (insn, addr))
+                avr_asm_len ("sbiw %2,3", xop, plen, 1);
+            }
+
+          break; /* 4 */
+        } /* n_bytes */
+
+      break; /* REG */
+
+    case POST_INC:
+
+      gcc_assert (REG_Z == REGNO (XEXP (addr, 0))
+                  && n_bytes <= 4);
+
+      avr_asm_len                    ("%4lpm %A0,%a2+", xop, plen, 1);
+      if (n_bytes >= 2)  avr_asm_len ("%4lpm %B0,%a2+", xop, plen, 1);
+      if (n_bytes >= 3)  avr_asm_len ("%4lpm %C0,%a2+", xop, plen, 1);
+      if (n_bytes >= 4)  avr_asm_len ("%4lpm %D0,%a2+", xop, plen, 1);
+
+      break; /* POST_INC */
+
+    } /* switch CODE (addr) */
+
+  if (xop[4] == xstring_e && AVR_HAVE_RAMPD)
+    {
+      /* Reset RAMPZ to 0 so that EBI devices don't read garbage from RAM.  */
+
+      xop[0] = zero_reg_rtx;
+      avr_asm_len ("out %i6,%0", xop, plen, 1);
+    }
+
+  return "";
+}
+
+
+/* Worker function for xload_8 insn.  */
+
+const char*
+avr_out_xload (rtx_insn *insn ATTRIBUTE_UNUSED, rtx *op, int *plen)
+{
+  rtx xop[4];
+
+  xop[0] = op[0];
+  xop[1] = op[1];
+  xop[2] = lpm_addr_reg_rtx;
+  xop[3] = AVR_HAVE_LPMX ? op[0] : lpm_reg_rtx;
+
+  avr_asm_len (AVR_HAVE_LPMX ? "lpm %3,%a2" : "lpm", xop, plen, -1);
+
+  avr_asm_len ("sbrc %1,7" CR_TAB
+               "ld %3,%a2", xop, plen, 2);
+
+  if (REGNO (xop[0]) != REGNO (xop[3]))
+    avr_asm_len ("mov %0,%3", xop, plen, 1);
+
+  return "";
+}
+
+
+const char*
+output_movqi (rtx_insn *insn, rtx operands[], int *plen)
+{
+  rtx dest = operands[0];
+  rtx src = operands[1];
+
+  if (avr_mem_flash_p (src)
+      || avr_mem_flash_p (dest))
+    {
+      return avr_out_lpm (insn, operands, plen);
+    }
+
+  gcc_assert (GET_MODE_SIZE (GET_MODE (dest)) == 1);
+
+  if (REG_P (dest))
+    {
+      if (REG_P (src)) /* mov r,r */
+        {
+          if (test_hard_reg_class (STACK_REG, dest))
+            return avr_asm_len ("out %0,%1", operands, plen, -1);
+          else if (test_hard_reg_class (STACK_REG, src))
+            return avr_asm_len ("in %0,%1", operands, plen, -1);
+
+          return avr_asm_len ("mov %0,%1", operands, plen, -1);
+        }
+      else if (CONSTANT_P (src))
+        {
+          output_reload_in_const (operands, NULL_RTX, plen, false);
+          return "";
+        }
+      else if (MEM_P (src))
+        return out_movqi_r_mr (insn, operands, plen); /* mov r,m */
+    }
+  else if (MEM_P (dest))
+    {
+      rtx xop[2];
+
+      xop[0] = dest;
+      xop[1] = src == CONST0_RTX (GET_MODE (dest)) ? zero_reg_rtx : src;
+
+      return out_movqi_mr_r (insn, xop, plen);
+    }
+
+  return "";
+}
+
+
+const char *
+output_movhi (rtx_insn *insn, rtx xop[], int *plen)
+{
+  rtx dest = xop[0];
+  rtx src = xop[1];
+
+  gcc_assert (GET_MODE_SIZE (GET_MODE (dest)) == 2);
+
+  if (avr_mem_flash_p (src)
+      || avr_mem_flash_p (dest))
+    {
+      return avr_out_lpm (insn, xop, plen);
+    }
+
+  if (REG_P (dest))
+    {
+      if (REG_P (src)) /* mov r,r */
+        {
+          if (test_hard_reg_class (STACK_REG, dest))
+            {
+              if (AVR_HAVE_8BIT_SP)
+                return avr_asm_len ("out __SP_L__,%A1", xop, plen, -1);
+
+              if (AVR_XMEGA)
+                return avr_asm_len ("out __SP_L__,%A1" CR_TAB
+                                    "out __SP_H__,%B1", xop, plen, -2);
+
+              /* Use simple load of SP if no interrupts are  used.  */
+
+              return TARGET_NO_INTERRUPTS
+                ? avr_asm_len ("out __SP_H__,%B1" CR_TAB
+                               "out __SP_L__,%A1", xop, plen, -2)
+                : avr_asm_len ("in __tmp_reg__,__SREG__"  CR_TAB
+                               "cli"                      CR_TAB
+                               "out __SP_H__,%B1"         CR_TAB
+                               "out __SREG__,__tmp_reg__" CR_TAB
+                               "out __SP_L__,%A1", xop, plen, -5);
+            }
+          else if (test_hard_reg_class (STACK_REG, src))
+            {
+              return !AVR_HAVE_SPH
+                ? avr_asm_len ("in %A0,__SP_L__" CR_TAB
+                               "clr %B0", xop, plen, -2)
+
+                : avr_asm_len ("in %A0,__SP_L__" CR_TAB
+                               "in %B0,__SP_H__", xop, plen, -2);
+            }
+
+          return AVR_HAVE_MOVW
+            ? avr_asm_len ("movw %0,%1", xop, plen, -1)
+
+            : avr_asm_len ("mov %A0,%A1" CR_TAB
+                           "mov %B0,%B1", xop, plen, -2);
+        } /* REG_P (src) */
+      else if (CONSTANT_P (src))
+        {
+          return output_reload_inhi (xop, NULL, plen);
+        }
+      else if (MEM_P (src))
+        {
+          return out_movhi_r_mr (insn, xop, plen); /* mov r,m */
+        }
+    }
+  else if (MEM_P (dest))
+    {
+      rtx xop[2];
+
+      xop[0] = dest;
+      xop[1] = src == CONST0_RTX (GET_MODE (dest)) ? zero_reg_rtx : src;
+
+      return out_movhi_mr_r (insn, xop, plen);
+    }
+
+  fatal_insn ("invalid insn:", insn);
+
+  return "";
+}
+
+
+/* Same as out_movqi_r_mr, but TINY does not have ADIW or SBIW */
+
+static const char*
+avr_out_movqi_r_mr_reg_disp_tiny (rtx_insn *insn, rtx op[], int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx x = XEXP (src, 0);
+
+  avr_asm_len (TINY_ADIW (%I1, %J1, %o1) CR_TAB
+               "ld %0,%b1" , op, plen, -3);
+
+  if (!reg_overlap_mentioned_p (dest, XEXP (x, 0))
+      && !reg_unused_after (insn, XEXP (x, 0)))
+    avr_asm_len (TINY_SBIW (%I1, %J1, %o1), op, plen, 2);
+
+  return "";
+}
+
+static const char*
+out_movqi_r_mr (rtx_insn *insn, rtx op[], int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx x = XEXP (src, 0);
+
+  if (CONSTANT_ADDRESS_P (x))
+    {
+      int n_words = AVR_TINY ? 1 : 2;
+      return io_address_operand (x, QImode)
+        ? avr_asm_len ("in %0,%i1", op, plen, -1)
+        : avr_asm_len ("lds %0,%m1", op, plen, -n_words);
+    }
+
+  if (GET_CODE (x) == PLUS
+      && REG_P (XEXP (x, 0))
+      && CONST_INT_P (XEXP (x, 1)))
+    {
+      /* memory access by reg+disp */
+
+      int disp = INTVAL (XEXP (x, 1));
+
+      if (AVR_TINY)
+        return avr_out_movqi_r_mr_reg_disp_tiny (insn, op, plen);
+
+      if (disp - GET_MODE_SIZE (GET_MODE (src)) >= 63)
+        {
+          if (REGNO (XEXP (x, 0)) != REG_Y)
+            fatal_insn ("incorrect insn:",insn);
+
+          if (disp <= 63 + MAX_LD_OFFSET (GET_MODE (src)))
+            return avr_asm_len ("adiw r28,%o1-63" CR_TAB
+                                "ldd %0,Y+63"     CR_TAB
+                                "sbiw r28,%o1-63", op, plen, -3);
+
+          return avr_asm_len ("subi r28,lo8(-%o1)" CR_TAB
+                              "sbci r29,hi8(-%o1)" CR_TAB
+                              "ld %0,Y"            CR_TAB
+                              "subi r28,lo8(%o1)"  CR_TAB
+                              "sbci r29,hi8(%o1)", op, plen, -5);
+        }
+      else if (REGNO (XEXP (x, 0)) == REG_X)
+        {
+          /* This is a paranoid case LEGITIMIZE_RELOAD_ADDRESS must exclude
+             it but I have this situation with extremal optimizing options.  */
+
+          avr_asm_len ("adiw r26,%o1" CR_TAB
+                       "ld %0,X", op, plen, -2);
+
+          if (!reg_overlap_mentioned_p (dest, XEXP (x, 0))
+              && !reg_unused_after (insn, XEXP (x, 0)))
+            {
+              avr_asm_len ("sbiw r26,%o1", op, plen, 1);
+            }
+
+          return "";
+        }
+
+      return avr_asm_len ("ldd %0,%1", op, plen, -1);
+    }
+
+  return avr_asm_len ("ld %0,%1", op, plen, -1);
+}
+
+
+/* Same as movhi_r_mr, but TINY does not have ADIW, SBIW and LDD */
+
+static const char*
+avr_out_movhi_r_mr_reg_no_disp_tiny (rtx_insn *insn, rtx op[], int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (src, 0);
+
+  int reg_dest = true_regnum (dest);
+  int reg_base = true_regnum (base);
+
+  if (reg_dest == reg_base)         /* R = (R) */
+    return avr_asm_len ("ld __tmp_reg__,%1+" CR_TAB
+			"ld %B0,%1"          CR_TAB
+			"mov %A0,__tmp_reg__", op, plen, -3);
+
+  avr_asm_len ("ld %A0,%1+" CR_TAB
+               "ld %B0,%1", op, plen, -2);
+
+  if (!reg_unused_after (insn, base))
+    avr_asm_len (TINY_SBIW (%E1, %F1, 1), op, plen, 2);
+
+  return "";
+}
+
+
+/* Same as movhi_r_mr, but TINY does not have ADIW, SBIW and LDD */
+
+static const char*
+avr_out_movhi_r_mr_reg_disp_tiny (rtx_insn *insn, rtx op[], int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (src, 0);
+
+  int reg_dest = true_regnum (dest);
+  int reg_base = true_regnum (XEXP (base, 0));
+
+  if (reg_base == reg_dest)
+    {
+      return avr_asm_len (TINY_ADIW (%I1, %J1, %o1) CR_TAB
+                          "ld __tmp_reg__,%b1+"     CR_TAB
+                          "ld %B0,%b1"              CR_TAB
+                          "mov %A0,__tmp_reg__", op, plen, -5);
+    }
+  else
+    {
+      avr_asm_len (TINY_ADIW (%I1, %J1, %o1) CR_TAB
+                   "ld %A0,%b1+"             CR_TAB
+                   "ld %B0,%b1", op, plen, -4);
+
+      if (!reg_unused_after (insn, XEXP (base, 0)))
+        avr_asm_len (TINY_SBIW (%I1, %J1, %o1+1), op, plen, 2);
+
+      return "";
+    }
+}
+
+
+/* Same as movhi_r_mr, but TINY does not have ADIW, SBIW and LDD */
+
+static const char*
+avr_out_movhi_r_mr_pre_dec_tiny (rtx_insn *insn, rtx op[], int *plen)
+{
+  int mem_volatile_p = 0;
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (src, 0);
+
+  /* "volatile" forces reading low byte first, even if less efficient,
+     for correct operation with 16-bit I/O registers.  */
+  mem_volatile_p = MEM_VOLATILE_P (src);
+
+  if (reg_overlap_mentioned_p (dest, XEXP (base, 0)))
+    fatal_insn ("incorrect insn:", insn);
+
+  if (!mem_volatile_p)
+    return avr_asm_len ("ld %B0,%1" CR_TAB
+                        "ld %A0,%1", op, plen, -2);
+
+  return avr_asm_len (TINY_SBIW (%I1, %J1, 2)  CR_TAB
+                      "ld %A0,%p1+"            CR_TAB
+                      "ld %B0,%p1"             CR_TAB
+                      TINY_SBIW (%I1, %J1, 1), op, plen, -6);
+}
+
+
+static const char*
+out_movhi_r_mr (rtx_insn *insn, rtx op[], int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (src, 0);
+  int reg_dest = true_regnum (dest);
+  int reg_base = true_regnum (base);
+  /* "volatile" forces reading low byte first, even if less efficient,
+     for correct operation with 16-bit I/O registers.  */
+  int mem_volatile_p = MEM_VOLATILE_P (src);
+
+  if (reg_base > 0)
+    {
+      if (AVR_TINY)
+        return avr_out_movhi_r_mr_reg_no_disp_tiny (insn, op, plen);
+
+      if (reg_dest == reg_base)         /* R = (R) */
+        return avr_asm_len ("ld __tmp_reg__,%1+" CR_TAB
+                            "ld %B0,%1"          CR_TAB
+                            "mov %A0,__tmp_reg__", op, plen, -3);
+
+      if (reg_base != REG_X)
+        return avr_asm_len ("ld %A0,%1" CR_TAB
+                            "ldd %B0,%1+1", op, plen, -2);
+
+      avr_asm_len ("ld %A0,X+" CR_TAB
+                   "ld %B0,X", op, plen, -2);
+
+      if (!reg_unused_after (insn, base))
+        avr_asm_len ("sbiw r26,1", op, plen, 1);
+
+      return "";
+    }
+  else if (GET_CODE (base) == PLUS) /* (R + i) */
+    {
+      int disp = INTVAL (XEXP (base, 1));
+      int reg_base = true_regnum (XEXP (base, 0));
+
+      if (AVR_TINY)
+        return avr_out_movhi_r_mr_reg_disp_tiny (insn, op, plen);
+
+      if (disp > MAX_LD_OFFSET (GET_MODE (src)))
+        {
+          if (REGNO (XEXP (base, 0)) != REG_Y)
+            fatal_insn ("incorrect insn:",insn);
+
+          return disp <= 63 + MAX_LD_OFFSET (GET_MODE (src))
+            ? avr_asm_len ("adiw r28,%o1-62" CR_TAB
+                           "ldd %A0,Y+62"    CR_TAB
+                           "ldd %B0,Y+63"    CR_TAB
+                           "sbiw r28,%o1-62", op, plen, -4)
+
+            : avr_asm_len ("subi r28,lo8(-%o1)" CR_TAB
+                           "sbci r29,hi8(-%o1)" CR_TAB
+                           "ld %A0,Y"           CR_TAB
+                           "ldd %B0,Y+1"        CR_TAB
+                           "subi r28,lo8(%o1)"  CR_TAB
+                           "sbci r29,hi8(%o1)", op, plen, -6);
+        }
+
+      /* This is a paranoid case. LEGITIMIZE_RELOAD_ADDRESS must exclude
+         it but I have this situation with extremal
+         optimization options.  */
+
+      if (reg_base == REG_X)
+        {
+          if (reg_base == reg_dest)
+            return avr_asm_len ("adiw r26,%o1"      CR_TAB
+                                "ld __tmp_reg__,X+" CR_TAB
+                                "ld %B0,X"          CR_TAB
+                                "mov %A0,__tmp_reg__", op, plen, -4);
+
+          avr_asm_len ("adiw r26,%o1" CR_TAB
+                       "ld %A0,X+"    CR_TAB
+                       "ld %B0,X", op, plen, -3);
+
+          if (!reg_unused_after (insn, XEXP (base, 0)))
+            avr_asm_len ("sbiw r26,%o1+1", op, plen, 1);
+
+          return "";
+        }
+
+      return reg_base == reg_dest
+        ? avr_asm_len ("ldd __tmp_reg__,%A1" CR_TAB
+                       "ldd %B0,%B1"         CR_TAB
+                       "mov %A0,__tmp_reg__", op, plen, -3)
+
+        : avr_asm_len ("ldd %A0,%A1" CR_TAB
+                       "ldd %B0,%B1", op, plen, -2);
+    }
+  else if (GET_CODE (base) == PRE_DEC) /* (--R) */
+    {
+      if (AVR_TINY)
+	return avr_out_movhi_r_mr_pre_dec_tiny (insn, op, plen);
+
+      if (reg_overlap_mentioned_p (dest, XEXP (base, 0)))
+        fatal_insn ("incorrect insn:", insn);
+
+      if (!mem_volatile_p)
+        return avr_asm_len ("ld %B0,%1" CR_TAB
+                            "ld %A0,%1", op, plen, -2);
+
+      return REGNO (XEXP (base, 0)) == REG_X
+        ? avr_asm_len ("sbiw r26,2"  CR_TAB
+                       "ld %A0,X+"   CR_TAB
+                       "ld %B0,X"    CR_TAB
+                       "sbiw r26,1", op, plen, -4)
+
+        : avr_asm_len ("sbiw %r1,2"  CR_TAB
+                       "ld %A0,%p1"  CR_TAB
+                       "ldd %B0,%p1+1", op, plen, -3);
+    }
+  else if (GET_CODE (base) == POST_INC) /* (R++) */
+    {
+      if (reg_overlap_mentioned_p (dest, XEXP (base, 0)))
+        fatal_insn ("incorrect insn:", insn);
+
+      return avr_asm_len ("ld %A0,%1"  CR_TAB
+                          "ld %B0,%1", op, plen, -2);
+    }
+  else if (CONSTANT_ADDRESS_P (base))
+    {
+      int n_words = AVR_TINY ? 2 : 4;
+      return io_address_operand (base, HImode)
+        ? avr_asm_len ("in %A0,%i1" CR_TAB
+                       "in %B0,%i1+1", op, plen, -2)
+
+        : avr_asm_len ("lds %A0,%m1" CR_TAB
+                       "lds %B0,%m1+1", op, plen, -n_words);
+    }
+
+  fatal_insn ("unknown move insn:",insn);
+  return "";
+}
+
+static const char*
+avr_out_movsi_r_mr_reg_no_disp_tiny (rtx_insn *insn, rtx op[], int *l)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (src, 0);
+  int reg_dest = true_regnum (dest);
+  int reg_base = true_regnum (base);
+
+  if (reg_dest == reg_base)
+    {
+      /* "ld r26,-X" is undefined */
+      return *l = 9, (TINY_ADIW (%E1, %F1, 3) CR_TAB
+		      "ld %D0,%1"             CR_TAB
+		      "ld %C0,-%1"            CR_TAB
+		      "ld __tmp_reg__,-%1"    CR_TAB
+		      TINY_SBIW (%E1, %F1, 1) CR_TAB
+		      "ld %A0,%1"             CR_TAB
+		      "mov %B0,__tmp_reg__");
+    }
+  else if (reg_dest == reg_base - 2)
+    {
+      return *l = 5, ("ld %A0,%1+"            CR_TAB
+		      "ld %B0,%1+"            CR_TAB
+		      "ld __tmp_reg__,%1+"    CR_TAB
+		      "ld %D0,%1"             CR_TAB
+		      "mov %C0,__tmp_reg__");
+    }
+  else if (reg_unused_after (insn, base))
+    {
+      return *l = 4, ("ld %A0,%1+"    CR_TAB
+		      "ld %B0,%1+"    CR_TAB
+		      "ld %C0,%1+"    CR_TAB
+		      "ld %D0,%1");
+    }
+  else
+    {
+      return *l = 6, ("ld %A0,%1+"    CR_TAB
+		      "ld %B0,%1+"    CR_TAB
+		      "ld %C0,%1+"    CR_TAB
+		      "ld %D0,%1"     CR_TAB
+		      TINY_SBIW (%E1, %F1, 3));
+    }
+}
+
+
+static const char*
+avr_out_movsi_r_mr_reg_disp_tiny (rtx_insn *insn, rtx op[], int *l)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (src, 0);
+  int reg_dest = true_regnum (dest);
+  int reg_base = true_regnum (XEXP (base, 0));
+
+  if (reg_dest == reg_base)
+    {
+      /* "ld r26,-X" is undefined */
+      return *l = 9, (TINY_ADIW (%I1, %J1, %o1+3) CR_TAB
+                      "ld %D0,%b1"                CR_TAB
+                      "ld %C0,-%b1"               CR_TAB
+                      "ld __tmp_reg__,-%b1"       CR_TAB
+                      TINY_SBIW (%I1, %J1, 1)     CR_TAB
+                      "ld %A0,%b1"                CR_TAB
+                      "mov %B0,__tmp_reg__");
+    }
+  else if (reg_dest == reg_base - 2)
+    {
+      return *l = 7, (TINY_ADIW (%I1, %J1, %o1) CR_TAB
+                      "ld %A0,%b1+"             CR_TAB
+                      "ld %B0,%b1+"             CR_TAB
+                      "ld __tmp_reg__,%b1+"     CR_TAB
+                      "ld %D0,%b1"              CR_TAB
+                      "mov %C0,__tmp_reg__");
+    }
+  else if (reg_unused_after (insn, XEXP (base, 0)))
+    {
+      return *l = 6, (TINY_ADIW (%I1, %J1, %o1) CR_TAB
+                      "ld %A0,%b1+"             CR_TAB
+                      "ld %B0,%b1+"             CR_TAB
+                      "ld %C0,%b1+"             CR_TAB
+                      "ld %D0,%b1");
+    }
+  else
+    {
+      return *l = 8, (TINY_ADIW (%I1, %J1, %o1)  CR_TAB
+                      "ld %A0,%b1+"              CR_TAB
+                      "ld %B0,%b1+"              CR_TAB
+                      "ld %C0,%b1+"              CR_TAB
+                      "ld %D0,%b1"               CR_TAB
+                      TINY_SBIW (%I1, %J1, %o1+3));
+    }
+}
+
+static const char*
+out_movsi_r_mr (rtx_insn *insn, rtx op[], int *l)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (src, 0);
+  int reg_dest = true_regnum (dest);
+  int reg_base = true_regnum (base);
+  int tmp;
+
+  if (!l)
+    l = &tmp;
+
+  if (reg_base > 0)
+    {
+      if (AVR_TINY)
+        return avr_out_movsi_r_mr_reg_no_disp_tiny (insn, op, l);
+
+      if (reg_base == REG_X)        /* (R26) */
+        {
+          if (reg_dest == REG_X)
+	    /* "ld r26,-X" is undefined */
+	    return *l=7, ("adiw r26,3"        CR_TAB
+			  "ld r29,X"          CR_TAB
+			  "ld r28,-X"         CR_TAB
+			  "ld __tmp_reg__,-X" CR_TAB
+			  "sbiw r26,1"        CR_TAB
+			  "ld r26,X"          CR_TAB
+			  "mov r27,__tmp_reg__");
+          else if (reg_dest == REG_X - 2)
+            return *l=5, ("ld %A0,X+"          CR_TAB
+                          "ld %B0,X+"          CR_TAB
+                          "ld __tmp_reg__,X+"  CR_TAB
+                          "ld %D0,X"           CR_TAB
+                          "mov %C0,__tmp_reg__");
+          else if (reg_unused_after (insn, base))
+            return  *l=4, ("ld %A0,X+" CR_TAB
+                           "ld %B0,X+" CR_TAB
+                           "ld %C0,X+" CR_TAB
+                           "ld %D0,X");
+          else
+            return  *l=5, ("ld %A0,X+" CR_TAB
+                           "ld %B0,X+" CR_TAB
+                           "ld %C0,X+" CR_TAB
+                           "ld %D0,X"  CR_TAB
+                           "sbiw r26,3");
+        }
+      else
+        {
+          if (reg_dest == reg_base)
+            return *l=5, ("ldd %D0,%1+3" CR_TAB
+                          "ldd %C0,%1+2" CR_TAB
+                          "ldd __tmp_reg__,%1+1"  CR_TAB
+                          "ld %A0,%1"  CR_TAB
+                          "mov %B0,__tmp_reg__");
+          else if (reg_base == reg_dest + 2)
+            return *l=5, ("ld %A0,%1"             CR_TAB
+                          "ldd %B0,%1+1"          CR_TAB
+                          "ldd __tmp_reg__,%1+2"  CR_TAB
+                          "ldd %D0,%1+3"          CR_TAB
+                          "mov %C0,__tmp_reg__");
+          else
+            return *l=4, ("ld %A0,%1"    CR_TAB
+                          "ldd %B0,%1+1" CR_TAB
+                          "ldd %C0,%1+2" CR_TAB
+                          "ldd %D0,%1+3");
+        }
+    }
+  else if (GET_CODE (base) == PLUS) /* (R + i) */
+    {
+      int disp = INTVAL (XEXP (base, 1));
+
+      if (AVR_TINY)
+        return avr_out_movsi_r_mr_reg_disp_tiny (insn, op, l);
+
+      if (disp > MAX_LD_OFFSET (GET_MODE (src)))
+	{
+	  if (REGNO (XEXP (base, 0)) != REG_Y)
+	    fatal_insn ("incorrect insn:",insn);
+
+	  if (disp <= 63 + MAX_LD_OFFSET (GET_MODE (src)))
+	    return *l = 6, ("adiw r28,%o1-60" CR_TAB
+			    "ldd %A0,Y+60"    CR_TAB
+			    "ldd %B0,Y+61"    CR_TAB
+			    "ldd %C0,Y+62"    CR_TAB
+			    "ldd %D0,Y+63"    CR_TAB
+			    "sbiw r28,%o1-60");
+
+	  return *l = 8, ("subi r28,lo8(-%o1)" CR_TAB
+			  "sbci r29,hi8(-%o1)" CR_TAB
+			  "ld %A0,Y"           CR_TAB
+			  "ldd %B0,Y+1"        CR_TAB
+			  "ldd %C0,Y+2"        CR_TAB
+			  "ldd %D0,Y+3"        CR_TAB
+			  "subi r28,lo8(%o1)"  CR_TAB
+			  "sbci r29,hi8(%o1)");
+	}
+
+      reg_base = true_regnum (XEXP (base, 0));
+      if (reg_base == REG_X)
+	{
+	  /* R = (X + d) */
+	  if (reg_dest == REG_X)
+	    {
+	      *l = 7;
+	      /* "ld r26,-X" is undefined */
+	      return ("adiw r26,%o1+3"    CR_TAB
+		      "ld r29,X"          CR_TAB
+		      "ld r28,-X"         CR_TAB
+		      "ld __tmp_reg__,-X" CR_TAB
+		      "sbiw r26,1"        CR_TAB
+		      "ld r26,X"          CR_TAB
+		      "mov r27,__tmp_reg__");
+	    }
+	  *l = 6;
+	  if (reg_dest == REG_X - 2)
+	    return ("adiw r26,%o1"      CR_TAB
+		    "ld r24,X+"         CR_TAB
+		    "ld r25,X+"         CR_TAB
+		    "ld __tmp_reg__,X+" CR_TAB
+		    "ld r27,X"          CR_TAB
+		    "mov r26,__tmp_reg__");
+
+	  return ("adiw r26,%o1" CR_TAB
+		  "ld %A0,X+"    CR_TAB
+		  "ld %B0,X+"    CR_TAB
+		  "ld %C0,X+"    CR_TAB
+		  "ld %D0,X"     CR_TAB
+		  "sbiw r26,%o1+3");
+	}
+      if (reg_dest == reg_base)
+        return *l=5, ("ldd %D0,%D1"          CR_TAB
+                      "ldd %C0,%C1"          CR_TAB
+                      "ldd __tmp_reg__,%B1"  CR_TAB
+                      "ldd %A0,%A1"          CR_TAB
+                      "mov %B0,__tmp_reg__");
+      else if (reg_dest == reg_base - 2)
+        return *l=5, ("ldd %A0,%A1"          CR_TAB
+                      "ldd %B0,%B1"          CR_TAB
+                      "ldd __tmp_reg__,%C1"  CR_TAB
+                      "ldd %D0,%D1"          CR_TAB
+                      "mov %C0,__tmp_reg__");
+      return *l=4, ("ldd %A0,%A1" CR_TAB
+                    "ldd %B0,%B1" CR_TAB
+                    "ldd %C0,%C1" CR_TAB
+                    "ldd %D0,%D1");
+    }
+  else if (GET_CODE (base) == PRE_DEC) /* (--R) */
+    return *l=4, ("ld %D0,%1" CR_TAB
+		  "ld %C0,%1" CR_TAB
+		  "ld %B0,%1" CR_TAB
+		  "ld %A0,%1");
+  else if (GET_CODE (base) == POST_INC) /* (R++) */
+    return *l=4, ("ld %A0,%1" CR_TAB
+		  "ld %B0,%1" CR_TAB
+		  "ld %C0,%1" CR_TAB
+		  "ld %D0,%1");
+  else if (CONSTANT_ADDRESS_P (base))
+    {
+      if (io_address_operand (base, SImode))
+        {
+          *l = 4;
+          return ("in %A0,%i1"   CR_TAB
+                  "in %B0,%i1+1" CR_TAB
+                  "in %C0,%i1+2" CR_TAB
+                  "in %D0,%i1+3");
+        }
+      else
+        {
+          *l = AVR_TINY ? 4 : 8;
+          return ("lds %A0,%m1"   CR_TAB
+                  "lds %B0,%m1+1" CR_TAB
+                  "lds %C0,%m1+2" CR_TAB
+                  "lds %D0,%m1+3");
+        }
+    }
+
+  fatal_insn ("unknown move insn:",insn);
+  return "";
+}
+
+static const char*
+avr_out_movsi_mr_r_reg_no_disp_tiny (rtx_insn *insn, rtx op[], int *l)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (dest, 0);
+  int reg_base = true_regnum (base);
+  int reg_src = true_regnum (src);
+
+  if (reg_base == reg_src)
+    {
+      /* "ld r26,-X" is undefined */
+      if (reg_unused_after (insn, base))
+        {
+          return *l = 7, ("mov __tmp_reg__, %B1"  CR_TAB
+			  "st %0,%A1"             CR_TAB
+			  TINY_ADIW (%E0, %F0, 1) CR_TAB
+			  "st %0+,__tmp_reg__"    CR_TAB
+			  "st %0+,%C1"            CR_TAB
+			  "st %0+,%D1");
+        }
+      else
+        {
+          return *l = 9, ("mov __tmp_reg__, %B1"  CR_TAB
+			  "st %0,%A1"             CR_TAB
+			  TINY_ADIW (%E0, %F0, 1) CR_TAB
+			  "st %0+,__tmp_reg__"    CR_TAB
+			  "st %0+,%C1"            CR_TAB
+			  "st %0+,%D1"            CR_TAB
+			  TINY_SBIW (%E0, %F0, 3));
+        }
+    }
+  else if (reg_base == reg_src + 2)
+    {
+      if (reg_unused_after (insn, base))
+	return *l = 7, ("mov __zero_reg__,%C1" CR_TAB
+                        "mov __tmp_reg__,%D1"  CR_TAB
+                        "st %0+,%A1"           CR_TAB
+                        "st %0+,%B1"           CR_TAB
+                        "st %0+,__zero_reg__"  CR_TAB
+                        "st %0,__tmp_reg__"    CR_TAB
+                        "clr __zero_reg__");
+      else
+	return *l = 9, ("mov __zero_reg__,%C1" CR_TAB
+			"mov __tmp_reg__,%D1"  CR_TAB
+			"st %0+,%A1"           CR_TAB
+			"st %0+,%B1"           CR_TAB
+			"st %0+,__zero_reg__"  CR_TAB
+			"st %0,__tmp_reg__"    CR_TAB
+			"clr __zero_reg__"     CR_TAB
+			TINY_SBIW (%E0, %F0, 3));
+    }
+
+  return *l = 6, ("st %0+,%A1" CR_TAB
+		  "st %0+,%B1" CR_TAB
+		  "st %0+,%C1" CR_TAB
+		  "st %0,%D1"  CR_TAB
+		  TINY_SBIW (%E0, %F0, 3));
+}
+
+static const char*
+avr_out_movsi_mr_r_reg_disp_tiny (rtx op[], int *l)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (dest, 0);
+  int reg_base = REGNO (XEXP (base, 0));
+  int reg_src =true_regnum (src);
+
+  if (reg_base == reg_src)
+    {
+      *l = 11;
+      return ("mov __tmp_reg__,%A2"        CR_TAB
+              "mov __zero_reg__,%B2"       CR_TAB
+              TINY_ADIW (%I0, %J0, %o0)    CR_TAB
+              "st %b0+,__tmp_reg__"        CR_TAB
+              "st %b0+,__zero_reg__"       CR_TAB
+              "st %b0+,%C2"                CR_TAB
+              "st %b0,%D2"                 CR_TAB
+              "clr __zero_reg__"           CR_TAB
+              TINY_SBIW (%I0, %J0, %o0+3));
+    }
+  else if (reg_src == reg_base - 2)
+    {
+      *l = 11;
+      return ("mov __tmp_reg__,%C2"         CR_TAB
+              "mov __zero_reg__,%D2"        CR_TAB
+              TINY_ADIW (%I0, %J0, %o0)     CR_TAB
+              "st %b0+,%A0"                 CR_TAB
+              "st %b0+,%B0"                 CR_TAB
+              "st %b0+,__tmp_reg__"         CR_TAB
+              "st %b0,__zero_reg__"         CR_TAB
+              "clr __zero_reg__"            CR_TAB
+              TINY_SBIW (%I0, %J0, %o0+3));
+    }
+  *l = 8;
+  return (TINY_ADIW (%I0, %J0, %o0)     CR_TAB
+          "st %b0+,%A1"                 CR_TAB
+          "st %b0+,%B1"                 CR_TAB
+          "st %b0+,%C1"                 CR_TAB
+          "st %b0,%D1"                  CR_TAB
+          TINY_SBIW (%I0, %J0, %o0+3));
+}
+
+static const char*
+out_movsi_mr_r (rtx_insn *insn, rtx op[], int *l)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (dest, 0);
+  int reg_base = true_regnum (base);
+  int reg_src = true_regnum (src);
+  int tmp;
+
+  if (!l)
+    l = &tmp;
+
+  if (CONSTANT_ADDRESS_P (base))
+    {
+      if (io_address_operand (base, SImode))
+        {
+          return *l=4,("out %i0, %A1"  CR_TAB
+                       "out %i0+1,%B1" CR_TAB
+                       "out %i0+2,%C1" CR_TAB
+                       "out %i0+3,%D1");
+        }
+      else
+        {
+          *l = AVR_TINY ? 4 : 8;
+          return ("sts %m0,%A1"   CR_TAB
+                  "sts %m0+1,%B1" CR_TAB
+                  "sts %m0+2,%C1" CR_TAB
+                  "sts %m0+3,%D1");
+        }
+    }
+
+  if (reg_base > 0)                 /* (r) */
+    {
+      if (AVR_TINY)
+        return avr_out_movsi_mr_r_reg_no_disp_tiny (insn, op, l);
+
+      if (reg_base == REG_X)                /* (R26) */
+        {
+          if (reg_src == REG_X)
+            {
+	      /* "st X+,r26" is undefined */
+              if (reg_unused_after (insn, base))
+		return *l=6, ("mov __tmp_reg__,r27" CR_TAB
+			      "st X,r26"            CR_TAB
+			      "adiw r26,1"          CR_TAB
+			      "st X+,__tmp_reg__"   CR_TAB
+			      "st X+,r28"           CR_TAB
+			      "st X,r29");
+              else
+                return *l=7, ("mov __tmp_reg__,r27" CR_TAB
+			      "st X,r26"            CR_TAB
+			      "adiw r26,1"          CR_TAB
+			      "st X+,__tmp_reg__"   CR_TAB
+			      "st X+,r28"           CR_TAB
+			      "st X,r29"            CR_TAB
+			      "sbiw r26,3");
+            }
+          else if (reg_base == reg_src + 2)
+            {
+              if (reg_unused_after (insn, base))
+                return *l=7, ("mov __zero_reg__,%C1" CR_TAB
+                              "mov __tmp_reg__,%D1"  CR_TAB
+                              "st %0+,%A1"           CR_TAB
+                              "st %0+,%B1"           CR_TAB
+                              "st %0+,__zero_reg__"  CR_TAB
+                              "st %0,__tmp_reg__"    CR_TAB
+                              "clr __zero_reg__");
+              else
+                return *l=8, ("mov __zero_reg__,%C1" CR_TAB
+                              "mov __tmp_reg__,%D1"  CR_TAB
+                              "st %0+,%A1"           CR_TAB
+                              "st %0+,%B1"           CR_TAB
+                              "st %0+,__zero_reg__"  CR_TAB
+                              "st %0,__tmp_reg__"    CR_TAB
+                              "clr __zero_reg__"     CR_TAB
+                              "sbiw r26,3");
+            }
+          return *l=5, ("st %0+,%A1" CR_TAB
+                        "st %0+,%B1" CR_TAB
+                        "st %0+,%C1" CR_TAB
+                        "st %0,%D1"  CR_TAB
+                        "sbiw r26,3");
+        }
+      else
+        return *l=4, ("st %0,%A1"    CR_TAB
+		      "std %0+1,%B1" CR_TAB
+		      "std %0+2,%C1" CR_TAB
+		      "std %0+3,%D1");
+    }
+  else if (GET_CODE (base) == PLUS) /* (R + i) */
+    {
+      int disp = INTVAL (XEXP (base, 1));
+
+      if (AVR_TINY)
+        return avr_out_movsi_mr_r_reg_disp_tiny (op, l);
+
+      reg_base = REGNO (XEXP (base, 0));
+      if (disp > MAX_LD_OFFSET (GET_MODE (dest)))
+	{
+	  if (reg_base != REG_Y)
+	    fatal_insn ("incorrect insn:",insn);
+
+	  if (disp <= 63 + MAX_LD_OFFSET (GET_MODE (dest)))
+	    return *l = 6, ("adiw r28,%o0-60" CR_TAB
+			    "std Y+60,%A1"    CR_TAB
+			    "std Y+61,%B1"    CR_TAB
+			    "std Y+62,%C1"    CR_TAB
+			    "std Y+63,%D1"    CR_TAB
+			    "sbiw r28,%o0-60");
+
+	  return *l = 8, ("subi r28,lo8(-%o0)" CR_TAB
+			  "sbci r29,hi8(-%o0)" CR_TAB
+			  "st Y,%A1"           CR_TAB
+			  "std Y+1,%B1"        CR_TAB
+			  "std Y+2,%C1"        CR_TAB
+			  "std Y+3,%D1"        CR_TAB
+			  "subi r28,lo8(%o0)"  CR_TAB
+			  "sbci r29,hi8(%o0)");
+	}
+      if (reg_base == REG_X)
+	{
+	  /* (X + d) = R */
+	  if (reg_src == REG_X)
+	    {
+	      *l = 9;
+	      return ("mov __tmp_reg__,r26"  CR_TAB
+		      "mov __zero_reg__,r27" CR_TAB
+		      "adiw r26,%o0"         CR_TAB
+		      "st X+,__tmp_reg__"    CR_TAB
+		      "st X+,__zero_reg__"   CR_TAB
+		      "st X+,r28"            CR_TAB
+		      "st X,r29"             CR_TAB
+		      "clr __zero_reg__"     CR_TAB
+		      "sbiw r26,%o0+3");
+	    }
+	  else if (reg_src == REG_X - 2)
+	    {
+	      *l = 9;
+	      return ("mov __tmp_reg__,r26"  CR_TAB
+		      "mov __zero_reg__,r27" CR_TAB
+		      "adiw r26,%o0"         CR_TAB
+		      "st X+,r24"            CR_TAB
+		      "st X+,r25"            CR_TAB
+		      "st X+,__tmp_reg__"    CR_TAB
+		      "st X,__zero_reg__"    CR_TAB
+		      "clr __zero_reg__"     CR_TAB
+		      "sbiw r26,%o0+3");
+	    }
+	  *l = 6;
+	  return ("adiw r26,%o0" CR_TAB
+		  "st X+,%A1"    CR_TAB
+		  "st X+,%B1"    CR_TAB
+		  "st X+,%C1"    CR_TAB
+		  "st X,%D1"     CR_TAB
+		  "sbiw r26,%o0+3");
+	}
+      return *l=4, ("std %A0,%A1" CR_TAB
+		    "std %B0,%B1" CR_TAB
+		    "std %C0,%C1" CR_TAB
+		    "std %D0,%D1");
+    }
+  else if (GET_CODE (base) == PRE_DEC) /* (--R) */
+    return *l=4, ("st %0,%D1" CR_TAB
+		  "st %0,%C1" CR_TAB
+		  "st %0,%B1" CR_TAB
+		  "st %0,%A1");
+  else if (GET_CODE (base) == POST_INC) /* (R++) */
+    return *l=4, ("st %0,%A1" CR_TAB
+		  "st %0,%B1" CR_TAB
+		  "st %0,%C1" CR_TAB
+		  "st %0,%D1");
+  fatal_insn ("unknown move insn:",insn);
+  return "";
+}
+
+const char *
+output_movsisf (rtx_insn *insn, rtx operands[], int *l)
+{
+  int dummy;
+  rtx dest = operands[0];
+  rtx src = operands[1];
+  int *real_l = l;
+
+  if (avr_mem_flash_p (src)
+      || avr_mem_flash_p (dest))
+    {
+      return avr_out_lpm (insn, operands, real_l);
+    }
+
+  if (!l)
+    l = &dummy;
+
+  gcc_assert (GET_MODE_SIZE (GET_MODE (dest)) == 4);
+
+  if (REG_P (dest))
+    {
+      if (REG_P (src)) /* mov r,r */
+	{
+	  if (true_regnum (dest) > true_regnum (src))
+	    {
+	      if (AVR_HAVE_MOVW)
+		{
+		  *l = 2;
+		  return ("movw %C0,%C1" CR_TAB
+			  "movw %A0,%A1");
+		}
+	      *l = 4;
+	      return ("mov %D0,%D1" CR_TAB
+		      "mov %C0,%C1" CR_TAB
+		      "mov %B0,%B1" CR_TAB
+		      "mov %A0,%A1");
+	    }
+	  else
+	    {
+	      if (AVR_HAVE_MOVW)
+		{
+		  *l = 2;
+		  return ("movw %A0,%A1" CR_TAB
+			  "movw %C0,%C1");
+		}
+	      *l = 4;
+	      return ("mov %A0,%A1" CR_TAB
+		      "mov %B0,%B1" CR_TAB
+		      "mov %C0,%C1" CR_TAB
+		      "mov %D0,%D1");
+	    }
+	}
+      else if (CONSTANT_P (src))
+	{
+          return output_reload_insisf (operands, NULL_RTX, real_l);
+        }
+      else if (MEM_P (src))
+	return out_movsi_r_mr (insn, operands, real_l); /* mov r,m */
+    }
+  else if (MEM_P (dest))
+    {
+      const char *templ;
+
+      if (src == CONST0_RTX (GET_MODE (dest)))
+        operands[1] = zero_reg_rtx;
+
+      templ = out_movsi_mr_r (insn, operands, real_l);
+
+      if (!real_l)
+	output_asm_insn (templ, operands);
+
+      operands[1] = src;
+      return "";
+    }
+  fatal_insn ("invalid insn:", insn);
+  return "";
+}
+
+
+/* Handle loads of 24-bit types from memory to register.  */
+
+static const char*
+avr_out_load_psi_reg_no_disp_tiny (rtx_insn *insn, rtx *op, int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (src, 0);
+  int reg_dest = true_regnum (dest);
+  int reg_base = true_regnum (base);
+
+  if (reg_base == reg_dest)
+    {
+      return avr_asm_len (TINY_ADIW (%E1, %F1, 2)   CR_TAB
+                          "ld %C0,%1"               CR_TAB
+                          "ld __tmp_reg__,-%1"      CR_TAB
+                          TINY_SBIW (%E1, %F1, 1)   CR_TAB
+                          "ld %A0,%1"               CR_TAB
+                          "mov %B0,__tmp_reg__", op, plen, -8);
+    }
+  else
+    {
+      avr_asm_len ("ld %A0,%1+"  CR_TAB
+		   "ld %B0,%1+"  CR_TAB
+		   "ld %C0,%1", op, plen, -3);
+
+      if (reg_dest != reg_base - 2
+          && !reg_unused_after (insn, base))
+        {
+          avr_asm_len (TINY_SBIW (%E1, %F1, 2), op, plen, 2);
+        }
+      return "";
+    }
+}
+
+static const char*
+avr_out_load_psi_reg_disp_tiny (rtx_insn *insn, rtx *op, int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (src, 0);
+  int reg_dest = true_regnum (dest);
+  int reg_base = true_regnum (base);
+
+  reg_base = true_regnum (XEXP (base, 0));
+  if (reg_base == reg_dest)
+    {
+      return avr_asm_len (TINY_ADIW (%I1, %J1, %o1+2) CR_TAB
+                          "ld %C0,%b1"                CR_TAB
+                          "ld __tmp_reg__,-%b1"       CR_TAB
+                          TINY_SBIW (%I1, %J1, 1)     CR_TAB
+                          "ld %A0,%b1"                CR_TAB
+                          "mov %B0,__tmp_reg__", op, plen, -8);
+    }
+  else
+    {
+      avr_asm_len (TINY_ADIW (%I1, %J1, %o1)   CR_TAB
+                   "ld %A0,%b1+"               CR_TAB
+                   "ld %B0,%b1+"               CR_TAB
+                   "ld %C0,%b1", op, plen, -5);
+
+      if (reg_dest != reg_base - 2
+          && !reg_unused_after (insn, XEXP (base, 0)))
+        avr_asm_len (TINY_SBIW (%I1, %J1, %o1+2), op, plen, 2);
+
+      return "";
+    }
+}
+
+static const char*
+avr_out_load_psi (rtx_insn *insn, rtx *op, int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (src, 0);
+  int reg_dest = true_regnum (dest);
+  int reg_base = true_regnum (base);
+
+  if (reg_base > 0)
+    {
+      if (AVR_TINY)
+        return avr_out_load_psi_reg_no_disp_tiny (insn, op, plen);
+
+      if (reg_base == REG_X)        /* (R26) */
+        {
+          if (reg_dest == REG_X)
+            /* "ld r26,-X" is undefined */
+            return avr_asm_len ("adiw r26,2"        CR_TAB
+                                "ld r28,X"          CR_TAB
+                                "ld __tmp_reg__,-X" CR_TAB
+                                "sbiw r26,1"        CR_TAB
+                                "ld r26,X"          CR_TAB
+                                "mov r27,__tmp_reg__", op, plen, -6);
+          else
+            {
+              avr_asm_len ("ld %A0,X+" CR_TAB
+                           "ld %B0,X+" CR_TAB
+                           "ld %C0,X", op, plen, -3);
+
+              if (reg_dest != REG_X - 2
+                  && !reg_unused_after (insn, base))
+                {
+                  avr_asm_len ("sbiw r26,2", op, plen, 1);
+                }
+
+              return "";
+            }
+        }
+      else /* reg_base != REG_X */
+        {
+          if (reg_dest == reg_base)
+            return avr_asm_len ("ldd %C0,%1+2"          CR_TAB
+                                "ldd __tmp_reg__,%1+1"  CR_TAB
+                                "ld  %A0,%1"            CR_TAB
+                                "mov %B0,__tmp_reg__", op, plen, -4);
+          else
+            return avr_asm_len ("ld  %A0,%1"    CR_TAB
+                                "ldd %B0,%1+1"  CR_TAB
+                                "ldd %C0,%1+2", op, plen, -3);
+        }
+    }
+  else if (GET_CODE (base) == PLUS) /* (R + i) */
+    {
+      int disp = INTVAL (XEXP (base, 1));
+
+      if (AVR_TINY)
+        return avr_out_load_psi_reg_disp_tiny (insn, op, plen);
+
+      if (disp > MAX_LD_OFFSET (GET_MODE (src)))
+        {
+          if (REGNO (XEXP (base, 0)) != REG_Y)
+            fatal_insn ("incorrect insn:",insn);
+
+          if (disp <= 63 + MAX_LD_OFFSET (GET_MODE (src)))
+            return avr_asm_len ("adiw r28,%o1-61" CR_TAB
+                                "ldd %A0,Y+61"    CR_TAB
+                                "ldd %B0,Y+62"    CR_TAB
+                                "ldd %C0,Y+63"    CR_TAB
+                                "sbiw r28,%o1-61", op, plen, -5);
+
+          return avr_asm_len ("subi r28,lo8(-%o1)" CR_TAB
+                              "sbci r29,hi8(-%o1)" CR_TAB
+                              "ld  %A0,Y"          CR_TAB
+                              "ldd %B0,Y+1"        CR_TAB
+                              "ldd %C0,Y+2"        CR_TAB
+                              "subi r28,lo8(%o1)"  CR_TAB
+                              "sbci r29,hi8(%o1)", op, plen, -7);
+        }
+
+      reg_base = true_regnum (XEXP (base, 0));
+      if (reg_base == REG_X)
+        {
+          /* R = (X + d) */
+          if (reg_dest == REG_X)
+            {
+              /* "ld r26,-X" is undefined */
+              return avr_asm_len ("adiw r26,%o1+2"     CR_TAB
+                                  "ld  r28,X"          CR_TAB
+                                  "ld  __tmp_reg__,-X" CR_TAB
+                                  "sbiw r26,1"         CR_TAB
+                                  "ld  r26,X"          CR_TAB
+                                  "mov r27,__tmp_reg__", op, plen, -6);
+            }
+
+          avr_asm_len ("adiw r26,%o1" CR_TAB
+                       "ld %A0,X+"    CR_TAB
+                       "ld %B0,X+"    CR_TAB
+                       "ld %C0,X", op, plen, -4);
+
+          if (reg_dest != REG_W
+              && !reg_unused_after (insn, XEXP (base, 0)))
+            avr_asm_len ("sbiw r26,%o1+2", op, plen, 1);
+
+          return "";
+        }
+
+      if (reg_dest == reg_base)
+        return avr_asm_len ("ldd %C0,%C1" CR_TAB
+                            "ldd __tmp_reg__,%B1"  CR_TAB
+                            "ldd %A0,%A1" CR_TAB
+                            "mov %B0,__tmp_reg__", op, plen, -4);
+
+      return avr_asm_len ("ldd %A0,%A1" CR_TAB
+                          "ldd %B0,%B1" CR_TAB
+                          "ldd %C0,%C1", op, plen, -3);
+    }
+  else if (GET_CODE (base) == PRE_DEC) /* (--R) */
+    return avr_asm_len ("ld %C0,%1" CR_TAB
+                        "ld %B0,%1" CR_TAB
+                        "ld %A0,%1", op, plen, -3);
+  else if (GET_CODE (base) == POST_INC) /* (R++) */
+    return avr_asm_len ("ld %A0,%1" CR_TAB
+                        "ld %B0,%1" CR_TAB
+                        "ld %C0,%1", op, plen, -3);
+
+  else if (CONSTANT_ADDRESS_P (base))
+    {
+      int n_words = AVR_TINY ? 3 : 6;
+      return avr_asm_len ("lds %A0,%m1" CR_TAB
+                          "lds %B0,%m1+1" CR_TAB
+                          "lds %C0,%m1+2", op, plen , -n_words);
+    }
+
+  fatal_insn ("unknown move insn:",insn);
+  return "";
+}
+
+
+static const char*
+avr_out_store_psi_reg_no_disp_tiny (rtx_insn *insn, rtx *op, int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (dest, 0);
+  int reg_base = true_regnum (base);
+  int reg_src = true_regnum (src);
+
+  if (reg_base == reg_src)
+    {
+      avr_asm_len ("st %0,%A1"              CR_TAB
+                   "mov __tmp_reg__,%B1"    CR_TAB
+                   TINY_ADIW (%E0, %F0, 1)  CR_TAB /* st X+, r27 is undefined */
+                   "st %0+,__tmp_reg__"     CR_TAB
+                   "st %0,%C1", op, plen, -6);
+
+    }
+  else if (reg_src == reg_base - 2)
+    {
+      avr_asm_len ("st %0,%A1"              CR_TAB
+                   "mov __tmp_reg__,%C1"    CR_TAB
+                   TINY_ADIW (%E0, %F0, 1)  CR_TAB
+                   "st %0+,%B1"             CR_TAB
+                   "st %0,__tmp_reg__", op, plen, 6);
+    }
+  else
+    {
+      avr_asm_len ("st %0+,%A1"  CR_TAB
+                   "st %0+,%B1" CR_TAB
+                   "st %0,%C1", op, plen, -3);
+    }
+
+  if (!reg_unused_after (insn, base))
+    avr_asm_len (TINY_SBIW (%E0, %F0, 2), op, plen, 2);
+
+  return "";
+}
+
+static const char*
+avr_out_store_psi_reg_disp_tiny (rtx_insn *insn, rtx *op, int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (dest, 0);
+  int reg_base = REGNO (XEXP (base, 0));
+  int reg_src = true_regnum (src);
+
+  if (reg_src == reg_base)
+    avr_asm_len ("mov __tmp_reg__,%A1"          CR_TAB
+                 "mov __zero_reg__,%B1"         CR_TAB
+                 TINY_ADIW (%I0, %J0, %o0)      CR_TAB
+                 "st %b0+,__tmp_reg__"          CR_TAB
+                 "st %b0+,__zero_reg__"         CR_TAB
+                 "st %b0,%C1"                   CR_TAB
+                 "clr __zero_reg__", op, plen, -8);
+  else if (reg_src == reg_base - 2)
+    avr_asm_len ("mov __tmp_reg__,%C1"          CR_TAB
+                 TINY_ADIW (%I0, %J0, %o0)      CR_TAB
+                 "st %b0+,%A1"                  CR_TAB
+                 "st %b0+,%B1"                  CR_TAB
+                 "st %b0,__tmp_reg__", op, plen, -6);
+  else
+    avr_asm_len (TINY_ADIW (%I0, %J0, %o0)      CR_TAB
+                 "st %b0+,%A1"                  CR_TAB
+                 "st %b0+,%B1"                  CR_TAB
+                 "st %b0,%C1", op, plen, -5);
+
+  if (!reg_unused_after (insn, XEXP (base, 0)))
+    avr_asm_len (TINY_SBIW (%I0, %J0, %o0+2), op, plen, 2);
+
+  return "";
+}
+
+/* Handle store of 24-bit type from register or zero to memory.  */
+
+static const char*
+avr_out_store_psi (rtx_insn *insn, rtx *op, int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (dest, 0);
+  int reg_base = true_regnum (base);
+
+  if (CONSTANT_ADDRESS_P (base))
+    {
+      int n_words = AVR_TINY ? 3 : 6;
+      return avr_asm_len ("sts %m0,%A1"   CR_TAB
+                          "sts %m0+1,%B1" CR_TAB
+                          "sts %m0+2,%C1", op, plen, -n_words);
+    }
+
+  if (reg_base > 0)                 /* (r) */
+    {
+      if (AVR_TINY)
+        return avr_out_store_psi_reg_no_disp_tiny (insn, op, plen);
+
+      if (reg_base == REG_X)        /* (R26) */
+        {
+          gcc_assert (!reg_overlap_mentioned_p (base, src));
+
+          avr_asm_len ("st %0+,%A1"  CR_TAB
+                       "st %0+,%B1" CR_TAB
+                       "st %0,%C1", op, plen, -3);
+
+          if (!reg_unused_after (insn, base))
+            avr_asm_len ("sbiw r26,2", op, plen, 1);
+
+          return "";
+        }
+      else
+        return avr_asm_len ("st %0,%A1"    CR_TAB
+                            "std %0+1,%B1" CR_TAB
+                            "std %0+2,%C1", op, plen, -3);
+    }
+  else if (GET_CODE (base) == PLUS) /* (R + i) */
+    {
+      int disp = INTVAL (XEXP (base, 1));
+
+      if (AVR_TINY)
+        return avr_out_store_psi_reg_disp_tiny (insn, op, plen);
+
+      reg_base = REGNO (XEXP (base, 0));
+
+      if (disp > MAX_LD_OFFSET (GET_MODE (dest)))
+        {
+          if (reg_base != REG_Y)
+            fatal_insn ("incorrect insn:",insn);
+
+          if (disp <= 63 + MAX_LD_OFFSET (GET_MODE (dest)))
+            return avr_asm_len ("adiw r28,%o0-61" CR_TAB
+                                "std Y+61,%A1"    CR_TAB
+                                "std Y+62,%B1"    CR_TAB
+                                "std Y+63,%C1"    CR_TAB
+                                "sbiw r28,%o0-61", op, plen, -5);
+
+          return avr_asm_len ("subi r28,lo8(-%o0)" CR_TAB
+                              "sbci r29,hi8(-%o0)" CR_TAB
+                              "st Y,%A1"           CR_TAB
+                              "std Y+1,%B1"        CR_TAB
+                              "std Y+2,%C1"        CR_TAB
+                              "subi r28,lo8(%o0)"  CR_TAB
+                              "sbci r29,hi8(%o0)", op, plen, -7);
+        }
+      if (reg_base == REG_X)
+        {
+          /* (X + d) = R */
+          gcc_assert (!reg_overlap_mentioned_p (XEXP (base, 0), src));
+
+          avr_asm_len ("adiw r26,%o0" CR_TAB
+                       "st X+,%A1"    CR_TAB
+                       "st X+,%B1"    CR_TAB
+                       "st X,%C1", op, plen, -4);
+
+          if (!reg_unused_after (insn, XEXP (base, 0)))
+            avr_asm_len ("sbiw r26,%o0+2", op, plen, 1);
+
+          return "";
+        }
+
+      return avr_asm_len ("std %A0,%A1" CR_TAB
+                          "std %B0,%B1" CR_TAB
+                          "std %C0,%C1", op, plen, -3);
+    }
+  else if (GET_CODE (base) == PRE_DEC) /* (--R) */
+    return avr_asm_len ("st %0,%C1" CR_TAB
+                        "st %0,%B1" CR_TAB
+                        "st %0,%A1", op, plen, -3);
+  else if (GET_CODE (base) == POST_INC) /* (R++) */
+    return avr_asm_len ("st %0,%A1" CR_TAB
+                        "st %0,%B1" CR_TAB
+                        "st %0,%C1", op, plen, -3);
+
+  fatal_insn ("unknown move insn:",insn);
+  return "";
+}
+
+
+/* Move around 24-bit stuff.  */
+
+const char *
+avr_out_movpsi (rtx_insn *insn, rtx *op, int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+
+  if (avr_mem_flash_p (src)
+      || avr_mem_flash_p (dest))
+    {
+      return avr_out_lpm (insn, op, plen);
+    }
+
+  if (register_operand (dest, VOIDmode))
+    {
+      if (register_operand (src, VOIDmode)) /* mov r,r */
+        {
+          if (true_regnum (dest) > true_regnum (src))
+            {
+              avr_asm_len ("mov %C0,%C1", op, plen, -1);
+
+              if (AVR_HAVE_MOVW)
+                return avr_asm_len ("movw %A0,%A1", op, plen, 1);
+              else
+                return avr_asm_len ("mov %B0,%B1"  CR_TAB
+                                    "mov %A0,%A1", op, plen, 2);
+            }
+          else
+            {
+              if (AVR_HAVE_MOVW)
+                avr_asm_len ("movw %A0,%A1", op, plen, -1);
+              else
+                avr_asm_len ("mov %A0,%A1"  CR_TAB
+                             "mov %B0,%B1", op, plen, -2);
+
+              return avr_asm_len ("mov %C0,%C1", op, plen, 1);
+            }
+        }
+      else if (CONSTANT_P (src))
+        {
+          return avr_out_reload_inpsi (op, NULL_RTX, plen);
+        }
+      else if (MEM_P (src))
+        return avr_out_load_psi (insn, op, plen); /* mov r,m */
+    }
+  else if (MEM_P (dest))
+    {
+      rtx xop[2];
+
+      xop[0] = dest;
+      xop[1] = src == CONST0_RTX (GET_MODE (dest)) ? zero_reg_rtx : src;
+
+      return avr_out_store_psi (insn, xop, plen);
+    }
+
+  fatal_insn ("invalid insn:", insn);
+  return "";
+}
+
+static const char*
+avr_out_movqi_mr_r_reg_disp_tiny (rtx_insn *insn, rtx op[], int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx x = XEXP (dest, 0);
+
+  if (reg_overlap_mentioned_p (src, XEXP (x, 0)))
+    {
+      avr_asm_len ("mov __tmp_reg__,%1"      CR_TAB
+                   TINY_ADIW (%I0, %J0, %o0) CR_TAB
+                   "st %b0,__tmp_reg__", op, plen, -4);
+    }
+  else
+    {
+      avr_asm_len (TINY_ADIW (%I0, %J0, %o0) CR_TAB
+                   "st %b0,%1", op, plen, -3);
+    }
+
+  if (!reg_unused_after (insn, XEXP (x, 0)))
+    avr_asm_len (TINY_SBIW (%I0, %J0, %o0), op, plen, 2);
+
+  return "";
+}
+
+static const char*
+out_movqi_mr_r (rtx_insn *insn, rtx op[], int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx x = XEXP (dest, 0);
+
+  if (CONSTANT_ADDRESS_P (x))
+    {
+      int n_words = AVR_TINY ? 1 : 2;
+      return io_address_operand (x, QImode)
+        ? avr_asm_len ("out %i0,%1", op, plen, -1)
+        : avr_asm_len ("sts %m0,%1", op, plen, -n_words);
+    }
+  else if (GET_CODE (x) == PLUS
+           && REG_P (XEXP (x, 0))
+           && CONST_INT_P (XEXP (x, 1)))
+    {
+      /* memory access by reg+disp */
+
+      int disp = INTVAL (XEXP (x, 1));
+
+      if (AVR_TINY)
+        return avr_out_movqi_mr_r_reg_disp_tiny (insn, op, plen);
+
+      if (disp - GET_MODE_SIZE (GET_MODE (dest)) >= 63)
+        {
+          if (REGNO (XEXP (x, 0)) != REG_Y)
+            fatal_insn ("incorrect insn:",insn);
+
+          if (disp <= 63 + MAX_LD_OFFSET (GET_MODE (dest)))
+            return avr_asm_len ("adiw r28,%o0-63" CR_TAB
+                                "std Y+63,%1"     CR_TAB
+                                "sbiw r28,%o0-63", op, plen, -3);
+
+          return avr_asm_len ("subi r28,lo8(-%o0)" CR_TAB
+                              "sbci r29,hi8(-%o0)" CR_TAB
+                              "st Y,%1"            CR_TAB
+                              "subi r28,lo8(%o0)"  CR_TAB
+                              "sbci r29,hi8(%o0)", op, plen, -5);
+        }
+      else if (REGNO (XEXP (x, 0)) == REG_X)
+        {
+          if (reg_overlap_mentioned_p (src, XEXP (x, 0)))
+            {
+              avr_asm_len ("mov __tmp_reg__,%1" CR_TAB
+                           "adiw r26,%o0"       CR_TAB
+                           "st X,__tmp_reg__", op, plen, -3);
+            }
+          else
+            {
+              avr_asm_len ("adiw r26,%o0" CR_TAB
+                           "st X,%1", op, plen, -2);
+            }
+
+          if (!reg_unused_after (insn, XEXP (x, 0)))
+            avr_asm_len ("sbiw r26,%o0", op, plen, 1);
+
+          return "";
+        }
+
+      return avr_asm_len ("std %0,%1", op, plen, -1);
+    }
+
+  return avr_asm_len ("st %0,%1", op, plen, -1);
+}
+
+
+/* Helper for the next function for XMEGA.  It does the same
+   but with low byte first.  */
+
+static const char*
+avr_out_movhi_mr_r_xmega (rtx_insn *insn, rtx op[], int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (dest, 0);
+  int reg_base = true_regnum (base);
+  int reg_src = true_regnum (src);
+
+  /* "volatile" forces writing low byte first, even if less efficient,
+     for correct operation with 16-bit I/O registers like SP.  */
+  int mem_volatile_p = MEM_VOLATILE_P (dest);
+
+  if (CONSTANT_ADDRESS_P (base))
+    {
+      return io_address_operand (base, HImode)
+        ? avr_asm_len ("out %i0,%A1" CR_TAB
+                       "out %i0+1,%B1", op, plen, -2)
+
+        : avr_asm_len ("sts %m0,%A1" CR_TAB
+                       "sts %m0+1,%B1", op, plen, -4);
+    }
+
+  if (reg_base > 0)
+    {
+      if (reg_base != REG_X)
+        return avr_asm_len ("st %0,%A1" CR_TAB
+                            "std %0+1,%B1", op, plen, -2);
+
+      if (reg_src == REG_X)
+        /* "st X+,r26" and "st -X,r26" are undefined.  */
+        avr_asm_len ("mov __tmp_reg__,r27" CR_TAB
+                     "st X,r26"            CR_TAB
+                     "adiw r26,1"          CR_TAB
+                     "st X,__tmp_reg__", op, plen, -4);
+      else
+        avr_asm_len ("st X+,%A1" CR_TAB
+                     "st X,%B1", op, plen, -2);
+
+      return reg_unused_after (insn, base)
+        ? ""
+        : avr_asm_len ("sbiw r26,1", op, plen, 1);
+    }
+  else if (GET_CODE (base) == PLUS)
+    {
+      int disp = INTVAL (XEXP (base, 1));
+      reg_base = REGNO (XEXP (base, 0));
+      if (disp > MAX_LD_OFFSET (GET_MODE (dest)))
+        {
+          if (reg_base != REG_Y)
+            fatal_insn ("incorrect insn:",insn);
+
+          return disp <= 63 + MAX_LD_OFFSET (GET_MODE (dest))
+            ? avr_asm_len ("adiw r28,%o0-62" CR_TAB
+                           "std Y+62,%A1"    CR_TAB
+                           "std Y+63,%B1"    CR_TAB
+                           "sbiw r28,%o0-62", op, plen, -4)
+
+            : avr_asm_len ("subi r28,lo8(-%o0)" CR_TAB
+                           "sbci r29,hi8(-%o0)" CR_TAB
+                           "st Y,%A1"           CR_TAB
+                           "std Y+1,%B1"        CR_TAB
+                           "subi r28,lo8(%o0)"  CR_TAB
+                           "sbci r29,hi8(%o0)", op, plen, -6);
+        }
+
+      if (reg_base != REG_X)
+        return avr_asm_len ("std %A0,%A1" CR_TAB
+                            "std %B0,%B1", op, plen, -2);
+      /* (X + d) = R */
+      return reg_src == REG_X
+        ? avr_asm_len ("mov __tmp_reg__,r26"  CR_TAB
+                       "mov __zero_reg__,r27" CR_TAB
+                       "adiw r26,%o0"         CR_TAB
+                       "st X+,__tmp_reg__"    CR_TAB
+                       "st X,__zero_reg__"    CR_TAB
+                       "clr __zero_reg__"     CR_TAB
+                       "sbiw r26,%o0+1", op, plen, -7)
+
+        : avr_asm_len ("adiw r26,%o0" CR_TAB
+                       "st X+,%A1"    CR_TAB
+                       "st X,%B1"     CR_TAB
+                       "sbiw r26,%o0+1", op, plen, -4);
+    }
+  else if (GET_CODE (base) == PRE_DEC) /* (--R) */
+    {
+      if (!mem_volatile_p)
+        return avr_asm_len ("st %0,%B1" CR_TAB
+                            "st %0,%A1", op, plen, -2);
+
+      return REGNO (XEXP (base, 0)) == REG_X
+        ? avr_asm_len ("sbiw r26,2"  CR_TAB
+                       "st X+,%A1"   CR_TAB
+                       "st X,%B1"    CR_TAB
+                       "sbiw r26,1", op, plen, -4)
+
+        : avr_asm_len ("sbiw %r0,2"  CR_TAB
+                       "st %p0,%A1"  CR_TAB
+                       "std %p0+1,%B1", op, plen, -3);
+    }
+  else if (GET_CODE (base) == POST_INC) /* (R++) */
+    {
+      return avr_asm_len ("st %0,%A1"  CR_TAB
+                          "st %0,%B1", op, plen, -2);
+
+    }
+  fatal_insn ("unknown move insn:",insn);
+  return "";
+}
+
+static const char*
+avr_out_movhi_mr_r_reg_no_disp_tiny (rtx_insn *insn, rtx op[], int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (dest, 0);
+  int reg_base = true_regnum (base);
+  int reg_src = true_regnum (src);
+  int mem_volatile_p = MEM_VOLATILE_P (dest);
+
+  if (reg_base == reg_src)
+    {
+      return !mem_volatile_p && reg_unused_after (insn, src)
+        ? avr_asm_len ("mov __tmp_reg__,%B1"   CR_TAB
+                       "st %0,%A1"             CR_TAB
+                       TINY_ADIW (%E0, %F0, 1) CR_TAB
+                       "st %0,__tmp_reg__", op, plen, -5)
+        : avr_asm_len ("mov __tmp_reg__,%B1"   CR_TAB
+                       TINY_ADIW (%E0, %F0, 1) CR_TAB
+                       "st %0,__tmp_reg__"     CR_TAB
+                       TINY_SBIW (%E0, %F0, 1) CR_TAB
+                       "st %0, %A1", op, plen, -7);
+    }
+
+  return !mem_volatile_p && reg_unused_after (insn, base)
+    ? avr_asm_len ("st %0+,%A1" CR_TAB
+                   "st %0,%B1", op, plen, -2)
+    : avr_asm_len (TINY_ADIW (%E0, %F0, 1) CR_TAB
+                   "st %0,%B1"             CR_TAB
+                   "st -%0,%A1", op, plen, -4);
+}
+
+static const char*
+avr_out_movhi_mr_r_reg_disp_tiny (rtx_insn *insn, rtx op[], int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (dest, 0);
+  int reg_base = REGNO (XEXP (base, 0));
+  int reg_src = true_regnum (src);
+
+  if (reg_src == reg_base)
+    avr_asm_len ("mov __tmp_reg__,%A1"          CR_TAB
+                 "mov __zero_reg__,%B1"         CR_TAB
+                 TINY_ADIW (%I0, %J0, %o0+1)    CR_TAB
+                 "st %b0,__zero_reg__"          CR_TAB
+                 "st -%b0,__tmp_reg__"          CR_TAB
+                 "clr __zero_reg__", op, plen, -7);
+  else
+    avr_asm_len (TINY_ADIW (%I0, %J0, %o0+1) CR_TAB
+                 "st %b0,%B1"                CR_TAB
+                 "st -%b0,%A1", op, plen, -4);
+
+  if (!reg_unused_after (insn, XEXP (base, 0)))
+    avr_asm_len (TINY_SBIW (%I0, %J0, %o0), op, plen, 2);
+
+  return "";
+}
+
+static const char*
+avr_out_movhi_mr_r_post_inc_tiny (rtx op[], int *plen)
+{
+  return avr_asm_len (TINY_ADIW (%I0, %J0, 1)  CR_TAB
+                      "st %p0,%B1"    CR_TAB
+                      "st -%p0,%A1"   CR_TAB
+                      TINY_ADIW (%I0, %J0, 2), op, plen, -6);
+}
+
+static const char*
+out_movhi_mr_r (rtx_insn *insn, rtx op[], int *plen)
+{
+  rtx dest = op[0];
+  rtx src = op[1];
+  rtx base = XEXP (dest, 0);
+  int reg_base = true_regnum (base);
+  int reg_src = true_regnum (src);
+  int mem_volatile_p;
+
+  /* "volatile" forces writing high-byte first (no-xmega) resp.
+     low-byte first (xmega) even if less efficient, for correct
+     operation with 16-bit I/O registers like.  */
+
+  if (AVR_XMEGA)
+    return avr_out_movhi_mr_r_xmega (insn, op, plen);
+
+  mem_volatile_p = MEM_VOLATILE_P (dest);
+
+  if (CONSTANT_ADDRESS_P (base))
+    {
+      int n_words = AVR_TINY ? 2 : 4;
+      return io_address_operand (base, HImode)
+        ? avr_asm_len ("out %i0+1,%B1" CR_TAB
+                       "out %i0,%A1", op, plen, -2)
+
+        : avr_asm_len ("sts %m0+1,%B1" CR_TAB
+                       "sts %m0,%A1", op, plen, -n_words);
+    }
+
+  if (reg_base > 0)
+    {
+      if (AVR_TINY)
+        return avr_out_movhi_mr_r_reg_no_disp_tiny (insn, op, plen);
+
+      if (reg_base != REG_X)
+        return avr_asm_len ("std %0+1,%B1" CR_TAB
+                            "st %0,%A1", op, plen, -2);
+
+      if (reg_src == REG_X)
+        /* "st X+,r26" and "st -X,r26" are undefined.  */
+        return !mem_volatile_p && reg_unused_after (insn, src)
+          ? avr_asm_len ("mov __tmp_reg__,r27" CR_TAB
+                         "st X,r26"            CR_TAB
+                         "adiw r26,1"          CR_TAB
+                         "st X,__tmp_reg__", op, plen, -4)
+
+          : avr_asm_len ("mov __tmp_reg__,r27" CR_TAB
+                         "adiw r26,1"          CR_TAB
+                         "st X,__tmp_reg__"    CR_TAB
+                         "sbiw r26,1"          CR_TAB
+                         "st X,r26", op, plen, -5);
+
+      return !mem_volatile_p && reg_unused_after (insn, base)
+        ? avr_asm_len ("st X+,%A1" CR_TAB
+                       "st X,%B1", op, plen, -2)
+        : avr_asm_len ("adiw r26,1" CR_TAB
+                       "st X,%B1"   CR_TAB
+                       "st -X,%A1", op, plen, -3);
+    }
+  else if (GET_CODE (base) == PLUS)
+    {
+      int disp = INTVAL (XEXP (base, 1));
+
+      if (AVR_TINY)
+        return avr_out_movhi_mr_r_reg_disp_tiny (insn, op, plen);
+
+      reg_base = REGNO (XEXP (base, 0));
+      if (disp > MAX_LD_OFFSET (GET_MODE (dest)))
+        {
+          if (reg_base != REG_Y)
+            fatal_insn ("incorrect insn:",insn);
+
+          return disp <= 63 + MAX_LD_OFFSET (GET_MODE (dest))
+            ? avr_asm_len ("adiw r28,%o0-62" CR_TAB
+                           "std Y+63,%B1"    CR_TAB
+                           "std Y+62,%A1"    CR_TAB
+                           "sbiw r28,%o0-62", op, plen, -4)
+
+            : avr_asm_len ("subi r28,lo8(-%o0)" CR_TAB
+                           "sbci r29,hi8(-%o0)" CR_TAB
+                           "std Y+1,%B1"        CR_TAB
+                           "st Y,%A1"           CR_TAB
+                           "subi r28,lo8(%o0)"  CR_TAB
+                           "sbci r29,hi8(%o0)", op, plen, -6);
+        }
+
+      if (reg_base != REG_X)
+        return avr_asm_len ("std %B0,%B1" CR_TAB
+                            "std %A0,%A1", op, plen, -2);
+      /* (X + d) = R */
+      return reg_src == REG_X
+        ? avr_asm_len ("mov __tmp_reg__,r26"  CR_TAB
+                       "mov __zero_reg__,r27" CR_TAB
+                       "adiw r26,%o0+1"       CR_TAB
+                       "st X,__zero_reg__"    CR_TAB
+                       "st -X,__tmp_reg__"    CR_TAB
+                       "clr __zero_reg__"     CR_TAB
+                       "sbiw r26,%o0", op, plen, -7)
+
+        : avr_asm_len ("adiw r26,%o0+1" CR_TAB
+                       "st X,%B1"       CR_TAB
+                       "st -X,%A1"      CR_TAB
+                       "sbiw r26,%o0", op, plen, -4);
+    }
+  else if (GET_CODE (base) == PRE_DEC) /* (--R) */
+    {
+      return avr_asm_len ("st %0,%B1" CR_TAB
+                          "st %0,%A1", op, plen, -2);
+    }
+  else if (GET_CODE (base) == POST_INC) /* (R++) */
+    {
+      if (!mem_volatile_p)
+        return avr_asm_len ("st %0,%A1"  CR_TAB
+                            "st %0,%B1", op, plen, -2);
+
+      if (AVR_TINY)
+        return avr_out_movhi_mr_r_post_inc_tiny (op, plen);
+
+      return REGNO (XEXP (base, 0)) == REG_X
+        ? avr_asm_len ("adiw r26,1"  CR_TAB
+                       "st X,%B1"    CR_TAB
+                       "st -X,%A1"   CR_TAB
+                       "adiw r26,2", op, plen, -4)
+
+        : avr_asm_len ("std %p0+1,%B1" CR_TAB
+                       "st %p0,%A1"    CR_TAB
+                       "adiw %r0,2", op, plen, -3);
+    }
+  fatal_insn ("unknown move insn:",insn);
+  return "";
+}
+
+/* Return 1 if frame pointer for current function required.  */
+
+static bool
+avr_frame_pointer_required_p (void)
+{
+  return (cfun->calls_alloca
+          || cfun->calls_setjmp
+          || cfun->has_nonlocal_label
+          || crtl->args.info.nregs == 0
+          || get_frame_size () > 0);
+}
+
+/* Returns the condition of compare insn INSN, or UNKNOWN.  */
+
+static RTX_CODE
+compare_condition (rtx_insn *insn)
+{
+  rtx_insn *next = next_real_insn (insn);
+
+  if (next && JUMP_P (next))
+    {
+      rtx pat = PATTERN (next);
+      rtx src = SET_SRC (pat);
+
+      if (IF_THEN_ELSE == GET_CODE (src))
+        return GET_CODE (XEXP (src, 0));
+    }
+
+  return UNKNOWN;
+}
+
+
+/* Returns true iff INSN is a tst insn that only tests the sign.  */
+
+static bool
+compare_sign_p (rtx_insn *insn)
+{
+  RTX_CODE cond = compare_condition (insn);
+  return (cond == GE || cond == LT);
+}
+
+
+/* Returns true iff the next insn is a JUMP_INSN with a condition
+   that needs to be swapped (GT, GTU, LE, LEU).  */
+
+static bool
+compare_diff_p (rtx_insn *insn)
+{
+  RTX_CODE cond = compare_condition (insn);
+  return (cond == GT || cond == GTU || cond == LE || cond == LEU) ? cond : 0;
+}
+
+/* Returns true iff INSN is a compare insn with the EQ or NE condition.  */
+
+static bool
+compare_eq_p (rtx_insn *insn)
+{
+  RTX_CODE cond = compare_condition (insn);
+  return (cond == EQ || cond == NE);
+}
+
+
+/* Output compare instruction
+
+      compare (XOP[0], XOP[1])
+
+   for a register XOP[0] and a compile-time constant XOP[1].  Return "".
+   XOP[2] is an 8-bit scratch register as needed.
+
+   PLEN == NULL:  Output instructions.
+   PLEN != NULL:  Set *PLEN to the length (in words) of the sequence.
+                  Don't output anything.  */
+
+const char*
+avr_out_compare (rtx_insn *insn, rtx *xop, int *plen)
+{
+  /* Register to compare and value to compare against. */
+  rtx xreg = xop[0];
+  rtx xval = xop[1];
+
+  /* MODE of the comparison.  */
+  machine_mode mode;
+
+  /* Number of bytes to operate on.  */
+  int n_bytes = GET_MODE_SIZE (GET_MODE (xreg));
+
+  /* Value (0..0xff) held in clobber register xop[2] or -1 if unknown.  */
+  int clobber_val = -1;
+
+  /* Map fixed mode operands to integer operands with the same binary
+     representation.  They are easier to handle in the remainder.  */
+
+  if (CONST_FIXED_P (xval))
+    {
+      xreg = avr_to_int_mode (xop[0]);
+      xval = avr_to_int_mode (xop[1]);
+    }
+
+  mode = GET_MODE (xreg);
+
+  gcc_assert (REG_P (xreg));
+  gcc_assert ((CONST_INT_P (xval) && n_bytes <= 4)
+              || (const_double_operand (xval, VOIDmode) && n_bytes == 8));
+
+  if (plen)
+    *plen = 0;
+
+  /* Comparisons == +/-1 and != +/-1 can be done similar to camparing
+     against 0 by ORing the bytes.  This is one instruction shorter.
+     Notice that 64-bit comparisons are always against reg:ALL8 18 (ACC_A)
+     and therefore don't use this.  */
+
+  if (!test_hard_reg_class (LD_REGS, xreg)
+      && compare_eq_p (insn)
+      && reg_unused_after (insn, xreg))
+    {
+      if (xval == const1_rtx)
+        {
+          avr_asm_len ("dec %A0" CR_TAB
+                       "or %A0,%B0", xop, plen, 2);
+
+          if (n_bytes >= 3)
+            avr_asm_len ("or %A0,%C0", xop, plen, 1);
+
+          if (n_bytes >= 4)
+            avr_asm_len ("or %A0,%D0", xop, plen, 1);
+
+          return "";
+        }
+      else if (xval == constm1_rtx)
+        {
+          if (n_bytes >= 4)
+            avr_asm_len ("and %A0,%D0", xop, plen, 1);
+
+          if (n_bytes >= 3)
+            avr_asm_len ("and %A0,%C0", xop, plen, 1);
+
+          return avr_asm_len ("and %A0,%B0" CR_TAB
+                              "com %A0", xop, plen, 2);
+        }
+    }
+
+  /* Comparisons == -1 and != -1 of a d-register that's used after the
+     comparison.  (If it's unused after we use CPI / SBCI or ADIW sequence
+     from below.)  Instead of  CPI Rlo,-1 / LDI Rx,-1 / CPC Rhi,Rx  we can
+     use  CPI Rlo,-1 / CPC Rhi,Rlo  which is 1 instruction shorter:
+     If CPI is true then Rlo contains -1 and we can use Rlo instead of Rx
+     when CPC'ing the high part.  If CPI is false then CPC cannot render
+     the result to true.  This also works for the more generic case where
+     the constant is of the form 0xabab.  */
+
+  if (n_bytes == 2
+      && xval != const0_rtx
+      && test_hard_reg_class (LD_REGS, xreg)
+      && compare_eq_p (insn)
+      && !reg_unused_after (insn, xreg))
+    {
+      rtx xlo8 = simplify_gen_subreg (QImode, xval, mode, 0);
+      rtx xhi8 = simplify_gen_subreg (QImode, xval, mode, 1);
+
+      if (INTVAL (xlo8) == INTVAL (xhi8))
+        {
+          xop[0] = xreg;
+          xop[1] = xlo8;
+
+          return avr_asm_len ("cpi %A0,%1"  CR_TAB
+                              "cpc %B0,%A0", xop, plen, 2);
+        }
+    }
+
+  for (int i = 0; i < n_bytes; i++)
+    {
+      /* We compare byte-wise.  */
+      rtx reg8 = simplify_gen_subreg (QImode, xreg, mode, i);
+      rtx xval8 = simplify_gen_subreg (QImode, xval, mode, i);
+
+      /* 8-bit value to compare with this byte.  */
+      unsigned int val8 = UINTVAL (xval8) & GET_MODE_MASK (QImode);
+
+      /* Registers R16..R31 can operate with immediate.  */
+      bool ld_reg_p = test_hard_reg_class (LD_REGS, reg8);
+
+      xop[0] = reg8;
+      xop[1] = gen_int_mode (val8, QImode);
+
+      /* Word registers >= R24 can use SBIW/ADIW with 0..63.  */
+
+      if (i == 0
+          && test_hard_reg_class (ADDW_REGS, reg8))
+        {
+          int val16 = trunc_int_for_mode (INTVAL (xval), HImode);
+
+          if (IN_RANGE (val16, 0, 63)
+              && (val8 == 0
+                  || reg_unused_after (insn, xreg)))
+            {
+              if (AVR_TINY)
+                avr_asm_len (TINY_SBIW (%A0, %B0, %1), xop, plen, 2);
+              else
+                avr_asm_len ("sbiw %0,%1", xop, plen, 1);
+
+              i++;
+              continue;
+            }
+
+          if (n_bytes == 2
+              && IN_RANGE (val16, -63, -1)
+              && compare_eq_p (insn)
+              && reg_unused_after (insn, xreg))
+            {
+              return AVR_TINY
+                ? avr_asm_len (TINY_ADIW (%A0, %B0, %n1), xop, plen, 2)
+                : avr_asm_len ("adiw %0,%n1", xop, plen, 1);
+            }
+        }
+
+      /* Comparing against 0 is easy.  */
+
+      if (val8 == 0)
+        {
+          avr_asm_len (i == 0
+                       ? "cp %0,__zero_reg__"
+                       : "cpc %0,__zero_reg__", xop, plen, 1);
+          continue;
+        }
+
+      /* Upper registers can compare and subtract-with-carry immediates.
+         Notice that compare instructions do the same as respective subtract
+         instruction; the only difference is that comparisons don't write
+         the result back to the target register.  */
+
+      if (ld_reg_p)
+        {
+          if (i == 0)
+            {
+              avr_asm_len ("cpi %0,%1", xop, plen, 1);
+              continue;
+            }
+          else if (reg_unused_after (insn, xreg))
+            {
+              avr_asm_len ("sbci %0,%1", xop, plen, 1);
+              continue;
+            }
+        }
+
+      /* Must load the value into the scratch register.  */
+
+      gcc_assert (REG_P (xop[2]));
+
+      if (clobber_val != (int) val8)
+        avr_asm_len ("ldi %2,%1", xop, plen, 1);
+      clobber_val = (int) val8;
+
+      avr_asm_len (i == 0
+                   ? "cp %0,%2"
+                   : "cpc %0,%2", xop, plen, 1);
+    }
+
+  return "";
+}
+
+
+/* Prepare operands of compare_const_di2 to be used with avr_out_compare.  */
+
+const char*
+avr_out_compare64 (rtx_insn *insn, rtx *op, int *plen)
+{
+  rtx xop[3];
+
+  xop[0] = gen_rtx_REG (DImode, 18);
+  xop[1] = op[0];
+  xop[2] = op[1];
+
+  return avr_out_compare (insn, xop, plen);
+}
+
+/* Output test instruction for HImode.  */
+
+const char*
+avr_out_tsthi (rtx_insn *insn, rtx *op, int *plen)
+{
+  if (compare_sign_p (insn))
+    {
+      avr_asm_len ("tst %B0", op, plen, -1);
+    }
+  else if (reg_unused_after (insn, op[0])
+           && compare_eq_p (insn))
+    {
+      /* Faster than sbiw if we can clobber the operand.  */
+      avr_asm_len ("or %A0,%B0", op, plen, -1);
+    }
+  else
+    {
+      avr_out_compare (insn, op, plen);
+    }
+
+  return "";
+}
+
+
+/* Output test instruction for PSImode.  */
+
+const char*
+avr_out_tstpsi (rtx_insn *insn, rtx *op, int *plen)
+{
+  if (compare_sign_p (insn))
+    {
+      avr_asm_len ("tst %C0", op, plen, -1);
+    }
+  else if (reg_unused_after (insn, op[0])
+           && compare_eq_p (insn))
+    {
+      /* Faster than sbiw if we can clobber the operand.  */
+      avr_asm_len ("or %A0,%B0" CR_TAB
+                   "or %A0,%C0", op, plen, -2);
+    }
+  else
+    {
+      avr_out_compare (insn, op, plen);
+    }
+
+  return "";
+}
+
+
+/* Output test instruction for SImode.  */
+
+const char*
+avr_out_tstsi (rtx_insn *insn, rtx *op, int *plen)
+{
+  if (compare_sign_p (insn))
+    {
+      avr_asm_len ("tst %D0", op, plen, -1);
+    }
+  else if (reg_unused_after (insn, op[0])
+           && compare_eq_p (insn))
+    {
+      /* Faster than sbiw if we can clobber the operand.  */
+      avr_asm_len ("or %A0,%B0" CR_TAB
+                   "or %A0,%C0" CR_TAB
+                   "or %A0,%D0", op, plen, -3);
+    }
+  else
+    {
+      avr_out_compare (insn, op, plen);
+    }
+
+  return "";
+}
+
+
+/* Generate asm equivalent for various shifts.  This only handles cases
+   that are not already carefully hand-optimized in ?sh??i3_out.
+
+   OPERANDS[0] resp. %0 in TEMPL is the operand to be shifted.
+   OPERANDS[2] is the shift count as CONST_INT, MEM or REG.
+   OPERANDS[3] is a QImode scratch register from LD regs if
+               available and SCRATCH, otherwise (no scratch available)
+
+   TEMPL is an assembler template that shifts by one position.
+   T_LEN is the length of this template.  */
+
+void
+out_shift_with_cnt (const char *templ, rtx_insn *insn, rtx operands[],
+		    int *plen, int t_len)
+{
+  bool second_label = true;
+  bool saved_in_tmp = false;
+  bool use_zero_reg = false;
+  rtx op[5];
+
+  op[0] = operands[0];
+  op[1] = operands[1];
+  op[2] = operands[2];
+  op[3] = operands[3];
+
+  if (plen)
+    *plen = 0;
+
+  if (CONST_INT_P (operands[2]))
+    {
+      bool scratch = (GET_CODE (PATTERN (insn)) == PARALLEL
+                      && REG_P (operands[3]));
+      int count = INTVAL (operands[2]);
+      int max_len = 10;  /* If larger than this, always use a loop.  */
+
+      if (count <= 0)
+        return;
+
+      if (count < 8 && !scratch)
+        use_zero_reg = true;
+
+      if (optimize_size)
+        max_len = t_len + (scratch ? 3 : (use_zero_reg ? 4 : 5));
+
+      if (t_len * count <= max_len)
+        {
+          /* Output shifts inline with no loop - faster.  */
+
+          while (count-- > 0)
+            avr_asm_len (templ, op, plen, t_len);
+
+          return;
+        }
+
+      if (scratch)
+        {
+          avr_asm_len ("ldi %3,%2", op, plen, 1);
+        }
+      else if (use_zero_reg)
+        {
+          /* Hack to save one word: use __zero_reg__ as loop counter.
+             Set one bit, then shift in a loop until it is 0 again.  */
+
+          op[3] = zero_reg_rtx;
+
+          avr_asm_len ("set" CR_TAB
+                       "bld %3,%2-1", op, plen, 2);
+        }
+      else
+        {
+          /* No scratch register available, use one from LD_REGS (saved in
+             __tmp_reg__) that doesn't overlap with registers to shift.  */
+
+          op[3] = all_regs_rtx[((REGNO (op[0]) - 1) & 15) + 16];
+          op[4] = tmp_reg_rtx;
+          saved_in_tmp = true;
+
+          avr_asm_len ("mov %4,%3" CR_TAB
+                       "ldi %3,%2", op, plen, 2);
+        }
+
+      second_label = false;
+    }
+  else if (MEM_P (op[2]))
+    {
+      rtx op_mov[2];
+
+      op_mov[0] = op[3] = tmp_reg_rtx;
+      op_mov[1] = op[2];
+
+      out_movqi_r_mr (insn, op_mov, plen);
+    }
+  else if (register_operand (op[2], QImode))
+    {
+      op[3] = op[2];
+
+      if (!reg_unused_after (insn, op[2])
+          || reg_overlap_mentioned_p (op[0], op[2]))
+        {
+          op[3] = tmp_reg_rtx;
+          avr_asm_len ("mov %3,%2", op, plen, 1);
+        }
+    }
+  else
+    fatal_insn ("bad shift insn:", insn);
+
+  if (second_label)
+    avr_asm_len ("rjmp 2f", op, plen, 1);
+
+  avr_asm_len ("1:", op, plen, 0);
+  avr_asm_len (templ, op, plen, t_len);
+
+  if (second_label)
+    avr_asm_len ("2:", op, plen, 0);
+
+  avr_asm_len (use_zero_reg ? "lsr %3" : "dec %3", op, plen, 1);
+  avr_asm_len (second_label ? "brpl 1b" : "brne 1b", op, plen, 1);
+
+  if (saved_in_tmp)
+    avr_asm_len ("mov %3,%4", op, plen, 1);
+}
+
+
+/* 8bit shift left ((char)x << i)   */
+
+const char *
+ashlqi3_out (rtx_insn *insn, rtx operands[], int *len)
+{
+  if (CONST_INT_P (operands[2]))
+    {
+      int k;
+
+      if (!len)
+	len = &k;
+
+      switch (INTVAL (operands[2]))
+	{
+	default:
+	  if (INTVAL (operands[2]) < 8)
+	    break;
+
+	  *len = 1;
+	  return "clr %0";
+
+	case 1:
+	  *len = 1;
+	  return "lsl %0";
+
+	case 2:
+	  *len = 2;
+	  return ("lsl %0" CR_TAB
+		  "lsl %0");
+
+	case 3:
+	  *len = 3;
+	  return ("lsl %0" CR_TAB
+		  "lsl %0" CR_TAB
+		  "lsl %0");
+
+	case 4:
+	  if (test_hard_reg_class (LD_REGS, operands[0]))
+	    {
+	      *len = 2;
+	      return ("swap %0" CR_TAB
+		      "andi %0,0xf0");
+	    }
+	  *len = 4;
+	  return ("lsl %0" CR_TAB
+		  "lsl %0" CR_TAB
+		  "lsl %0" CR_TAB
+		  "lsl %0");
+
+	case 5:
+	  if (test_hard_reg_class (LD_REGS, operands[0]))
+	    {
+	      *len = 3;
+	      return ("swap %0" CR_TAB
+		      "lsl %0"  CR_TAB
+		      "andi %0,0xe0");
+	    }
+	  *len = 5;
+	  return ("lsl %0" CR_TAB
+		  "lsl %0" CR_TAB
+		  "lsl %0" CR_TAB
+		  "lsl %0" CR_TAB
+		  "lsl %0");
+
+	case 6:
+	  if (test_hard_reg_class (LD_REGS, operands[0]))
+	    {
+	      *len = 4;
+	      return ("swap %0" CR_TAB
+		      "lsl %0"  CR_TAB
+		      "lsl %0"  CR_TAB
+		      "andi %0,0xc0");
+	    }
+	  *len = 6;
+	  return ("lsl %0" CR_TAB
+		  "lsl %0" CR_TAB
+		  "lsl %0" CR_TAB
+		  "lsl %0" CR_TAB
+		  "lsl %0" CR_TAB
+		  "lsl %0");
+
+	case 7:
+	  *len = 3;
+	  return ("ror %0" CR_TAB
+		  "clr %0" CR_TAB
+		  "ror %0");
+	}
+    }
+  else if (CONSTANT_P (operands[2]))
+    fatal_insn ("internal compiler error.  Incorrect shift:", insn);
+
+  out_shift_with_cnt ("lsl %0",
+                      insn, operands, len, 1);
+  return "";
+}
+
+
+/* 16bit shift left ((short)x << i)   */
+
+const char *
+ashlhi3_out (rtx_insn *insn, rtx operands[], int *len)
+{
+  if (CONST_INT_P (operands[2]))
+    {
+      int scratch = (GET_CODE (PATTERN (insn)) == PARALLEL);
+      int ldi_ok = test_hard_reg_class (LD_REGS, operands[0]);
+      int k;
+      int *t = len;
+
+      if (!len)
+	len = &k;
+
+      switch (INTVAL (operands[2]))
+	{
+	default:
+	  if (INTVAL (operands[2]) < 16)
+	    break;
+
+	  *len = 2;
+	  return ("clr %B0" CR_TAB
+		  "clr %A0");
+
+	case 4:
+	  if (optimize_size && scratch)
+	    break;  /* 5 */
+	  if (ldi_ok)
+	    {
+	      *len = 6;
+	      return ("swap %A0"      CR_TAB
+		      "swap %B0"      CR_TAB
+		      "andi %B0,0xf0" CR_TAB
+		      "eor %B0,%A0"   CR_TAB
+		      "andi %A0,0xf0" CR_TAB
+		      "eor %B0,%A0");
+	    }
+	  if (scratch)
+	    {
+	      *len = 7;
+	      return ("swap %A0"    CR_TAB
+		      "swap %B0"    CR_TAB
+		      "ldi %3,0xf0" CR_TAB
+		      "and %B0,%3"  CR_TAB
+		      "eor %B0,%A0" CR_TAB
+		      "and %A0,%3"  CR_TAB
+		      "eor %B0,%A0");
+	    }
+	  break;  /* optimize_size ? 6 : 8 */
+
+	case 5:
+	  if (optimize_size)
+	    break;  /* scratch ? 5 : 6 */
+	  if (ldi_ok)
+	    {
+	      *len = 8;
+	      return ("lsl %A0"       CR_TAB
+		      "rol %B0"       CR_TAB
+		      "swap %A0"      CR_TAB
+		      "swap %B0"      CR_TAB
+		      "andi %B0,0xf0" CR_TAB
+		      "eor %B0,%A0"   CR_TAB
+		      "andi %A0,0xf0" CR_TAB
+		      "eor %B0,%A0");
+	    }
+	  if (scratch)
+	    {
+	      *len = 9;
+	      return ("lsl %A0"     CR_TAB
+		      "rol %B0"     CR_TAB
+		      "swap %A0"    CR_TAB
+		      "swap %B0"    CR_TAB
+		      "ldi %3,0xf0" CR_TAB
+		      "and %B0,%3"  CR_TAB
+		      "eor %B0,%A0" CR_TAB
+		      "and %A0,%3"  CR_TAB
+		      "eor %B0,%A0");
+	    }
+	  break;  /* 10 */
+
+	case 6:
+	  if (optimize_size)
+	    break;  /* scratch ? 5 : 6 */
+	  *len = 9;
+	  return ("clr __tmp_reg__" CR_TAB
+		  "lsr %B0"         CR_TAB
+		  "ror %A0"         CR_TAB
+		  "ror __tmp_reg__" CR_TAB
+		  "lsr %B0"         CR_TAB
+		  "ror %A0"         CR_TAB
+		  "ror __tmp_reg__" CR_TAB
+		  "mov %B0,%A0"     CR_TAB
+		  "mov %A0,__tmp_reg__");
+
+	case 7:
+	  *len = 5;
+	  return ("lsr %B0"     CR_TAB
+		  "mov %B0,%A0" CR_TAB
+		  "clr %A0"     CR_TAB
+		  "ror %B0"     CR_TAB
+		  "ror %A0");
+
+	case 8:
+	  return *len = 2, ("mov %B0,%A1" CR_TAB
+			    "clr %A0");
+
+	case 9:
+	  *len = 3;
+	  return ("mov %B0,%A0" CR_TAB
+		  "clr %A0"     CR_TAB
+		  "lsl %B0");
+
+	case 10:
+	  *len = 4;
+	  return ("mov %B0,%A0" CR_TAB
+		  "clr %A0"     CR_TAB
+		  "lsl %B0"     CR_TAB
+		  "lsl %B0");
+
+	case 11:
+	  *len = 5;
+	  return ("mov %B0,%A0" CR_TAB
+		  "clr %A0"     CR_TAB
+		  "lsl %B0"     CR_TAB
+		  "lsl %B0"     CR_TAB
+		  "lsl %B0");
+
+	case 12:
+	  if (ldi_ok)
+	    {
+	      *len = 4;
+	      return ("mov %B0,%A0" CR_TAB
+		      "clr %A0"     CR_TAB
+		      "swap %B0"    CR_TAB
+		      "andi %B0,0xf0");
+	    }
+	  if (scratch)
+	    {
+	      *len = 5;
+	      return ("mov %B0,%A0" CR_TAB
+		      "clr %A0"     CR_TAB
+		      "swap %B0"    CR_TAB
+		      "ldi %3,0xf0" CR_TAB
+		      "and %B0,%3");
+	    }
+	  *len = 6;
+	  return ("mov %B0,%A0" CR_TAB
+		  "clr %A0"     CR_TAB
+		  "lsl %B0"     CR_TAB
+		  "lsl %B0"     CR_TAB
+		  "lsl %B0"     CR_TAB
+		  "lsl %B0");
+
+	case 13:
+	  if (ldi_ok)
+	    {
+	      *len = 5;
+	      return ("mov %B0,%A0" CR_TAB
+		      "clr %A0"     CR_TAB
+		      "swap %B0"    CR_TAB
+		      "lsl %B0"     CR_TAB
+		      "andi %B0,0xe0");
+	    }
+	  if (AVR_HAVE_MUL && scratch)
+	    {
+	      *len = 5;
+	      return ("ldi %3,0x20" CR_TAB
+		      "mul %A0,%3"  CR_TAB
+		      "mov %B0,r0"  CR_TAB
+		      "clr %A0"     CR_TAB
+		      "clr __zero_reg__");
+	    }
+	  if (optimize_size && scratch)
+	    break;  /* 5 */
+	  if (scratch)
+	    {
+	      *len = 6;
+	      return ("mov %B0,%A0" CR_TAB
+		      "clr %A0"     CR_TAB
+		      "swap %B0"    CR_TAB
+		      "lsl %B0"     CR_TAB
+		      "ldi %3,0xe0" CR_TAB
+		      "and %B0,%3");
+	    }
+	  if (AVR_HAVE_MUL)
+	    {
+	      *len = 6;
+	      return ("set"        CR_TAB
+		      "bld r1,5"   CR_TAB
+		      "mul %A0,r1" CR_TAB
+		      "mov %B0,r0" CR_TAB
+		      "clr %A0"    CR_TAB
+		      "clr __zero_reg__");
+	    }
+	  *len = 7;
+	  return ("mov %B0,%A0" CR_TAB
+		  "clr %A0"     CR_TAB
+		  "lsl %B0"     CR_TAB
+		  "lsl %B0"     CR_TAB
+		  "lsl %B0"     CR_TAB
+		  "lsl %B0"     CR_TAB
+		  "lsl %B0");
+
+	case 14:
+	  if (AVR_HAVE_MUL && ldi_ok)
+	    {
+	      *len = 5;
+	      return ("ldi %B0,0x40" CR_TAB
+		      "mul %A0,%B0"  CR_TAB
+		      "mov %B0,r0"   CR_TAB
+		      "clr %A0"      CR_TAB
+		      "clr __zero_reg__");
+	    }
+	  if (AVR_HAVE_MUL && scratch)
+	    {
+	      *len = 5;
+	      return ("ldi %3,0x40" CR_TAB
+		      "mul %A0,%3"  CR_TAB
+		      "mov %B0,r0"  CR_TAB
+		      "clr %A0"     CR_TAB
+		      "clr __zero_reg__");
+	    }
+	  if (optimize_size && ldi_ok)
+	    {
+	      *len = 5;
+	      return ("mov %B0,%A0" CR_TAB
+		      "ldi %A0,6" "\n1:\t"
+		      "lsl %B0"     CR_TAB
+		      "dec %A0"     CR_TAB
+		      "brne 1b");
+	    }
+	  if (optimize_size && scratch)
+	    break;  /* 5 */
+	  *len = 6;
+	  return ("clr %B0" CR_TAB
+		  "lsr %A0" CR_TAB
+		  "ror %B0" CR_TAB
+		  "lsr %A0" CR_TAB
+		  "ror %B0" CR_TAB
+		  "clr %A0");
+
+	case 15:
+	  *len = 4;
+	  return ("clr %B0" CR_TAB
+		  "lsr %A0" CR_TAB
+		  "ror %B0" CR_TAB
+		  "clr %A0");
+	}
+      len = t;
+    }
+  out_shift_with_cnt ("lsl %A0" CR_TAB
+                      "rol %B0", insn, operands, len, 2);
+  return "";
+}
+
+
+/* 24-bit shift left */
+
+const char*
+avr_out_ashlpsi3 (rtx_insn *insn, rtx *op, int *plen)
+{
+  if (plen)
+    *plen = 0;
+
+  if (CONST_INT_P (op[2]))
+    {
+      switch (INTVAL (op[2]))
+        {
+        default:
+          if (INTVAL (op[2]) < 24)
+            break;
+
+          return avr_asm_len ("clr %A0" CR_TAB
+                              "clr %B0" CR_TAB
+                              "clr %C0", op, plen, 3);
+
+        case 8:
+          {
+            int reg0 = REGNO (op[0]);
+            int reg1 = REGNO (op[1]);
+
+            if (reg0 >= reg1)
+              return avr_asm_len ("mov %C0,%B1"  CR_TAB
+                                  "mov %B0,%A1"  CR_TAB
+                                  "clr %A0", op, plen, 3);
+            else
+              return avr_asm_len ("clr %A0"      CR_TAB
+                                  "mov %B0,%A1"  CR_TAB
+                                  "mov %C0,%B1", op, plen, 3);
+          }
+
+        case 16:
+          {
+            int reg0 = REGNO (op[0]);
+            int reg1 = REGNO (op[1]);
+
+            if (reg0 + 2 != reg1)
+              avr_asm_len ("mov %C0,%A0", op, plen, 1);
+
+            return avr_asm_len ("clr %B0"  CR_TAB
+                                "clr %A0", op, plen, 2);
+          }
+
+        case 23:
+          return avr_asm_len ("clr %C0" CR_TAB
+                              "lsr %A0" CR_TAB
+                              "ror %C0" CR_TAB
+                              "clr %B0" CR_TAB
+                              "clr %A0", op, plen, 5);
+        }
+    }
+
+  out_shift_with_cnt ("lsl %A0" CR_TAB
+                      "rol %B0" CR_TAB
+                      "rol %C0", insn, op, plen, 3);
+  return "";
+}
+
+
+/* 32bit shift left ((long)x << i)   */
+
+const char *
+ashlsi3_out (rtx_insn *insn, rtx operands[], int *len)
+{
+  if (CONST_INT_P (operands[2]))
+    {
+      int k;
+      int *t = len;
+
+      if (!len)
+	len = &k;
+
+      switch (INTVAL (operands[2]))
+	{
+	default:
+	  if (INTVAL (operands[2]) < 32)
+	    break;
+
+	  if (AVR_HAVE_MOVW)
+	    return *len = 3, ("clr %D0" CR_TAB
+			      "clr %C0" CR_TAB
+			      "movw %A0,%C0");
+	  *len = 4;
+	  return ("clr %D0" CR_TAB
+		  "clr %C0" CR_TAB
+		  "clr %B0" CR_TAB
+		  "clr %A0");
+
+	case 8:
+	  {
+	    int reg0 = true_regnum (operands[0]);
+	    int reg1 = true_regnum (operands[1]);
+	    *len = 4;
+	    if (reg0 >= reg1)
+	      return ("mov %D0,%C1"  CR_TAB
+		      "mov %C0,%B1"  CR_TAB
+		      "mov %B0,%A1"  CR_TAB
+		      "clr %A0");
+	    else
+	      return ("clr %A0"      CR_TAB
+		      "mov %B0,%A1"  CR_TAB
+		      "mov %C0,%B1"  CR_TAB
+		      "mov %D0,%C1");
+	  }
+
+	case 16:
+	  {
+	    int reg0 = true_regnum (operands[0]);
+	    int reg1 = true_regnum (operands[1]);
+	    if (reg0 + 2 == reg1)
+	      return *len = 2, ("clr %B0"      CR_TAB
+				"clr %A0");
+	    if (AVR_HAVE_MOVW)
+	      return *len = 3, ("movw %C0,%A1" CR_TAB
+				"clr %B0"      CR_TAB
+				"clr %A0");
+	    else
+	      return *len = 4, ("mov %C0,%A1"  CR_TAB
+				"mov %D0,%B1"  CR_TAB
+				"clr %B0"      CR_TAB
+				"clr %A0");
+	  }
+
+	case 24:
+	  *len = 4;
+	  return ("mov %D0,%A1"  CR_TAB
+		  "clr %C0"      CR_TAB
+		  "clr %B0"      CR_TAB
+		  "clr %A0");
+
+	case 31:
+	  *len = 6;
+	  return ("clr %D0" CR_TAB
+		  "lsr %A0" CR_TAB
+		  "ror %D0" CR_TAB
+		  "clr %C0" CR_TAB
+		  "clr %B0" CR_TAB
+		  "clr %A0");
+	}
+      len = t;
+    }
+  out_shift_with_cnt ("lsl %A0" CR_TAB
+                      "rol %B0" CR_TAB
+                      "rol %C0" CR_TAB
+                      "rol %D0", insn, operands, len, 4);
+  return "";
+}
+
+/* 8bit arithmetic shift right  ((signed char)x >> i) */
+
+const char *
+ashrqi3_out (rtx_insn *insn, rtx operands[], int *len)
+{
+  if (CONST_INT_P (operands[2]))
+    {
+      int k;
+
+      if (!len)
+	len = &k;
+
+      switch (INTVAL (operands[2]))
+	{
+	case 1:
+	  *len = 1;
+	  return "asr %0";
+
+	case 2:
+	  *len = 2;
+	  return ("asr %0" CR_TAB
+		  "asr %0");
+
+	case 3:
+	  *len = 3;
+	  return ("asr %0" CR_TAB
+		  "asr %0" CR_TAB
+		  "asr %0");
+
+	case 4:
+	  *len = 4;
+	  return ("asr %0" CR_TAB
+		  "asr %0" CR_TAB
+		  "asr %0" CR_TAB
+		  "asr %0");
+
+	case 5:
+	  *len = 5;
+	  return ("asr %0" CR_TAB
+		  "asr %0" CR_TAB
+		  "asr %0" CR_TAB
+		  "asr %0" CR_TAB
+		  "asr %0");
+
+	case 6:
+	  *len = 4;
+	  return ("bst %0,6"  CR_TAB
+		  "lsl %0"    CR_TAB
+		  "sbc %0,%0" CR_TAB
+		  "bld %0,0");
+
+	default:
+	  if (INTVAL (operands[2]) < 8)
+	    break;
+
+	  /* fall through */
+
+	case 7:
+	  *len = 2;
+	  return ("lsl %0" CR_TAB
+		  "sbc %0,%0");
+	}
+    }
+  else if (CONSTANT_P (operands[2]))
+    fatal_insn ("internal compiler error.  Incorrect shift:", insn);
+
+  out_shift_with_cnt ("asr %0",
+                      insn, operands, len, 1);
+  return "";
+}
+
+
+/* 16bit arithmetic shift right  ((signed short)x >> i) */
+
+const char *
+ashrhi3_out (rtx_insn *insn, rtx operands[], int *len)
+{
+  if (CONST_INT_P (operands[2]))
+    {
+      int scratch = (GET_CODE (PATTERN (insn)) == PARALLEL);
+      int ldi_ok = test_hard_reg_class (LD_REGS, operands[0]);
+      int k;
+      int *t = len;
+
+      if (!len)
+	len = &k;
+
+      switch (INTVAL (operands[2]))
+	{
+	case 4:
+	case 5:
+	  /* XXX try to optimize this too? */
+	  break;
+
+	case 6:
+	  if (optimize_size)
+	    break;  /* scratch ? 5 : 6 */
+	  *len = 8;
+	  return ("mov __tmp_reg__,%A0" CR_TAB
+		  "mov %A0,%B0"         CR_TAB
+		  "lsl __tmp_reg__"     CR_TAB
+		  "rol %A0"             CR_TAB
+		  "sbc %B0,%B0"         CR_TAB
+		  "lsl __tmp_reg__"     CR_TAB
+		  "rol %A0"             CR_TAB
+		  "rol %B0");
+
+	case 7:
+	  *len = 4;
+	  return ("lsl %A0"     CR_TAB
+		  "mov %A0,%B0" CR_TAB
+		  "rol %A0"     CR_TAB
+		  "sbc %B0,%B0");
+
+	case 8:
+	  {
+	    int reg0 = true_regnum (operands[0]);
+	    int reg1 = true_regnum (operands[1]);
+
+	    if (reg0 == reg1)
+	      return *len = 3, ("mov %A0,%B0" CR_TAB
+				"lsl %B0"     CR_TAB
+				"sbc %B0,%B0");
+	    else
+	      return *len = 4, ("mov %A0,%B1" CR_TAB
+			        "clr %B0"     CR_TAB
+			        "sbrc %A0,7"  CR_TAB
+			        "dec %B0");
+	  }
+
+	case 9:
+	  *len = 4;
+	  return ("mov %A0,%B0" CR_TAB
+		  "lsl %B0"      CR_TAB
+		  "sbc %B0,%B0" CR_TAB
+		  "asr %A0");
+
+	case 10:
+	  *len = 5;
+	  return ("mov %A0,%B0" CR_TAB
+		  "lsl %B0"     CR_TAB
+		  "sbc %B0,%B0" CR_TAB
+		  "asr %A0"     CR_TAB
+		  "asr %A0");
+
+	case 11:
+	  if (AVR_HAVE_MUL && ldi_ok)
+	    {
+	      *len = 5;
+	      return ("ldi %A0,0x20" CR_TAB
+		      "muls %B0,%A0" CR_TAB
+		      "mov %A0,r1"   CR_TAB
+		      "sbc %B0,%B0"  CR_TAB
+		      "clr __zero_reg__");
+	    }
+	  if (optimize_size && scratch)
+	    break;  /* 5 */
+	  *len = 6;
+	  return ("mov %A0,%B0" CR_TAB
+		  "lsl %B0"     CR_TAB
+		  "sbc %B0,%B0" CR_TAB
+		  "asr %A0"     CR_TAB
+		  "asr %A0"     CR_TAB
+		  "asr %A0");
+
+	case 12:
+	  if (AVR_HAVE_MUL && ldi_ok)
+	    {
+	      *len = 5;
+	      return ("ldi %A0,0x10" CR_TAB
+		      "muls %B0,%A0" CR_TAB
+		      "mov %A0,r1"   CR_TAB
+		      "sbc %B0,%B0"  CR_TAB
+		      "clr __zero_reg__");
+	    }
+	  if (optimize_size && scratch)
+	    break;  /* 5 */
+	  *len = 7;
+	  return ("mov %A0,%B0" CR_TAB
+		  "lsl %B0"     CR_TAB
+		  "sbc %B0,%B0" CR_TAB
+		  "asr %A0"     CR_TAB
+		  "asr %A0"     CR_TAB
+		  "asr %A0"     CR_TAB
+		  "asr %A0");
+
+	case 13:
+	  if (AVR_HAVE_MUL && ldi_ok)
+	    {
+	      *len = 5;
+	      return ("ldi %A0,0x08" CR_TAB
+		      "muls %B0,%A0" CR_TAB
+		      "mov %A0,r1"   CR_TAB
+		      "sbc %B0,%B0"  CR_TAB
+		      "clr __zero_reg__");
+	    }
+	  if (optimize_size)
+	    break;  /* scratch ? 5 : 7 */
+	  *len = 8;
+	  return ("mov %A0,%B0" CR_TAB
+		  "lsl %B0"     CR_TAB
+		  "sbc %B0,%B0" CR_TAB
+		  "asr %A0"     CR_TAB
+		  "asr %A0"     CR_TAB
+		  "asr %A0"     CR_TAB
+		  "asr %A0"     CR_TAB
+		  "asr %A0");
+
+	case 14:
+	  *len = 5;
+	  return ("lsl %B0"     CR_TAB
+		  "sbc %A0,%A0" CR_TAB
+		  "lsl %B0"     CR_TAB
+		  "mov %B0,%A0" CR_TAB
+		  "rol %A0");
+
+	default:
+	  if (INTVAL (operands[2]) < 16)
+	    break;
+
+	  /* fall through */
+
+	case 15:
+	  return *len = 3, ("lsl %B0"     CR_TAB
+			    "sbc %A0,%A0" CR_TAB
+			    "mov %B0,%A0");
+	}
+      len = t;
+    }
+  out_shift_with_cnt ("asr %B0" CR_TAB
+                      "ror %A0", insn, operands, len, 2);
+  return "";
+}
+
+
+/* 24-bit arithmetic shift right */
+
+const char*
+avr_out_ashrpsi3 (rtx_insn *insn, rtx *op, int *plen)
+{
+  int dest = REGNO (op[0]);
+  int src = REGNO (op[1]);
+
+  if (CONST_INT_P (op[2]))
+    {
+      if (plen)
+        *plen = 0;
+
+      switch (INTVAL (op[2]))
+        {
+        case 8:
+          if (dest <= src)
+            return avr_asm_len ("mov %A0,%B1" CR_TAB
+                                "mov %B0,%C1" CR_TAB
+                                "clr %C0"     CR_TAB
+                                "sbrc %B0,7"  CR_TAB
+                                "dec %C0", op, plen, 5);
+          else
+            return avr_asm_len ("clr %C0"     CR_TAB
+                                "sbrc %C1,7"  CR_TAB
+                                "dec %C0"     CR_TAB
+                                "mov %B0,%C1" CR_TAB
+                                "mov %A0,%B1", op, plen, 5);
+
+        case 16:
+          if (dest != src + 2)
+            avr_asm_len ("mov %A0,%C1", op, plen, 1);
+
+          return avr_asm_len ("clr %B0"     CR_TAB
+                              "sbrc %A0,7"  CR_TAB
+                              "com %B0"     CR_TAB
+                              "mov %C0,%B0", op, plen, 4);
+
+        default:
+          if (INTVAL (op[2]) < 24)
+            break;
+
+          /* fall through */
+
+        case 23:
+          return avr_asm_len ("lsl %C0"     CR_TAB
+                              "sbc %A0,%A0" CR_TAB
+                              "mov %B0,%A0" CR_TAB
+                              "mov %C0,%A0", op, plen, 4);
+        } /* switch */
+    }
+
+  out_shift_with_cnt ("asr %C0" CR_TAB
+                      "ror %B0" CR_TAB
+                      "ror %A0", insn, op, plen, 3);
+  return "";
+}
+
+
+/* 32-bit arithmetic shift right  ((signed long)x >> i) */
+
+const char *
+ashrsi3_out (rtx_insn *insn, rtx operands[], int *len)
+{
+  if (CONST_INT_P (operands[2]))
+    {
+      int k;
+      int *t = len;
+
+      if (!len)
+	len = &k;
+
+      switch (INTVAL (operands[2]))
+	{
+	case 8:
+	  {
+	    int reg0 = true_regnum (operands[0]);
+	    int reg1 = true_regnum (operands[1]);
+	    *len=6;
+	    if (reg0 <= reg1)
+	      return ("mov %A0,%B1" CR_TAB
+		      "mov %B0,%C1" CR_TAB
+		      "mov %C0,%D1" CR_TAB
+		      "clr %D0"     CR_TAB
+		      "sbrc %C0,7"  CR_TAB
+		      "dec %D0");
+	    else
+	      return ("clr %D0"     CR_TAB
+		      "sbrc %D1,7"  CR_TAB
+		      "dec %D0"     CR_TAB
+		      "mov %C0,%D1" CR_TAB
+		      "mov %B0,%C1" CR_TAB
+		      "mov %A0,%B1");
+	  }
+
+	case 16:
+	  {
+	    int reg0 = true_regnum (operands[0]);
+	    int reg1 = true_regnum (operands[1]);
+
+	    if (reg0 == reg1 + 2)
+	      return *len = 4, ("clr %D0"     CR_TAB
+				"sbrc %B0,7"  CR_TAB
+				"com %D0"     CR_TAB
+				"mov %C0,%D0");
+	    if (AVR_HAVE_MOVW)
+	      return *len = 5, ("movw %A0,%C1" CR_TAB
+				"clr %D0"      CR_TAB
+				"sbrc %B0,7"   CR_TAB
+				"com %D0"      CR_TAB
+				"mov %C0,%D0");
+	    else
+	      return *len = 6, ("mov %B0,%D1" CR_TAB
+				"mov %A0,%C1" CR_TAB
+				"clr %D0"     CR_TAB
+				"sbrc %B0,7"  CR_TAB
+				"com %D0"     CR_TAB
+				"mov %C0,%D0");
+	  }
+
+	case 24:
+	  return *len = 6, ("mov %A0,%D1" CR_TAB
+			    "clr %D0"     CR_TAB
+			    "sbrc %A0,7"  CR_TAB
+			    "com %D0"     CR_TAB
+			    "mov %B0,%D0" CR_TAB
+			    "mov %C0,%D0");
+
+	default:
+	  if (INTVAL (operands[2]) < 32)
+	    break;
+
+	  /* fall through */
+
+	case 31:
+	  if (AVR_HAVE_MOVW)
+	    return *len = 4, ("lsl %D0"     CR_TAB
+			      "sbc %A0,%A0" CR_TAB
+			      "mov %B0,%A0" CR_TAB
+			      "movw %C0,%A0");
+	  else
+	    return *len = 5, ("lsl %D0"     CR_TAB
+			      "sbc %A0,%A0" CR_TAB
+			      "mov %B0,%A0" CR_TAB
+			      "mov %C0,%A0" CR_TAB
+			      "mov %D0,%A0");
+	}
+      len = t;
+    }
+  out_shift_with_cnt ("asr %D0" CR_TAB
+                      "ror %C0" CR_TAB
+                      "ror %B0" CR_TAB
+                      "ror %A0", insn, operands, len, 4);
+  return "";
+}
+
+/* 8-bit logic shift right ((unsigned char)x >> i) */
+
+const char *
+lshrqi3_out (rtx_insn *insn, rtx operands[], int *len)
+{
+  if (CONST_INT_P (operands[2]))
+    {
+      int k;
+
+      if (!len)
+	len = &k;
+
+      switch (INTVAL (operands[2]))
+	{
+	default:
+	  if (INTVAL (operands[2]) < 8)
+	    break;
+
+	  *len = 1;
+	  return "clr %0";
+
+	case 1:
+	  *len = 1;
+	  return "lsr %0";
+
+	case 2:
+	  *len = 2;
+	  return ("lsr %0" CR_TAB
+		  "lsr %0");
+	case 3:
+	  *len = 3;
+	  return ("lsr %0" CR_TAB
+		  "lsr %0" CR_TAB
+		  "lsr %0");
+
+	case 4:
+	  if (test_hard_reg_class (LD_REGS, operands[0]))
+	    {
+	      *len=2;
+	      return ("swap %0" CR_TAB
+		      "andi %0,0x0f");
+	    }
+	  *len = 4;
+	  return ("lsr %0" CR_TAB
+		  "lsr %0" CR_TAB
+		  "lsr %0" CR_TAB
+		  "lsr %0");
+
+	case 5:
+	  if (test_hard_reg_class (LD_REGS, operands[0]))
+	    {
+	      *len = 3;
+	      return ("swap %0" CR_TAB
+		      "lsr %0"  CR_TAB
+		      "andi %0,0x7");
+	    }
+	  *len = 5;
+	  return ("lsr %0" CR_TAB
+		  "lsr %0" CR_TAB
+		  "lsr %0" CR_TAB
+		  "lsr %0" CR_TAB
+		  "lsr %0");
+
+	case 6:
+	  if (test_hard_reg_class (LD_REGS, operands[0]))
+	    {
+	      *len = 4;
+	      return ("swap %0" CR_TAB
+		      "lsr %0"  CR_TAB
+		      "lsr %0"  CR_TAB
+		      "andi %0,0x3");
+	    }
+	  *len = 6;
+	  return ("lsr %0" CR_TAB
+		  "lsr %0" CR_TAB
+		  "lsr %0" CR_TAB
+		  "lsr %0" CR_TAB
+		  "lsr %0" CR_TAB
+		  "lsr %0");
+
+	case 7:
+	  *len = 3;
+	  return ("rol %0" CR_TAB
+		  "clr %0" CR_TAB
+		  "rol %0");
+	}
+    }
+  else if (CONSTANT_P (operands[2]))
+    fatal_insn ("internal compiler error.  Incorrect shift:", insn);
+
+  out_shift_with_cnt ("lsr %0",
+                      insn, operands, len, 1);
+  return "";
+}
+
+/* 16-bit logic shift right ((unsigned short)x >> i) */
+
+const char *
+lshrhi3_out (rtx_insn *insn, rtx operands[], int *len)
+{
+  if (CONST_INT_P (operands[2]))
+    {
+      int scratch = (GET_CODE (PATTERN (insn)) == PARALLEL);
+      int ldi_ok = test_hard_reg_class (LD_REGS, operands[0]);
+      int k;
+      int *t = len;
+
+      if (!len)
+	len = &k;
+
+      switch (INTVAL (operands[2]))
+	{
+	default:
+	  if (INTVAL (operands[2]) < 16)
+	    break;
+
+	  *len = 2;
+	  return ("clr %B0" CR_TAB
+		  "clr %A0");
+
+	case 4:
+	  if (optimize_size && scratch)
+	    break;  /* 5 */
+	  if (ldi_ok)
+	    {
+	      *len = 6;
+	      return ("swap %B0"      CR_TAB
+		      "swap %A0"      CR_TAB
+		      "andi %A0,0x0f" CR_TAB
+		      "eor %A0,%B0"   CR_TAB
+		      "andi %B0,0x0f" CR_TAB
+		      "eor %A0,%B0");
+	    }
+	  if (scratch)
+	    {
+	      *len = 7;
+	      return ("swap %B0"    CR_TAB
+		      "swap %A0"    CR_TAB
+		      "ldi %3,0x0f" CR_TAB
+		      "and %A0,%3"  CR_TAB
+		      "eor %A0,%B0" CR_TAB
+		      "and %B0,%3"  CR_TAB
+		      "eor %A0,%B0");
+	    }
+	  break;  /* optimize_size ? 6 : 8 */
+
+	case 5:
+	  if (optimize_size)
+	    break;  /* scratch ? 5 : 6 */
+	  if (ldi_ok)
+	    {
+	      *len = 8;
+	      return ("lsr %B0"       CR_TAB
+		      "ror %A0"       CR_TAB
+		      "swap %B0"      CR_TAB
+		      "swap %A0"      CR_TAB
+		      "andi %A0,0x0f" CR_TAB
+		      "eor %A0,%B0"   CR_TAB
+		      "andi %B0,0x0f" CR_TAB
+		      "eor %A0,%B0");
+	    }
+	  if (scratch)
+	    {
+	      *len = 9;
+	      return ("lsr %B0"     CR_TAB
+		      "ror %A0"     CR_TAB
+		      "swap %B0"    CR_TAB
+		      "swap %A0"    CR_TAB
+		      "ldi %3,0x0f" CR_TAB
+		      "and %A0,%3"  CR_TAB
+		      "eor %A0,%B0" CR_TAB
+		      "and %B0,%3"  CR_TAB
+		      "eor %A0,%B0");
+	    }
+	  break;  /* 10 */
+
+	case 6:
+	  if (optimize_size)
+	    break;  /* scratch ? 5 : 6 */
+	  *len = 9;
+	  return ("clr __tmp_reg__" CR_TAB
+		  "lsl %A0"         CR_TAB
+		  "rol %B0"         CR_TAB
+		  "rol __tmp_reg__" CR_TAB
+		  "lsl %A0"         CR_TAB
+		  "rol %B0"         CR_TAB
+		  "rol __tmp_reg__" CR_TAB
+		  "mov %A0,%B0"     CR_TAB
+		  "mov %B0,__tmp_reg__");
+
+	case 7:
+	  *len = 5;
+	  return ("lsl %A0"     CR_TAB
+		  "mov %A0,%B0" CR_TAB
+		  "rol %A0"     CR_TAB
+		  "sbc %B0,%B0" CR_TAB
+		  "neg %B0");
+
+	case 8:
+	  return *len = 2, ("mov %A0,%B1" CR_TAB
+			    "clr %B0");
+
+	case 9:
+	  *len = 3;
+	  return ("mov %A0,%B0" CR_TAB
+		  "clr %B0"     CR_TAB
+		  "lsr %A0");
+
+	case 10:
+	  *len = 4;
+	  return ("mov %A0,%B0" CR_TAB
+		  "clr %B0"     CR_TAB
+		  "lsr %A0"     CR_TAB
+		  "lsr %A0");
+
+	case 11:
+	  *len = 5;
+	  return ("mov %A0,%B0" CR_TAB
+		  "clr %B0"     CR_TAB
+		  "lsr %A0"     CR_TAB
+		  "lsr %A0"     CR_TAB
+		  "lsr %A0");
+
+	case 12:
+	  if (ldi_ok)
+	    {
+	      *len = 4;
+	      return ("mov %A0,%B0" CR_TAB
+		      "clr %B0"     CR_TAB
+		      "swap %A0"    CR_TAB
+		      "andi %A0,0x0f");
+	    }
+	  if (scratch)
+	    {
+	      *len = 5;
+	      return ("mov %A0,%B0" CR_TAB
+		      "clr %B0"     CR_TAB
+		      "swap %A0"    CR_TAB
+		      "ldi %3,0x0f" CR_TAB
+		      "and %A0,%3");
+	    }
+	  *len = 6;
+	  return ("mov %A0,%B0" CR_TAB
+		  "clr %B0"     CR_TAB
+		  "lsr %A0"     CR_TAB
+		  "lsr %A0"     CR_TAB
+		  "lsr %A0"     CR_TAB
+		  "lsr %A0");
+
+	case 13:
+	  if (ldi_ok)
+	    {
+	      *len = 5;
+	      return ("mov %A0,%B0" CR_TAB
+		      "clr %B0"     CR_TAB
+		      "swap %A0"    CR_TAB
+		      "lsr %A0"     CR_TAB
+		      "andi %A0,0x07");
+	    }
+	  if (AVR_HAVE_MUL && scratch)
+	    {
+	      *len = 5;
+	      return ("ldi %3,0x08" CR_TAB
+		      "mul %B0,%3"  CR_TAB
+		      "mov %A0,r1"  CR_TAB
+		      "clr %B0"     CR_TAB
+		      "clr __zero_reg__");
+	    }
+	  if (optimize_size && scratch)
+	    break;  /* 5 */
+	  if (scratch)
+	    {
+	      *len = 6;
+	      return ("mov %A0,%B0" CR_TAB
+		      "clr %B0"     CR_TAB
+		      "swap %A0"    CR_TAB
+		      "lsr %A0"     CR_TAB
+		      "ldi %3,0x07" CR_TAB
+		      "and %A0,%3");
+	    }
+	  if (AVR_HAVE_MUL)
+	    {
+	      *len = 6;
+	      return ("set"        CR_TAB
+		      "bld r1,3"   CR_TAB
+		      "mul %B0,r1" CR_TAB
+		      "mov %A0,r1" CR_TAB
+		      "clr %B0"    CR_TAB
+		      "clr __zero_reg__");
+	    }
+	  *len = 7;
+	  return ("mov %A0,%B0" CR_TAB
+		  "clr %B0"     CR_TAB
+		  "lsr %A0"     CR_TAB
+		  "lsr %A0"     CR_TAB
+		  "lsr %A0"     CR_TAB
+		  "lsr %A0"     CR_TAB
+		  "lsr %A0");
+
+	case 14:
+	  if (AVR_HAVE_MUL && ldi_ok)
+	    {
+	      *len = 5;
+	      return ("ldi %A0,0x04" CR_TAB
+		      "mul %B0,%A0"  CR_TAB
+		      "mov %A0,r1"   CR_TAB
+		      "clr %B0"      CR_TAB
+		      "clr __zero_reg__");
+	    }
+	  if (AVR_HAVE_MUL && scratch)
+	    {
+	      *len = 5;
+	      return ("ldi %3,0x04" CR_TAB
+		      "mul %B0,%3"  CR_TAB
+		      "mov %A0,r1"  CR_TAB
+		      "clr %B0"     CR_TAB
+		      "clr __zero_reg__");
+	    }
+	  if (optimize_size && ldi_ok)
+	    {
+	      *len = 5;
+	      return ("mov %A0,%B0" CR_TAB
+		      "ldi %B0,6" "\n1:\t"
+		      "lsr %A0"     CR_TAB
+		      "dec %B0"     CR_TAB
+		      "brne 1b");
+	    }
+	  if (optimize_size && scratch)
+	    break;  /* 5 */
+	  *len = 6;
+	  return ("clr %A0" CR_TAB
+		  "lsl %B0" CR_TAB
+		  "rol %A0" CR_TAB
+		  "lsl %B0" CR_TAB
+		  "rol %A0" CR_TAB
+		  "clr %B0");
+
+	case 15:
+	  *len = 4;
+	  return ("clr %A0" CR_TAB
+		  "lsl %B0" CR_TAB
+		  "rol %A0" CR_TAB
+		  "clr %B0");
+	}
+      len = t;
+    }
+  out_shift_with_cnt ("lsr %B0" CR_TAB
+                      "ror %A0", insn, operands, len, 2);
+  return "";
+}
+
+
+/* 24-bit logic shift right */
+
+const char*
+avr_out_lshrpsi3 (rtx_insn *insn, rtx *op, int *plen)
+{
+  int dest = REGNO (op[0]);
+  int src = REGNO (op[1]);
+
+  if (CONST_INT_P (op[2]))
+    {
+      if (plen)
+        *plen = 0;
+
+      switch (INTVAL (op[2]))
+        {
+        case 8:
+          if (dest <= src)
+            return avr_asm_len ("mov %A0,%B1" CR_TAB
+                                "mov %B0,%C1" CR_TAB
+                                "clr %C0", op, plen, 3);
+          else
+            return avr_asm_len ("clr %C0"     CR_TAB
+                                "mov %B0,%C1" CR_TAB
+                                "mov %A0,%B1", op, plen, 3);
+
+        case 16:
+          if (dest != src + 2)
+            avr_asm_len ("mov %A0,%C1", op, plen, 1);
+
+          return avr_asm_len ("clr %B0"  CR_TAB
+                              "clr %C0", op, plen, 2);
+
+        default:
+          if (INTVAL (op[2]) < 24)
+            break;
+
+          /* fall through */
+
+        case 23:
+          return avr_asm_len ("clr %A0"    CR_TAB
+                              "sbrc %C0,7" CR_TAB
+                              "inc %A0"    CR_TAB
+                              "clr %B0"    CR_TAB
+                              "clr %C0", op, plen, 5);
+        } /* switch */
+    }
+
+  out_shift_with_cnt ("lsr %C0" CR_TAB
+                      "ror %B0" CR_TAB
+                      "ror %A0", insn, op, plen, 3);
+  return "";
+}
+
+
+/* 32-bit logic shift right ((unsigned int)x >> i) */
+
+const char *
+lshrsi3_out (rtx_insn *insn, rtx operands[], int *len)
+{
+  if (CONST_INT_P (operands[2]))
+    {
+      int k;
+      int *t = len;
+
+      if (!len)
+	len = &k;
+
+      switch (INTVAL (operands[2]))
+	{
+	default:
+	  if (INTVAL (operands[2]) < 32)
+	    break;
+
+	  if (AVR_HAVE_MOVW)
+	    return *len = 3, ("clr %D0" CR_TAB
+			      "clr %C0" CR_TAB
+			      "movw %A0,%C0");
+	  *len = 4;
+	  return ("clr %D0" CR_TAB
+		  "clr %C0" CR_TAB
+		  "clr %B0" CR_TAB
+		  "clr %A0");
+
+	case 8:
+	  {
+	    int reg0 = true_regnum (operands[0]);
+	    int reg1 = true_regnum (operands[1]);
+	    *len = 4;
+	    if (reg0 <= reg1)
+	      return ("mov %A0,%B1" CR_TAB
+		      "mov %B0,%C1" CR_TAB
+		      "mov %C0,%D1" CR_TAB
+		      "clr %D0");
+	    else
+	      return ("clr %D0"     CR_TAB
+		      "mov %C0,%D1" CR_TAB
+		      "mov %B0,%C1" CR_TAB
+		      "mov %A0,%B1");
+	  }
+
+	case 16:
+	  {
+	    int reg0 = true_regnum (operands[0]);
+	    int reg1 = true_regnum (operands[1]);
+
+	    if (reg0 == reg1 + 2)
+	      return *len = 2, ("clr %C0"     CR_TAB
+				"clr %D0");
+	    if (AVR_HAVE_MOVW)
+	      return *len = 3, ("movw %A0,%C1" CR_TAB
+				"clr %C0"      CR_TAB
+				"clr %D0");
+	    else
+	      return *len = 4, ("mov %B0,%D1" CR_TAB
+				"mov %A0,%C1" CR_TAB
+				"clr %C0"     CR_TAB
+				"clr %D0");
+	  }
+
+	case 24:
+	  return *len = 4, ("mov %A0,%D1" CR_TAB
+			    "clr %B0"     CR_TAB
+			    "clr %C0"     CR_TAB
+			    "clr %D0");
+
+	case 31:
+	  *len = 6;
+	  return ("clr %A0"    CR_TAB
+		  "sbrc %D0,7" CR_TAB
+		  "inc %A0"    CR_TAB
+		  "clr %B0"    CR_TAB
+		  "clr %C0"    CR_TAB
+		  "clr %D0");
+	}
+      len = t;
+    }
+  out_shift_with_cnt ("lsr %D0" CR_TAB
+                      "ror %C0" CR_TAB
+                      "ror %B0" CR_TAB
+                      "ror %A0", insn, operands, len, 4);
+  return "";
+}
+
+
+/* Output addition of register XOP[0] and compile time constant XOP[2].
+   CODE == PLUS:  perform addition by using ADD instructions or
+   CODE == MINUS: perform addition by using SUB instructions:
+
+      XOP[0] = XOP[0] + XOP[2]
+
+   Or perform addition/subtraction with register XOP[2] depending on CODE:
+
+      XOP[0] = XOP[0] +/- XOP[2]
+
+   If PLEN == NULL, print assembler instructions to perform the operation;
+   otherwise, set *PLEN to the length of the instruction sequence (in words)
+   printed with PLEN == NULL.  XOP[3] is an 8-bit scratch register or NULL_RTX.
+   Set *PCC to effect on cc0 according to respective CC_* insn attribute.
+
+   CODE_SAT == UNKNOWN: Perform ordinary, non-saturating operation.
+   CODE_SAT != UNKNOWN: Perform operation and saturate according to CODE_SAT.
+   If  CODE_SAT != UNKNOWN  then SIGN contains the sign of the summand resp.
+   the subtrahend in the original insn, provided it is a compile time constant.
+   In all other cases, SIGN is 0.
+
+   If OUT_LABEL is true, print the final 0: label which is needed for
+   saturated addition / subtraction.  The only case where OUT_LABEL = false
+   is useful is for saturated addition / subtraction performed during
+   fixed-point rounding, cf. `avr_out_round'.  */
+
+static void
+avr_out_plus_1 (rtx *xop, int *plen, enum rtx_code code, int *pcc,
+                enum rtx_code code_sat, int sign, bool out_label)
+{
+  /* MODE of the operation.  */
+  machine_mode mode = GET_MODE (xop[0]);
+
+  /* INT_MODE of the same size.  */
+  scalar_int_mode imode = int_mode_for_mode (mode).require ();
+
+  /* Number of bytes to operate on.  */
+  int n_bytes = GET_MODE_SIZE (mode);
+
+  /* Value (0..0xff) held in clobber register op[3] or -1 if unknown.  */
+  int clobber_val = -1;
+
+  /* op[0]: 8-bit destination register
+     op[1]: 8-bit const int
+     op[2]: 8-bit scratch register */
+  rtx op[3];
+
+  /* Started the operation?  Before starting the operation we may skip
+     adding 0.  This is no more true after the operation started because
+     carry must be taken into account.  */
+  bool started = false;
+
+  /* Value to add.  There are two ways to add VAL: R += VAL and R -= -VAL.  */
+  rtx xval = xop[2];
+
+  /* Output a BRVC instruction.  Only needed with saturation.  */
+  bool out_brvc = true;
+
+  if (plen)
+    *plen = 0;
+
+  if (REG_P (xop[2]))
+    {
+      *pcc = MINUS == code ? (int) CC_SET_CZN : (int) CC_CLOBBER;
+
+      for (int i = 0; i < n_bytes; i++)
+        {
+          /* We operate byte-wise on the destination.  */
+          op[0] = simplify_gen_subreg (QImode, xop[0], mode, i);
+          op[1] = simplify_gen_subreg (QImode, xop[2], mode, i);
+
+          if (i == 0)
+            avr_asm_len (code == PLUS ? "add %0,%1" : "sub %0,%1",
+                         op, plen, 1);
+          else
+            avr_asm_len (code == PLUS ? "adc %0,%1" : "sbc %0,%1",
+                         op, plen, 1);
+        }
+
+      if (reg_overlap_mentioned_p (xop[0], xop[2]))
+        {
+          gcc_assert (REGNO (xop[0]) == REGNO (xop[2]));
+
+          if (MINUS == code)
+            return;
+        }
+
+      goto saturate;
+    }
+
+  /* Except in the case of ADIW with 16-bit register (see below)
+     addition does not set cc0 in a usable way.  */
+
+  *pcc = (MINUS == code) ? CC_SET_CZN : CC_CLOBBER;
+
+  if (CONST_FIXED_P (xval))
+    xval = avr_to_int_mode (xval);
+
+  /* Adding/Subtracting zero is a no-op.  */
+
+  if (xval == const0_rtx)
+    {
+      *pcc = CC_NONE;
+      return;
+    }
+
+  if (MINUS == code)
+    xval = simplify_unary_operation (NEG, imode, xval, imode);
+
+  op[2] = xop[3];
+
+  if (SS_PLUS == code_sat && MINUS == code
+      && sign < 0
+      && 0x80 == (INTVAL (simplify_gen_subreg (QImode, xval, imode, n_bytes-1))
+                  & GET_MODE_MASK (QImode)))
+    {
+      /* We compute x + 0x80 by means of SUB instructions.  We negated the
+         constant subtrahend above and are left with  x - (-128)  so that we
+         need something like SUBI r,128 which does not exist because SUBI sets
+         V according to the sign of the subtrahend.  Notice the only case
+         where this must be done is when NEG overflowed in case [2s] because
+         the V computation needs the right sign of the subtrahend.  */
+
+      rtx msb = simplify_gen_subreg (QImode, xop[0], mode, n_bytes - 1);
+
+      avr_asm_len ("subi %0,128" CR_TAB
+                   "brmi 0f", &msb, plen, 2);
+      out_brvc = false;
+
+      goto saturate;
+    }
+
+  for (int i = 0; i < n_bytes; i++)
+    {
+      /* We operate byte-wise on the destination.  */
+      rtx reg8 = simplify_gen_subreg (QImode, xop[0], mode, i);
+      rtx xval8 = simplify_gen_subreg (QImode, xval, imode, i);
+
+      /* 8-bit value to operate with this byte. */
+      unsigned int val8 = UINTVAL (xval8) & GET_MODE_MASK (QImode);
+
+      /* Registers R16..R31 can operate with immediate.  */
+      bool ld_reg_p = test_hard_reg_class (LD_REGS, reg8);
+
+      op[0] = reg8;
+      op[1] = gen_int_mode (val8, QImode);
+
+      /* To get usable cc0 no low-bytes must have been skipped.  */
+
+      if (i && !started)
+        *pcc = CC_CLOBBER;
+
+      if (!started
+          && i % 2 == 0
+          && i + 2 <= n_bytes
+          && test_hard_reg_class (ADDW_REGS, reg8))
+        {
+          rtx xval16 = simplify_gen_subreg (HImode, xval, imode, i);
+          unsigned int val16 = UINTVAL (xval16) & GET_MODE_MASK (HImode);
+
+          /* Registers R24, X, Y, Z can use ADIW/SBIW with constants < 64
+             i.e. operate word-wise.  */
+
+          if (val16 < 64)
+            {
+              if (val16 != 0)
+                {
+                  started = true;
+                  avr_asm_len (code == PLUS ? "adiw %0,%1" : "sbiw %0,%1",
+                               op, plen, 1);
+
+                  if (n_bytes == 2 && PLUS == code)
+                    *pcc = CC_SET_CZN;
+                }
+
+              i++;
+              continue;
+            }
+        }
+
+      if (val8 == 0)
+        {
+          if (started)
+            avr_asm_len (code == PLUS
+                         ? "adc %0,__zero_reg__" : "sbc %0,__zero_reg__",
+                         op, plen, 1);
+          continue;
+        }
+      else if ((val8 == 1 || val8 == 0xff)
+               && UNKNOWN == code_sat
+               && !started
+               && i == n_bytes - 1)
+        {
+          avr_asm_len ((code == PLUS) ^ (val8 == 1) ? "dec %0" : "inc %0",
+                       op, plen, 1);
+          *pcc = CC_CLOBBER;
+          break;
+        }
+
+      switch (code)
+        {
+        case PLUS:
+
+          gcc_assert (plen != NULL || (op[2] && REG_P (op[2])));
+
+          if (plen != NULL && UNKNOWN != code_sat)
+            {
+              /* This belongs to the x + 0x80 corner case.  The code with
+                 ADD instruction is not smaller, thus make this case
+                 expensive so that the caller won't pick it.  */
+
+              *plen += 10;
+              break;
+            }
+
+          if (clobber_val != (int) val8)
+            avr_asm_len ("ldi %2,%1", op, plen, 1);
+          clobber_val = (int) val8;
+
+          avr_asm_len (started ? "adc %0,%2" : "add %0,%2", op, plen, 1);
+
+          break; /* PLUS */
+
+        case MINUS:
+
+          if (ld_reg_p)
+            avr_asm_len (started ? "sbci %0,%1" : "subi %0,%1", op, plen, 1);
+          else
+            {
+              gcc_assert (plen != NULL || REG_P (op[2]));
+
+              if (clobber_val != (int) val8)
+                avr_asm_len ("ldi %2,%1", op, plen, 1);
+              clobber_val = (int) val8;
+
+              avr_asm_len (started ? "sbc %0,%2" : "sub %0,%2", op, plen, 1);
+            }
+
+          break; /* MINUS */
+
+        default:
+          /* Unknown code */
+          gcc_unreachable();
+        }
+
+      started = true;
+
+    } /* for all sub-bytes */
+
+ saturate:
+
+  if (UNKNOWN == code_sat)
+    return;
+
+  *pcc = (int) CC_CLOBBER;
+
+  /* Vanilla addition/subtraction is done.  We are left with saturation.
+
+     We have to compute  A = A <op> B  where  A  is a register and
+     B is a register or a non-zero compile time constant CONST.
+     A is register class "r" if unsigned && B is REG.  Otherwise, A is in "d".
+     B stands for the original operand $2 in INSN.  In the case of B = CONST,
+     SIGN in { -1, 1 } is the sign of B.  Otherwise, SIGN is 0.
+
+     CODE is the instruction flavor we use in the asm sequence to perform <op>.
+
+
+     unsigned
+     operation        |  code |  sat if  |    b is      | sat value |  case
+     -----------------+-------+----------+--------------+-----------+-------
+     +  as  a + b     |  add  |  C == 1  |  const, reg  | u+ = 0xff |  [1u]
+     +  as  a - (-b)  |  sub  |  C == 0  |  const       | u+ = 0xff |  [2u]
+     -  as  a - b     |  sub  |  C == 1  |  const, reg  | u- = 0    |  [3u]
+     -  as  a + (-b)  |  add  |  C == 0  |  const       | u- = 0    |  [4u]
+
+
+     signed
+     operation        |  code |  sat if  |    b is      | sat value |  case
+     -----------------+-------+----------+--------------+-----------+-------
+     +  as  a + b     |  add  |  V == 1  |  const, reg  | s+        |  [1s]
+     +  as  a - (-b)  |  sub  |  V == 1  |  const       | s+        |  [2s]
+     -  as  a - b     |  sub  |  V == 1  |  const, reg  | s-        |  [3s]
+     -  as  a + (-b)  |  add  |  V == 1  |  const       | s-        |  [4s]
+
+     s+  =  b < 0  ?  -0x80 :  0x7f
+     s-  =  b < 0  ?   0x7f : -0x80
+
+     The cases a - b actually perform  a - (-(-b))  if B is CONST.
+  */
+
+  op[0] = simplify_gen_subreg (QImode, xop[0], mode, n_bytes-1);
+  op[1] = n_bytes > 1
+    ? simplify_gen_subreg (QImode, xop[0], mode, n_bytes-2)
+    : NULL_RTX;
+
+  bool need_copy = true;
+  int len_call = 1 + AVR_HAVE_JMP_CALL;
+
+  switch (code_sat)
+    {
+    default:
+      gcc_unreachable();
+
+    case SS_PLUS:
+    case SS_MINUS:
+
+      if (out_brvc)
+        avr_asm_len ("brvc 0f", op, plen, 1);
+
+      if (reg_overlap_mentioned_p (xop[0], xop[2]))
+        {
+          /* [1s,reg] */
+
+          if (n_bytes == 1)
+            avr_asm_len ("ldi %0,0x7f" CR_TAB
+                         "adc %0,__zero_reg__", op, plen, 2);
+          else
+            avr_asm_len ("ldi %0,0x7f" CR_TAB
+                         "ldi %1,0xff" CR_TAB
+                         "adc %1,__zero_reg__" CR_TAB
+                         "adc %0,__zero_reg__", op, plen, 4);
+        }
+      else if (sign == 0 && PLUS == code)
+        {
+          /* [1s,reg] */
+
+          op[2] = simplify_gen_subreg (QImode, xop[2], mode, n_bytes-1);
+
+          if (n_bytes == 1)
+            avr_asm_len ("ldi %0,0x80" CR_TAB
+                         "sbrs %2,7"   CR_TAB
+                         "dec %0", op, plen, 3);
+          else
+            avr_asm_len ("ldi %0,0x80" CR_TAB
+                         "cp %2,%0"    CR_TAB
+                         "sbc %1,%1"   CR_TAB
+                         "sbci %0,0", op, plen, 4);
+        }
+      else if (sign == 0 && MINUS == code)
+        {
+          /* [3s,reg] */
+
+          op[2] = simplify_gen_subreg (QImode, xop[2], mode, n_bytes-1);
+
+          if (n_bytes == 1)
+            avr_asm_len ("ldi %0,0x7f" CR_TAB
+                         "sbrs %2,7"   CR_TAB
+                         "inc %0", op, plen, 3);
+          else
+            avr_asm_len ("ldi %0,0x7f" CR_TAB
+                         "cp %0,%2"    CR_TAB
+                         "sbc %1,%1"   CR_TAB
+                         "sbci %0,-1", op, plen, 4);
+        }
+      else if ((sign < 0) ^ (SS_MINUS == code_sat))
+        {
+          /* [1s,const,B < 0] [2s,B < 0] */
+          /* [3s,const,B > 0] [4s,B > 0] */
+
+          if (n_bytes == 8)
+            {
+              avr_asm_len ("%~call __clr_8", op, plen, len_call);
+              need_copy = false;
+            }
+
+          avr_asm_len ("ldi %0,0x80", op, plen, 1);
+          if (n_bytes > 1 && need_copy)
+            avr_asm_len ("clr %1", op, plen, 1);
+        }
+      else if ((sign > 0) ^ (SS_MINUS == code_sat))
+        {
+          /* [1s,const,B > 0] [2s,B > 0] */
+          /* [3s,const,B < 0] [4s,B < 0] */
+
+          if (n_bytes == 8)
+            {
+              avr_asm_len ("sec" CR_TAB
+                           "%~call __sbc_8", op, plen, 1 + len_call);
+              need_copy = false;
+            }
+
+          avr_asm_len ("ldi %0,0x7f", op, plen, 1);
+          if (n_bytes > 1 && need_copy)
+            avr_asm_len ("ldi %1,0xff", op, plen, 1);
+        }
+      else
+        gcc_unreachable();
+
+      break;
+
+    case US_PLUS:
+      /* [1u] : [2u] */
+
+      avr_asm_len (PLUS == code ? "brcc 0f" : "brcs 0f", op, plen, 1);
+
+      if (n_bytes == 8)
+        {
+          if (MINUS == code)
+            avr_asm_len ("sec", op, plen, 1);
+          avr_asm_len ("%~call __sbc_8", op, plen, len_call);
+
+          need_copy = false;
+        }
+      else
+        {
+          if (MINUS == code && !test_hard_reg_class (LD_REGS, op[0]))
+            avr_asm_len ("sec" CR_TAB
+                         "sbc %0,%0", op, plen, 2);
+          else
+            avr_asm_len (PLUS == code ? "sbc %0,%0" : "ldi %0,0xff",
+                         op, plen, 1);
+        }
+      break; /* US_PLUS */
+
+    case US_MINUS:
+      /* [4u] : [3u] */
+
+      avr_asm_len (PLUS == code ? "brcs 0f" : "brcc 0f", op, plen, 1);
+
+      if (n_bytes == 8)
+        {
+          avr_asm_len ("%~call __clr_8", op, plen, len_call);
+          need_copy = false;
+        }
+      else
+        avr_asm_len ("clr %0", op, plen, 1);
+
+      break;
+    }
+
+  /* We set the MSB in the unsigned case and the 2 MSBs in the signed case.
+     Now copy the right value to the LSBs.  */
+
+  if (need_copy && n_bytes > 1)
+    {
+      if (US_MINUS == code_sat || US_PLUS == code_sat)
+        {
+          avr_asm_len ("mov %1,%0", op, plen, 1);
+
+          if (n_bytes > 2)
+            {
+              op[0] = xop[0];
+              if (AVR_HAVE_MOVW)
+                avr_asm_len ("movw %0,%1", op, plen, 1);
+              else
+                avr_asm_len ("mov %A0,%1" CR_TAB
+                             "mov %B0,%1", op, plen, 2);
+            }
+        }
+      else if (n_bytes > 2)
+        {
+          op[0] = xop[0];
+          avr_asm_len ("mov %A0,%1" CR_TAB
+                       "mov %B0,%1", op, plen, 2);
+        }
+    }
+
+  if (need_copy && n_bytes == 8)
+    {
+      if (AVR_HAVE_MOVW)
+        avr_asm_len ("movw %r0+2,%0" CR_TAB
+                     "movw %r0+4,%0", xop, plen, 2);
+      else
+        avr_asm_len ("mov %r0+2,%0" CR_TAB
+                     "mov %r0+3,%0" CR_TAB
+                     "mov %r0+4,%0" CR_TAB
+                     "mov %r0+5,%0", xop, plen, 4);
+    }
+
+  if (out_label)
+    avr_asm_len ("0:", op, plen, 0);
+}
+
+
+/* Output addition/subtraction of register XOP[0] and a constant XOP[2] that
+   is ont a compile-time constant:
+
+      XOP[0] = XOP[0] +/- XOP[2]
+
+   This is a helper for the function below.  The only insns that need this
+   are additions/subtraction for pointer modes, i.e. HImode and PSImode.  */
+
+static const char*
+avr_out_plus_symbol (rtx *xop, enum rtx_code code, int *plen, int *pcc)
+{
+  machine_mode mode = GET_MODE (xop[0]);
+
+  /* Only pointer modes want to add symbols.  */
+
+  gcc_assert (mode == HImode || mode == PSImode);
+
+  *pcc = MINUS == code ? (int) CC_SET_CZN : (int) CC_SET_N;
+
+  avr_asm_len (PLUS == code
+               ? "subi %A0,lo8(-(%2))" CR_TAB "sbci %B0,hi8(-(%2))"
+               : "subi %A0,lo8(%2)"    CR_TAB "sbci %B0,hi8(%2)",
+               xop, plen, -2);
+
+  if (PSImode == mode)
+    avr_asm_len (PLUS == code
+                 ? "sbci %C0,hlo8(-(%2))"
+                 : "sbci %C0,hlo8(%2)", xop, plen, 1);
+  return "";
+}
+
+
+/* Prepare operands of addition/subtraction to be used with avr_out_plus_1.
+
+   INSN is a single_set insn or an insn pattern with a binary operation as
+   SET_SRC that is one of: PLUS, SS_PLUS, US_PLUS, MINUS, SS_MINUS, US_MINUS.
+
+   XOP are the operands of INSN.  In the case of 64-bit operations with
+   constant XOP[] has just one element:  The summand/subtrahend in XOP[0].
+   The non-saturating insns up to 32 bits may or may not supply a "d" class
+   scratch as XOP[3].
+
+   If PLEN == NULL output the instructions.
+   If PLEN != NULL set *PLEN to the length of the sequence in words.
+
+   PCC is a pointer to store the instructions' effect on cc0.
+   PCC may be NULL.
+
+   PLEN and PCC default to NULL.
+
+   OUT_LABEL defaults to TRUE.  For a description, see AVR_OUT_PLUS_1.
+
+   Return ""  */
+
+const char*
+avr_out_plus (rtx insn, rtx *xop, int *plen, int *pcc, bool out_label)
+{
+  int cc_plus, cc_minus, cc_dummy;
+  int len_plus, len_minus;
+  rtx op[4];
+  rtx xpattern = INSN_P (insn) ? single_set (as_a <rtx_insn *> (insn)) : insn;
+  rtx xdest = SET_DEST (xpattern);
+  machine_mode mode = GET_MODE (xdest);
+  scalar_int_mode imode = int_mode_for_mode (mode).require ();
+  int n_bytes = GET_MODE_SIZE (mode);
+  enum rtx_code code_sat = GET_CODE (SET_SRC (xpattern));
+  enum rtx_code code
+    = (PLUS == code_sat || SS_PLUS == code_sat || US_PLUS == code_sat
+       ? PLUS : MINUS);
+
+  if (!pcc)
+    pcc = &cc_dummy;
+
+  /* PLUS and MINUS don't saturate:  Use modular wrap-around.  */
+
+  if (PLUS == code_sat || MINUS == code_sat)
+    code_sat = UNKNOWN;
+
+  if (n_bytes <= 4 && REG_P (xop[2]))
+    {
+      avr_out_plus_1 (xop, plen, code, pcc, code_sat, 0, out_label);
+      return "";
+    }
+
+  if (n_bytes == 8)
+    {
+      op[0] = gen_rtx_REG (DImode, ACC_A);
+      op[1] = gen_rtx_REG (DImode, ACC_A);
+      op[2] = avr_to_int_mode (xop[0]);
+    }
+  else
+    {
+      if (!REG_P (xop[2])
+          && !CONST_INT_P (xop[2])
+          && !CONST_FIXED_P (xop[2]))
+        {
+          return avr_out_plus_symbol (xop, code, plen, pcc);
+        }
+
+      op[0] = avr_to_int_mode (xop[0]);
+      op[1] = avr_to_int_mode (xop[1]);
+      op[2] = avr_to_int_mode (xop[2]);
+    }
+
+  /* Saturations and 64-bit operations don't have a clobber operand.
+     For the other cases, the caller will provide a proper XOP[3].  */
+
+  xpattern = INSN_P (insn) ? PATTERN (insn) : insn;
+  op[3] = PARALLEL == GET_CODE (xpattern) ? xop[3] : NULL_RTX;
+
+  /* Saturation will need the sign of the original operand.  */
+
+  rtx xmsb = simplify_gen_subreg (QImode, op[2], imode, n_bytes-1);
+  int sign = INTVAL (xmsb) < 0 ? -1 : 1;
+
+  /* If we subtract and the subtrahend is a constant, then negate it
+     so that avr_out_plus_1 can be used.  */
+
+  if (MINUS == code)
+    op[2] = simplify_unary_operation (NEG, imode, op[2], imode);
+
+  /* Work out the shortest sequence.  */
+
+  avr_out_plus_1 (op, &len_minus, MINUS, &cc_minus, code_sat, sign, out_label);
+  avr_out_plus_1 (op, &len_plus, PLUS, &cc_plus, code_sat, sign, out_label);
+
+  if (plen)
+    {
+      *plen = (len_minus <= len_plus) ? len_minus : len_plus;
+      *pcc  = (len_minus <= len_plus) ? cc_minus : cc_plus;
+    }
+  else if (len_minus <= len_plus)
+    avr_out_plus_1 (op, NULL, MINUS, pcc, code_sat, sign, out_label);
+  else
+    avr_out_plus_1 (op, NULL, PLUS, pcc, code_sat, sign, out_label);
+
+  return "";
+}
+
+
+/* Output bit operation (IOR, AND, XOR) with register XOP[0] and compile
+   time constant XOP[2]:
+
+      XOP[0] = XOP[0] <op> XOP[2]
+
+   and return "".  If PLEN == NULL, print assembler instructions to perform the
+   operation; otherwise, set *PLEN to the length of the instruction sequence
+   (in words) printed with PLEN == NULL.  XOP[3] is either an 8-bit clobber
+   register or SCRATCH if no clobber register is needed for the operation.
+   INSN is an INSN_P or a pattern of an insn.  */
+
+const char*
+avr_out_bitop (rtx insn, rtx *xop, int *plen)
+{
+  /* CODE and MODE of the operation.  */
+  rtx xpattern = INSN_P (insn) ? single_set (as_a <rtx_insn *> (insn)) : insn;
+  enum rtx_code code = GET_CODE (SET_SRC (xpattern));
+  machine_mode mode = GET_MODE (xop[0]);
+
+  /* Number of bytes to operate on.  */
+  int n_bytes = GET_MODE_SIZE (mode);
+
+  /* Value of T-flag (0 or 1) or -1 if unknow.  */
+  int set_t = -1;
+
+  /* Value (0..0xff) held in clobber register op[3] or -1 if unknown.  */
+  int clobber_val = -1;
+
+  /* op[0]: 8-bit destination register
+     op[1]: 8-bit const int
+     op[2]: 8-bit clobber register, SCRATCH or NULL_RTX.
+     op[3]: 8-bit register containing 0xff or NULL_RTX  */
+  rtx op[4];
+
+  op[2] = QImode == mode ? NULL_RTX : xop[3];
+  op[3] = NULL_RTX;
+
+  if (plen)
+    *plen = 0;
+
+  for (int i = 0; i < n_bytes; i++)
+    {
+      /* We operate byte-wise on the destination.  */
+      rtx reg8 = simplify_gen_subreg (QImode, xop[0], mode, i);
+      rtx xval8 = simplify_gen_subreg (QImode, xop[2], mode, i);
+
+      /* 8-bit value to operate with this byte. */
+      unsigned int val8 = UINTVAL (xval8) & GET_MODE_MASK (QImode);
+
+      /* Number of bits set in the current byte of the constant.  */
+      int pop8 = popcount_hwi (val8);
+
+      /* Registers R16..R31 can operate with immediate.  */
+      bool ld_reg_p = test_hard_reg_class (LD_REGS, reg8);
+
+      op[0] = reg8;
+      op[1] = GEN_INT (val8);
+
+      switch (code)
+        {
+        case IOR:
+
+	  if (pop8 == 0)
+            continue;
+          else if (ld_reg_p)
+            avr_asm_len ("ori %0,%1", op, plen, 1);
+	  else if (pop8 == 1)
+            {
+              if (set_t != 1)
+                avr_asm_len ("set", op, plen, 1);
+              set_t = 1;
+
+              op[1] = GEN_INT (exact_log2 (val8));
+              avr_asm_len ("bld %0,%1", op, plen, 1);
+            }
+	  else if (pop8 == 8)
+            {
+              if (op[3] != NULL_RTX)
+                avr_asm_len ("mov %0,%3", op, plen, 1);
+              else
+                avr_asm_len ("clr %0" CR_TAB
+                             "dec %0", op, plen, 2);
+
+              op[3] = op[0];
+            }
+          else
+            {
+              if (clobber_val != (int) val8)
+                avr_asm_len ("ldi %2,%1", op, plen, 1);
+              clobber_val = (int) val8;
+
+              avr_asm_len ("or %0,%2", op, plen, 1);
+            }
+
+          continue; /* IOR */
+
+        case AND:
+
+	  if (pop8 == 8)
+            continue;
+	  else if (pop8 == 0)
+            avr_asm_len ("clr %0", op, plen, 1);
+          else if (ld_reg_p)
+            avr_asm_len ("andi %0,%1", op, plen, 1);
+	  else if (pop8 == 7)
+            {
+              if (set_t != 0)
+                avr_asm_len ("clt", op, plen, 1);
+              set_t = 0;
+
+              op[1] = GEN_INT (exact_log2 (GET_MODE_MASK (QImode) & ~val8));
+              avr_asm_len ("bld %0,%1", op, plen, 1);
+            }
+          else
+            {
+              if (clobber_val != (int) val8)
+                avr_asm_len ("ldi %2,%1", op, plen, 1);
+              clobber_val = (int) val8;
+
+              avr_asm_len ("and %0,%2", op, plen, 1);
+            }
+
+          continue; /* AND */
+
+        case XOR:
+
+	  if (pop8 == 0)
+            continue;
+	  else if (pop8 == 8)
+            avr_asm_len ("com %0", op, plen, 1);
+          else if (ld_reg_p && val8 == (1 << 7))
+            avr_asm_len ("subi %0,%1", op, plen, 1);
+          else
+            {
+              if (clobber_val != (int) val8)
+                avr_asm_len ("ldi %2,%1", op, plen, 1);
+              clobber_val = (int) val8;
+
+              avr_asm_len ("eor %0,%2", op, plen, 1);
+            }
+
+          continue; /* XOR */
+
+        default:
+          /* Unknown rtx_code */
+          gcc_unreachable();
+        }
+    } /* for all sub-bytes */
+
+  return "";
+}
+
+
+/* Output sign extension from XOP[1] to XOP[0] and return "".
+   If PLEN == NULL, print assembler instructions to perform the operation;
+   otherwise, set *PLEN to the length of the instruction sequence (in words)
+   as printed with PLEN == NULL.  */
+
+const char*
+avr_out_sign_extend (rtx_insn *insn, rtx *xop, int *plen)
+{
+  // Size in bytes of source resp. destination operand.
+  unsigned n_src = GET_MODE_SIZE (GET_MODE (xop[1]));
+  unsigned n_dest = GET_MODE_SIZE (GET_MODE (xop[0]));
+  rtx r_msb = all_regs_rtx[REGNO (xop[1]) + n_src - 1];
+
+  if (plen)
+    *plen = 0;
+
+  // Copy destination to source
+
+  if (REGNO (xop[0]) != REGNO (xop[1]))
+    {
+      gcc_assert (n_src <= 2);
+
+      if (n_src == 2)
+        avr_asm_len (AVR_HAVE_MOVW
+                     ? "movw %0,%1"
+                     : "mov %B0,%B1", xop, plen, 1);
+      if (n_src == 1 || !AVR_HAVE_MOVW)
+        avr_asm_len ("mov %A0,%A1", xop, plen, 1);
+    }
+
+  // Set Carry to the sign bit MSB.7...
+
+  if (REGNO (xop[0]) == REGNO (xop[1])
+      || !reg_unused_after (insn, r_msb))
+    {
+      avr_asm_len ("mov __tmp_reg__,%0", &r_msb, plen, 1);
+      r_msb = tmp_reg_rtx;
+    }
+
+  avr_asm_len ("lsl %0", &r_msb, plen, 1);
+
+  // ...and propagate it to all the new sign bits
+
+  for (unsigned n = n_src; n < n_dest; n++)
+    avr_asm_len ("sbc %0,%0", &all_regs_rtx[REGNO (xop[0]) + n], plen, 1);
+
+  return "";
+}
+
+
+/* PLEN == NULL: Output code to add CONST_INT OP[0] to SP.
+   PLEN != NULL: Set *PLEN to the length of that sequence.
+   Return "".  */
+
+const char*
+avr_out_addto_sp (rtx *op, int *plen)
+{
+  int pc_len = AVR_2_BYTE_PC ? 2 : 3;
+  int addend = INTVAL (op[0]);
+
+  if (plen)
+    *plen = 0;
+
+  if (addend < 0)
+    {
+      if (flag_verbose_asm || flag_print_asm_name)
+        avr_asm_len (ASM_COMMENT_START "SP -= %n0", op, plen, 0);
+
+      while (addend <= -pc_len)
+        {
+          addend += pc_len;
+          avr_asm_len ("rcall .", op, plen, 1);
+        }
+
+      while (addend++ < 0)
+        avr_asm_len ("push __tmp_reg__", op, plen, 1);
+    }
+  else if (addend > 0)
+    {
+      if (flag_verbose_asm || flag_print_asm_name)
+        avr_asm_len (ASM_COMMENT_START "SP += %0", op, plen, 0);
+
+      while (addend-- > 0)
+        avr_asm_len ("pop __tmp_reg__", op, plen, 1);
+    }
+
+  return "";
+}
+
+
+/* Output instructions to insert an inverted bit into OPERANDS[0]:
+   $0.$1 = ~$2.$3      if XBITNO = NULL
+   $0.$1 = ~$2.XBITNO  if XBITNO != NULL.
+   If PLEN = NULL then output the respective instruction sequence which
+   is a combination of BST / BLD and some instruction(s) to invert the bit.
+   If PLEN != NULL then store the length of the sequence (in words) in *PLEN.
+   Return "".  */
+
+const char*
+avr_out_insert_notbit (rtx_insn *insn, rtx operands[], rtx xbitno, int *plen)
+{
+  rtx op[4] = { operands[0], operands[1], operands[2],
+                xbitno == NULL_RTX ? operands [3] : xbitno };
+
+  if (INTVAL (op[1]) == 7
+      && test_hard_reg_class (LD_REGS, op[0]))
+    {
+      /* If the inserted bit number is 7 and we have a d-reg, then invert
+         the bit after the insertion by means of SUBI *,0x80.  */
+
+      if (INTVAL (op[3]) == 7
+          && REGNO (op[0]) == REGNO (op[2]))
+        {
+          avr_asm_len ("subi %0,0x80", op, plen, -1);
+        }
+      else
+        {
+          avr_asm_len ("bst %2,%3" CR_TAB
+                       "bld %0,%1" CR_TAB
+                       "subi %0,0x80", op, plen, -3);
+        }
+    }
+  else if (test_hard_reg_class (LD_REGS, op[0])
+           && (INTVAL (op[1]) != INTVAL (op[3])
+               || !reg_overlap_mentioned_p (op[0], op[2])))
+    {
+      /* If the destination bit is in a d-reg we can jump depending
+         on the source bit and use ANDI / ORI.  This just applies if we
+         have not an early-clobber situation with the bit.  */
+
+      avr_asm_len ("andi %0,~(1<<%1)" CR_TAB
+                   "sbrs %2,%3"       CR_TAB
+                   "ori %0,1<<%1", op, plen, -3);
+    }
+  else
+    {
+      /* Otherwise, invert the bit by means of COM before we store it with
+         BST and then undo the COM if needed.  */
+
+      avr_asm_len ("com %2" CR_TAB
+                   "bst %2,%3", op, plen, -2);
+
+      if (!reg_unused_after (insn, op[2])
+          // A simple 'reg_unused_after' is not enough because that function
+          // assumes that the destination register is overwritten completely
+          // and hence is in order for our purpose.  This is not the case
+          // with BLD which just changes one bit of the destination.
+          || reg_overlap_mentioned_p (op[0], op[2]))
+        {
+          /* Undo the COM from above.  */
+          avr_asm_len ("com %2", op, plen, 1);
+        }
+
+      avr_asm_len ("bld %0,%1", op, plen, 1);
+    }
+
+  return "";
+}
+
+
+/* Outputs instructions needed for fixed point type conversion.
+   This includes converting between any fixed point type, as well
+   as converting to any integer type.  Conversion between integer
+   types is not supported.
+
+   Converting signed fractional types requires a bit shift if converting
+   to or from any unsigned fractional type because the decimal place is
+   shifted by 1 bit.  When the destination is a signed fractional, the sign
+   is stored in either the carry or T bit.  */
+
+const char*
+avr_out_fract (rtx_insn *insn, rtx operands[], bool intsigned, int *plen)
+{
+  rtx xop[6];
+  RTX_CODE shift = UNKNOWN;
+  bool sign_in_carry = false;
+  bool msb_in_carry = false;
+  bool lsb_in_tmp_reg = false;
+  bool lsb_in_carry = false;
+  bool frac_rounded = false;
+  const char *code_ashift = "lsl %0";
+
+
+#define MAY_CLOBBER(RR)                                                 \
+  /* Shorthand used below.  */                                          \
+  ((sign_bytes                                                          \
+    && IN_RANGE (RR, dest.regno_msb - sign_bytes + 1, dest.regno_msb))  \
+   || (offset && IN_RANGE (RR, dest.regno, dest.regno_msb))		\
+   || (reg_unused_after (insn, all_regs_rtx[RR])                        \
+       && !IN_RANGE (RR, dest.regno, dest.regno_msb)))
+
+  struct
+  {
+    /* bytes       : Length of operand in bytes.
+       ibyte       : Length of integral part in bytes.
+       fbyte, fbit : Length of fractional part in bytes, bits.  */
+
+    bool sbit;
+    unsigned fbit, bytes, ibyte, fbyte;
+    unsigned regno, regno_msb;
+  } dest, src, *val[2] = { &dest, &src };
+
+  if (plen)
+    *plen = 0;
+
+  /* Step 0:  Determine information on source and destination operand we
+     ======   will need in the remainder.  */
+
+  for (size_t i = 0; i < ARRAY_SIZE (val); i++)
+    {
+      machine_mode mode;
+
+      xop[i] = operands[i];
+
+      mode = GET_MODE (xop[i]);
+
+      val[i]->bytes = GET_MODE_SIZE (mode);
+      val[i]->regno = REGNO (xop[i]);
+      val[i]->regno_msb = REGNO (xop[i]) + val[i]->bytes - 1;
+
+      if (SCALAR_INT_MODE_P (mode))
+        {
+          val[i]->sbit = intsigned;
+          val[i]->fbit = 0;
+        }
+      else if (ALL_SCALAR_FIXED_POINT_MODE_P (mode))
+        {
+          val[i]->sbit = SIGNED_SCALAR_FIXED_POINT_MODE_P (mode);
+          val[i]->fbit = GET_MODE_FBIT (mode);
+        }
+      else
+        fatal_insn ("unsupported fixed-point conversion", insn);
+
+      val[i]->fbyte = (1 + val[i]->fbit) / BITS_PER_UNIT;
+      val[i]->ibyte = val[i]->bytes - val[i]->fbyte;
+    }
+
+  // Byte offset of the decimal point taking into account different place
+  // of the decimal point in input and output and different register numbers
+  // of input and output.
+  int offset = dest.regno - src.regno + dest.fbyte - src.fbyte;
+
+  // Number of destination bytes that will come from sign / zero extension.
+  int sign_bytes = (dest.ibyte - src.ibyte) * (dest.ibyte > src.ibyte);
+
+  // Number of bytes at the low end to be filled with zeros.
+  int zero_bytes = (dest.fbyte - src.fbyte) * (dest.fbyte > src.fbyte);
+
+  // Do we have a 16-Bit register that is cleared?
+  rtx clrw = NULL_RTX;
+
+  bool sign_extend = src.sbit && sign_bytes;
+
+  if (dest.fbit % 8 == 0 && src.fbit % 8 == 7)
+    shift = ASHIFT;
+  else if (dest.fbit % 8 == 7 && src.fbit % 8 == 0)
+    shift = ASHIFTRT;
+  else if (dest.fbit % 8 == src.fbit % 8)
+    shift = UNKNOWN;
+  else
+    gcc_unreachable();
+
+  /* If we need to round the fraction part, we might need to save/round it
+     before clobbering any of it in Step 1.  Also, we might want to do
+     the rounding now to make use of LD_REGS.  */
+  if (SCALAR_INT_MODE_P (GET_MODE (xop[0]))
+      && SCALAR_ACCUM_MODE_P (GET_MODE (xop[1]))
+      && !TARGET_FRACT_CONV_TRUNC)
+    {
+      bool overlap
+        = (src.regno <=
+           (offset ? dest.regno_msb - sign_bytes : dest.regno + zero_bytes - 1)
+           && dest.regno - offset -1 >= dest.regno);
+      unsigned s0 = dest.regno - offset -1;
+      bool use_src = true;
+      unsigned sn;
+      unsigned copied_msb = src.regno_msb;
+      bool have_carry = false;
+
+      if (src.ibyte > dest.ibyte)
+        copied_msb -= src.ibyte - dest.ibyte;
+
+      for (sn = s0; sn <= copied_msb; sn++)
+        if (!IN_RANGE (sn, dest.regno, dest.regno_msb)
+            && !reg_unused_after (insn, all_regs_rtx[sn]))
+          use_src = false;
+      if (use_src && TEST_HARD_REG_BIT (reg_class_contents[LD_REGS], s0))
+        {
+          avr_asm_len ("tst %0" CR_TAB "brpl 0f",
+                       &all_regs_rtx[src.regno_msb], plen, 2);
+          sn = src.regno;
+          if (sn < s0)
+            {
+              if (TEST_HARD_REG_BIT (reg_class_contents[LD_REGS], sn))
+                avr_asm_len ("cpi %0,1", &all_regs_rtx[sn], plen, 1);
+              else
+                avr_asm_len ("sec" CR_TAB
+                             "cpc %0,__zero_reg__",
+                             &all_regs_rtx[sn], plen, 2);
+              have_carry = true;
+            }
+          while (++sn < s0)
+            avr_asm_len ("cpc %0,__zero_reg__", &all_regs_rtx[sn], plen, 1);
+
+          avr_asm_len (have_carry ? "sbci %0,128" : "subi %0,129",
+                       &all_regs_rtx[s0], plen, 1);
+          for (sn = src.regno + src.fbyte; sn <= copied_msb; sn++)
+            avr_asm_len ("sbci %0,255", &all_regs_rtx[sn], plen, 1);
+          avr_asm_len ("\n0:", NULL, plen, 0);
+          frac_rounded = true;
+        }
+      else if (use_src && overlap)
+        {
+          avr_asm_len ("clr __tmp_reg__" CR_TAB
+                       "sbrc %1,0"       CR_TAB
+                       "dec __tmp_reg__", xop, plen, 1);
+          sn = src.regno;
+          if (sn < s0)
+            {
+              avr_asm_len ("add %0,__tmp_reg__", &all_regs_rtx[sn], plen, 1);
+              have_carry = true;
+            }
+
+          while (++sn < s0)
+            avr_asm_len ("adc %0,__tmp_reg__", &all_regs_rtx[sn], plen, 1);
+
+          if (have_carry)
+            avr_asm_len ("clt"                CR_TAB
+                         "bld __tmp_reg__,7"  CR_TAB
+                         "adc %0,__tmp_reg__",
+                         &all_regs_rtx[s0], plen, 1);
+          else
+            avr_asm_len ("lsr __tmp_reg" CR_TAB
+                         "add %0,__tmp_reg__",
+                         &all_regs_rtx[s0], plen, 2);
+          for (sn = src.regno + src.fbyte; sn <= copied_msb; sn++)
+            avr_asm_len ("adc %0,__zero_reg__", &all_regs_rtx[sn], plen, 1);
+          frac_rounded = true;
+        }
+      else if (overlap)
+        {
+          bool use_src
+            = (TEST_HARD_REG_BIT (reg_class_contents[LD_REGS], s0)
+               && (IN_RANGE (s0, dest.regno, dest.regno_msb)
+                   || reg_unused_after (insn, all_regs_rtx[s0])));
+          xop[2] = all_regs_rtx[s0];
+          unsigned sn = src.regno;
+          if (!use_src || sn == s0)
+            avr_asm_len ("mov __tmp_reg__,%2", xop, plen, 1);
+          /* We need to consider to-be-discarded bits
+             if the value is negative.  */
+          if (sn < s0)
+            {
+              avr_asm_len ("tst %0" CR_TAB
+                           "brpl 0f",
+                           &all_regs_rtx[src.regno_msb], plen, 2);
+              /* Test to-be-discarded bytes for any nozero bits.
+                 ??? Could use OR or SBIW to test two registers at once.  */
+              if (sn < s0)
+                avr_asm_len ("cp %0,__zero_reg__", &all_regs_rtx[sn], plen, 1);
+
+              while (++sn < s0)
+                avr_asm_len ("cpc %0,__zero_reg__", &all_regs_rtx[sn], plen, 1);
+              /* Set bit 0 in __tmp_reg__ if any of the lower bits was set.  */
+              if (use_src)
+                avr_asm_len ("breq 0f" CR_TAB
+                             "ori %2,1"
+                             "\n0:\t" "mov __tmp_reg__,%2",
+                             xop, plen, 3);
+              else
+                avr_asm_len ("breq 0f" CR_TAB
+                             "set"     CR_TAB
+                             "bld __tmp_reg__,0\n0:",
+                             xop, plen, 3);
+            }
+          lsb_in_tmp_reg = true;
+        }
+    }
+
+  /* Step 1:  Clear bytes at the low end and copy payload bits from source
+     ======   to destination.  */
+
+  int step = offset < 0 ? 1 : -1;
+  unsigned d0 = offset < 0 ? dest.regno : dest.regno_msb;
+
+  // We cleared at least that number of registers.
+  int clr_n = 0;
+
+  for (; d0 >= dest.regno && d0 <= dest.regno_msb; d0 += step)
+    {
+      // Next regno of destination is needed for MOVW
+      unsigned d1 = d0 + step;
+
+      // Current and next regno of source
+      signed s0 = d0 - offset;
+      signed s1 = s0 + step;
+
+      // Must current resp. next regno be CLRed?  This applies to the low
+      // bytes of the destination that have no associated source bytes.
+      bool clr0 = s0 < (signed) src.regno;
+      bool clr1 = s1 < (signed) src.regno && d1 >= dest.regno;
+
+      // First gather what code to emit (if any) and additional step to
+      // apply if a MOVW is in use.  xop[2] is destination rtx and xop[3]
+      // is the source rtx for the current loop iteration.
+      const char *code = NULL;
+      int stepw = 0;
+
+      if (clr0)
+        {
+          if (AVR_HAVE_MOVW && clr1 && clrw)
+            {
+              xop[2] = all_regs_rtx[d0 & ~1];
+              xop[3] = clrw;
+              code = "movw %2,%3";
+              stepw = step;
+            }
+          else
+            {
+              xop[2] = all_regs_rtx[d0];
+              code = "clr %2";
+
+              if (++clr_n >= 2
+                  && !clrw
+                  && d0 % 2 == (step > 0))
+                {
+                  clrw = all_regs_rtx[d0 & ~1];
+                }
+            }
+        }
+      else if (offset && s0 <= (signed) src.regno_msb)
+        {
+          int movw = AVR_HAVE_MOVW && offset % 2 == 0
+            && d0 % 2 == (offset > 0)
+            && d1 <= dest.regno_msb && d1 >= dest.regno
+            && s1 <= (signed) src.regno_msb  && s1 >= (signed) src.regno;
+
+          xop[2] = all_regs_rtx[d0 & ~movw];
+          xop[3] = all_regs_rtx[s0 & ~movw];
+          code = movw ? "movw %2,%3" : "mov %2,%3";
+          stepw = step * movw;
+        }
+
+      if (code)
+        {
+          if (sign_extend && shift != ASHIFT && !sign_in_carry
+              && (d0 == src.regno_msb || d0 + stepw == src.regno_msb))
+            {
+              /* We are going to override the sign bit.  If we sign-extend,
+                 store the sign in the Carry flag.  This is not needed if
+                 the destination will be ASHIFT in the remainder because
+                 the ASHIFT will set Carry without extra instruction.  */
+
+              avr_asm_len ("lsl %0", &all_regs_rtx[src.regno_msb], plen, 1);
+              sign_in_carry = true;
+            }
+
+          unsigned src_msb = dest.regno_msb - sign_bytes - offset + 1;
+
+          if (!sign_extend && shift == ASHIFTRT && !msb_in_carry
+              && src.ibyte > dest.ibyte
+              && (d0 == src_msb || d0 + stepw == src_msb))
+            {
+              /* We are going to override the MSB.  If we shift right,
+                 store the MSB in the Carry flag.  This is only needed if
+                 we don't sign-extend becaue with sign-extension the MSB
+                 (the sign) will be produced by the sign extension.  */
+
+              avr_asm_len ("lsr %0", &all_regs_rtx[src_msb], plen, 1);
+              msb_in_carry = true;
+            }
+
+          unsigned src_lsb = dest.regno - offset -1;
+
+          if (shift == ASHIFT && src.fbyte > dest.fbyte && !lsb_in_carry
+	      && !lsb_in_tmp_reg
+              && (d0 == src_lsb || d0 + stepw == src_lsb))
+            {
+              /* We are going to override the new LSB; store it into carry.  */
+
+              avr_asm_len ("lsl %0", &all_regs_rtx[src_lsb], plen, 1);
+              code_ashift = "rol %0";
+              lsb_in_carry = true;
+            }
+
+          avr_asm_len (code, xop, plen, 1);
+          d0 += stepw;
+        }
+    }
+
+  /* Step 2:  Shift destination left by 1 bit position.  This might be needed
+     ======   for signed input and unsigned output.  */
+
+  if (shift == ASHIFT && src.fbyte > dest.fbyte && !lsb_in_carry)
+    {
+      unsigned s0 = dest.regno - offset -1;
+
+      /* n1169 4.1.4 says:
+	 "Conversions from a fixed-point to an integer type round toward zero."
+	 Hence, converting a fract type to integer only gives a non-zero result
+	 for -1.  */
+      if (SCALAR_INT_MODE_P (GET_MODE (xop[0]))
+	  && SCALAR_FRACT_MODE_P (GET_MODE (xop[1]))
+	  && !TARGET_FRACT_CONV_TRUNC)
+	{
+	  gcc_assert (s0 == src.regno_msb);
+	  /* Check if the input is -1.  We do that by checking if negating
+	     the input causes an integer overflow.  */
+	  unsigned sn = src.regno;
+	  avr_asm_len ("cp __zero_reg__,%0", &all_regs_rtx[sn++], plen, 1);
+	  while (sn <= s0)
+	    avr_asm_len ("cpc __zero_reg__,%0", &all_regs_rtx[sn++], plen, 1);
+
+	  /* Overflow goes with set carry.  Clear carry otherwise.  */
+	  avr_asm_len ("brvs 0f" CR_TAB
+                       "clc\n0:", NULL, plen, 2);
+	}
+      /* Likewise, when converting from accumulator types to integer, we
+	 need to round up negative values.  */
+      else if (SCALAR_INT_MODE_P (GET_MODE (xop[0]))
+	       && SCALAR_ACCUM_MODE_P (GET_MODE (xop[1]))
+	       && !TARGET_FRACT_CONV_TRUNC
+	       && !frac_rounded)
+	{
+	  bool have_carry = false;
+
+	  xop[2] = all_regs_rtx[s0];
+	  if (!lsb_in_tmp_reg && !MAY_CLOBBER (s0))
+	    avr_asm_len ("mov __tmp_reg__,%2", xop, plen, 1);
+	  avr_asm_len ("tst %0" CR_TAB "brpl 0f",
+		       &all_regs_rtx[src.regno_msb], plen, 2);
+	  if (!lsb_in_tmp_reg)
+	    {
+	      unsigned sn = src.regno;
+	      if (sn < s0)
+		{
+		  avr_asm_len ("cp __zero_reg__,%0", &all_regs_rtx[sn],
+			       plen, 1);
+		  have_carry = true;
+		}
+	      while (++sn < s0)
+		avr_asm_len ("cpc __zero_reg__,%0", &all_regs_rtx[sn], plen, 1);
+	      lsb_in_tmp_reg = !MAY_CLOBBER (s0);
+	    }
+	  /* Add in C and the rounding value 127.  */
+	  /* If the destination msb is a sign byte, and in LD_REGS,
+	     grab it as a temporary.  */
+	  if (sign_bytes
+	      && TEST_HARD_REG_BIT (reg_class_contents[LD_REGS],
+				    dest.regno_msb))
+	    {
+	      xop[3] = all_regs_rtx[dest.regno_msb];
+	      avr_asm_len ("ldi %3,127", xop, plen, 1);
+	      avr_asm_len ((have_carry && lsb_in_tmp_reg ? "adc __tmp_reg__,%3"
+			    : have_carry ? "adc %2,%3"
+			    : lsb_in_tmp_reg ? "add __tmp_reg__,%3"
+			    : "add %2,%3"),
+			   xop, plen, 1);
+	    }
+	  else
+	    {
+	      /* Fall back to use __zero_reg__ as a temporary.  */
+	      avr_asm_len ("dec __zero_reg__", NULL, plen, 1);
+	      if (have_carry)
+		avr_asm_len ("clt" CR_TAB
+                             "bld __zero_reg__,7", NULL, plen, 2);
+	      else
+		avr_asm_len ("lsr __zero_reg__", NULL, plen, 1);
+	      avr_asm_len (have_carry && lsb_in_tmp_reg
+                           ? "adc __tmp_reg__,__zero_reg__"
+                           : have_carry ? "adc %2,__zero_reg__"
+                           : lsb_in_tmp_reg ? "add __tmp_reg__,__zero_reg__"
+                           : "add %2,__zero_reg__",
+			   xop, plen, 1);
+	      avr_asm_len ("eor __zero_reg__,__zero_reg__", NULL, plen, 1);
+	    }
+
+          for (d0 = dest.regno + zero_bytes;
+	       d0 <= dest.regno_msb - sign_bytes; d0++)
+	    avr_asm_len ("adc %0,__zero_reg__", &all_regs_rtx[d0], plen, 1);
+
+          avr_asm_len (lsb_in_tmp_reg
+		       ? "\n0:\t" "lsl __tmp_reg__"
+                       : "\n0:\t" "lsl %2",
+		       xop, plen, 1);
+	}
+      else if (MAY_CLOBBER (s0))
+        avr_asm_len ("lsl %0", &all_regs_rtx[s0], plen, 1);
+      else
+        avr_asm_len ("mov __tmp_reg__,%0" CR_TAB
+                     "lsl __tmp_reg__", &all_regs_rtx[s0], plen, 2);
+
+      code_ashift = "rol %0";
+      lsb_in_carry = true;
+    }
+
+  if (shift == ASHIFT)
+    {
+      for (d0 = dest.regno + zero_bytes;
+           d0 <= dest.regno_msb - sign_bytes; d0++)
+        {
+          avr_asm_len (code_ashift, &all_regs_rtx[d0], plen, 1);
+          code_ashift = "rol %0";
+        }
+
+      lsb_in_carry = false;
+      sign_in_carry = true;
+    }
+
+  /* Step 4a:  Store MSB in carry if we don't already have it or will produce
+     =======   it in sign-extension below.  */
+
+  if (!sign_extend && shift == ASHIFTRT && !msb_in_carry
+      && src.ibyte > dest.ibyte)
+    {
+      unsigned s0 = dest.regno_msb - sign_bytes - offset + 1;
+
+      if (MAY_CLOBBER (s0))
+        avr_asm_len ("lsr %0", &all_regs_rtx[s0], plen, 1);
+      else
+        avr_asm_len ("mov __tmp_reg__,%0" CR_TAB
+                     "lsr __tmp_reg__", &all_regs_rtx[s0], plen, 2);
+
+      msb_in_carry = true;
+    }
+
+  /* Step 3:  Sign-extend or zero-extend the destination as needed.
+     ======   */
+
+  if (sign_extend && !sign_in_carry)
+    {
+      unsigned s0 = src.regno_msb;
+
+      if (MAY_CLOBBER (s0))
+        avr_asm_len ("lsl %0", &all_regs_rtx[s0], plen, 1);
+      else
+        avr_asm_len ("mov __tmp_reg__,%0" CR_TAB
+                     "lsl __tmp_reg__", &all_regs_rtx[s0], plen, 2);
+
+      sign_in_carry = true;
+    }
+
+  gcc_assert (sign_in_carry + msb_in_carry + lsb_in_carry <= 1);
+
+  unsigned copies = 0;
+  rtx movw = sign_extend ? NULL_RTX : clrw;
+
+  for (d0 = dest.regno_msb - sign_bytes + 1; d0 <= dest.regno_msb; d0++)
+    {
+      if (AVR_HAVE_MOVW && movw
+          && d0 % 2 == 0 && d0 + 1 <= dest.regno_msb)
+        {
+          xop[2] = all_regs_rtx[d0];
+          xop[3] = movw;
+          avr_asm_len ("movw %2,%3", xop, plen, 1);
+          d0++;
+        }
+      else
+        {
+          avr_asm_len (sign_extend ? "sbc %0,%0" : "clr %0",
+                       &all_regs_rtx[d0], plen, 1);
+
+          if (++copies >= 2 && !movw && d0 % 2 == 1)
+            movw = all_regs_rtx[d0-1];
+        }
+    } /* for */
+
+
+  /* Step 4:  Right shift the destination.  This might be needed for
+     ======   conversions from unsigned to signed.  */
+
+  if (shift == ASHIFTRT)
+    {
+      const char *code_ashiftrt = "lsr %0";
+
+      if (sign_extend || msb_in_carry)
+        code_ashiftrt = "ror %0";
+
+      if (src.sbit && src.ibyte == dest.ibyte)
+        code_ashiftrt = "asr %0";
+
+      for (d0 = dest.regno_msb - sign_bytes;
+           d0 >= dest.regno + zero_bytes - 1 && d0 >= dest.regno; d0--)
+        {
+          avr_asm_len (code_ashiftrt, &all_regs_rtx[d0], plen, 1);
+          code_ashiftrt = "ror %0";
+        }
+    }
+
+#undef MAY_CLOBBER
+
+  return "";
+}
+
+
+/* Output fixed-point rounding.  XOP[0] = XOP[1] is the operand to round.
+   XOP[2] is the rounding point, a CONST_INT.  The function prints the
+   instruction sequence if PLEN = NULL and computes the length in words
+   of the sequence if PLEN != NULL.  Most of this function deals with
+   preparing operands for calls to `avr_out_plus' and `avr_out_bitop'.  */
+
+const char*
+avr_out_round (rtx_insn *insn ATTRIBUTE_UNUSED, rtx *xop, int *plen)
+{
+  scalar_mode mode = as_a <scalar_mode> (GET_MODE (xop[0]));
+  scalar_int_mode imode = int_mode_for_mode (mode).require ();
+  // The smallest fractional bit not cleared by the rounding is 2^(-RP).
+  int fbit = (int) GET_MODE_FBIT (mode);
+  double_int i_add = double_int_zero.set_bit (fbit-1 - INTVAL (xop[2]));
+  wide_int wi_add = wi::set_bit_in_zero (fbit-1 - INTVAL (xop[2]),
+					 GET_MODE_PRECISION (imode));
+  // Lengths of PLUS and AND parts.
+  int len_add = 0, *plen_add = plen ? &len_add : NULL;
+  int len_and = 0, *plen_and = plen ? &len_and : NULL;
+
+  // Add-Saturate  1/2 * 2^(-RP).  Don't print the label "0:" when printing
+  // the saturated addition so that we can emit the "rjmp 1f" before the
+  // "0:" below.
+
+  rtx xadd = const_fixed_from_double_int (i_add, mode);
+  rtx xpattern, xsrc, op[4];
+
+  xsrc = SIGNED_FIXED_POINT_MODE_P (mode)
+    ? gen_rtx_SS_PLUS (mode, xop[1], xadd)
+    : gen_rtx_US_PLUS (mode, xop[1], xadd);
+  xpattern = gen_rtx_SET (xop[0], xsrc);
+
+  op[0] = xop[0];
+  op[1] = xop[1];
+  op[2] = xadd;
+  avr_out_plus (xpattern, op, plen_add, NULL, false /* Don't print "0:" */);
+
+  avr_asm_len ("rjmp 1f" CR_TAB
+               "0:", NULL, plen_add, 1);
+
+  // Keep  all bits from RP and higher:   ... 2^(-RP)
+  // Clear all bits from RP+1 and lower:              2^(-RP-1) ...
+  // Rounding point                           ^^^^^^^
+  // Added above                                      ^^^^^^^^^
+  rtx xreg = simplify_gen_subreg (imode, xop[0], mode, 0);
+  rtx xmask = immed_wide_int_const (-wi_add - wi_add, imode);
+
+  xpattern = gen_rtx_SET (xreg, gen_rtx_AND (imode, xreg, xmask));
+
+  op[0] = xreg;
+  op[1] = xreg;
+  op[2] = xmask;
+  op[3] = gen_rtx_SCRATCH (QImode);
+  avr_out_bitop (xpattern, op, plen_and);
+  avr_asm_len ("1:", NULL, plen, 0);
+
+  if (plen)
+    *plen = len_add + len_and;
+
+  return "";
+}
+
+
+/* Create RTL split patterns for byte sized rotate expressions.  This
+   produces a series of move instructions and considers overlap situations.
+   Overlapping non-HImode operands need a scratch register.  */
+
+bool
+avr_rotate_bytes (rtx operands[])
+{
+  machine_mode mode = GET_MODE (operands[0]);
+  bool overlapped = reg_overlap_mentioned_p (operands[0], operands[1]);
+  bool same_reg = rtx_equal_p (operands[0], operands[1]);
+  int num = INTVAL (operands[2]);
+  rtx scratch = operands[3];
+  /* Work out if byte or word move is needed.  Odd byte rotates need QImode.
+     Word move if no scratch is needed, otherwise use size of scratch.  */
+  machine_mode move_mode = QImode;
+  int move_size, offset, size;
+
+  if (num & 0xf)
+    move_mode = QImode;
+  else if ((mode == SImode && !same_reg) || !overlapped)
+    move_mode = HImode;
+  else
+    move_mode = GET_MODE (scratch);
+
+  /* Force DI rotate to use QI moves since other DI moves are currently split
+     into QI moves so forward propagation works better.  */
+  if (mode == DImode)
+    move_mode = QImode;
+  /* Make scratch smaller if needed.  */
+  if (SCRATCH != GET_CODE (scratch)
+      && HImode == GET_MODE (scratch)
+      && QImode == move_mode)
+    scratch = simplify_gen_subreg (move_mode, scratch, HImode, 0);
+
+  move_size = GET_MODE_SIZE (move_mode);
+  /* Number of bytes/words to rotate.  */
+  offset = (num  >> 3) / move_size;
+  /* Number of moves needed.  */
+  size = GET_MODE_SIZE (mode) / move_size;
+  /* Himode byte swap is special case to avoid a scratch register.  */
+  if (mode == HImode && same_reg)
+    {
+      /* HImode byte swap, using xor.  This is as quick as using scratch.  */
+      rtx src, dst;
+      src = simplify_gen_subreg (move_mode, operands[1], mode, 0);
+      dst = simplify_gen_subreg (move_mode, operands[0], mode, 1);
+      if (!rtx_equal_p (dst, src))
+        {
+          emit_move_insn (dst, gen_rtx_XOR (QImode, dst, src));
+          emit_move_insn (src, gen_rtx_XOR (QImode, src, dst));
+          emit_move_insn (dst, gen_rtx_XOR (QImode, dst, src));
+        }
+    }
+  else
+    {
+#define MAX_SIZE 8 /* GET_MODE_SIZE (DImode) / GET_MODE_SIZE (QImode)  */
+      /* Create linked list of moves to determine move order.  */
+      struct {
+        rtx src, dst;
+        int links;
+      } move[MAX_SIZE + 8];
+      int blocked, moves;
+
+      gcc_assert (size <= MAX_SIZE);
+      /* Generate list of subreg moves.  */
+      for (int i = 0; i < size; i++)
+        {
+          int from = i;
+          int to = (from + offset) % size;
+          move[i].src = simplify_gen_subreg (move_mode, operands[1],
+                                             mode, from * move_size);
+          move[i].dst = simplify_gen_subreg (move_mode, operands[0],
+                                             mode, to * move_size);
+          move[i].links = -1;
+        }
+      /* Mark dependence where a dst of one move is the src of another move.
+         The first move is a conflict as it must wait until second is
+         performed.  We ignore moves to self - we catch this later.  */
+      if (overlapped)
+        for (int i = 0; i < size; i++)
+          if (reg_overlap_mentioned_p (move[i].dst, operands[1]))
+            for (int j = 0; j < size; j++)
+              if (j != i && rtx_equal_p (move[j].src, move[i].dst))
+                {
+                  /* The dst of move i is the src of move j.  */
+                  move[i].links = j;
+                  break;
+                }
+
+      blocked = -1;
+      moves = 0;
+      /* Go through move list and perform non-conflicting moves.  As each
+         non-overlapping move is made, it may remove other conflicts
+         so the process is repeated until no conflicts remain.  */
+      do
+        {
+          blocked = -1;
+          moves = 0;
+          /* Emit move where dst is not also a src or we have used that
+             src already.  */
+          for (int i = 0; i < size; i++)
+            if (move[i].src != NULL_RTX)
+              {
+                if (move[i].links == -1
+                    || move[move[i].links].src == NULL_RTX)
+                  {
+                    moves++;
+                    /* Ignore NOP moves to self.  */
+                    if (!rtx_equal_p (move[i].dst, move[i].src))
+                      emit_move_insn (move[i].dst, move[i].src);
+
+                    /* Remove  conflict from list.  */
+                    move[i].src = NULL_RTX;
+                  }
+                else
+                  blocked = i;
+              }
+
+          /* Check for deadlock. This is when no moves occurred and we have
+             at least one blocked move.  */
+          if (moves == 0 && blocked != -1)
+            {
+              /* Need to use scratch register to break deadlock.
+                 Add move to put dst of blocked move into scratch.
+                 When this move occurs, it will break chain deadlock.
+                 The scratch register is substituted for real move.  */
+
+              gcc_assert (SCRATCH != GET_CODE (scratch));
+
+              move[size].src = move[blocked].dst;
+              move[size].dst =  scratch;
+              /* Scratch move is never blocked.  */
+              move[size].links = -1;
+              /* Make sure we have valid link.  */
+              gcc_assert (move[blocked].links != -1);
+              /* Replace src of  blocking move with scratch reg.  */
+              move[move[blocked].links].src = scratch;
+              /* Make dependent on scratch move occurring.  */
+              move[blocked].links = size;
+              size=size+1;
+            }
+        }
+      while (blocked != -1);
+    }
+  return true;
+}
+
+
+/* Worker function for `ADJUST_INSN_LENGTH'.  */
+/* Modifies the length assigned to instruction INSN
+   LEN is the initially computed length of the insn.  */
+
+int
+avr_adjust_insn_length (rtx_insn *insn, int len)
+{
+  rtx *op = recog_data.operand;
+  enum attr_adjust_len adjust_len;
+
+  /* As we pretend jump tables in .text, fix branch offsets crossing jump
+     tables now.  */
+
+  if (JUMP_TABLE_DATA_P (insn))
+    return 0;
+
+  /* Some complex insns don't need length adjustment and therefore
+     the length need not/must not be adjusted for these insns.
+     It is easier to state this in an insn attribute "adjust_len" than
+     to clutter up code here...  */
+
+  if (!NONDEBUG_INSN_P (insn) || recog_memoized (insn) == -1)
+    {
+      return len;
+    }
+
+  /* Read from insn attribute "adjust_len" if/how length is to be adjusted.  */
+
+  adjust_len = get_attr_adjust_len (insn);
+
+  if (adjust_len == ADJUST_LEN_NO)
+    {
+      /* Nothing to adjust: The length from attribute "length" is fine.
+         This is the default.  */
+
+      return len;
+    }
+
+  /* Extract insn's operands.  */
+
+  extract_constrain_insn_cached (insn);
+
+  /* Dispatch to right function.  */
+
+  switch (adjust_len)
+    {
+    case ADJUST_LEN_RELOAD_IN16: output_reload_inhi (op, op[2], &len); break;
+    case ADJUST_LEN_RELOAD_IN24: avr_out_reload_inpsi (op, op[2], &len); break;
+    case ADJUST_LEN_RELOAD_IN32: output_reload_insisf (op, op[2], &len); break;
+
+    case ADJUST_LEN_OUT_BITOP: avr_out_bitop (insn, op, &len); break;
+
+    case ADJUST_LEN_PLUS: avr_out_plus (insn, op, &len); break;
+    case ADJUST_LEN_ADDTO_SP: avr_out_addto_sp (op, &len); break;
+
+    case ADJUST_LEN_MOV8:  output_movqi (insn, op, &len); break;
+    case ADJUST_LEN_MOV16: output_movhi (insn, op, &len); break;
+    case ADJUST_LEN_MOV24: avr_out_movpsi (insn, op, &len); break;
+    case ADJUST_LEN_MOV32: output_movsisf (insn, op, &len); break;
+    case ADJUST_LEN_CPYMEM: avr_out_cpymem (insn, op, &len); break;
+    case ADJUST_LEN_XLOAD: avr_out_xload (insn, op, &len); break;
+    case ADJUST_LEN_SEXT: avr_out_sign_extend (insn, op, &len); break;
+
+    case ADJUST_LEN_SFRACT: avr_out_fract (insn, op, true, &len); break;
+    case ADJUST_LEN_UFRACT: avr_out_fract (insn, op, false, &len); break;
+    case ADJUST_LEN_ROUND: avr_out_round (insn, op, &len); break;
+
+    case ADJUST_LEN_TSTHI: avr_out_tsthi (insn, op, &len); break;
+    case ADJUST_LEN_TSTPSI: avr_out_tstpsi (insn, op, &len); break;
+    case ADJUST_LEN_TSTSI: avr_out_tstsi (insn, op, &len); break;
+    case ADJUST_LEN_COMPARE: avr_out_compare (insn, op, &len); break;
+    case ADJUST_LEN_COMPARE64: avr_out_compare64 (insn, op, &len); break;
+
+    case ADJUST_LEN_LSHRQI: lshrqi3_out (insn, op, &len); break;
+    case ADJUST_LEN_LSHRHI: lshrhi3_out (insn, op, &len); break;
+    case ADJUST_LEN_LSHRSI: lshrsi3_out (insn, op, &len); break;
+
+    case ADJUST_LEN_ASHRQI: ashrqi3_out (insn, op, &len); break;
+    case ADJUST_LEN_ASHRHI: ashrhi3_out (insn, op, &len); break;
+    case ADJUST_LEN_ASHRSI: ashrsi3_out (insn, op, &len); break;
+
+    case ADJUST_LEN_ASHLQI: ashlqi3_out (insn, op, &len); break;
+    case ADJUST_LEN_ASHLHI: ashlhi3_out (insn, op, &len); break;
+    case ADJUST_LEN_ASHLSI: ashlsi3_out (insn, op, &len); break;
+
+    case ADJUST_LEN_ASHLPSI: avr_out_ashlpsi3 (insn, op, &len); break;
+    case ADJUST_LEN_ASHRPSI: avr_out_ashrpsi3 (insn, op, &len); break;
+    case ADJUST_LEN_LSHRPSI: avr_out_lshrpsi3 (insn, op, &len); break;
+
+    case ADJUST_LEN_CALL: len = AVR_HAVE_JMP_CALL ? 2 : 1; break;
+
+    case ADJUST_LEN_INSERT_BITS: avr_out_insert_bits (op, &len); break;
+
+    case ADJUST_LEN_INSV_NOTBIT:
+      avr_out_insert_notbit (insn, op, NULL_RTX, &len);
+      break;
+    case ADJUST_LEN_INSV_NOTBIT_0:
+      avr_out_insert_notbit (insn, op, const0_rtx, &len);
+      break;
+    case ADJUST_LEN_INSV_NOTBIT_7:
+      avr_out_insert_notbit (insn, op, GEN_INT (7), &len);
+      break;
+
+    default:
+      gcc_unreachable();
+    }
+
+  return len;
+}
+
+/* Return nonzero if register REG dead after INSN.  */
+
+int
+reg_unused_after (rtx_insn *insn, rtx reg)
+{
+  return (dead_or_set_p (insn, reg)
+	  || (REG_P (reg) && _reg_unused_after (insn, reg)));
+}
+
+/* Return nonzero if REG is not used after INSN.
+   We assume REG is a reload reg, and therefore does
+   not live past labels.  It may live past calls or jumps though.  */
+
+int
+_reg_unused_after (rtx_insn *insn, rtx reg)
+{
+  enum rtx_code code;
+  rtx set;
+
+  /* If the reg is set by this instruction, then it is safe for our
+     case.  Disregard the case where this is a store to memory, since
+     we are checking a register used in the store address.  */
+  set = single_set (insn);
+  if (set && !MEM_P (SET_DEST (set))
+      && reg_overlap_mentioned_p (reg, SET_DEST (set)))
+    return 1;
+
+  while ((insn = NEXT_INSN (insn)))
+    {
+      rtx set;
+      code = GET_CODE (insn);
+
+#if 0
+      /* If this is a label that existed before reload, then the register
+	 if dead here.  However, if this is a label added by reorg, then
+	 the register may still be live here.  We can't tell the difference,
+	 so we just ignore labels completely.  */
+      if (code == CODE_LABEL)
+	return 1;
+      /* else */
+#endif
+
+      if (!INSN_P (insn))
+	continue;
+
+      if (code == JUMP_INSN)
+	return 0;
+
+      /* If this is a sequence, we must handle them all at once.
+	 We could have for instance a call that sets the target register,
+	 and an insn in a delay slot that uses the register.  In this case,
+	 we must return 0.  */
+      else if (code == INSN && GET_CODE (PATTERN (insn)) == SEQUENCE)
+	{
+	  rtx_sequence *seq = as_a <rtx_sequence *> (PATTERN (insn));
+	  int retval = 0;
+
+	  for (int i = 0; i < seq->len (); i++)
+	    {
+	      rtx_insn *this_insn = seq->insn (i);
+	      rtx set = single_set (this_insn);
+
+	      if (CALL_P (this_insn))
+		code = CALL_INSN;
+	      else if (JUMP_P (this_insn))
+		{
+		  if (INSN_ANNULLED_BRANCH_P (this_insn))
+		    return 0;
+		  code = JUMP_INSN;
+		}
+
+	      if (set && reg_overlap_mentioned_p (reg, SET_SRC (set)))
+		return 0;
+	      if (set && reg_overlap_mentioned_p (reg, SET_DEST (set)))
+		{
+		  if (!MEM_P (SET_DEST (set)))
+		    retval = 1;
+		  else
+		    return 0;
+		}
+	      if (set == 0
+		  && reg_overlap_mentioned_p (reg, PATTERN (this_insn)))
+		return 0;
+	    }
+	  if (retval == 1)
+	    return 1;
+	  else if (code == JUMP_INSN)
+	    return 0;
+	}
+
+      if (code == CALL_INSN)
+	{
+	  rtx tem;
+	  for (tem = CALL_INSN_FUNCTION_USAGE (insn); tem; tem = XEXP (tem, 1))
+	    if (GET_CODE (XEXP (tem, 0)) == USE
+		&& REG_P (XEXP (XEXP (tem, 0), 0))
+		&& reg_overlap_mentioned_p (reg, XEXP (XEXP (tem, 0), 0)))
+	      return 0;
+	  if (call_used_or_fixed_reg_p (REGNO (reg)))
+	    return 1;
+	}
+
+      set = single_set (insn);
+
+      if (set && reg_overlap_mentioned_p (reg, SET_SRC (set)))
+	return 0;
+      if (set && reg_overlap_mentioned_p (reg, SET_DEST (set)))
+	return !MEM_P (SET_DEST (set));
+      if (set == 0 && reg_overlap_mentioned_p (reg, PATTERN (insn)))
+	return 0;
+    }
+  return 1;
+}
+
+
+/* Implement `TARGET_ASM_INTEGER'.  */
+/* Target hook for assembling integer objects.  The AVR version needs
+   special handling for references to certain labels.  */
+
+static bool
+avr_assemble_integer (rtx x, unsigned int size, int aligned_p)
+{
+  if (size == POINTER_SIZE / BITS_PER_UNIT && aligned_p
+      && text_segment_operand (x, VOIDmode))
+    {
+      fputs ("\t.word\tgs(", asm_out_file);
+      output_addr_const (asm_out_file, x);
+      fputs (")\n", asm_out_file);
+
+      return true;
+    }
+  else if (GET_MODE (x) == PSImode)
+    {
+      /* This needs binutils 2.23+, see PR binutils/13503  */
+
+      fputs ("\t.byte\tlo8(", asm_out_file);
+      output_addr_const (asm_out_file, x);
+      fputs (")" ASM_COMMENT_START "need binutils PR13503\n", asm_out_file);
+
+      fputs ("\t.byte\thi8(", asm_out_file);
+      output_addr_const (asm_out_file, x);
+      fputs (")" ASM_COMMENT_START "need binutils PR13503\n", asm_out_file);
+
+      fputs ("\t.byte\thh8(", asm_out_file);
+      output_addr_const (asm_out_file, x);
+      fputs (")" ASM_COMMENT_START "need binutils PR13503\n", asm_out_file);
+
+      return true;
+    }
+  else if (CONST_FIXED_P (x))
+    {
+      /* varasm fails to handle big fixed modes that don't fit in hwi.  */
+
+      for (unsigned n = 0; n < size; n++)
+        {
+          rtx xn = simplify_gen_subreg (QImode, x, GET_MODE (x), n);
+          default_assemble_integer (xn, 1, aligned_p);
+        }
+
+      return true;
+    }
+
+  if (AVR_TINY
+      && avr_address_tiny_pm_p (x))
+    {
+      x = plus_constant (Pmode, x, avr_arch->flash_pm_offset);
+    }
+
+  return default_assemble_integer (x, size, aligned_p);
+}
+
+
+/* Implement `TARGET_CLASS_LIKELY_SPILLED_P'.  */
+/* Return value is nonzero if pseudos that have been
+   assigned to registers of class CLASS would likely be spilled
+   because registers of CLASS are needed for spill registers.  */
+
+static bool
+avr_class_likely_spilled_p (reg_class_t c)
+{
+  return (c != ALL_REGS &&
+           (AVR_TINY ? 1 : c != ADDW_REGS));
+}
+
+
+/* Valid attributes:
+   progmem   -  Put data to program memory.
+   signal    -  Make a function to be hardware interrupt.
+                After function prologue interrupts remain disabled.
+   interrupt -  Make a function to be hardware interrupt. Before function
+                prologue interrupts are enabled by means of SEI.
+   naked     -  Don't generate function prologue/epilogue and RET
+                instruction.  */
+
+/* Handle a "progmem" attribute; arguments as in
+   struct attribute_spec.handler.  */
+
+static tree
+avr_handle_progmem_attribute (tree *node, tree name,
+			      tree args ATTRIBUTE_UNUSED,
+			      int flags ATTRIBUTE_UNUSED,
+			      bool *no_add_attrs)
+{
+  if (DECL_P (*node))
+    {
+      if (TREE_CODE (*node) == TYPE_DECL)
+	{
+	  /* This is really a decl attribute, not a type attribute,
+	     but try to handle it for GCC 3.0 backwards compatibility.  */
+
+	  tree type = TREE_TYPE (*node);
+	  tree attr = tree_cons (name, args, TYPE_ATTRIBUTES (type));
+	  tree newtype = build_type_attribute_variant (type, attr);
+
+	  TYPE_MAIN_VARIANT (newtype) = TYPE_MAIN_VARIANT (type);
+	  TREE_TYPE (*node) = newtype;
+	  *no_add_attrs = true;
+	}
+      else if (TREE_STATIC (*node) || DECL_EXTERNAL (*node))
+	{
+          *no_add_attrs = false;
+	}
+      else
+	{
+	  warning (OPT_Wattributes, "%qE attribute ignored",
+		   name);
+	  *no_add_attrs = true;
+	}
+    }
+
+  return NULL_TREE;
+}
+
+/* Handle an attribute requiring a FUNCTION_DECL; arguments as in
+   struct attribute_spec.handler.  */
+
+static tree
+avr_handle_fndecl_attribute (tree *node, tree name,
+			     tree args ATTRIBUTE_UNUSED,
+			     int flags ATTRIBUTE_UNUSED,
+			     bool *no_add_attrs)
+{
+  if (TREE_CODE (*node) != FUNCTION_DECL)
+    {
+      warning (OPT_Wattributes, "%qE attribute only applies to functions",
+	       name);
+      *no_add_attrs = true;
+    }
+
+  return NULL_TREE;
+}
+
+static tree
+avr_handle_fntype_attribute (tree *node, tree name,
+                             tree args ATTRIBUTE_UNUSED,
+                             int flags ATTRIBUTE_UNUSED,
+                             bool *no_add_attrs)
+{
+  if (TREE_CODE (*node) != FUNCTION_TYPE)
+    {
+      warning (OPT_Wattributes, "%qE attribute only applies to functions",
+	       name);
+      *no_add_attrs = true;
+    }
+
+  return NULL_TREE;
+}
+
+static tree
+avr_handle_absdata_attribute (tree *node, tree name, tree /* args */,
+                              int /* flags */, bool *no_add)
+{
+  location_t loc = DECL_SOURCE_LOCATION (*node);
+
+  if (AVR_TINY)
+    {
+      if (TREE_CODE (*node) != VAR_DECL
+          || (!TREE_STATIC (*node) && !DECL_EXTERNAL (*node)))
+        {
+          warning_at (loc, OPT_Wattributes, "%qE attribute only applies to"
+                      " variables in static storage", name);
+          *no_add = true;
+        }
+    }
+  else
+    {
+      warning_at (loc, OPT_Wattributes, "%qE attribute only supported"
+                  " for reduced Tiny cores", name);
+      *no_add = true;
+    }
+
+  return NULL_TREE;
+}
+
+static tree
+avr_handle_addr_attribute (tree *node, tree name, tree args,
+			   int flags ATTRIBUTE_UNUSED, bool *no_add)
+{
+  bool io_p = (strncmp (IDENTIFIER_POINTER (name), "io", 2) == 0);
+  location_t loc = DECL_SOURCE_LOCATION (*node);
+
+  if (!VAR_P (*node))
+    {
+      warning_at (loc, OPT_Wattributes, "%qE attribute only applies to "
+		  "variables", name);
+      *no_add = true;
+      return NULL_TREE;
+    }
+
+  if (args != NULL_TREE)
+    {
+      if (TREE_CODE (TREE_VALUE (args)) == NON_LVALUE_EXPR)
+	TREE_VALUE (args) = TREE_OPERAND (TREE_VALUE (args), 0);
+      tree arg = TREE_VALUE (args);
+      if (TREE_CODE (arg) != INTEGER_CST)
+	{
+	  warning_at (loc, OPT_Wattributes, "%qE attribute allows only an "
+		      "integer constant argument", name);
+	  *no_add = true;
+	}
+      else if (io_p
+	       && (!tree_fits_shwi_p (arg)
+		   || !(strcmp (IDENTIFIER_POINTER (name), "io_low") == 0
+			? low_io_address_operand : io_address_operand)
+			 (GEN_INT (TREE_INT_CST_LOW (arg)), QImode)))
+	{
+	  warning_at (loc, OPT_Wattributes, "%qE attribute address "
+		      "out of range", name);
+	  *no_add = true;
+	}
+      else
+	{
+	  tree attribs = DECL_ATTRIBUTES (*node);
+	  const char *names[] = { "io", "io_low", "address", NULL };
+	  for (const char **p = names; *p; p++)
+	    {
+	      tree other = lookup_attribute (*p, attribs);
+	      if (other && TREE_VALUE (other))
+		{
+		  warning_at (loc, OPT_Wattributes,
+			      "both %s and %qE attribute provide address",
+			      *p, name);
+		  *no_add = true;
+		  break;
+		}
+	    }
+	}
+    }
+
+  if (*no_add == false && io_p && !TREE_THIS_VOLATILE (*node))
+    warning_at (loc, OPT_Wattributes, "%qE attribute on non-volatile variable",
+		name);
+
+  return NULL_TREE;
+}
+
+rtx
+avr_eval_addr_attrib (rtx x)
+{
+  if (SYMBOL_REF_P (x)
+      && (SYMBOL_REF_FLAGS (x) & SYMBOL_FLAG_ADDRESS))
+    {
+      tree decl = SYMBOL_REF_DECL (x);
+      tree attr = NULL_TREE;
+
+      if (SYMBOL_REF_FLAGS (x) & SYMBOL_FLAG_IO)
+	{
+	  attr = lookup_attribute ("io", DECL_ATTRIBUTES (decl));
+          if (!attr || !TREE_VALUE (attr))
+            attr = lookup_attribute ("io_low", DECL_ATTRIBUTES (decl));
+	  gcc_assert (attr);
+	}
+      if (!attr || !TREE_VALUE (attr))
+	attr = lookup_attribute ("address", DECL_ATTRIBUTES (decl));
+      gcc_assert (attr && TREE_VALUE (attr) && TREE_VALUE (TREE_VALUE (attr)));
+      return GEN_INT (TREE_INT_CST_LOW (TREE_VALUE (TREE_VALUE (attr))));
+    }
+  return x;
+}
+
+
+/* AVR attributes.  */
+static const struct attribute_spec avr_attribute_table[] =
+{
+  /* { name, min_len, max_len, decl_req, type_req, fn_type_req,
+       affects_type_identity, handler, exclude } */
+  { "progmem",   0, 0, false, false, false, false,
+    avr_handle_progmem_attribute, NULL },
+  { "signal",    0, 0, true,  false, false, false,
+    avr_handle_fndecl_attribute, NULL },
+  { "interrupt", 0, 0, true,  false, false, false,
+    avr_handle_fndecl_attribute, NULL },
+  { "no_gccisr", 0, 0, true,  false, false, false,
+    avr_handle_fndecl_attribute, NULL },
+  { "naked",     0, 0, false, true,  true,  false,
+    avr_handle_fntype_attribute, NULL },
+  { "OS_task",   0, 0, false, true,  true,  false,
+    avr_handle_fntype_attribute, NULL },
+  { "OS_main",   0, 0, false, true,  true,  false,
+    avr_handle_fntype_attribute, NULL },
+  { "io",        0, 1, true, false, false,  false,
+    avr_handle_addr_attribute, NULL },
+  { "io_low",    0, 1, true, false, false,  false,
+    avr_handle_addr_attribute, NULL },
+  { "address",   1, 1, true, false, false,  false,
+    avr_handle_addr_attribute, NULL },
+  { "absdata",   0, 0, true, false, false,  false,
+    avr_handle_absdata_attribute, NULL },
+  { NULL,        0, 0, false, false, false, false, NULL, NULL }
+};
+
+
+/* Return true if we support address space AS for the architecture in effect
+   and false, otherwise.  If LOC is not UNKNOWN_LOCATION then also issue
+   a respective error.  */
+
+bool
+avr_addr_space_supported_p (addr_space_t as, location_t loc)
+{
+  if (AVR_TINY)
+    {
+      if (loc != UNKNOWN_LOCATION)
+        error_at (loc, "address spaces are not supported for reduced "
+                  "Tiny devices");
+      return false;
+    }
+  else if (avr_addrspace[as].segment >= avr_n_flash)
+    {
+      if (loc != UNKNOWN_LOCATION)
+        error_at (loc, "address space %qs not supported for devices with "
+                  "flash size up to %d KiB", avr_addrspace[as].name,
+                  64 * avr_n_flash);
+      return false;
+    }
+
+  return true;
+}
+
+
+/* Implement `TARGET_ADDR_SPACE_DIAGNOSE_USAGE'.  */
+
+static void
+avr_addr_space_diagnose_usage (addr_space_t as, location_t loc)
+{
+  (void) avr_addr_space_supported_p (as, loc);
+}
+
+
+/* Look if DECL shall be placed in program memory space by
+   means of attribute `progmem' or some address-space qualifier.
+   Return non-zero if DECL is data that must end up in Flash and
+   zero if the data lives in RAM (.bss, .data, .rodata, ...).
+
+   Return 2   if DECL is located in 24-bit flash address-space
+   Return 1   if DECL is located in 16-bit flash address-space
+   Return -1  if attribute `progmem' occurs in DECL or ATTRIBUTES
+   Return 0   otherwise  */
+
+int
+avr_progmem_p (tree decl, tree attributes)
+{
+  tree a;
+
+  if (TREE_CODE (decl) != VAR_DECL)
+    return 0;
+
+  if (avr_decl_memx_p (decl))
+    return 2;
+
+  if (avr_decl_flash_p (decl))
+    return 1;
+
+  if (NULL_TREE
+      != lookup_attribute ("progmem", attributes))
+    return -1;
+
+  a = decl;
+
+  do
+    a = TREE_TYPE(a);
+  while (TREE_CODE (a) == ARRAY_TYPE);
+
+  if (a == error_mark_node)
+    return 0;
+
+  if (NULL_TREE != lookup_attribute ("progmem", TYPE_ATTRIBUTES (a)))
+    return -1;
+
+  return 0;
+}
+
+
+/* Return true if DECL has attribute `absdata' set.  This function should
+   only be used for AVR_TINY.  */
+
+static bool
+avr_decl_absdata_p (tree decl, tree attributes)
+{
+  return (TREE_CODE (decl) == VAR_DECL
+          && NULL_TREE != lookup_attribute ("absdata", attributes));
+}
+
+
+/* Scan type TYP for pointer references to address space ASn.
+   Return ADDR_SPACE_GENERIC (i.e. 0) if all pointers targeting
+   the AS are also declared to be CONST.
+   Otherwise, return the respective address space, i.e. a value != 0.  */
+
+static addr_space_t
+avr_nonconst_pointer_addrspace (tree typ)
+{
+  while (ARRAY_TYPE == TREE_CODE (typ))
+    typ = TREE_TYPE (typ);
+
+  if (POINTER_TYPE_P (typ))
+    {
+      addr_space_t as;
+      tree target = TREE_TYPE (typ);
+
+      /* Pointer to function: Test the function's return type.  */
+
+      if (FUNCTION_TYPE == TREE_CODE (target))
+        return avr_nonconst_pointer_addrspace (TREE_TYPE (target));
+
+      /* "Ordinary" pointers... */
+
+      while (TREE_CODE (target) == ARRAY_TYPE)
+        target = TREE_TYPE (target);
+
+      /* Pointers to non-generic address space must be const.  */
+
+      as = TYPE_ADDR_SPACE (target);
+
+      if (!ADDR_SPACE_GENERIC_P (as)
+          && !TYPE_READONLY (target)
+          && avr_addr_space_supported_p (as))
+        {
+          return as;
+        }
+
+      /* Scan pointer's target type.  */
+
+      return avr_nonconst_pointer_addrspace (target);
+    }
+
+  return ADDR_SPACE_GENERIC;
+}
+
+
+/* Sanity check NODE so that all pointers targeting non-generic address spaces
+   go along with CONST qualifier.  Writing to these address spaces should
+   be detected and complained about as early as possible.  */
+
+static bool
+avr_pgm_check_var_decl (tree node)
+{
+  const char *reason = NULL;
+
+  addr_space_t as = ADDR_SPACE_GENERIC;
+
+  gcc_assert (as == 0);
+
+  if (avr_log.progmem)
+    avr_edump ("%?: %t\n", node);
+
+  switch (TREE_CODE (node))
+    {
+    default:
+      break;
+
+    case VAR_DECL:
+      if (as = avr_nonconst_pointer_addrspace (TREE_TYPE (node)), as)
+        reason = _("variable");
+      break;
+
+    case PARM_DECL:
+      if (as = avr_nonconst_pointer_addrspace (TREE_TYPE (node)), as)
+        reason = _("function parameter");
+      break;
+
+    case FIELD_DECL:
+      if (as = avr_nonconst_pointer_addrspace (TREE_TYPE (node)), as)
+        reason = _("structure field");
+      break;
+
+    case FUNCTION_DECL:
+      if (as = avr_nonconst_pointer_addrspace (TREE_TYPE (TREE_TYPE (node))),
+          as)
+        reason = _("return type of function");
+      break;
+
+    case POINTER_TYPE:
+      if (as = avr_nonconst_pointer_addrspace (node), as)
+        reason = _("pointer");
+      break;
+    }
+
+  if (reason)
+    {
+      if (TYPE_P (node))
+        error ("pointer targeting address space %qs must be const in %qT",
+               avr_addrspace[as].name, node);
+      else
+        error ("pointer targeting address space %qs must be const"
+               " in %s %q+D",
+               avr_addrspace[as].name, reason, node);
+    }
+
+  return reason == NULL;
+}
+
+
+/* Implement `TARGET_INSERT_ATTRIBUTES'.  */
+
+static void
+avr_insert_attributes (tree node, tree *attributes)
+{
+  avr_pgm_check_var_decl (node);
+
+  if (TARGET_MAIN_IS_OS_TASK
+      && TREE_CODE (node) == FUNCTION_DECL
+      && MAIN_NAME_P (DECL_NAME (node))
+      // FIXME:  We'd like to also test `flag_hosted' which is only
+      // available in the C-ish fronts, hence no such test for now.
+      // Instead, we test the return type of "main" which is not exactly
+      // the same but good enough.
+      && INTEGRAL_TYPE_P (TREE_TYPE (TREE_TYPE (node)))
+      && NULL == lookup_attribute ("OS_task", *attributes))
+    {
+      *attributes = tree_cons (get_identifier ("OS_task"),
+                               NULL, *attributes);
+    }
+
+  /* Add the section attribute if the variable is in progmem.  */
+
+  if (TREE_CODE (node) == VAR_DECL
+      && (TREE_STATIC (node) || DECL_EXTERNAL (node))
+      && avr_progmem_p (node, *attributes))
+    {
+      addr_space_t as;
+      tree node0 = node;
+
+      /* For C++, we have to peel arrays in order to get correct
+         determination of readonlyness.  */
+
+      do
+        node0 = TREE_TYPE (node0);
+      while (TREE_CODE (node0) == ARRAY_TYPE);
+
+      if (error_mark_node == node0)
+        return;
+
+      as = TYPE_ADDR_SPACE (TREE_TYPE (node));
+
+      if (!TYPE_READONLY (node0)
+          && !TREE_READONLY (node))
+        {
+          const char *reason = "__attribute__((progmem))";
+
+          if (!ADDR_SPACE_GENERIC_P (as))
+            reason = avr_addrspace[as].name;
+
+          if (avr_log.progmem)
+            avr_edump ("\n%?: %t\n%t\n", node, node0);
+
+          error ("variable %q+D must be const in order to be put into"
+                 " read-only section by means of %qs", node, reason);
+        }
+    }
+}
+
+
+/* Implement `ASM_OUTPUT_ALIGNED_DECL_LOCAL'.  */
+/* Implement `ASM_OUTPUT_ALIGNED_DECL_COMMON'.  */
+/* Track need of __do_clear_bss.  */
+
+void
+avr_asm_output_aligned_decl_common (FILE * stream,
+                                    tree decl,
+                                    const char *name,
+                                    unsigned HOST_WIDE_INT size,
+                                    unsigned int align, bool local_p)
+{
+  rtx mem = decl == NULL_TREE ? NULL_RTX : DECL_RTL (decl);
+  rtx symbol;
+
+  if (mem != NULL_RTX && MEM_P (mem)
+      && SYMBOL_REF_P ((symbol = XEXP (mem, 0)))
+      && (SYMBOL_REF_FLAGS (symbol) & (SYMBOL_FLAG_IO | SYMBOL_FLAG_ADDRESS)))
+    {
+      if (!local_p)
+	{
+	  fprintf (stream, "\t.globl\t");
+	  assemble_name (stream, name);
+	  fprintf (stream, "\n");
+	}
+      if (SYMBOL_REF_FLAGS (symbol) & SYMBOL_FLAG_ADDRESS)
+	{
+	  assemble_name (stream, name);
+	  fprintf (stream, " = %ld\n",
+		   (long) INTVAL (avr_eval_addr_attrib (symbol)));
+	}
+      else if (local_p)
+	error_at (DECL_SOURCE_LOCATION (decl),
+		  "static IO declaration for %q+D needs an address", decl);
+      return;
+    }
+
+  /* __gnu_lto_slim is just a marker for the linker injected by toplev.c.
+     There is no need to trigger __do_clear_bss code for them.  */
+
+  if (!STR_PREFIX_P (name, "__gnu_lto"))
+    avr_need_clear_bss_p = true;
+
+  if (local_p)
+    ASM_OUTPUT_ALIGNED_LOCAL (stream, name, size, align);
+  else
+    ASM_OUTPUT_ALIGNED_COMMON (stream, name, size, align);
+}
+
+void
+avr_asm_asm_output_aligned_bss (FILE *file, tree decl, const char *name,
+				unsigned HOST_WIDE_INT size, int align,
+				void (*default_func)
+				  (FILE *, tree, const char *,
+				   unsigned HOST_WIDE_INT, int))
+{
+  rtx mem = decl == NULL_TREE ? NULL_RTX : DECL_RTL (decl);
+  rtx symbol;
+
+  if (mem != NULL_RTX && MEM_P (mem)
+      && SYMBOL_REF_P ((symbol = XEXP (mem, 0)))
+      && (SYMBOL_REF_FLAGS (symbol) & (SYMBOL_FLAG_IO | SYMBOL_FLAG_ADDRESS)))
+    {
+      if (!(SYMBOL_REF_FLAGS (symbol) & SYMBOL_FLAG_ADDRESS))
+	error_at (DECL_SOURCE_LOCATION (decl),
+		  "IO definition for %q+D needs an address", decl);
+      avr_asm_output_aligned_decl_common (file, decl, name, size, align, false);
+    }
+  else
+    default_func (file, decl, name, size, align);
+}
+
+
+/* Unnamed section callback for data_section
+   to track need of __do_copy_data.  */
+
+static void
+avr_output_data_section_asm_op (const void *data)
+{
+  avr_need_copy_data_p = true;
+
+  /* Dispatch to default.  */
+  output_section_asm_op (data);
+}
+
+
+/* Unnamed section callback for bss_section
+   to track need of __do_clear_bss.  */
+
+static void
+avr_output_bss_section_asm_op (const void *data)
+{
+  avr_need_clear_bss_p = true;
+
+  /* Dispatch to default.  */
+  output_section_asm_op (data);
+}
+
+
+/* Unnamed section callback for progmem*.data sections.  */
+
+static void
+avr_output_progmem_section_asm_op (const void *data)
+{
+  fprintf (asm_out_file, "\t.section\t%s,\"a\",@progbits\n",
+           (const char*) data);
+}
+
+
+/* Implement `TARGET_ASM_INIT_SECTIONS'.  */
+
+static void
+avr_asm_init_sections (void)
+{
+  /* Override section callbacks to keep track of `avr_need_clear_bss_p'
+     resp. `avr_need_copy_data_p'.  If flash is not mapped to RAM then
+     we have also to track .rodata because it is located in RAM then.  */
+
+#if defined HAVE_LD_AVR_AVRXMEGA3_RODATA_IN_FLASH
+  if (avr_arch->flash_pm_offset == 0)
+#endif
+    readonly_data_section->unnamed.callback = avr_output_data_section_asm_op;
+  data_section->unnamed.callback = avr_output_data_section_asm_op;
+  bss_section->unnamed.callback = avr_output_bss_section_asm_op;
+}
+
+
+/* Implement `TARGET_ASM_NAMED_SECTION'.  */
+/* Track need of __do_clear_bss, __do_copy_data for named sections.  */
+
+static void
+avr_asm_named_section (const char *name, unsigned int flags, tree decl)
+{
+  if (flags & AVR_SECTION_PROGMEM)
+    {
+      addr_space_t as = (flags & AVR_SECTION_PROGMEM) / SECTION_MACH_DEP;
+      const char *old_prefix = ".rodata";
+      const char *new_prefix = avr_addrspace[as].section_name;
+
+      if (STR_PREFIX_P (name, old_prefix))
+        {
+          const char *sname = ACONCAT ((new_prefix,
+                                        name + strlen (old_prefix), NULL));
+          default_elf_asm_named_section (sname, flags, decl);
+          return;
+        }
+
+      default_elf_asm_named_section (new_prefix, flags, decl);
+      return;
+    }
+
+  if (!avr_need_copy_data_p)
+    avr_need_copy_data_p = (STR_PREFIX_P (name, ".data")
+                            || STR_PREFIX_P (name, ".gnu.linkonce.d"));
+
+  if (!avr_need_copy_data_p
+#if defined HAVE_LD_AVR_AVRXMEGA3_RODATA_IN_FLASH
+      && avr_arch->flash_pm_offset == 0
+#endif
+      )
+    avr_need_copy_data_p = (STR_PREFIX_P (name, ".rodata")
+                            || STR_PREFIX_P (name, ".gnu.linkonce.r"));
+
+  if (!avr_need_clear_bss_p)
+    avr_need_clear_bss_p = STR_PREFIX_P (name, ".bss");
+
+  default_elf_asm_named_section (name, flags, decl);
+}
+
+
+/* Implement `TARGET_SECTION_TYPE_FLAGS'.  */
+
+static unsigned int
+avr_section_type_flags (tree decl, const char *name, int reloc)
+{
+  unsigned int flags = default_section_type_flags (decl, name, reloc);
+
+  if (STR_PREFIX_P (name, ".noinit"))
+    {
+      if (decl && TREE_CODE (decl) == VAR_DECL
+	  && DECL_INITIAL (decl) == NULL_TREE)
+	flags |= SECTION_BSS;  /* @nobits */
+      else
+	warning (0, "only uninitialized variables can be placed in the "
+		 ".noinit section");
+    }
+
+  if (decl && DECL_P (decl)
+      && avr_progmem_p (decl, DECL_ATTRIBUTES (decl)))
+    {
+      addr_space_t as = TYPE_ADDR_SPACE (TREE_TYPE (decl));
+
+      /* Attribute progmem puts data in generic address space.
+         Set section flags as if it was in __flash to get the right
+         section prefix in the remainder.  */
+
+      if (ADDR_SPACE_GENERIC_P (as))
+        as = ADDR_SPACE_FLASH;
+
+      flags |= as * SECTION_MACH_DEP;
+      flags &= ~SECTION_WRITE;
+      flags &= ~SECTION_BSS;
+    }
+
+  return flags;
+}
+
+
+/* A helper for the next function.  NODE is a decl that is associated with
+   a symbol.  Return TRUE if the respective object may be accessed by LDS.
+   There might still be other reasons for why LDS is not appropriate.
+   This function is only appropriate for AVR_TINY.  */
+
+static bool
+avr_decl_maybe_lds_p (tree node)
+{
+  if (!node
+      || TREE_CODE (node) != VAR_DECL
+      || DECL_SECTION_NAME (node) != NULL)
+    return false;
+
+  /* Don't use LDS for objects that go to .rodata.  The current default
+     linker description file still locates .rodata in RAM, but this is not
+     a must.  A better linker script would just keep .rodata in flash and
+     add an offset of 0x4000 to the VMA.  Hence avoid LDS for such data.  */
+
+  if (TREE_READONLY (node))
+    return false;
+
+  // C++ requires peeling arrays.
+
+  do
+    node = TREE_TYPE (node);
+  while (ARRAY_TYPE == TREE_CODE (node));
+
+  return (node != error_mark_node
+          && !TYPE_READONLY (node));
+}
+
+
+/* Implement `TARGET_ENCODE_SECTION_INFO'.  */
+
+static void
+avr_encode_section_info (tree decl, rtx rtl, int new_decl_p)
+{
+  tree addr_attr = NULL_TREE;
+
+  /* In avr_handle_progmem_attribute, DECL_INITIAL is not yet
+     readily available, see PR34734.  So we postpone the warning
+     about uninitialized data in program memory section until here.  */
+
+  if (new_decl_p
+      && decl && DECL_P (decl)
+      && !DECL_EXTERNAL (decl)
+      && avr_progmem_p (decl, DECL_ATTRIBUTES (decl)))
+    {
+      if (!TREE_READONLY (decl))
+        {
+          // This might happen with C++ if stuff needs constructing.
+          error ("variable %q+D with dynamic initialization put "
+                 "into program memory area", decl);
+        }
+      else if (NULL_TREE == DECL_INITIAL (decl))
+        {
+          // Don't warn for (implicit) aliases like in PR80462.
+          tree asmname = DECL_ASSEMBLER_NAME (decl);
+          varpool_node *node = varpool_node::get_for_asmname (asmname);
+          bool alias_p = node && node->alias;
+
+          if (!alias_p)
+            warning (OPT_Wuninitialized, "uninitialized variable %q+D put "
+                     "into program memory area", decl);
+        }
+    }
+
+  default_encode_section_info (decl, rtl, new_decl_p);
+
+  if (decl && DECL_P (decl)
+      && TREE_CODE (decl) != FUNCTION_DECL
+      && MEM_P (rtl)
+      && SYMBOL_REF_P (XEXP (rtl, 0)))
+    {
+      rtx sym = XEXP (rtl, 0);
+      tree type = TREE_TYPE (decl);
+      tree attr = DECL_ATTRIBUTES (decl);
+      if (type == error_mark_node)
+	return;
+
+      addr_space_t as = TYPE_ADDR_SPACE (type);
+
+      /* PSTR strings are in generic space but located in flash:
+         patch address space.  */
+
+      if (!AVR_TINY && avr_progmem_p (decl, attr) == -1)
+        as = ADDR_SPACE_FLASH;
+
+      AVR_SYMBOL_SET_ADDR_SPACE (sym, as);
+
+      tree io_low_attr = lookup_attribute ("io_low", attr);
+      tree io_attr = lookup_attribute ("io", attr);
+
+      if (io_low_attr
+	  && TREE_VALUE (io_low_attr) && TREE_VALUE (TREE_VALUE (io_low_attr)))
+	addr_attr = io_attr;
+      else if (io_attr
+	       && TREE_VALUE (io_attr) && TREE_VALUE (TREE_VALUE (io_attr)))
+	addr_attr = io_attr;
+      else
+	addr_attr = lookup_attribute ("address", attr);
+      if (io_low_attr
+	  || (io_attr && addr_attr
+              && low_io_address_operand
+                  (GEN_INT (TREE_INT_CST_LOW
+                            (TREE_VALUE (TREE_VALUE (addr_attr)))), QImode)))
+	SYMBOL_REF_FLAGS (sym) |= SYMBOL_FLAG_IO_LOW;
+      if (io_attr || io_low_attr)
+	SYMBOL_REF_FLAGS (sym) |= SYMBOL_FLAG_IO;
+      /* If we have an (io) address attribute specification, but the variable
+	 is external, treat the address as only a tentative definition
+	 to be used to determine if an io port is in the lower range, but
+	 don't use the exact value for constant propagation.  */
+      if (addr_attr && !DECL_EXTERNAL (decl))
+	SYMBOL_REF_FLAGS (sym) |= SYMBOL_FLAG_ADDRESS;
+    }
+
+  if (AVR_TINY
+      && decl
+      && VAR_DECL == TREE_CODE (decl)
+      && MEM_P (rtl)
+      && SYMBOL_REF_P (XEXP (rtl, 0)))
+    {
+      rtx sym = XEXP (rtl, 0);
+      bool progmem_p = avr_progmem_p (decl, DECL_ATTRIBUTES (decl)) == -1;
+
+      if (progmem_p)
+        {
+          // Tag symbols for addition of 0x4000 (avr_arch->flash_pm_offset).
+          SYMBOL_REF_FLAGS (sym) |= AVR_SYMBOL_FLAG_TINY_PM;
+        }
+
+      if (avr_decl_absdata_p (decl, DECL_ATTRIBUTES (decl))
+          || (TARGET_ABSDATA
+              && !progmem_p
+              && !addr_attr
+              && avr_decl_maybe_lds_p (decl))
+          || (addr_attr
+              // If addr_attr is non-null, it has an argument.  Peek into it.
+              && TREE_INT_CST_LOW (TREE_VALUE (TREE_VALUE (addr_attr))) < 0xc0))
+        {
+          // May be accessed by LDS / STS.
+          SYMBOL_REF_FLAGS (sym) |= AVR_SYMBOL_FLAG_TINY_ABSDATA;
+        }
+
+      if (progmem_p
+          && avr_decl_absdata_p (decl, DECL_ATTRIBUTES (decl)))
+        {
+          error ("%q+D has incompatible attributes %qs and %qs",
+                 decl, "progmem", "absdata");
+        }
+    }
+}
+
+
+/* Implement `TARGET_ASM_SELECT_SECTION' */
+
+static section *
+avr_asm_select_section (tree decl, int reloc, unsigned HOST_WIDE_INT align)
+{
+  section * sect = default_elf_select_section (decl, reloc, align);
+
+  if (decl && DECL_P (decl)
+      && avr_progmem_p (decl, DECL_ATTRIBUTES (decl)))
+    {
+      addr_space_t as = TYPE_ADDR_SPACE (TREE_TYPE (decl));
+
+      /* __progmem__ goes in generic space but shall be allocated to
+         .progmem.data  */
+
+      if (ADDR_SPACE_GENERIC_P (as))
+        as = ADDR_SPACE_FLASH;
+
+      if (sect->common.flags & SECTION_NAMED)
+        {
+          const char * name = sect->named.name;
+          const char * old_prefix = ".rodata";
+          const char * new_prefix = avr_addrspace[as].section_name;
+
+          if (STR_PREFIX_P (name, old_prefix))
+            {
+              const char *sname = ACONCAT ((new_prefix,
+                                            name + strlen (old_prefix), NULL));
+              return get_section (sname,
+                                  sect->common.flags & ~SECTION_DECLARED,
+                                  sect->named.decl);
+            }
+        }
+
+      if (!progmem_section[as])
+        {
+          progmem_section[as]
+            = get_unnamed_section (0, avr_output_progmem_section_asm_op,
+                                   avr_addrspace[as].section_name);
+        }
+
+      return progmem_section[as];
+    }
+
+  return sect;
+}
+
+/* Implement `TARGET_ASM_FILE_START'.  */
+/* Outputs some text at the start of each assembler file.  */
+
+static void
+avr_file_start (void)
+{
+  int sfr_offset = avr_arch->sfr_offset;
+
+  if (avr_arch->asm_only)
+    error ("architecture %qs supported for assembler only", avr_mmcu);
+
+  default_file_start ();
+
+  /* Print I/O addresses of some SFRs used with IN and OUT.  */
+
+  if (AVR_HAVE_SPH)
+    fprintf (asm_out_file, "__SP_H__ = 0x%02x\n", avr_addr.sp_h - sfr_offset);
+
+  fprintf (asm_out_file, "__SP_L__ = 0x%02x\n", avr_addr.sp_l - sfr_offset);
+  fprintf (asm_out_file, "__SREG__ = 0x%02x\n", avr_addr.sreg - sfr_offset);
+  if (AVR_HAVE_RAMPZ)
+    fprintf (asm_out_file, "__RAMPZ__ = 0x%02x\n", avr_addr.rampz - sfr_offset);
+  if (AVR_HAVE_RAMPY)
+    fprintf (asm_out_file, "__RAMPY__ = 0x%02x\n", avr_addr.rampy - sfr_offset);
+  if (AVR_HAVE_RAMPX)
+    fprintf (asm_out_file, "__RAMPX__ = 0x%02x\n", avr_addr.rampx - sfr_offset);
+  if (AVR_HAVE_RAMPD)
+    fprintf (asm_out_file, "__RAMPD__ = 0x%02x\n", avr_addr.rampd - sfr_offset);
+  if (AVR_XMEGA || AVR_TINY)
+    fprintf (asm_out_file, "__CCP__ = 0x%02x\n", avr_addr.ccp - sfr_offset);
+  fprintf (asm_out_file, "__tmp_reg__ = %d\n", AVR_TMP_REGNO);
+  fprintf (asm_out_file, "__zero_reg__ = %d\n", AVR_ZERO_REGNO);
+}
+
+
+/* Implement `TARGET_ASM_FILE_END'.  */
+/* Outputs to the stdio stream FILE some
+   appropriate text to go at the end of an assembler file.  */
+
+static void
+avr_file_end (void)
+{
+  /* Output these only if there is anything in the
+     .data* / .rodata* / .gnu.linkonce.* resp. .bss* or COMMON
+     input section(s) - some code size can be saved by not
+     linking in the initialization code from libgcc if resp.
+     sections are empty, see PR18145.  */
+
+  if (avr_need_copy_data_p)
+    fputs (".global __do_copy_data\n", asm_out_file);
+
+  if (avr_need_clear_bss_p)
+    fputs (".global __do_clear_bss\n", asm_out_file);
+}
+
+
+/* Worker function for `ADJUST_REG_ALLOC_ORDER'.  */
+/* Choose the order in which to allocate hard registers for
+   pseudo-registers local to a basic block.
+
+   Store the desired register order in the array `reg_alloc_order'.
+   Element 0 should be the register to allocate first; element 1, the
+   next register; and so on.  */
+
+void
+avr_adjust_reg_alloc_order (void)
+{
+  static const int order_0[] =
+    {
+      24, 25,
+      18, 19, 20, 21, 22, 23,
+      30, 31,
+      26, 27, 28, 29,
+      17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2,
+      0, 1,
+      32, 33, 34, 35
+    };
+  static const int tiny_order_0[] = {
+    20, 21,
+    22, 23,
+    24, 25,
+    30, 31,
+    26, 27,
+    28, 29,
+    19, 18,
+    16, 17,
+    32, 33, 34, 35,
+    15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0
+  };
+  static const int order_1[] =
+    {
+      18, 19, 20, 21, 22, 23, 24, 25,
+      30, 31,
+      26, 27, 28, 29,
+      17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2,
+      0, 1,
+      32, 33, 34, 35
+    };
+  static const int tiny_order_1[] = {
+    22, 23,
+    24, 25,
+    30, 31,
+    26, 27,
+    28, 29,
+    21, 20, 19, 18,
+    16, 17,
+    32, 33, 34, 35,
+    15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0
+  };
+  static const int order_2[] =
+    {
+      25, 24, 23, 22, 21, 20, 19, 18,
+      30, 31,
+      26, 27, 28, 29,
+      17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2,
+      1, 0,
+      32, 33, 34, 35
+    };
+
+  /* Select specific register allocation order.
+     Tiny Core (ATtiny4/5/9/10/20/40) devices have only 16 registers,
+     so different allocation order should be used.  */
+
+  const int *order = (TARGET_ORDER_1 ? (AVR_TINY ? tiny_order_1 : order_1)
+                      : TARGET_ORDER_2 ? (AVR_TINY ? tiny_order_0 : order_2)
+                      : (AVR_TINY ? tiny_order_0 : order_0));
+
+  for (size_t i = 0; i < ARRAY_SIZE (order_0); ++i)
+    reg_alloc_order[i] = order[i];
+}
+
+
+/* Implement `TARGET_REGISTER_MOVE_COST' */
+
+static int
+avr_register_move_cost (machine_mode mode ATTRIBUTE_UNUSED,
+                        reg_class_t from, reg_class_t to)
+{
+  return (from == STACK_REG ? 6
+          : to == STACK_REG ? 12
+          : 2);
+}
+
+
+/* Implement `TARGET_MEMORY_MOVE_COST' */
+
+static int
+avr_memory_move_cost (machine_mode mode,
+                      reg_class_t rclass ATTRIBUTE_UNUSED,
+                      bool in ATTRIBUTE_UNUSED)
+{
+  return (mode == QImode ? 2
+          : mode == HImode ? 4
+          : mode == SImode ? 8
+          : mode == SFmode ? 8
+          : 16);
+}
+
+
+/* Cost for mul highpart.  X is a LSHIFTRT, i.e. the outer TRUNCATE is
+   already stripped off.  */
+
+static int
+avr_mul_highpart_cost (rtx x, int)
+{
+  if (AVR_HAVE_MUL
+      && LSHIFTRT == GET_CODE (x)
+      && MULT == GET_CODE (XEXP (x, 0))
+      && CONST_INT_P (XEXP (x, 1)))
+    {
+      // This is the wider mode.
+      machine_mode mode = GET_MODE (x);
+  
+      // The middle-end might still have PR81444, i.e. it is calling the cost
+      // functions with strange modes.  Fix this now by also considering
+      // PSImode (should actually be SImode instead).
+      if (HImode == mode || PSImode == mode || SImode == mode)
+        {
+          return COSTS_N_INSNS (2);
+        }
+    }
+
+  return 10000;
+}
+
+
+/* Mutually recursive subroutine of avr_rtx_cost for calculating the
+   cost of an RTX operand given its context.  X is the rtx of the
+   operand, MODE is its mode, and OUTER is the rtx_code of this
+   operand's parent operator.  */
+
+static int
+avr_operand_rtx_cost (rtx x, machine_mode mode, enum rtx_code outer,
+		      int opno, bool speed)
+{
+  enum rtx_code code = GET_CODE (x);
+  int total;
+
+  switch (code)
+    {
+    case REG:
+    case SUBREG:
+      return 0;
+
+    case CONST_INT:
+    case CONST_FIXED:
+    case CONST_DOUBLE:
+      return COSTS_N_INSNS (GET_MODE_SIZE (mode));
+
+    default:
+      break;
+    }
+
+  total = 0;
+  avr_rtx_costs (x, mode, outer, opno, &total, speed);
+  return total;
+}
+
+/* Worker function for AVR backend's rtx_cost function.
+   X is rtx expression whose cost is to be calculated.
+   Return true if the complete cost has been computed.
+   Return false if subexpressions should be scanned.
+   In either case, *TOTAL contains the cost result.  */
+
+static bool
+avr_rtx_costs_1 (rtx x, machine_mode mode, int outer_code,
+                 int opno ATTRIBUTE_UNUSED, int *total, bool speed)
+{
+  enum rtx_code code = GET_CODE (x);
+  HOST_WIDE_INT val;
+
+  switch (code)
+    {
+    case CONST_INT:
+    case CONST_FIXED:
+    case CONST_DOUBLE:
+    case SYMBOL_REF:
+    case CONST:
+    case LABEL_REF:
+      /* Immediate constants are as cheap as registers.  */
+      *total = 0;
+      return true;
+
+    case MEM:
+      *total = COSTS_N_INSNS (GET_MODE_SIZE (mode));
+      return true;
+
+    case NEG:
+      switch (mode)
+	{
+	case E_QImode:
+	case E_SFmode:
+	  *total = COSTS_N_INSNS (1);
+	  break;
+
+        case E_HImode:
+        case E_PSImode:
+        case E_SImode:
+          *total = COSTS_N_INSNS (2 * GET_MODE_SIZE (mode) - 1);
+          break;
+
+	default:
+	  return false;
+	}
+      *total += avr_operand_rtx_cost (XEXP (x, 0), mode, code, 0, speed);
+      return true;
+
+    case ABS:
+      switch (mode)
+	{
+	case E_QImode:
+	case E_SFmode:
+	  *total = COSTS_N_INSNS (1);
+	  break;
+
+	default:
+	  return false;
+	}
+      *total += avr_operand_rtx_cost (XEXP (x, 0), mode, code, 0, speed);
+      return true;
+
+    case NOT:
+      *total = COSTS_N_INSNS (GET_MODE_SIZE (mode));
+      *total += avr_operand_rtx_cost (XEXP (x, 0), mode, code, 0, speed);
+      return true;
+
+    case ZERO_EXTEND:
+      *total = COSTS_N_INSNS (GET_MODE_SIZE (mode)
+			      - GET_MODE_SIZE (GET_MODE (XEXP (x, 0))));
+      *total += avr_operand_rtx_cost (XEXP (x, 0), GET_MODE (XEXP (x, 0)),
+				      code, 0, speed);
+      return true;
+
+    case SIGN_EXTEND:
+      *total = COSTS_N_INSNS (GET_MODE_SIZE (mode) + 2
+			      - GET_MODE_SIZE (GET_MODE (XEXP (x, 0))));
+      *total += avr_operand_rtx_cost (XEXP (x, 0), GET_MODE (XEXP (x, 0)),
+				      code, 0, speed);
+      return true;
+
+    case PLUS:
+      switch (mode)
+	{
+	case E_QImode:
+          if (AVR_HAVE_MUL
+              && MULT == GET_CODE (XEXP (x, 0))
+              && register_operand (XEXP (x, 1), QImode))
+            {
+              /* multiply-add */
+              *total = COSTS_N_INSNS (speed ? 4 : 3);
+              /* multiply-add with constant: will be split and load constant. */
+              if (CONST_INT_P (XEXP (XEXP (x, 0), 1)))
+                *total = COSTS_N_INSNS (1) + *total;
+              return true;
+            }
+	  *total = COSTS_N_INSNS (1);
+	  if (!CONST_INT_P (XEXP (x, 1)))
+	    *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1, speed);
+	  break;
+
+	case E_HImode:
+          if (AVR_HAVE_MUL
+              && (MULT == GET_CODE (XEXP (x, 0))
+                  || ASHIFT == GET_CODE (XEXP (x, 0)))
+              && register_operand (XEXP (x, 1), HImode)
+              && (ZERO_EXTEND == GET_CODE (XEXP (XEXP (x, 0), 0))
+                  || SIGN_EXTEND == GET_CODE (XEXP (XEXP (x, 0), 0))))
+            {
+              /* multiply-add */
+              *total = COSTS_N_INSNS (speed ? 5 : 4);
+              /* multiply-add with constant: will be split and load constant. */
+              if (CONST_INT_P (XEXP (XEXP (x, 0), 1)))
+                *total = COSTS_N_INSNS (1) + *total;
+              return true;
+            }
+	  if (!CONST_INT_P (XEXP (x, 1)))
+	    {
+	      *total = COSTS_N_INSNS (2);
+	      *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+					      speed);
+	    }
+	  else if (IN_RANGE (INTVAL (XEXP (x, 1)), -63, 63))
+	    *total = COSTS_N_INSNS (1);
+	  else
+	    *total = COSTS_N_INSNS (2);
+	  break;
+
+        case E_PSImode:
+          if (!CONST_INT_P (XEXP (x, 1)))
+            {
+              *total = COSTS_N_INSNS (3);
+              *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+                                              speed);
+            }
+          else if (IN_RANGE (INTVAL (XEXP (x, 1)), -63, 63))
+            *total = COSTS_N_INSNS (2);
+          else
+            *total = COSTS_N_INSNS (3);
+          break;
+
+	case E_SImode:
+	  if (!CONST_INT_P (XEXP (x, 1)))
+	    {
+	      *total = COSTS_N_INSNS (4);
+	      *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+					      speed);
+	    }
+	  else if (IN_RANGE (INTVAL (XEXP (x, 1)), -63, 63))
+	    *total = COSTS_N_INSNS (1);
+	  else
+	    *total = COSTS_N_INSNS (4);
+	  break;
+
+	default:
+	  return false;
+	}
+      *total += avr_operand_rtx_cost (XEXP (x, 0), mode, code, 0, speed);
+      return true;
+
+    case MINUS:
+      if (AVR_HAVE_MUL
+          && QImode == mode
+          && register_operand (XEXP (x, 0), QImode)
+          && MULT == GET_CODE (XEXP (x, 1)))
+        {
+          /* multiply-sub */
+          *total = COSTS_N_INSNS (speed ? 4 : 3);
+          /* multiply-sub with constant: will be split and load constant. */
+          if (CONST_INT_P (XEXP (XEXP (x, 1), 1)))
+            *total = COSTS_N_INSNS (1) + *total;
+          return true;
+        }
+      if (AVR_HAVE_MUL
+          && HImode == mode
+          && register_operand (XEXP (x, 0), HImode)
+          && (MULT == GET_CODE (XEXP (x, 1))
+              || ASHIFT == GET_CODE (XEXP (x, 1)))
+          && (ZERO_EXTEND == GET_CODE (XEXP (XEXP (x, 1), 0))
+              || SIGN_EXTEND == GET_CODE (XEXP (XEXP (x, 1), 0))))
+        {
+          /* multiply-sub */
+          *total = COSTS_N_INSNS (speed ? 5 : 4);
+          /* multiply-sub with constant: will be split and load constant. */
+          if (CONST_INT_P (XEXP (XEXP (x, 1), 1)))
+            *total = COSTS_N_INSNS (1) + *total;
+          return true;
+        }
+      /* FALLTHRU */
+    case AND:
+    case IOR:
+      if (IOR == code
+          && HImode == mode
+          && ASHIFT == GET_CODE (XEXP (x, 0)))
+        {
+          *total = COSTS_N_INSNS (2);
+          // Just a rough estimate.  If we see no sign- or zero-extend,
+          // then increase the cost a little bit.
+          if (REG_P (XEXP (XEXP (x, 0), 0)))
+            *total += COSTS_N_INSNS (1);
+          if (REG_P (XEXP (x, 1)))
+            *total += COSTS_N_INSNS (1);
+          return true;
+        }
+      *total = COSTS_N_INSNS (GET_MODE_SIZE (mode));
+      *total += avr_operand_rtx_cost (XEXP (x, 0), mode, code, 0, speed);
+      if (!CONST_INT_P (XEXP (x, 1)))
+	*total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1, speed);
+      return true;
+
+    case XOR:
+      *total = COSTS_N_INSNS (GET_MODE_SIZE (mode));
+      *total += avr_operand_rtx_cost (XEXP (x, 0), mode, code, 0, speed);
+      *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1, speed);
+      return true;
+
+    case MULT:
+      switch (mode)
+	{
+	case E_QImode:
+	  if (AVR_HAVE_MUL)
+	    *total = COSTS_N_INSNS (!speed ? 3 : 4);
+	  else if (!speed)
+	    *total = COSTS_N_INSNS (AVR_HAVE_JMP_CALL ? 2 : 1);
+	  else
+	    return false;
+	  break;
+
+	case E_HImode:
+	  if (AVR_HAVE_MUL)
+            {
+              rtx op0 = XEXP (x, 0);
+              rtx op1 = XEXP (x, 1);
+              enum rtx_code code0 = GET_CODE (op0);
+              enum rtx_code code1 = GET_CODE (op1);
+              bool ex0 = SIGN_EXTEND == code0 || ZERO_EXTEND == code0;
+              bool ex1 = SIGN_EXTEND == code1 || ZERO_EXTEND == code1;
+
+              if (ex0
+                  && (u8_operand (op1, HImode)
+                      || s8_operand (op1, HImode)))
+                {
+                  *total = COSTS_N_INSNS (!speed ? 4 : 6);
+                  return true;
+                }
+              if (ex0
+                  && register_operand (op1, HImode))
+                {
+                  *total = COSTS_N_INSNS (!speed ? 5 : 8);
+                  return true;
+                }
+              else if (ex0 || ex1)
+                {
+                  *total = COSTS_N_INSNS (!speed ? 3 : 5);
+                  return true;
+                }
+              else if (register_operand (op0, HImode)
+                       && (u8_operand (op1, HImode)
+                           || s8_operand (op1, HImode)))
+                {
+                  *total = COSTS_N_INSNS (!speed ? 6 : 9);
+                  return true;
+                }
+              else
+                *total = COSTS_N_INSNS (!speed ? 7 : 10);
+            }
+	  else if (!speed)
+	    *total = COSTS_N_INSNS (AVR_HAVE_JMP_CALL ? 2 : 1);
+	  else
+	    return false;
+	  break;
+
+        case E_PSImode:
+          if (!speed)
+            *total = COSTS_N_INSNS (AVR_HAVE_JMP_CALL ? 2 : 1);
+          else
+            *total = 10;
+          break;
+
+	case E_SImode:
+	case E_DImode:
+	  if (AVR_HAVE_MUL)
+            {
+              if (!speed)
+                {
+                  /* Add some additional costs besides CALL like moves etc.  */
+
+                  *total = COSTS_N_INSNS (AVR_HAVE_JMP_CALL ? 5 : 4);
+                }
+              else
+                {
+                  /* Just a rough estimate.  Even with -O2 we don't want bulky
+                     code expanded inline.  */
+
+                  *total = COSTS_N_INSNS (25);
+                }
+            }
+          else
+            {
+              if (speed)
+                *total = COSTS_N_INSNS (300);
+              else
+                /* Add some additional costs besides CALL like moves etc.  */
+                *total = COSTS_N_INSNS (AVR_HAVE_JMP_CALL ? 5 : 4);
+            }
+
+	  if (mode == DImode)
+	    *total *= 2;
+
+	  return true;
+
+	default:
+	  return false;
+	}
+      *total += avr_operand_rtx_cost (XEXP (x, 0), mode, code, 0, speed);
+      *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1, speed);
+      return true;
+
+    case DIV:
+    case MOD:
+    case UDIV:
+    case UMOD:
+      if (!speed)
+        *total = COSTS_N_INSNS (AVR_HAVE_JMP_CALL ? 2 : 1);
+      else
+        *total = COSTS_N_INSNS (15 * GET_MODE_SIZE (mode));
+      *total += avr_operand_rtx_cost (XEXP (x, 0), mode, code, 0, speed);
+      /* For div/mod with const-int divisor we have at least the cost of
+         loading the divisor. */
+      if (CONST_INT_P (XEXP (x, 1)))
+        *total += COSTS_N_INSNS (GET_MODE_SIZE (mode));
+      /* Add some overall penaly for clobbering and moving around registers */
+      *total += COSTS_N_INSNS (2);
+      return true;
+
+    case ROTATE:
+      switch (mode)
+	{
+	case E_QImode:
+	  if (CONST_INT_P (XEXP (x, 1)) && INTVAL (XEXP (x, 1)) == 4)
+	    *total = COSTS_N_INSNS (1);
+
+	  break;
+
+	case E_HImode:
+	  if (CONST_INT_P (XEXP (x, 1)) && INTVAL (XEXP (x, 1)) == 8)
+	    *total = COSTS_N_INSNS (3);
+
+	  break;
+
+	case E_SImode:
+	  if (CONST_INT_P (XEXP (x, 1)))
+	    switch (INTVAL (XEXP (x, 1)))
+	      {
+	      case 8:
+	      case 24:
+		*total = COSTS_N_INSNS (5);
+		break;
+	      case 16:
+		*total = COSTS_N_INSNS (AVR_HAVE_MOVW ? 4 : 6);
+		break;
+	      }
+	  break;
+
+	default:
+	  return false;
+	}
+      *total += avr_operand_rtx_cost (XEXP (x, 0), mode, code, 0, speed);
+      return true;
+
+    case ASHIFT:
+      switch (mode)
+	{
+	case E_QImode:
+	  if (!CONST_INT_P (XEXP (x, 1)))
+	    {
+	      *total = COSTS_N_INSNS (!speed ? 4 : 17);
+	      *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+					      speed);
+	    }
+	  else
+	    {
+	      val = INTVAL (XEXP (x, 1));
+	      if (val == 7)
+		*total = COSTS_N_INSNS (3);
+	      else if (val >= 0 && val <= 7)
+		*total = COSTS_N_INSNS (val);
+	      else
+		*total = COSTS_N_INSNS (1);
+	    }
+	  break;
+
+	case E_HImode:
+          if (AVR_HAVE_MUL)
+            {
+              if (const_2_to_7_operand (XEXP (x, 1), HImode)
+                  && (SIGN_EXTEND == GET_CODE (XEXP (x, 0))
+                      || ZERO_EXTEND == GET_CODE (XEXP (x, 0))))
+                {
+                  *total = COSTS_N_INSNS (!speed ? 4 : 6);
+                  return true;
+                }
+            }
+
+          if (const1_rtx == (XEXP (x, 1))
+              && SIGN_EXTEND == GET_CODE (XEXP (x, 0)))
+            {
+              *total = COSTS_N_INSNS (2);
+              return true;
+            }
+
+	  if (!CONST_INT_P (XEXP (x, 1)))
+	    {
+	      *total = COSTS_N_INSNS (!speed ? 5 : 41);
+	      *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+					      speed);
+	    }
+	  else
+	    switch (INTVAL (XEXP (x, 1)))
+	      {
+	      case 0:
+		*total = 0;
+		break;
+	      case 1:
+	      case 8:
+		*total = COSTS_N_INSNS (2);
+		break;
+	      case 9:
+		*total = COSTS_N_INSNS (3);
+		break;
+	      case 2:
+	      case 3:
+	      case 10:
+	      case 15:
+		*total = COSTS_N_INSNS (4);
+		break;
+	      case 7:
+	      case 11:
+	      case 12:
+		*total = COSTS_N_INSNS (5);
+		break;
+	      case 4:
+		*total = COSTS_N_INSNS (!speed ? 5 : 8);
+		break;
+	      case 6:
+		*total = COSTS_N_INSNS (!speed ? 5 : 9);
+		break;
+	      case 5:
+		*total = COSTS_N_INSNS (!speed ? 5 : 10);
+		break;
+	      default:
+	        *total = COSTS_N_INSNS (!speed ? 5 : 41);
+	        *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+						speed);
+	      }
+	  break;
+
+        case E_PSImode:
+          if (!CONST_INT_P (XEXP (x, 1)))
+            {
+              *total = COSTS_N_INSNS (!speed ? 6 : 73);
+            }
+          else
+            switch (INTVAL (XEXP (x, 1)))
+              {
+              case 0:
+                *total = 0;
+                break;
+              case 1:
+              case 8:
+              case 16:
+                *total = COSTS_N_INSNS (3);
+                break;
+              case 23:
+                *total = COSTS_N_INSNS (5);
+                break;
+              default:
+                *total = COSTS_N_INSNS (!speed ? 5 : 3 * INTVAL (XEXP (x, 1)));
+                break;
+              }
+          break;
+
+	case E_SImode:
+	  if (!CONST_INT_P (XEXP (x, 1)))
+	    {
+	      *total = COSTS_N_INSNS (!speed ? 7 : 113);
+	      *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+					      speed);
+	    }
+	  else
+	    switch (INTVAL (XEXP (x, 1)))
+	      {
+	      case 0:
+		*total = 0;
+		break;
+	      case 24:
+		*total = COSTS_N_INSNS (3);
+		break;
+	      case 1:
+	      case 8:
+	      case 16:
+		*total = COSTS_N_INSNS (4);
+		break;
+	      case 31:
+		*total = COSTS_N_INSNS (6);
+		break;
+	      case 2:
+		*total = COSTS_N_INSNS (!speed ? 7 : 8);
+		break;
+	      default:
+		*total = COSTS_N_INSNS (!speed ? 7 : 113);
+		*total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+						speed);
+	      }
+	  break;
+
+	default:
+	  return false;
+	}
+      *total += avr_operand_rtx_cost (XEXP (x, 0), mode, code, 0, speed);
+      return true;
+
+    case ASHIFTRT:
+      switch (mode)
+	{
+	case E_QImode:
+	  if (!CONST_INT_P (XEXP (x, 1)))
+	    {
+	      *total = COSTS_N_INSNS (!speed ? 4 : 17);
+	      *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+					      speed);
+	    }
+	  else
+	    {
+	      val = INTVAL (XEXP (x, 1));
+	      if (val == 6)
+		*total = COSTS_N_INSNS (4);
+	      else if (val == 7)
+		*total = COSTS_N_INSNS (2);
+	      else if (val >= 0 && val <= 7)
+		*total = COSTS_N_INSNS (val);
+	      else
+		*total = COSTS_N_INSNS (1);
+	    }
+	  break;
+
+	case E_HImode:
+	  if (!CONST_INT_P (XEXP (x, 1)))
+	    {
+	      *total = COSTS_N_INSNS (!speed ? 5 : 41);
+	      *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+					      speed);
+	    }
+	  else
+	    switch (INTVAL (XEXP (x, 1)))
+	      {
+	      case 0:
+		*total = 0;
+		break;
+	      case 1:
+		*total = COSTS_N_INSNS (2);
+		break;
+	      case 15:
+		*total = COSTS_N_INSNS (3);
+		break;
+	      case 2:
+	      case 7:
+              case 8:
+              case 9:
+		*total = COSTS_N_INSNS (4);
+		break;
+              case 10:
+	      case 14:
+		*total = COSTS_N_INSNS (5);
+		break;
+              case 11:
+                *total = COSTS_N_INSNS (!speed ? 5 : 6);
+		break;
+              case 12:
+                *total = COSTS_N_INSNS (!speed ? 5 : 7);
+		break;
+              case 6:
+	      case 13:
+                *total = COSTS_N_INSNS (!speed ? 5 : 8);
+		break;
+	      default:
+	        *total = COSTS_N_INSNS (!speed ? 5 : 41);
+	        *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+						speed);
+	      }
+	  break;
+
+        case E_PSImode:
+          if (!CONST_INT_P (XEXP (x, 1)))
+            {
+              *total = COSTS_N_INSNS (!speed ? 6 : 73);
+            }
+          else
+            switch (INTVAL (XEXP (x, 1)))
+              {
+              case 0:
+                *total = 0;
+                break;
+              case 1:
+                *total = COSTS_N_INSNS (3);
+                break;
+              case 16:
+              case 8:
+                *total = COSTS_N_INSNS (5);
+                break;
+              case 23:
+                *total = COSTS_N_INSNS (4);
+                break;
+              default:
+                *total = COSTS_N_INSNS (!speed ? 5 : 3 * INTVAL (XEXP (x, 1)));
+                break;
+              }
+          break;
+
+	case E_SImode:
+	  if (!CONST_INT_P (XEXP (x, 1)))
+	    {
+	      *total = COSTS_N_INSNS (!speed ? 7 : 113);
+	      *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+					      speed);
+	    }
+	  else
+	    switch (INTVAL (XEXP (x, 1)))
+	      {
+	      case 0:
+		*total = 0;
+		break;
+	      case 1:
+		*total = COSTS_N_INSNS (4);
+		break;
+	      case 8:
+	      case 16:
+	      case 24:
+		*total = COSTS_N_INSNS (6);
+		break;
+	      case 2:
+		*total = COSTS_N_INSNS (!speed ? 7 : 8);
+		break;
+	      case 31:
+		*total = COSTS_N_INSNS (AVR_HAVE_MOVW ? 4 : 5);
+		break;
+	      default:
+		*total = COSTS_N_INSNS (!speed ? 7 : 113);
+		*total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+						speed);
+	      }
+	  break;
+
+	default:
+	  return false;
+	}
+      *total += avr_operand_rtx_cost (XEXP (x, 0), mode, code, 0, speed);
+      return true;
+
+    case LSHIFTRT:
+      if (outer_code == TRUNCATE)
+        {
+          *total = avr_mul_highpart_cost (x, speed);
+          return true;
+        }
+
+      switch (mode)
+	{
+	case E_QImode:
+	  if (!CONST_INT_P (XEXP (x, 1)))
+	    {
+	      *total = COSTS_N_INSNS (!speed ? 4 : 17);
+	      *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+					      speed);
+	    }
+	  else
+	    {
+	      val = INTVAL (XEXP (x, 1));
+	      if (val == 7)
+		*total = COSTS_N_INSNS (3);
+	      else if (val >= 0 && val <= 7)
+		*total = COSTS_N_INSNS (val);
+	      else
+		*total = COSTS_N_INSNS (1);
+	    }
+	  break;
+
+	case E_HImode:
+	  if (!CONST_INT_P (XEXP (x, 1)))
+	    {
+	      *total = COSTS_N_INSNS (!speed ? 5 : 41);
+	      *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+					      speed);
+	    }
+	  else
+	    switch (INTVAL (XEXP (x, 1)))
+	      {
+	      case 0:
+		*total = 0;
+		break;
+	      case 1:
+	      case 8:
+		*total = COSTS_N_INSNS (2);
+		break;
+	      case 9:
+		*total = COSTS_N_INSNS (3);
+		break;
+	      case 2:
+	      case 10:
+	      case 15:
+		*total = COSTS_N_INSNS (4);
+		break;
+	      case 7:
+              case 11:
+		*total = COSTS_N_INSNS (5);
+		break;
+	      case 3:
+	      case 12:
+	      case 13:
+	      case 14:
+		*total = COSTS_N_INSNS (!speed ? 5 : 6);
+		break;
+	      case 4:
+		*total = COSTS_N_INSNS (!speed ? 5 : 7);
+		break;
+	      case 5:
+	      case 6:
+		*total = COSTS_N_INSNS (!speed ? 5 : 9);
+		break;
+	      default:
+	        *total = COSTS_N_INSNS (!speed ? 5 : 41);
+	        *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+						speed);
+	      }
+	  break;
+
+        case E_PSImode:
+          if (!CONST_INT_P (XEXP (x, 1)))
+            {
+              *total = COSTS_N_INSNS (!speed ? 6 : 73);
+            }
+          else
+            switch (INTVAL (XEXP (x, 1)))
+              {
+              case 0:
+                *total = 0;
+                break;
+              case 1:
+              case 8:
+              case 16:
+                *total = COSTS_N_INSNS (3);
+                break;
+              case 23:
+                *total = COSTS_N_INSNS (5);
+                break;
+              default:
+                *total = COSTS_N_INSNS (!speed ? 5 : 3 * INTVAL (XEXP (x, 1)));
+                break;
+              }
+          break;
+
+	case E_SImode:
+	  if (!CONST_INT_P (XEXP (x, 1)))
+	    {
+	      *total = COSTS_N_INSNS (!speed ? 7 : 113);
+	      *total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+					      speed);
+	    }
+	  else
+	    switch (INTVAL (XEXP (x, 1)))
+	      {
+	      case 0:
+		*total = 0;
+		break;
+	      case 1:
+		*total = COSTS_N_INSNS (4);
+		break;
+	      case 2:
+		*total = COSTS_N_INSNS (!speed ? 7 : 8);
+		break;
+	      case 8:
+	      case 16:
+	      case 24:
+		*total = COSTS_N_INSNS (4);
+		break;
+	      case 31:
+		*total = COSTS_N_INSNS (6);
+		break;
+	      default:
+		*total = COSTS_N_INSNS (!speed ? 7 : 113);
+		*total += avr_operand_rtx_cost (XEXP (x, 1), mode, code, 1,
+						speed);
+	      }
+	  break;
+
+	default:
+	  return false;
+	}
+      *total += avr_operand_rtx_cost (XEXP (x, 0), mode, code, 0, speed);
+      return true;
+
+    case COMPARE:
+      switch (GET_MODE (XEXP (x, 0)))
+	{
+	case E_QImode:
+	  *total = COSTS_N_INSNS (1);
+	  if (!CONST_INT_P (XEXP (x, 1)))
+	    *total += avr_operand_rtx_cost (XEXP (x, 1), QImode, code,
+					    1, speed);
+	  break;
+
+        case E_HImode:
+	  *total = COSTS_N_INSNS (2);
+	  if (!CONST_INT_P (XEXP (x, 1)))
+            *total += avr_operand_rtx_cost (XEXP (x, 1), HImode, code,
+					    1, speed);
+	  else if (INTVAL (XEXP (x, 1)) != 0)
+	    *total += COSTS_N_INSNS (1);
+          break;
+
+        case E_PSImode:
+          *total = COSTS_N_INSNS (3);
+          if (CONST_INT_P (XEXP (x, 1)) && INTVAL (XEXP (x, 1)) != 0)
+            *total += COSTS_N_INSNS (2);
+          break;
+
+        case E_SImode:
+          *total = COSTS_N_INSNS (4);
+          if (!CONST_INT_P (XEXP (x, 1)))
+            *total += avr_operand_rtx_cost (XEXP (x, 1), SImode, code,
+					    1, speed);
+	  else if (INTVAL (XEXP (x, 1)) != 0)
+	    *total += COSTS_N_INSNS (3);
+          break;
+
+	default:
+	  return false;
+	}
+      *total += avr_operand_rtx_cost (XEXP (x, 0), GET_MODE (XEXP (x, 0)),
+				      code, 0, speed);
+      return true;
+
+    case TRUNCATE:
+      if (LSHIFTRT == GET_CODE (XEXP (x, 0)))
+        {
+          *total = avr_mul_highpart_cost (XEXP (x, 0), speed);
+          return true;
+        }
+      break;
+
+    default:
+      break;
+    }
+  return false;
+}
+
+
+/* Implement `TARGET_RTX_COSTS'.  */
+
+static bool
+avr_rtx_costs (rtx x, machine_mode mode, int outer_code,
+	       int opno, int *total, bool speed)
+{
+  bool done = avr_rtx_costs_1 (x, mode, outer_code, opno, total, speed);
+
+  if (avr_log.rtx_costs)
+    {
+      avr_edump ("\n%?=%b (%s) total=%d, outer=%C:\n%r\n",
+                 done, speed ? "speed" : "size", *total, outer_code, x);
+    }
+
+  return done;
+}
+
+
+/* Implement `TARGET_ADDRESS_COST'.  */
+
+static int
+avr_address_cost (rtx x, machine_mode mode ATTRIBUTE_UNUSED,
+                  addr_space_t as ATTRIBUTE_UNUSED,
+                  bool speed ATTRIBUTE_UNUSED)
+{
+  int cost = 4;
+
+  if (GET_CODE (x) == PLUS
+      && CONST_INT_P (XEXP (x, 1))
+      && (REG_P (XEXP (x, 0))
+          || SUBREG_P (XEXP (x, 0))))
+    {
+      if (INTVAL (XEXP (x, 1)) > MAX_LD_OFFSET(mode))
+        cost = 18;
+    }
+  else if (CONSTANT_ADDRESS_P (x))
+    {
+      if (io_address_operand (x, QImode))
+        cost = 2;
+
+      if (AVR_TINY
+          && avr_address_tiny_absdata_p (x, QImode))
+        cost = 2;
+    }
+
+  if (avr_log.address_cost)
+    avr_edump ("\n%?: %d = %r\n", cost, x);
+
+  return cost;
+}
+
+/* Test for extra memory constraint 'Q'.
+   It's a memory address based on Y or Z pointer with valid displacement.  */
+
+int
+extra_constraint_Q (rtx x)
+{
+  int ok = 0;
+  rtx plus = XEXP (x, 0);
+
+  if (GET_CODE (plus) == PLUS
+      && REG_P (XEXP (plus, 0))
+      && CONST_INT_P (XEXP (plus, 1))
+      && (INTVAL (XEXP (plus, 1))
+	  <= MAX_LD_OFFSET (GET_MODE (x))))
+    {
+      rtx xx = XEXP (plus, 0);
+      int regno = REGNO (xx);
+
+      ok = (/* allocate pseudos */
+            regno >= FIRST_PSEUDO_REGISTER
+            /* strictly check */
+            || regno == REG_Z || regno == REG_Y
+            /* XXX frame & arg pointer checks */
+            || xx == frame_pointer_rtx
+            || xx == arg_pointer_rtx);
+
+      if (avr_log.constraints)
+        avr_edump ("\n%?=%d reload_completed=%d reload_in_progress=%d\n %r\n",
+                   ok, reload_completed, reload_in_progress, x);
+    }
+
+  return ok;
+}
+
+/* Convert condition code CONDITION to the valid AVR condition code.  */
+
+RTX_CODE
+avr_normalize_condition (RTX_CODE condition)
+{
+  switch (condition)
+    {
+    case GT:
+      return GE;
+    case GTU:
+      return GEU;
+    case LE:
+      return LT;
+    case LEU:
+      return LTU;
+    default:
+      gcc_unreachable ();
+    }
+}
+
+/* Helper function for `avr_reorg'.  */
+
+static rtx
+avr_compare_pattern (rtx_insn *insn)
+{
+  rtx pattern = single_set (insn);
+
+  if (pattern
+      && NONJUMP_INSN_P (insn)
+      && SET_DEST (pattern) == cc0_rtx
+      && GET_CODE (SET_SRC (pattern)) == COMPARE)
+    {
+      machine_mode mode0 = GET_MODE (XEXP (SET_SRC (pattern), 0));
+      machine_mode mode1 = GET_MODE (XEXP (SET_SRC (pattern), 1));
+
+      /* The 64-bit comparisons have fixed operands ACC_A and ACC_B.
+         They must not be swapped, thus skip them.  */
+
+      if ((mode0 == VOIDmode || GET_MODE_SIZE (mode0) <= 4)
+          && (mode1 == VOIDmode || GET_MODE_SIZE (mode1) <= 4))
+        return pattern;
+    }
+
+  return NULL_RTX;
+}
+
+/* Helper function for `avr_reorg'.  */
+
+/* Expansion of switch/case decision trees leads to code like
+
+       cc0 = compare (Reg, Num)
+       if (cc0 == 0)
+         goto L1
+
+       cc0 = compare (Reg, Num)
+       if (cc0 > 0)
+         goto L2
+
+   The second comparison is superfluous and can be deleted.
+   The second jump condition can be transformed from a
+   "difficult" one to a "simple" one because "cc0 > 0" and
+   "cc0 >= 0" will have the same effect here.
+
+   This function relies on the way switch/case is being expaned
+   as binary decision tree.  For example code see PR 49903.
+
+   Return TRUE if optimization performed.
+   Return FALSE if nothing changed.
+
+   INSN1 is a comparison, i.e. avr_compare_pattern != 0.
+
+   We don't want to do this in text peephole because it is
+   tedious to work out jump offsets there and the second comparison
+   might have been transormed by `avr_reorg'.
+
+   RTL peephole won't do because peephole2 does not scan across
+   basic blocks.  */
+
+static bool
+avr_reorg_remove_redundant_compare (rtx_insn *insn1)
+{
+  rtx comp1, ifelse1, xcond1;
+  rtx_insn *branch1;
+  rtx comp2, ifelse2, xcond2;
+  rtx_insn *branch2, *insn2;
+  enum rtx_code code;
+  rtx_insn *jump;
+  rtx target, cond;
+
+  /* Look out for:  compare1 - branch1 - compare2 - branch2  */
+
+  branch1 = next_nonnote_nondebug_insn (insn1);
+  if (!branch1 || !JUMP_P (branch1))
+    return false;
+
+  insn2 = next_nonnote_nondebug_insn (branch1);
+  if (!insn2 || !avr_compare_pattern (insn2))
+    return false;
+
+  branch2 = next_nonnote_nondebug_insn (insn2);
+  if (!branch2 || !JUMP_P (branch2))
+    return false;
+
+  comp1 = avr_compare_pattern (insn1);
+  comp2 = avr_compare_pattern (insn2);
+  xcond1 = single_set (branch1);
+  xcond2 = single_set (branch2);
+
+  if (!comp1 || !comp2
+      || !rtx_equal_p (comp1, comp2)
+      || !xcond1 || SET_DEST (xcond1) != pc_rtx
+      || !xcond2 || SET_DEST (xcond2) != pc_rtx
+      || IF_THEN_ELSE != GET_CODE (SET_SRC (xcond1))
+      || IF_THEN_ELSE != GET_CODE (SET_SRC (xcond2)))
+    {
+      return false;
+    }
+
+  comp1 = SET_SRC (comp1);
+  ifelse1 = SET_SRC (xcond1);
+  ifelse2 = SET_SRC (xcond2);
+
+  /* comp<n> is COMPARE now and ifelse<n> is IF_THEN_ELSE.  */
+
+  if (EQ != GET_CODE (XEXP (ifelse1, 0))
+      || !REG_P (XEXP (comp1, 0))
+      || !CONST_INT_P (XEXP (comp1, 1))
+      || XEXP (ifelse1, 2) != pc_rtx
+      || XEXP (ifelse2, 2) != pc_rtx
+      || LABEL_REF != GET_CODE (XEXP (ifelse1, 1))
+      || LABEL_REF != GET_CODE (XEXP (ifelse2, 1))
+      || !COMPARISON_P (XEXP (ifelse2, 0))
+      || cc0_rtx != XEXP (XEXP (ifelse1, 0), 0)
+      || cc0_rtx != XEXP (XEXP (ifelse2, 0), 0)
+      || const0_rtx != XEXP (XEXP (ifelse1, 0), 1)
+      || const0_rtx != XEXP (XEXP (ifelse2, 0), 1))
+    {
+      return false;
+    }
+
+  /* We filtered the insn sequence to look like
+
+        (set (cc0)
+             (compare (reg:M N)
+                      (const_int VAL)))
+        (set (pc)
+             (if_then_else (eq (cc0)
+                               (const_int 0))
+                           (label_ref L1)
+                           (pc)))
+
+        (set (cc0)
+             (compare (reg:M N)
+                      (const_int VAL)))
+        (set (pc)
+             (if_then_else (CODE (cc0)
+                                 (const_int 0))
+                           (label_ref L2)
+                           (pc)))
+  */
+
+  code = GET_CODE (XEXP (ifelse2, 0));
+
+  /* Map GT/GTU to GE/GEU which is easier for AVR.
+     The first two instructions compare/branch on EQ
+     so we may replace the difficult
+
+        if (x == VAL)   goto L1;
+        if (x > VAL)    goto L2;
+
+     with easy
+
+         if (x == VAL)   goto L1;
+         if (x >= VAL)   goto L2;
+
+     Similarly, replace LE/LEU by LT/LTU.  */
+
+  switch (code)
+    {
+    case EQ:
+    case LT:  case LTU:
+    case GE:  case GEU:
+      break;
+
+    case LE:  case LEU:
+    case GT:  case GTU:
+      code = avr_normalize_condition (code);
+      break;
+
+    default:
+      return false;
+    }
+
+  /* Wrap the branches into UNSPECs so they won't be changed or
+     optimized in the remainder.  */
+
+  target = XEXP (XEXP (ifelse1, 1), 0);
+  cond = XEXP (ifelse1, 0);
+  jump = emit_jump_insn_after (gen_branch_unspec (target, cond), insn1);
+
+  JUMP_LABEL (jump) = JUMP_LABEL (branch1);
+
+  target = XEXP (XEXP (ifelse2, 1), 0);
+  cond = gen_rtx_fmt_ee (code, VOIDmode, cc0_rtx, const0_rtx);
+  jump = emit_jump_insn_after (gen_branch_unspec (target, cond), insn2);
+
+  JUMP_LABEL (jump) = JUMP_LABEL (branch2);
+
+  /* The comparisons in insn1 and insn2 are exactly the same;
+     insn2 is superfluous so delete it.  */
+
+  delete_insn (insn2);
+  delete_insn (branch1);
+  delete_insn (branch2);
+
+  return true;
+}
+
+
+/* Implement `TARGET_MACHINE_DEPENDENT_REORG'.  */
+/* Optimize conditional jumps.  */
+
+static void
+avr_reorg (void)
+{
+  rtx_insn *insn = get_insns();
+
+  for (insn = next_real_insn (insn); insn; insn = next_real_insn (insn))
+    {
+      rtx pattern = avr_compare_pattern (insn);
+
+      if (!pattern)
+        continue;
+
+      if (optimize
+          && avr_reorg_remove_redundant_compare (insn))
+        {
+          continue;
+        }
+
+      if (compare_diff_p (insn))
+	{
+          /* Now we work under compare insn with difficult branch.  */
+
+	  rtx_insn *next = next_real_insn (insn);
+          rtx pat = PATTERN (next);
+
+          pattern = SET_SRC (pattern);
+
+          if (true_regnum (XEXP (pattern, 0)) >= 0
+              && true_regnum (XEXP (pattern, 1)) >= 0)
+            {
+              rtx x = XEXP (pattern, 0);
+              rtx src = SET_SRC (pat);
+              rtx t = XEXP (src, 0);
+              PUT_CODE (t, swap_condition (GET_CODE (t)));
+              XEXP (pattern, 0) = XEXP (pattern, 1);
+              XEXP (pattern, 1) = x;
+              INSN_CODE (next) = -1;
+            }
+          else if (true_regnum (XEXP (pattern, 0)) >= 0
+                   && XEXP (pattern, 1) == const0_rtx)
+            {
+              /* This is a tst insn, we can reverse it.  */
+              rtx src = SET_SRC (pat);
+              rtx t = XEXP (src, 0);
+
+              PUT_CODE (t, swap_condition (GET_CODE (t)));
+              XEXP (pattern, 1) = XEXP (pattern, 0);
+              XEXP (pattern, 0) = const0_rtx;
+              INSN_CODE (next) = -1;
+              INSN_CODE (insn) = -1;
+            }
+          else if (true_regnum (XEXP (pattern, 0)) >= 0
+                   && CONST_INT_P (XEXP (pattern, 1)))
+            {
+              rtx x = XEXP (pattern, 1);
+              rtx src = SET_SRC (pat);
+              rtx t = XEXP (src, 0);
+              machine_mode mode = GET_MODE (XEXP (pattern, 0));
+
+              if (avr_simplify_comparison_p (mode, GET_CODE (t), x))
+                {
+                  XEXP (pattern, 1) = gen_int_mode (INTVAL (x) + 1, mode);
+                  PUT_CODE (t, avr_normalize_condition (GET_CODE (t)));
+                  INSN_CODE (next) = -1;
+                  INSN_CODE (insn) = -1;
+                }
+            }
+        }
+    }
+}
+
+/* Returns register number for function return value.*/
+
+static inline unsigned int
+avr_ret_register (void)
+{
+  return 24;
+}
+
+
+/* Implement `TARGET_FUNCTION_VALUE_REGNO_P'.  */
+
+static bool
+avr_function_value_regno_p (const unsigned int regno)
+{
+  return (regno == avr_ret_register ());
+}
+
+
+/* Implement `TARGET_LIBCALL_VALUE'.  */
+/* Create an RTX representing the place where a
+   library function returns a value of mode MODE.  */
+
+static rtx
+avr_libcall_value (machine_mode mode,
+		   const_rtx func ATTRIBUTE_UNUSED)
+{
+  int offs = GET_MODE_SIZE (mode);
+
+  if (offs <= 4)
+    offs = (offs + 1) & ~1;
+
+  return gen_rtx_REG (mode, avr_ret_register () + 2 - offs);
+}
+
+
+/* Implement `TARGET_FUNCTION_VALUE'.  */
+/* Create an RTX representing the place where a
+   function returns a value of data type VALTYPE.  */
+
+static rtx
+avr_function_value (const_tree type,
+                    const_tree fn_decl_or_type ATTRIBUTE_UNUSED,
+                    bool outgoing ATTRIBUTE_UNUSED)
+{
+  unsigned int offs;
+
+  if (TYPE_MODE (type) != BLKmode)
+    return avr_libcall_value (TYPE_MODE (type), NULL_RTX);
+
+  offs = int_size_in_bytes (type);
+  if (offs < 2)
+    offs = 2;
+  if (offs > 2 && offs < GET_MODE_SIZE (SImode))
+    offs = GET_MODE_SIZE (SImode);
+  else if (offs > GET_MODE_SIZE (SImode) && offs < GET_MODE_SIZE (DImode))
+    offs = GET_MODE_SIZE (DImode);
+
+  return gen_rtx_REG (BLKmode, avr_ret_register () + 2 - offs);
+}
+
+int
+test_hard_reg_class (enum reg_class rclass, rtx x)
+{
+  int regno = true_regnum (x);
+  if (regno < 0)
+    return 0;
+
+  if (TEST_HARD_REG_CLASS (rclass, regno))
+    return 1;
+
+  return 0;
+}
+
+
+/* Helper for jump_over_one_insn_p:  Test if INSN is a 2-word instruction
+   and thus is suitable to be skipped by CPSE, SBRC, etc.  */
+
+static bool
+avr_2word_insn_p (rtx_insn *insn)
+{
+  if (TARGET_SKIP_BUG || !insn || get_attr_length (insn) != 2)
+    {
+      return false;
+    }
+
+  switch (INSN_CODE (insn))
+    {
+    default:
+      return false;
+
+    case CODE_FOR_movqi_insn:
+    case CODE_FOR_movuqq_insn:
+    case CODE_FOR_movqq_insn:
+      {
+        rtx set  = single_set (insn);
+        rtx src  = SET_SRC (set);
+        rtx dest = SET_DEST (set);
+
+        /* Factor out LDS and STS from movqi_insn.  */
+
+        if (MEM_P (dest)
+            && (REG_P (src) || src == CONST0_RTX (GET_MODE (dest))))
+          {
+            return CONSTANT_ADDRESS_P (XEXP (dest, 0));
+          }
+        else if (REG_P (dest)
+                 && MEM_P (src))
+          {
+            return CONSTANT_ADDRESS_P (XEXP (src, 0));
+          }
+
+        return false;
+      }
+
+    case CODE_FOR_call_insn:
+    case CODE_FOR_call_value_insn:
+      return true;
+    }
+}
+
+
+int
+jump_over_one_insn_p (rtx_insn *insn, rtx dest)
+{
+  int uid = INSN_UID (GET_CODE (dest) == LABEL_REF
+		      ? XEXP (dest, 0)
+		      : dest);
+  int jump_addr = INSN_ADDRESSES (INSN_UID (insn));
+  int dest_addr = INSN_ADDRESSES (uid);
+  int jump_offset = dest_addr - jump_addr - get_attr_length (insn);
+
+  return (jump_offset == 1
+          || (jump_offset == 2
+              && avr_2word_insn_p (next_active_insn (insn))));
+}
+
+
+/* Implement TARGET_HARD_REGNO_MODE_OK.  On the enhanced core, anything
+   larger than 1 byte must start in even numbered register for "movw" to
+   work (this way we don't have to check for odd registers everywhere).  */
+
+static bool
+avr_hard_regno_mode_ok (unsigned int regno, machine_mode mode)
+{
+  /* NOTE: 8-bit values must not be disallowed for R28 or R29.
+        Disallowing QI et al. in these regs might lead to code like
+            (set (subreg:QI (reg:HI 28) n) ...)
+        which will result in wrong code because reload does not
+        handle SUBREGs of hard regsisters like this.
+        This could be fixed in reload.  However, it appears
+        that fixing reload is not wanted by reload people.  */
+
+  /* Any GENERAL_REGS register can hold 8-bit values.  */
+
+  if (GET_MODE_SIZE (mode) == 1)
+    return true;
+
+  /* FIXME: Ideally, the following test is not needed.
+        However, it turned out that it can reduce the number
+        of spill fails.  AVR and it's poor endowment with
+        address registers is extreme stress test for reload.  */
+
+  if (GET_MODE_SIZE (mode) >= 4
+      && regno >= REG_X)
+    return false;
+
+  /* All modes larger than 8 bits should start in an even register.  */
+
+  return !(regno & 1);
+}
+
+
+/* Implement TARGET_HARD_REGNO_CALL_PART_CLOBBERED.  */
+
+static bool
+avr_hard_regno_call_part_clobbered (unsigned, unsigned regno,
+				    machine_mode mode)
+{
+  /* FIXME: This hook gets called with MODE:REGNO combinations that don't
+        represent valid hard registers like, e.g. HI:29.  Returning TRUE
+        for such registers can lead to performance degradation as mentioned
+        in PR53595.  Thus, report invalid hard registers as FALSE.  */
+
+  if (!avr_hard_regno_mode_ok (regno, mode))
+    return 0;
+
+  /* Return true if any of the following boundaries is crossed:
+     17/18 or 19/20 (if AVR_TINY), 27/28 and 29/30.  */
+
+  return ((regno <= LAST_CALLEE_SAVED_REG
+           && regno + GET_MODE_SIZE (mode) > 1 + LAST_CALLEE_SAVED_REG)
+          || (regno < REG_Y && regno + GET_MODE_SIZE (mode) > REG_Y)
+          || (regno < REG_Z && regno + GET_MODE_SIZE (mode) > REG_Z));
+}
+
+
+/* Implement `MODE_CODE_BASE_REG_CLASS'.  */
+
+enum reg_class
+avr_mode_code_base_reg_class (machine_mode mode ATTRIBUTE_UNUSED,
+                              addr_space_t as, RTX_CODE outer_code,
+                              RTX_CODE index_code ATTRIBUTE_UNUSED)
+{
+  if (!ADDR_SPACE_GENERIC_P (as))
+    {
+      return POINTER_Z_REGS;
+    }
+
+  if (!avr_strict_X)
+    return reload_completed ? BASE_POINTER_REGS : POINTER_REGS;
+
+  return PLUS == outer_code ? BASE_POINTER_REGS : POINTER_REGS;
+}
+
+
+/* Implement `REGNO_MODE_CODE_OK_FOR_BASE_P'.  */
+
+bool
+avr_regno_mode_code_ok_for_base_p (int regno,
+                                   machine_mode mode ATTRIBUTE_UNUSED,
+                                   addr_space_t as ATTRIBUTE_UNUSED,
+                                   RTX_CODE outer_code,
+                                   RTX_CODE index_code ATTRIBUTE_UNUSED)
+{
+  bool ok = false;
+
+  if (!ADDR_SPACE_GENERIC_P (as))
+    {
+      if (regno < FIRST_PSEUDO_REGISTER
+          && regno == REG_Z)
+        {
+          return true;
+        }
+
+      if (reg_renumber)
+        {
+          regno = reg_renumber[regno];
+
+          if (regno == REG_Z)
+            {
+              return true;
+            }
+        }
+
+      return false;
+    }
+
+  if (regno < FIRST_PSEUDO_REGISTER
+      && (regno == REG_X
+          || regno == REG_Y
+          || regno == REG_Z
+          || regno == ARG_POINTER_REGNUM))
+    {
+      ok = true;
+    }
+  else if (reg_renumber)
+    {
+      regno = reg_renumber[regno];
+
+      if (regno == REG_X
+          || regno == REG_Y
+          || regno == REG_Z
+          || regno == ARG_POINTER_REGNUM)
+        {
+          ok = true;
+        }
+    }
+
+  if (avr_strict_X
+      && PLUS == outer_code
+      && regno == REG_X)
+    {
+      ok = false;
+    }
+
+  return ok;
+}
+
+
+/* A helper for `output_reload_insisf' and `output_reload_inhi'.  */
+/* Set 32-bit register OP[0] to compile-time constant OP[1].
+   CLOBBER_REG is a QI clobber register or NULL_RTX.
+   LEN == NULL: output instructions.
+   LEN != NULL: set *LEN to the length of the instruction sequence
+                (in words) printed with LEN = NULL.
+   If CLEAR_P is true, OP[0] had been cleard to Zero already.
+   If CLEAR_P is false, nothing is known about OP[0].
+
+   The effect on cc0 is as follows:
+
+   Load 0 to any register except ZERO_REG : NONE
+   Load ld register with any value        : NONE
+   Anything else:                         : CLOBBER  */
+
+static void
+output_reload_in_const (rtx *op, rtx clobber_reg, int *len, bool clear_p)
+{
+  rtx src = op[1];
+  rtx dest = op[0];
+  rtx xval, xdest[4];
+  int ival[4];
+  int clobber_val = 1234;
+  bool cooked_clobber_p = false;
+  bool set_p = false;
+  machine_mode mode = GET_MODE (dest);
+  int n_bytes = GET_MODE_SIZE (mode);
+
+  gcc_assert (REG_P (dest)
+              && CONSTANT_P (src));
+
+  if (len)
+    *len = 0;
+
+  /* (REG:SI 14) is special: It's neither in LD_REGS nor in NO_LD_REGS
+     but has some subregs that are in LD_REGS.  Use the MSB (REG:QI 17).  */
+
+  if (REGNO (dest) < 16
+      && REGNO (dest) + GET_MODE_SIZE (mode) > 16)
+    {
+      clobber_reg = all_regs_rtx[REGNO (dest) + n_bytes - 1];
+    }
+
+  /* We might need a clobber reg but don't have one.  Look at the value to
+     be loaded more closely.  A clobber is only needed if it is a symbol
+     or contains a byte that is neither 0, -1 or a power of 2.  */
+
+  if (NULL_RTX == clobber_reg
+      && !test_hard_reg_class (LD_REGS, dest)
+      && (! (CONST_INT_P (src) || CONST_FIXED_P (src) || CONST_DOUBLE_P (src))
+          || !avr_popcount_each_byte (src, n_bytes,
+                                      (1 << 0) | (1 << 1) | (1 << 8))))
+    {
+      /* We have no clobber register but need one.  Cook one up.
+         That's cheaper than loading from constant pool.  */
+
+      cooked_clobber_p = true;
+      clobber_reg = all_regs_rtx[REG_Z + 1];
+      avr_asm_len ("mov __tmp_reg__,%0", &clobber_reg, len, 1);
+    }
+
+  /* Now start filling DEST from LSB to MSB.  */
+
+  for (int n = 0; n < n_bytes; n++)
+    {
+      int ldreg_p;
+      bool done_byte = false;
+      rtx xop[3];
+
+      /* Crop the n-th destination byte.  */
+
+      xdest[n] = simplify_gen_subreg (QImode, dest, mode, n);
+      ldreg_p = test_hard_reg_class (LD_REGS, xdest[n]);
+
+      if (!CONST_INT_P (src)
+          && !CONST_FIXED_P (src)
+          && !CONST_DOUBLE_P (src))
+        {
+          static const char* const asm_code[][2] =
+            {
+              { "ldi %2,lo8(%1)"  CR_TAB "mov %0,%2",    "ldi %0,lo8(%1)"  },
+              { "ldi %2,hi8(%1)"  CR_TAB "mov %0,%2",    "ldi %0,hi8(%1)"  },
+              { "ldi %2,hlo8(%1)" CR_TAB "mov %0,%2",    "ldi %0,hlo8(%1)" },
+              { "ldi %2,hhi8(%1)" CR_TAB "mov %0,%2",    "ldi %0,hhi8(%1)" }
+            };
+
+          xop[0] = xdest[n];
+          xop[1] = src;
+          xop[2] = clobber_reg;
+
+          avr_asm_len (asm_code[n][ldreg_p], xop, len, ldreg_p ? 1 : 2);
+
+          continue;
+        }
+
+      /* Crop the n-th source byte.  */
+
+      xval = simplify_gen_subreg (QImode, src, mode, n);
+      ival[n] = INTVAL (xval);
+
+      /* Look if we can reuse the low word by means of MOVW.  */
+
+      if (n == 2
+          && n_bytes >= 4
+          && AVR_HAVE_MOVW)
+        {
+          rtx lo16 = simplify_gen_subreg (HImode, src, mode, 0);
+          rtx hi16 = simplify_gen_subreg (HImode, src, mode, 2);
+
+          if (INTVAL (lo16) == INTVAL (hi16))
+            {
+	      if (INTVAL (lo16) != 0 || !clear_p)
+		avr_asm_len ("movw %C0,%A0", &op[0], len, 1);
+
+              break;
+            }
+        }
+
+      /* Don't use CLR so that cc0 is set as expected.  */
+
+      if (ival[n] == 0)
+        {
+          if (!clear_p)
+            avr_asm_len (ldreg_p ? "ldi %0,0"
+                         : AVR_ZERO_REGNO == REGNO (xdest[n]) ? "clr %0"
+                         : "mov %0,__zero_reg__",
+                         &xdest[n], len, 1);
+          continue;
+        }
+
+      if (clobber_val == ival[n]
+          && REGNO (clobber_reg) == REGNO (xdest[n]))
+        {
+          continue;
+        }
+
+      /* LD_REGS can use LDI to move a constant value */
+
+      if (ldreg_p)
+        {
+          xop[0] = xdest[n];
+          xop[1] = xval;
+          avr_asm_len ("ldi %0,lo8(%1)", xop, len, 1);
+          continue;
+        }
+
+      /* Try to reuse value already loaded in some lower byte. */
+
+      for (int j = 0; j < n; j++)
+        if (ival[j] == ival[n])
+          {
+            xop[0] = xdest[n];
+            xop[1] = xdest[j];
+
+            avr_asm_len ("mov %0,%1", xop, len, 1);
+            done_byte = true;
+            break;
+          }
+
+      if (done_byte)
+        continue;
+
+      /* Need no clobber reg for -1: Use CLR/DEC */
+
+      if (ival[n] == -1)
+        {
+          if (!clear_p)
+            avr_asm_len ("clr %0", &xdest[n], len, 1);
+
+          avr_asm_len ("dec %0", &xdest[n], len, 1);
+          continue;
+        }
+      else if (ival[n] == 1)
+        {
+          if (!clear_p)
+            avr_asm_len ("clr %0", &xdest[n], len, 1);
+
+          avr_asm_len ("inc %0", &xdest[n], len, 1);
+          continue;
+        }
+
+      /* Use T flag or INC to manage powers of 2 if we have
+         no clobber reg.  */
+
+      if (NULL_RTX == clobber_reg
+          && single_one_operand (xval, QImode))
+        {
+          xop[0] = xdest[n];
+          xop[1] = GEN_INT (exact_log2 (ival[n] & GET_MODE_MASK (QImode)));
+
+          gcc_assert (constm1_rtx != xop[1]);
+
+          if (!set_p)
+            {
+              set_p = true;
+              avr_asm_len ("set", xop, len, 1);
+            }
+
+          if (!clear_p)
+            avr_asm_len ("clr %0", xop, len, 1);
+
+          avr_asm_len ("bld %0,%1", xop, len, 1);
+          continue;
+        }
+
+      /* We actually need the LD_REGS clobber reg.  */
+
+      gcc_assert (NULL_RTX != clobber_reg);
+
+      xop[0] = xdest[n];
+      xop[1] = xval;
+      xop[2] = clobber_reg;
+      clobber_val = ival[n];
+
+      avr_asm_len ("ldi %2,lo8(%1)" CR_TAB
+                   "mov %0,%2", xop, len, 2);
+    }
+
+  /* If we cooked up a clobber reg above, restore it.  */
+
+  if (cooked_clobber_p)
+    {
+      avr_asm_len ("mov %0,__tmp_reg__", &clobber_reg, len, 1);
+    }
+}
+
+
+/* Reload the constant OP[1] into the HI register OP[0].
+   CLOBBER_REG is a QI clobber reg needed to move vast majority of consts
+   into a NO_LD_REGS register.  If CLOBBER_REG is NULL_RTX we either don't
+   need a clobber reg or have to cook one up.
+
+   PLEN == NULL: Output instructions.
+   PLEN != NULL: Output nothing.  Set *PLEN to number of words occupied
+                 by the insns printed.
+
+   Return "".  */
+
+const char*
+output_reload_inhi (rtx *op, rtx clobber_reg, int *plen)
+{
+  output_reload_in_const (op, clobber_reg, plen, false);
+  return "";
+}
+
+
+/* Reload a SI or SF compile time constant OP[1] into the register OP[0].
+   CLOBBER_REG is a QI clobber reg needed to move vast majority of consts
+   into a NO_LD_REGS register.  If CLOBBER_REG is NULL_RTX we either don't
+   need a clobber reg or have to cook one up.
+
+   LEN == NULL: Output instructions.
+
+   LEN != NULL: Output nothing.  Set *LEN to number of words occupied
+                by the insns printed.
+
+   Return "".  */
+
+const char *
+output_reload_insisf (rtx *op, rtx clobber_reg, int *len)
+{
+  if (AVR_HAVE_MOVW
+      && !test_hard_reg_class (LD_REGS, op[0])
+      && (CONST_INT_P (op[1])
+          || CONST_FIXED_P (op[1])
+          || CONST_DOUBLE_P (op[1])))
+    {
+      int len_clr, len_noclr;
+
+      /* In some cases it is better to clear the destination beforehand, e.g.
+
+             CLR R2   CLR R3   MOVW R4,R2   INC R2
+
+         is shorther than
+
+             CLR R2   INC R2   CLR  R3      CLR R4   CLR R5
+
+         We find it too tedious to work that out in the print function.
+         Instead, we call the print function twice to get the lengths of
+         both methods and use the shortest one.  */
+
+      output_reload_in_const (op, clobber_reg, &len_clr, true);
+      output_reload_in_const (op, clobber_reg, &len_noclr, false);
+
+      if (len_noclr - len_clr == 4)
+        {
+          /* Default needs 4 CLR instructions: clear register beforehand.  */
+
+          avr_asm_len ("mov %A0,__zero_reg__" CR_TAB
+                       "mov %B0,__zero_reg__" CR_TAB
+                       "movw %C0,%A0", &op[0], len, 3);
+
+          output_reload_in_const (op, clobber_reg, len, true);
+
+          if (len)
+            *len += 3;
+
+          return "";
+        }
+    }
+
+  /* Default: destination not pre-cleared.  */
+
+  output_reload_in_const (op, clobber_reg, len, false);
+  return "";
+}
+
+const char*
+avr_out_reload_inpsi (rtx *op, rtx clobber_reg, int *len)
+{
+  output_reload_in_const (op, clobber_reg, len, false);
+  return "";
+}
+
+
+/* Worker function for `ASM_OUTPUT_ADDR_VEC'.  */
+/* Emit jump tables out-of-line so that branches crossing the table
+   get shorter offsets.  If we have JUMP + CALL, then put the tables
+   in a dedicated non-.text section so that CALLs get better chance to
+   be relaxed to RCALLs.
+
+   We emit the tables by hand because `function_rodata_section' does not
+   work as expected, cf. PR71151, and we do *NOT* want the table to be
+   in .rodata, hence setting JUMP_TABLES_IN_TEXT_SECTION = 0 is of limited
+   use; and setting it to 1 attributes table lengths to branch offsets...
+   Moreover, fincal.c keeps switching section before each table entry
+   which we find too fragile as to rely on section caching.  */
+
+void
+avr_output_addr_vec (rtx_insn *labl, rtx table)
+{
+  FILE *stream = asm_out_file;
+
+  app_disable();
+
+  // Switch to appropriate (sub)section.
+
+  if (DECL_SECTION_NAME (current_function_decl)
+      && symtab_node::get (current_function_decl)
+      && ! symtab_node::get (current_function_decl)->implicit_section)
+    {
+      // .subsection will emit the code after the function and in the
+      // section as chosen by the user.
+
+      switch_to_section (current_function_section ());
+      fprintf (stream, "\t.subsection\t1\n");
+    }
+  else
+    {
+      // Since PR63223 there is no restriction where to put the table; it
+      // may even reside above 128 KiB.  We put it in a section as high as
+      // possible and avoid progmem in order not to waste flash <= 64 KiB.
+
+      const char *sec_name = ".jumptables.gcc";
+
+      // The table belongs to its host function, therefore use fine
+      // grained sections so that, if that function is removed by
+      // --gc-sections, the child table(s) may also be removed.  */
+
+      tree asm_name = DECL_ASSEMBLER_NAME (current_function_decl);
+      const char *fname = IDENTIFIER_POINTER (asm_name);
+      fname = targetm.strip_name_encoding (fname);
+      sec_name = ACONCAT ((sec_name, ".", fname, NULL));
+
+      fprintf (stream, "\t.section\t%s,\"%s\",@progbits\n", sec_name,
+               AVR_HAVE_JMP_CALL ? "a" : "ax");
+    }
+
+  // Output the label that preceeds the table.
+
+  ASM_OUTPUT_ALIGN (stream, 1);
+  targetm.asm_out.internal_label (stream, "L", CODE_LABEL_NUMBER (labl));
+
+  // Output the table's content.
+
+  int vlen = XVECLEN (table, 0);
+
+  for (int idx = 0; idx < vlen; idx++)
+    {
+      int value = CODE_LABEL_NUMBER (XEXP (XVECEXP (table, 0, idx), 0));
+
+      if (AVR_HAVE_JMP_CALL)
+        fprintf (stream, "\t.word gs(.L%d)\n", value);
+      else
+        fprintf (stream, "\trjmp .L%d\n", value);
+    }
+
+  // Switch back to original section.  As we clobbered the section above,
+  // forget the current section before switching back.
+
+  in_section = NULL;
+  switch_to_section (current_function_section ());
+}
+
+
+/* Implement `TARGET_CONDITIONAL_REGISTER_USAGE'.  */
+
+static void
+avr_conditional_register_usage (void)
+{
+  if (AVR_TINY)
+    {
+      const int tiny_reg_alloc_order[] = {
+        24, 25,
+        22, 23,
+        30, 31,
+        26, 27,
+        28, 29,
+        21, 20, 19, 18,
+        16, 17,
+        32, 33, 34, 35,
+        15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0
+      };
+
+      /* Set R0-R17 as fixed registers. Reset R0-R17 in call used register list
+         - R0-R15 are not available in Tiny Core devices
+         - R16 and R17 are fixed registers.  */
+
+      for (size_t i = 0; i <= 17;  i++)
+        {
+          fixed_regs[i] = 1;
+          call_used_regs[i] = 1;
+        }
+
+      /* Set R18 to R21 as callee saved registers
+         - R18, R19, R20 and R21 are the callee saved registers in
+           Tiny Core devices  */
+
+      for (size_t i = 18; i <= LAST_CALLEE_SAVED_REG; i++)
+        {
+          call_used_regs[i] = 0;
+        }
+
+      /* Update register allocation order for Tiny Core devices */
+
+      for (size_t i = 0; i < ARRAY_SIZE (tiny_reg_alloc_order); i++)
+        {
+          reg_alloc_order[i] = tiny_reg_alloc_order[i];
+        }
+
+      CLEAR_HARD_REG_SET (reg_class_contents[(int) ADDW_REGS]);
+      CLEAR_HARD_REG_SET (reg_class_contents[(int) NO_LD_REGS]);
+    }
+}
+
+/* Implement `TARGET_HARD_REGNO_SCRATCH_OK'.  */
+/* Returns true if SCRATCH are safe to be allocated as a scratch
+   registers (for a define_peephole2) in the current function.  */
+
+static bool
+avr_hard_regno_scratch_ok (unsigned int regno)
+{
+  /* Interrupt functions can only use registers that have already been saved
+     by the prologue, even if they would normally be call-clobbered.  */
+
+  if ((cfun->machine->is_interrupt || cfun->machine->is_signal)
+      && !df_regs_ever_live_p (regno))
+    return false;
+
+  /* Don't allow hard registers that might be part of the frame pointer.
+     Some places in the compiler just test for [HARD_]FRAME_POINTER_REGNUM
+     and don't care for a frame pointer that spans more than one register.  */
+
+  if ((!reload_completed || frame_pointer_needed)
+      && (regno == REG_Y || regno == REG_Y + 1))
+    {
+      return false;
+    }
+
+  return true;
+}
+
+
+/* Worker function for `HARD_REGNO_RENAME_OK'.  */
+/* Return nonzero if register OLD_REG can be renamed to register NEW_REG.  */
+
+int
+avr_hard_regno_rename_ok (unsigned int old_reg,
+			  unsigned int new_reg)
+{
+  /* Interrupt functions can only use registers that have already been
+     saved by the prologue, even if they would normally be
+     call-clobbered.  */
+
+  if ((cfun->machine->is_interrupt || cfun->machine->is_signal)
+      && !df_regs_ever_live_p (new_reg))
+    return 0;
+
+  /* Don't allow hard registers that might be part of the frame pointer.
+     Some places in the compiler just test for [HARD_]FRAME_POINTER_REGNUM
+     and don't care for a frame pointer that spans more than one register.  */
+
+  if ((!reload_completed || frame_pointer_needed)
+      && (old_reg == REG_Y || old_reg == REG_Y + 1
+          || new_reg == REG_Y || new_reg == REG_Y + 1))
+    {
+      return 0;
+    }
+
+  return 1;
+}
+
+/* Output a branch that tests a single bit of a register (QI, HI, SI or DImode)
+   or memory location in the I/O space (QImode only).
+
+   Operand 0: comparison operator (must be EQ or NE, compare bit to zero).
+   Operand 1: register operand to test, or CONST_INT memory address.
+   Operand 2: bit number.
+   Operand 3: label to jump to if the test is true.  */
+
+const char*
+avr_out_sbxx_branch (rtx_insn *insn, rtx operands[])
+{
+  enum rtx_code comp = GET_CODE (operands[0]);
+  bool long_jump = get_attr_length (insn) >= 4;
+  bool reverse = long_jump || jump_over_one_insn_p (insn, operands[3]);
+
+  if (comp == GE)
+    comp = EQ;
+  else if (comp == LT)
+    comp = NE;
+
+  if (reverse)
+    comp = reverse_condition (comp);
+
+  switch (GET_CODE (operands[1]))
+    {
+    default:
+      gcc_unreachable();
+
+    case CONST_INT:
+    case CONST:
+    case SYMBOL_REF:
+
+      if (low_io_address_operand (operands[1], QImode))
+        {
+          if (comp == EQ)
+            output_asm_insn ("sbis %i1,%2", operands);
+          else
+            output_asm_insn ("sbic %i1,%2", operands);
+        }
+      else
+        {
+	  gcc_assert (io_address_operand (operands[1], QImode));
+          output_asm_insn ("in __tmp_reg__,%i1", operands);
+          if (comp == EQ)
+            output_asm_insn ("sbrs __tmp_reg__,%2", operands);
+          else
+            output_asm_insn ("sbrc __tmp_reg__,%2", operands);
+        }
+
+      break; /* CONST_INT */
+
+    case REG:
+
+      if (comp == EQ)
+        output_asm_insn ("sbrs %T1%T2", operands);
+      else
+        output_asm_insn ("sbrc %T1%T2", operands);
+
+      break; /* REG */
+    }        /* switch */
+
+  if (long_jump)
+    return ("rjmp .+4" CR_TAB
+            "jmp %x3");
+
+  if (!reverse)
+    return "rjmp %x3";
+
+  return "";
+}
+
+/* Worker function for `TARGET_ASM_CONSTRUCTOR'.  */
+
+static void
+avr_asm_out_ctor (rtx symbol, int priority)
+{
+  fputs ("\t.global __do_global_ctors\n", asm_out_file);
+  default_ctor_section_asm_out_constructor (symbol, priority);
+}
+
+
+/* Worker function for `TARGET_ASM_DESTRUCTOR'.  */
+
+static void
+avr_asm_out_dtor (rtx symbol, int priority)
+{
+  fputs ("\t.global __do_global_dtors\n", asm_out_file);
+  default_dtor_section_asm_out_destructor (symbol, priority);
+}
+
+
+/* Worker function for `TARGET_RETURN_IN_MEMORY'.  */
+
+static bool
+avr_return_in_memory (const_tree type, const_tree fntype ATTRIBUTE_UNUSED)
+{
+  HOST_WIDE_INT size = int_size_in_bytes (type);
+  HOST_WIDE_INT ret_size_limit = AVR_TINY ? 4 : 8;
+
+  /* In avr, there are 8 return registers. But, for Tiny Core
+     (ATtiny4/5/9/10/20/40) devices, only 4 registers are available.
+     Return true if size is unknown or greater than the limit.  */
+
+  if (size == -1 || size > ret_size_limit)
+    {
+      return true;
+    }
+  else
+    {
+      return false;
+    }
+}
+
+
+/* Implement `CASE_VALUES_THRESHOLD'.  */
+/* Supply the default for --param case-values-threshold=0  */
+
+static unsigned int
+avr_case_values_threshold (void)
+{
+  /* The exact break-even point between a jump table and an if-else tree
+     depends on several factors not available here like, e.g. if 8-bit
+     comparisons can be used in the if-else tree or not, on the
+     range of the case values, if the case value can be reused, on the
+     register allocation, etc.  '7' appears to be a good choice.  */
+
+  return 7;
+}
+
+
+/* Implement `TARGET_ADDR_SPACE_ADDRESS_MODE'.  */
+
+static scalar_int_mode
+avr_addr_space_address_mode (addr_space_t as)
+{
+  return avr_addrspace[as].pointer_size == 3 ? PSImode : HImode;
+}
+
+
+/* Implement `TARGET_ADDR_SPACE_POINTER_MODE'.  */
+
+static scalar_int_mode
+avr_addr_space_pointer_mode (addr_space_t as)
+{
+  return avr_addr_space_address_mode (as);
+}
+
+
+/* Helper for following function.  */
+
+static bool
+avr_reg_ok_for_pgm_addr (rtx reg, bool strict)
+{
+  gcc_assert (REG_P (reg));
+
+  if (strict)
+    {
+      return REGNO (reg) == REG_Z;
+    }
+
+  /* Avoid combine to propagate hard regs.  */
+
+  if (can_create_pseudo_p()
+      && REGNO (reg) < REG_Z)
+    {
+      return false;
+    }
+
+  return true;
+}
+
+
+/* Implement `TARGET_ADDR_SPACE_LEGITIMATE_ADDRESS_P'.  */
+
+static bool
+avr_addr_space_legitimate_address_p (machine_mode mode, rtx x,
+                                     bool strict, addr_space_t as)
+{
+  bool ok = false;
+
+  switch (as)
+    {
+    default:
+      gcc_unreachable();
+
+    case ADDR_SPACE_GENERIC:
+      return avr_legitimate_address_p (mode, x, strict);
+
+    case ADDR_SPACE_FLASH:
+    case ADDR_SPACE_FLASH1:
+    case ADDR_SPACE_FLASH2:
+    case ADDR_SPACE_FLASH3:
+    case ADDR_SPACE_FLASH4:
+    case ADDR_SPACE_FLASH5:
+
+      switch (GET_CODE (x))
+        {
+        case REG:
+          ok = avr_reg_ok_for_pgm_addr (x, strict);
+          break;
+
+        case POST_INC:
+          ok = avr_reg_ok_for_pgm_addr (XEXP (x, 0), strict);
+          break;
+
+        default:
+          break;
+        }
+
+      break; /* FLASH */
+
+    case ADDR_SPACE_MEMX:
+      if (REG_P (x))
+        ok = (!strict
+              && can_create_pseudo_p());
+
+      if (LO_SUM == GET_CODE (x))
+        {
+          rtx hi = XEXP (x, 0);
+          rtx lo = XEXP (x, 1);
+
+          ok = (REG_P (hi)
+                && (!strict || REGNO (hi) < FIRST_PSEUDO_REGISTER)
+                && REG_P (lo)
+                && REGNO (lo) == REG_Z);
+        }
+
+      break; /* MEMX */
+    }
+
+  if (avr_log.legitimate_address_p)
+    {
+      avr_edump ("\n%?: ret=%b, mode=%m strict=%d "
+                 "reload_completed=%d reload_in_progress=%d %s:",
+                 ok, mode, strict, reload_completed, reload_in_progress,
+                 reg_renumber ? "(reg_renumber)" : "");
+
+      if (GET_CODE (x) == PLUS
+          && REG_P (XEXP (x, 0))
+          && CONST_INT_P (XEXP (x, 1))
+          && IN_RANGE (INTVAL (XEXP (x, 1)), 0, MAX_LD_OFFSET (mode))
+          && reg_renumber)
+        {
+          avr_edump ("(r%d ---> r%d)", REGNO (XEXP (x, 0)),
+                     true_regnum (XEXP (x, 0)));
+        }
+
+      avr_edump ("\n%r\n", x);
+    }
+
+  return ok;
+}
+
+
+/* Implement `TARGET_ADDR_SPACE_LEGITIMIZE_ADDRESS'.  */
+
+static rtx
+avr_addr_space_legitimize_address (rtx x, rtx old_x,
+                                   machine_mode mode, addr_space_t as)
+{
+  if (ADDR_SPACE_GENERIC_P (as))
+    return avr_legitimize_address (x, old_x, mode);
+
+  if (avr_log.legitimize_address)
+    {
+      avr_edump ("\n%?: mode=%m\n %r\n", mode, old_x);
+    }
+
+  return old_x;
+}
+
+
+/* Implement `TARGET_ADDR_SPACE_CONVERT'.  */
+
+static rtx
+avr_addr_space_convert (rtx src, tree type_from, tree type_to)
+{
+  addr_space_t as_from = TYPE_ADDR_SPACE (TREE_TYPE (type_from));
+  addr_space_t as_to = TYPE_ADDR_SPACE (TREE_TYPE (type_to));
+
+  if (avr_log.progmem)
+    avr_edump ("\n%!: op = %r\nfrom = %t\nto = %t\n",
+               src, type_from, type_to);
+
+  /* Up-casting from 16-bit to 24-bit pointer.  */
+
+  if (as_from != ADDR_SPACE_MEMX
+      && as_to == ADDR_SPACE_MEMX)
+    {
+      int msb;
+      rtx sym = src;
+      rtx reg = gen_reg_rtx (PSImode);
+
+      while (CONST == GET_CODE (sym) || PLUS == GET_CODE (sym))
+        sym = XEXP (sym, 0);
+
+      /* Look at symbol flags:  avr_encode_section_info set the flags
+         also if attribute progmem was seen so that we get the right
+         promotion for, e.g. PSTR-like strings that reside in generic space
+         but are located in flash.  In that case we patch the incoming
+         address space.  */
+
+      if (SYMBOL_REF_P (sym)
+          && ADDR_SPACE_FLASH == AVR_SYMBOL_GET_ADDR_SPACE (sym))
+        {
+          as_from = ADDR_SPACE_FLASH;
+        }
+
+      /* Linearize memory: RAM has bit 23 set.  */
+
+      msb = ADDR_SPACE_GENERIC_P (as_from)
+        ? 0x80
+        : avr_addrspace[as_from].segment;
+
+      src = force_reg (Pmode, src);
+
+      emit_insn (msb == 0
+                 ? gen_zero_extendhipsi2 (reg, src)
+                 : gen_n_extendhipsi2 (reg, gen_int_mode (msb, QImode), src));
+
+      return reg;
+    }
+
+  /* Down-casting from 24-bit to 16-bit throws away the high byte.  */
+
+  if (as_from == ADDR_SPACE_MEMX
+      && as_to != ADDR_SPACE_MEMX)
+    {
+      rtx new_src = gen_reg_rtx (Pmode);
+
+      src = force_reg (PSImode, src);
+
+      emit_move_insn (new_src,
+                      simplify_gen_subreg (Pmode, src, PSImode, 0));
+      return new_src;
+    }
+
+  return src;
+}
+
+
+/* Implement `TARGET_ADDR_SPACE_SUBSET_P'.  */
+
+static bool
+avr_addr_space_subset_p (addr_space_t subset ATTRIBUTE_UNUSED,
+                         addr_space_t superset ATTRIBUTE_UNUSED)
+{
+  /* Allow any kind of pointer mess.  */
+
+  return true;
+}
+
+
+/* Implement `TARGET_CONVERT_TO_TYPE'.  */
+
+static tree
+avr_convert_to_type (tree type, tree expr)
+{
+  /* Print a diagnose for pointer conversion that changes the address
+     space of the pointer target to a non-enclosing address space,
+     provided -Waddr-space-convert is on.
+
+     FIXME: Filter out cases where the target object is known to
+            be located in the right memory, like in
+
+                (const __flash*) PSTR ("text")
+
+            Also try to distinguish between explicit casts requested by
+            the user and implicit casts like
+
+                void f (const __flash char*);
+
+                void g (const char *p)
+                {
+                    f ((const __flash*) p);
+                }
+
+            under the assumption that an explicit casts means that the user
+            knows what he is doing, e.g. interface with PSTR or old style
+            code with progmem and pgm_read_xxx.
+  */
+
+  if (avr_warn_addr_space_convert
+      && expr != error_mark_node
+      && POINTER_TYPE_P (type)
+      && POINTER_TYPE_P (TREE_TYPE (expr)))
+    {
+      addr_space_t as_old = TYPE_ADDR_SPACE (TREE_TYPE (TREE_TYPE (expr)));
+      addr_space_t as_new = TYPE_ADDR_SPACE (TREE_TYPE (type));
+
+      if (avr_log.progmem)
+        avr_edump ("%?: type = %t\nexpr = %t\n\n", type, expr);
+
+      if (as_new != ADDR_SPACE_MEMX
+          && as_new != as_old)
+        {
+          location_t loc = EXPR_LOCATION (expr);
+          const char *name_old = avr_addrspace[as_old].name;
+          const char *name_new = avr_addrspace[as_new].name;
+
+          warning (OPT_Waddr_space_convert,
+                   "conversion from address space %qs to address space %qs",
+                   ADDR_SPACE_GENERIC_P (as_old) ? "generic" : name_old,
+                   ADDR_SPACE_GENERIC_P (as_new) ? "generic" : name_new);
+
+          return fold_build1_loc (loc, ADDR_SPACE_CONVERT_EXPR, type, expr);
+        }
+    }
+
+  return NULL_TREE;
+}
+
+
+/* Implement `TARGET_LEGITIMATE_COMBINED_INSN'.  */
+
+/* PR78883: Filter out paradoxical SUBREGs of MEM which are not handled
+   properly by following passes.  As INSN_SCHEDULING is off and hence
+   general_operand accepts such expressions, ditch them now.  */
+
+static bool
+avr_legitimate_combined_insn (rtx_insn *insn)
+{
+  subrtx_iterator::array_type array;
+
+  FOR_EACH_SUBRTX (iter, array, PATTERN (insn), NONCONST)
+    {
+      const_rtx op = *iter;
+
+      if (SUBREG_P (op)
+          && MEM_P (SUBREG_REG (op))
+          && (GET_MODE_SIZE (GET_MODE (op))
+              > GET_MODE_SIZE (GET_MODE (SUBREG_REG (op)))))
+        {
+          return false;
+        }
+    }
+
+  return true;
+}
+
+
+/* PR63633: The middle-end might come up with hard regs as input operands.
+
+   RMASK is a bit mask representing a subset of hard registers R0...R31:
+   Rn is an element of that set iff bit n of RMASK is set.
+   OPMASK describes a subset of OP[]:  If bit n of OPMASK is 1 then
+   OP[n] has to be fixed; otherwise OP[n] is left alone.
+
+   For each element of OPMASK which is a hard register overlapping RMASK,
+   replace OP[n] with a newly created pseudo register
+
+   HREG == 0:  Also emit a move insn that copies the contents of that
+               hard register into the new pseudo.
+
+   HREG != 0:  Also set HREG[n] to the hard register.  */
+
+static void
+avr_fix_operands (rtx *op, rtx *hreg, unsigned opmask, unsigned rmask)
+{
+  for (; opmask; opmask >>= 1, op++)
+    {
+      rtx reg = *op;
+
+      if (hreg)
+        *hreg = NULL_RTX;
+
+      if ((opmask & 1)
+          && REG_P (reg)
+          && REGNO (reg) < FIRST_PSEUDO_REGISTER
+          // This hard-reg overlaps other prohibited hard regs?
+          && (rmask & regmask (GET_MODE (reg), REGNO (reg))))
+        {
+          *op = gen_reg_rtx (GET_MODE (reg));
+          if (hreg == NULL)
+            emit_move_insn (*op, reg);
+          else
+            *hreg = reg;
+        }
+
+      if (hreg)
+        hreg++;
+    }
+}
+
+
+void
+avr_fix_inputs (rtx *op, unsigned opmask, unsigned rmask)
+{
+  avr_fix_operands (op, NULL, opmask, rmask);
+}
+
+
+/* Helper for the function below:  If bit n of MASK is set and
+   HREG[n] != NULL, then emit a move insn to copy OP[n] to HREG[n].
+   Otherwise do nothing for that n.  Return TRUE.  */
+
+static bool
+avr_move_fixed_operands (rtx *op, rtx *hreg, unsigned mask)
+{
+  for (; mask; mask >>= 1, op++, hreg++)
+    if ((mask & 1)
+        && *hreg)
+      emit_move_insn (*hreg, *op);
+
+  return true;
+}
+
+
+/* PR63633: The middle-end might come up with hard regs as output operands.
+
+   GEN is a sequence generating function like gen_mulsi3 with 3 operands OP[].
+   RMASK is a bit mask representing a subset of hard registers R0...R31:
+   Rn is an element of that set iff bit n of RMASK is set.
+   OPMASK describes a subset of OP[]:  If bit n of OPMASK is 1 then
+   OP[n] has to be fixed; otherwise OP[n] is left alone.
+
+   Emit the insn sequence as generated by GEN() with all elements of OPMASK
+   which are hard registers overlapping RMASK replaced by newly created
+   pseudo registers.  After the sequence has been emitted, emit insns that
+   move the contents of respective pseudos to their hard regs.  */
+
+bool
+avr_emit3_fix_outputs (rtx (*gen)(rtx,rtx,rtx), rtx *op,
+                       unsigned opmask, unsigned rmask)
+{
+  const int n = 3;
+  rtx hreg[n];
+
+  /* It is letigimate for GEN to call this function, and in order not to
+     get self-recursive we use the following static kludge.  This is the
+     only way not to duplicate all expanders and to avoid ugly and
+     hard-to-maintain C-code instead of the much more appreciated RTL
+     representation as supplied by define_expand.  */
+  static bool lock = false;
+
+  gcc_assert (opmask < (1u << n));
+
+  if (lock)
+    return false;
+
+  avr_fix_operands (op, hreg, opmask, rmask);
+
+  lock = true;
+  emit_insn (gen (op[0], op[1], op[2]));
+  lock = false;
+
+  return avr_move_fixed_operands (op, hreg, opmask);
+}
+
+
+/* Worker function for cpymemhi expander.
+   XOP[0]  Destination as MEM:BLK
+   XOP[1]  Source      "     "
+   XOP[2]  # Bytes to copy
+
+   Return TRUE  if the expansion is accomplished.
+   Return FALSE if the operand compination is not supported.  */
+
+bool
+avr_emit_cpymemhi (rtx *xop)
+{
+  HOST_WIDE_INT count;
+  machine_mode loop_mode;
+  addr_space_t as = MEM_ADDR_SPACE (xop[1]);
+  rtx loop_reg, addr1, a_src, a_dest, insn, xas;
+  rtx a_hi8 = NULL_RTX;
+
+  if (avr_mem_flash_p (xop[0]))
+    return false;
+
+  if (!CONST_INT_P (xop[2]))
+    return false;
+
+  count = INTVAL (xop[2]);
+  if (count <= 0)
+    return false;
+
+  a_src  = XEXP (xop[1], 0);
+  a_dest = XEXP (xop[0], 0);
+
+  if (PSImode == GET_MODE (a_src))
+    {
+      gcc_assert (as == ADDR_SPACE_MEMX);
+
+      loop_mode = (count < 0x100) ? QImode : HImode;
+      loop_reg = gen_rtx_REG (loop_mode, 24);
+      emit_move_insn (loop_reg, gen_int_mode (count, loop_mode));
+
+      addr1 = simplify_gen_subreg (HImode, a_src, PSImode, 0);
+      a_hi8 = simplify_gen_subreg (QImode, a_src, PSImode, 2);
+    }
+  else
+    {
+      int segment = avr_addrspace[as].segment;
+
+      if (segment
+          && avr_n_flash > 1)
+        {
+          a_hi8 = GEN_INT (segment);
+          emit_move_insn (rampz_rtx, a_hi8 = copy_to_mode_reg (QImode, a_hi8));
+        }
+      else if (!ADDR_SPACE_GENERIC_P (as))
+        {
+          as = ADDR_SPACE_FLASH;
+        }
+
+      addr1 = a_src;
+
+      loop_mode = (count <= 0x100) ? QImode : HImode;
+      loop_reg = copy_to_mode_reg (loop_mode, gen_int_mode (count, loop_mode));
+    }
+
+  xas = GEN_INT (as);
+
+  /* FIXME: Register allocator might come up with spill fails if it is left
+        on its own.  Thus, we allocate the pointer registers by hand:
+        Z = source address
+        X = destination address  */
+
+  emit_move_insn (lpm_addr_reg_rtx, addr1);
+  emit_move_insn (gen_rtx_REG (HImode, REG_X), a_dest);
+
+  /* FIXME: Register allocator does a bad job and might spill address
+        register(s) inside the loop leading to additional move instruction
+        to/from stack which could clobber tmp_reg.  Thus, do *not* emit
+        load and store as separate insns.  Instead, we perform the copy
+        by means of one monolithic insn.  */
+
+  gcc_assert (TMP_REGNO == LPM_REGNO);
+
+  if (as != ADDR_SPACE_MEMX)
+    {
+      /* Load instruction ([E]LPM or LD) is known at compile time:
+         Do the copy-loop inline.  */
+
+      rtx (*fun) (rtx, rtx, rtx)
+        = QImode == loop_mode ? gen_cpymem_qi : gen_cpymem_hi;
+
+      insn = fun (xas, loop_reg, loop_reg);
+    }
+  else
+    {
+      rtx (*fun) (rtx, rtx)
+        = QImode == loop_mode ? gen_cpymemx_qi : gen_cpymemx_hi;
+
+      emit_move_insn (gen_rtx_REG (QImode, 23), a_hi8);
+
+      insn = fun (xas, GEN_INT (avr_addr.rampz));
+    }
+
+  set_mem_addr_space (SET_SRC (XVECEXP (insn, 0, 0)), as);
+  emit_insn (insn);
+
+  return true;
+}
+
+
+/* Print assembler for cpymem_qi, cpymem_hi insns...
+       $0     : Address Space
+       $1, $2 : Loop register
+       Z      : Source address
+       X      : Destination address
+*/
+
+const char*
+avr_out_cpymem (rtx_insn *insn ATTRIBUTE_UNUSED, rtx *op, int *plen)
+{
+  addr_space_t as = (addr_space_t) INTVAL (op[0]);
+  machine_mode loop_mode = GET_MODE (op[1]);
+  bool sbiw_p = test_hard_reg_class (ADDW_REGS, op[1]);
+  rtx xop[3];
+
+  if (plen)
+    *plen = 0;
+
+  xop[0] = op[0];
+  xop[1] = op[1];
+  xop[2] = tmp_reg_rtx;
+
+  /* Loop label */
+
+  avr_asm_len ("0:", xop, plen, 0);
+
+  /* Load with post-increment */
+
+  switch (as)
+    {
+    default:
+      gcc_unreachable();
+
+    case ADDR_SPACE_GENERIC:
+
+      avr_asm_len ("ld %2,Z+", xop, plen, 1);
+      break;
+
+    case ADDR_SPACE_FLASH:
+
+      if (AVR_HAVE_LPMX)
+        avr_asm_len ("lpm %2,Z+", xop, plen, 1);
+      else
+        avr_asm_len ("lpm" CR_TAB
+                     "adiw r30,1", xop, plen, 2);
+      break;
+
+    case ADDR_SPACE_FLASH1:
+    case ADDR_SPACE_FLASH2:
+    case ADDR_SPACE_FLASH3:
+    case ADDR_SPACE_FLASH4:
+    case ADDR_SPACE_FLASH5:
+
+      if (AVR_HAVE_ELPMX)
+        avr_asm_len ("elpm %2,Z+", xop, plen, 1);
+      else
+        avr_asm_len ("elpm" CR_TAB
+                     "adiw r30,1", xop, plen, 2);
+      break;
+    }
+
+  /* Store with post-increment */
+
+  avr_asm_len ("st X+,%2", xop, plen, 1);
+
+  /* Decrement loop-counter and set Z-flag */
+
+  if (QImode == loop_mode)
+    {
+      avr_asm_len ("dec %1", xop, plen, 1);
+    }
+  else if (sbiw_p)
+    {
+      avr_asm_len ("sbiw %1,1", xop, plen, 1);
+    }
+  else
+    {
+      avr_asm_len ("subi %A1,1" CR_TAB
+                   "sbci %B1,0", xop, plen, 2);
+    }
+
+  /* Loop until zero */
+
+  return avr_asm_len ("brne 0b", xop, plen, 1);
+}
+
+
+
+/* Helper for __builtin_avr_delay_cycles */
+
+static rtx
+avr_mem_clobber (void)
+{
+  rtx mem = gen_rtx_MEM (BLKmode, gen_rtx_SCRATCH (Pmode));
+  MEM_VOLATILE_P (mem) = 1;
+  return mem;
+}
+
+static void
+avr_expand_delay_cycles (rtx operands0)
+{
+  unsigned HOST_WIDE_INT cycles = UINTVAL (operands0) & GET_MODE_MASK (SImode);
+  unsigned HOST_WIDE_INT cycles_used;
+  unsigned HOST_WIDE_INT loop_count;
+
+  if (IN_RANGE (cycles, 83886082, 0xFFFFFFFF))
+    {
+      loop_count = ((cycles - 9) / 6) + 1;
+      cycles_used = ((loop_count - 1) * 6) + 9;
+      emit_insn (gen_delay_cycles_4 (gen_int_mode (loop_count, SImode),
+                                     avr_mem_clobber()));
+      cycles -= cycles_used;
+    }
+
+  if (IN_RANGE (cycles, 262145, 83886081))
+    {
+      loop_count = ((cycles - 7) / 5) + 1;
+      if (loop_count > 0xFFFFFF)
+        loop_count = 0xFFFFFF;
+      cycles_used = ((loop_count - 1) * 5) + 7;
+      emit_insn (gen_delay_cycles_3 (gen_int_mode (loop_count, SImode),
+                                     avr_mem_clobber()));
+      cycles -= cycles_used;
+    }
+
+  if (IN_RANGE (cycles, 768, 262144))
+    {
+      loop_count = ((cycles - 5) / 4) + 1;
+      if (loop_count > 0xFFFF)
+        loop_count = 0xFFFF;
+      cycles_used = ((loop_count - 1) * 4) + 5;
+      emit_insn (gen_delay_cycles_2 (gen_int_mode (loop_count, HImode),
+                                     avr_mem_clobber()));
+      cycles -= cycles_used;
+    }
+
+  if (IN_RANGE (cycles, 6, 767))
+    {
+      loop_count = cycles / 3;
+      if (loop_count > 255)
+        loop_count = 255;
+      cycles_used = loop_count * 3;
+      emit_insn (gen_delay_cycles_1 (gen_int_mode (loop_count, QImode),
+                                     avr_mem_clobber()));
+      cycles -= cycles_used;
+    }
+
+  while (cycles >= 2)
+    {
+      emit_insn (gen_nopv (GEN_INT (2)));
+      cycles -= 2;
+    }
+
+  if (cycles == 1)
+    {
+      emit_insn (gen_nopv (GEN_INT (1)));
+      cycles--;
+    }
+}
+
+
+static void
+avr_expand_nops (rtx operands0)
+{
+  unsigned HOST_WIDE_INT n_nops = UINTVAL (operands0) & GET_MODE_MASK (HImode);
+
+  while (n_nops--)
+    {
+      emit_insn (gen_nopv (const1_rtx));
+    }
+}
+
+
+/* Compute the image of x under f, i.e. perform   x --> f(x)    */
+
+static int
+avr_map (unsigned int f, int x)
+{
+  return x < 8 ? (f >> (4 * x)) & 0xf : 0;
+}
+
+
+/* Return some metrics of map A.  */
+
+enum
+  {
+    /* Number of fixed points in { 0 ... 7 } */
+    MAP_FIXED_0_7,
+
+    /* Size of preimage of non-fixed points in { 0 ... 7 } */
+    MAP_NONFIXED_0_7,
+
+    /* Mask representing the fixed points in { 0 ... 7 } */
+    MAP_MASK_FIXED_0_7,
+
+    /* Size of the preimage of { 0 ... 7 } */
+    MAP_PREIMAGE_0_7,
+
+    /* Mask that represents the preimage of { f } */
+    MAP_MASK_PREIMAGE_F
+  };
+
+static unsigned
+avr_map_metric (unsigned int a, int mode)
+{
+  unsigned metric = 0;
+
+  for (unsigned i = 0; i < 8; i++)
+    {
+      unsigned ai = avr_map (a, i);
+
+      if (mode == MAP_FIXED_0_7)
+        metric += ai == i;
+      else if (mode == MAP_NONFIXED_0_7)
+        metric += ai < 8 && ai != i;
+      else if (mode == MAP_MASK_FIXED_0_7)
+        metric |= ((unsigned) (ai == i)) << i;
+      else if (mode == MAP_PREIMAGE_0_7)
+        metric += ai < 8;
+      else if (mode == MAP_MASK_PREIMAGE_F)
+        metric |= ((unsigned) (ai == 0xf)) << i;
+      else
+        gcc_unreachable();
+    }
+
+  return metric;
+}
+
+
+/* Return true if IVAL has a 0xf in its hexadecimal representation
+   and false, otherwise.  Only nibbles 0..7 are taken into account.
+   Used as constraint helper for C0f and Cxf.  */
+
+bool
+avr_has_nibble_0xf (rtx ival)
+{
+  unsigned int map = UINTVAL (ival) & GET_MODE_MASK (SImode);
+  return avr_map_metric (map, MAP_MASK_PREIMAGE_F) != 0;
+}
+
+
+/* We have a set of bits that are mapped by a function F.
+   Try to decompose F by means of a second function G so that
+
+      F = F o G^-1 o G
+
+   and
+
+      cost (F o G^-1) + cost (G)  <  cost (F)
+
+   Example:  Suppose builtin insert_bits supplies us with the map
+   F = 0x3210ffff.  Instead of doing 4 bit insertions to get the high
+   nibble of the result, we can just as well rotate the bits before inserting
+   them and use the map 0x7654ffff which is cheaper than the original map.
+   For this example G = G^-1 = 0x32107654 and F o G^-1 = 0x7654ffff.  */
+
+typedef struct
+{
+  /* tree code of binary function G */
+  enum tree_code code;
+
+  /* The constant second argument of G */
+  int arg;
+
+  /* G^-1, the inverse of G (*, arg) */
+  unsigned ginv;
+
+  /* The cost of applying G (*, arg) */
+  int cost;
+
+  /* The composition F o G^-1 (*, arg) for some function F */
+  unsigned int map;
+
+  /* For debug purpose only */
+  const char *str;
+} avr_map_op_t;
+
+static const avr_map_op_t avr_map_op[] =
+  {
+    { LROTATE_EXPR, 0, 0x76543210, 0, 0, "id" },
+    { LROTATE_EXPR, 1, 0x07654321, 2, 0, "<<<" },
+    { LROTATE_EXPR, 2, 0x10765432, 4, 0, "<<<" },
+    { LROTATE_EXPR, 3, 0x21076543, 4, 0, "<<<" },
+    { LROTATE_EXPR, 4, 0x32107654, 1, 0, "<<<" },
+    { LROTATE_EXPR, 5, 0x43210765, 3, 0, "<<<" },
+    { LROTATE_EXPR, 6, 0x54321076, 5, 0, "<<<" },
+    { LROTATE_EXPR, 7, 0x65432107, 3, 0, "<<<" },
+    { RSHIFT_EXPR, 1, 0x6543210c, 1, 0, ">>" },
+    { RSHIFT_EXPR, 1, 0x7543210c, 1, 0, ">>" },
+    { RSHIFT_EXPR, 2, 0x543210cc, 2, 0, ">>" },
+    { RSHIFT_EXPR, 2, 0x643210cc, 2, 0, ">>" },
+    { RSHIFT_EXPR, 2, 0x743210cc, 2, 0, ">>" },
+    { LSHIFT_EXPR, 1, 0xc7654321, 1, 0, "<<" },
+    { LSHIFT_EXPR, 2, 0xcc765432, 2, 0, "<<" }
+  };
+
+
+/* Try to decompose F as F = (F o G^-1) o G as described above.
+   The result is a struct representing F o G^-1 and G.
+   If result.cost < 0 then such a decomposition does not exist.  */
+
+static avr_map_op_t
+avr_map_decompose (unsigned int f, const avr_map_op_t *g, bool val_const_p)
+{
+  bool val_used_p = avr_map_metric (f, MAP_MASK_PREIMAGE_F) != 0;
+  avr_map_op_t f_ginv = *g;
+  unsigned int ginv = g->ginv;
+
+  f_ginv.cost = -1;
+
+  /* Step 1:  Computing F o G^-1  */
+
+  for (int i = 7; i >= 0; i--)
+    {
+      int x = avr_map (f, i);
+
+      if (x <= 7)
+        {
+          x = avr_map (ginv, x);
+
+          /* The bit is no element of the image of G: no avail (cost = -1)  */
+
+          if (x > 7)
+            return f_ginv;
+        }
+
+      f_ginv.map = (f_ginv.map << 4) + x;
+    }
+
+  /* Step 2:  Compute the cost of the operations.
+     The overall cost of doing an operation prior to the insertion is
+      the cost of the insertion plus the cost of the operation.  */
+
+  /* Step 2a:  Compute cost of F o G^-1  */
+
+  if (avr_map_metric (f_ginv.map, MAP_NONFIXED_0_7) == 0)
+    /* The mapping consists only of fixed points and can be folded
+       to AND/OR logic in the remainder.  Reasonable cost is 3. */
+    f_ginv.cost = 2 + (val_used_p && !val_const_p);
+  else
+    {
+      rtx xop[4];
+
+      /* Get the cost of the insn by calling the output worker with some
+         fake values.  Mimic effect of reloading xop[3]: Unused operands
+         are mapped to 0 and used operands are reloaded to xop[0].  */
+
+      xop[0] = all_regs_rtx[24];
+      xop[1] = gen_int_mode (f_ginv.map, SImode);
+      xop[2] = all_regs_rtx[25];
+      xop[3] = val_used_p ? xop[0] : const0_rtx;
+
+      avr_out_insert_bits (xop, &f_ginv.cost);
+
+      f_ginv.cost += val_const_p && val_used_p ? 1 : 0;
+    }
+
+  /* Step 2b:  Add cost of G  */
+
+  f_ginv.cost += g->cost;
+
+  if (avr_log.builtin)
+    avr_edump (" %s%d=%d", g->str, g->arg, f_ginv.cost);
+
+  return f_ginv;
+}
+
+
+/* Insert bits from XOP[1] into XOP[0] according to MAP.
+   XOP[0] and XOP[1] don't overlap.
+   If FIXP_P = true:  Move all bits according to MAP using BLD/BST sequences.
+   If FIXP_P = false: Just move the bit if its position in the destination
+   is different to its source position.  */
+
+static void
+avr_move_bits (rtx *xop, unsigned int map, bool fixp_p, int *plen)
+{
+  /* T-flag contains this bit of the source, i.e. of XOP[1]  */
+  int t_bit_src = -1;
+
+  /* We order the operations according to the requested source bit b.  */
+
+  for (int b = 0; b < 8; b++)
+    for (int bit_dest = 0; bit_dest < 8; bit_dest++)
+      {
+        int bit_src = avr_map (map, bit_dest);
+
+        if (b != bit_src
+            || bit_src >= 8
+            /* Same position: No need to copy as requested by FIXP_P.  */
+            || (bit_dest == bit_src && !fixp_p))
+          continue;
+
+        if (t_bit_src != bit_src)
+          {
+            /* Source bit is not yet in T: Store it to T.  */
+
+            t_bit_src = bit_src;
+
+            xop[3] = GEN_INT (bit_src);
+            avr_asm_len ("bst %T1%T3", xop, plen, 1);
+          }
+
+        /* Load destination bit with T.  */
+
+        xop[3] = GEN_INT (bit_dest);
+        avr_asm_len ("bld %T0%T3", xop, plen, 1);
+      }
+}
+
+
+/* PLEN == 0: Print assembler code for `insert_bits'.
+   PLEN != 0: Compute code length in bytes.
+
+   OP[0]:  Result
+   OP[1]:  The mapping composed of nibbles. If nibble no. N is
+           0:   Bit N of result is copied from bit OP[2].0
+           ...  ...
+           7:   Bit N of result is copied from bit OP[2].7
+           0xf: Bit N of result is copied from bit OP[3].N
+   OP[2]:  Bits to be inserted
+   OP[3]:  Target value  */
+
+const char*
+avr_out_insert_bits (rtx *op, int *plen)
+{
+  unsigned int map = UINTVAL (op[1]) & GET_MODE_MASK (SImode);
+  unsigned mask_fixed;
+  bool fixp_p = true;
+  rtx xop[4];
+
+  xop[0] = op[0];
+  xop[1] = op[2];
+  xop[2] = op[3];
+
+  gcc_assert (REG_P (xop[2]) || CONST_INT_P (xop[2]));
+
+  if (plen)
+    *plen = 0;
+  else if (flag_print_asm_name)
+    fprintf (asm_out_file, ASM_COMMENT_START "map = 0x%08x\n", map);
+
+  /* If MAP has fixed points it might be better to initialize the result
+     with the bits to be inserted instead of moving all bits by hand.  */
+
+  mask_fixed = avr_map_metric (map, MAP_MASK_FIXED_0_7);
+
+  if (REGNO (xop[0]) == REGNO (xop[1]))
+    {
+      /* Avoid early-clobber conflicts */
+
+      avr_asm_len ("mov __tmp_reg__,%1", xop, plen, 1);
+      xop[1] = tmp_reg_rtx;
+      fixp_p = false;
+    }
+
+  if (avr_map_metric (map, MAP_MASK_PREIMAGE_F))
+    {
+      /* XOP[2] is used and reloaded to XOP[0] already */
+
+      int n_fix = 0, n_nofix = 0;
+
+      gcc_assert (REG_P (xop[2]));
+
+      /* Get the code size of the bit insertions; once with all bits
+         moved and once with fixed points omitted.  */
+
+      avr_move_bits (xop, map, true, &n_fix);
+      avr_move_bits (xop, map, false, &n_nofix);
+
+      if (fixp_p && n_fix - n_nofix > 3)
+        {
+          xop[3] = gen_int_mode (~mask_fixed, QImode);
+
+          avr_asm_len ("eor %0,%1"   CR_TAB
+                       "andi %0,%3"  CR_TAB
+                       "eor %0,%1", xop, plen, 3);
+          fixp_p = false;
+        }
+    }
+  else
+    {
+      /* XOP[2] is unused */
+
+      if (fixp_p && mask_fixed)
+        {
+          avr_asm_len ("mov %0,%1", xop, plen, 1);
+          fixp_p = false;
+        }
+    }
+
+  /* Move/insert remaining bits.  */
+
+  avr_move_bits (xop, map, fixp_p, plen);
+
+  return "";
+}
+
+
+/* IDs for all the AVR builtins.  */
+
+enum avr_builtin_id
+  {
+#define DEF_BUILTIN(NAME, N_ARGS, TYPE, CODE, LIBNAME)  \
+    AVR_BUILTIN_ ## NAME,
+#include "builtins.def"
+#undef DEF_BUILTIN
+
+    AVR_BUILTIN_COUNT
+  };
+
+struct GTY(()) avr_builtin_description
+{
+  enum insn_code icode;
+  int n_args;
+  tree fndecl;
+};
+
+
+/* Notice that avr_bdesc[] and avr_builtin_id are initialized in such a way
+   that a built-in's ID can be used to access the built-in by means of
+   avr_bdesc[ID]  */
+
+static GTY(()) struct avr_builtin_description
+avr_bdesc[AVR_BUILTIN_COUNT] =
+  {
+#define DEF_BUILTIN(NAME, N_ARGS, TYPE, ICODE, LIBNAME)         \
+    { (enum insn_code) CODE_FOR_ ## ICODE, N_ARGS, NULL_TREE },
+#include "builtins.def"
+#undef DEF_BUILTIN
+  };
+
+
+/* Implement `TARGET_BUILTIN_DECL'.  */
+
+static tree
+avr_builtin_decl (unsigned id, bool initialize_p ATTRIBUTE_UNUSED)
+{
+  if (id < AVR_BUILTIN_COUNT)
+    return avr_bdesc[id].fndecl;
+
+  return error_mark_node;
+}
+
+
+static void
+avr_init_builtin_int24 (void)
+{
+  tree int24_type  = make_signed_type (GET_MODE_BITSIZE (PSImode));
+  tree uint24_type = make_unsigned_type (GET_MODE_BITSIZE (PSImode));
+
+  lang_hooks.types.register_builtin_type (int24_type, "__int24");
+  lang_hooks.types.register_builtin_type (uint24_type, "__uint24");
+}
+
+
+/* Implement `TARGET_INIT_BUILTINS' */
+/* Set up all builtin functions for this target.  */
+
+static void
+avr_init_builtins (void)
+{
+  tree void_ftype_void
+    = build_function_type_list (void_type_node, NULL_TREE);
+  tree uchar_ftype_uchar
+    = build_function_type_list (unsigned_char_type_node,
+                                unsigned_char_type_node,
+                                NULL_TREE);
+  tree uint_ftype_uchar_uchar
+    = build_function_type_list (unsigned_type_node,
+                                unsigned_char_type_node,
+                                unsigned_char_type_node,
+                                NULL_TREE);
+  tree int_ftype_char_char
+    = build_function_type_list (integer_type_node,
+                                char_type_node,
+                                char_type_node,
+                                NULL_TREE);
+  tree int_ftype_char_uchar
+    = build_function_type_list (integer_type_node,
+                                char_type_node,
+                                unsigned_char_type_node,
+                                NULL_TREE);
+  tree void_ftype_ulong
+    = build_function_type_list (void_type_node,
+                                long_unsigned_type_node,
+                                NULL_TREE);
+
+  tree uchar_ftype_ulong_uchar_uchar
+    = build_function_type_list (unsigned_char_type_node,
+                                long_unsigned_type_node,
+                                unsigned_char_type_node,
+                                unsigned_char_type_node,
+                                NULL_TREE);
+
+  tree const_memx_void_node
+    = build_qualified_type (void_type_node,
+                            TYPE_QUAL_CONST
+                            | ENCODE_QUAL_ADDR_SPACE (ADDR_SPACE_MEMX));
+
+  tree const_memx_ptr_type_node
+    = build_pointer_type_for_mode (const_memx_void_node, PSImode, false);
+
+  tree char_ftype_const_memx_ptr
+    = build_function_type_list (char_type_node,
+                                const_memx_ptr_type_node,
+                                NULL);
+
+#define ITYP(T)                                                         \
+  lang_hooks.types.type_for_size (TYPE_PRECISION (T), TYPE_UNSIGNED (T))
+
+#define FX_FTYPE_FX(fx)                                                 \
+  tree fx##r_ftype_##fx##r                                              \
+    = build_function_type_list (node_##fx##r, node_##fx##r, NULL);      \
+  tree fx##k_ftype_##fx##k                                              \
+    = build_function_type_list (node_##fx##k, node_##fx##k, NULL)
+
+#define FX_FTYPE_FX_INT(fx)                                             \
+  tree fx##r_ftype_##fx##r_int                                          \
+    = build_function_type_list (node_##fx##r, node_##fx##r,             \
+                                integer_type_node, NULL);               \
+  tree fx##k_ftype_##fx##k_int                                          \
+    = build_function_type_list (node_##fx##k, node_##fx##k,             \
+                                integer_type_node, NULL)
+
+#define INT_FTYPE_FX(fx)                                                \
+  tree int_ftype_##fx##r                                                \
+    = build_function_type_list (integer_type_node, node_##fx##r, NULL); \
+  tree int_ftype_##fx##k                                                \
+    = build_function_type_list (integer_type_node, node_##fx##k, NULL)
+
+#define INTX_FTYPE_FX(fx)                                               \
+  tree int##fx##r_ftype_##fx##r                                         \
+    = build_function_type_list (ITYP (node_##fx##r), node_##fx##r, NULL); \
+  tree int##fx##k_ftype_##fx##k                                         \
+    = build_function_type_list (ITYP (node_##fx##k), node_##fx##k, NULL)
+
+#define FX_FTYPE_INTX(fx)                                               \
+  tree fx##r_ftype_int##fx##r                                           \
+    = build_function_type_list (node_##fx##r, ITYP (node_##fx##r), NULL); \
+  tree fx##k_ftype_int##fx##k                                           \
+    = build_function_type_list (node_##fx##k, ITYP (node_##fx##k), NULL)
+
+  tree node_hr = short_fract_type_node;
+  tree node_nr = fract_type_node;
+  tree node_lr = long_fract_type_node;
+  tree node_llr = long_long_fract_type_node;
+
+  tree node_uhr = unsigned_short_fract_type_node;
+  tree node_unr = unsigned_fract_type_node;
+  tree node_ulr = unsigned_long_fract_type_node;
+  tree node_ullr = unsigned_long_long_fract_type_node;
+
+  tree node_hk = short_accum_type_node;
+  tree node_nk = accum_type_node;
+  tree node_lk = long_accum_type_node;
+  tree node_llk = long_long_accum_type_node;
+
+  tree node_uhk = unsigned_short_accum_type_node;
+  tree node_unk = unsigned_accum_type_node;
+  tree node_ulk = unsigned_long_accum_type_node;
+  tree node_ullk = unsigned_long_long_accum_type_node;
+
+
+  /* For absfx builtins.  */
+
+  FX_FTYPE_FX (h);
+  FX_FTYPE_FX (n);
+  FX_FTYPE_FX (l);
+  FX_FTYPE_FX (ll);
+
+  /* For roundfx builtins.  */
+
+  FX_FTYPE_FX_INT (h);
+  FX_FTYPE_FX_INT (n);
+  FX_FTYPE_FX_INT (l);
+  FX_FTYPE_FX_INT (ll);
+
+  FX_FTYPE_FX_INT (uh);
+  FX_FTYPE_FX_INT (un);
+  FX_FTYPE_FX_INT (ul);
+  FX_FTYPE_FX_INT (ull);
+
+  /* For countlsfx builtins.  */
+
+  INT_FTYPE_FX (h);
+  INT_FTYPE_FX (n);
+  INT_FTYPE_FX (l);
+  INT_FTYPE_FX (ll);
+
+  INT_FTYPE_FX (uh);
+  INT_FTYPE_FX (un);
+  INT_FTYPE_FX (ul);
+  INT_FTYPE_FX (ull);
+
+  /* For bitsfx builtins.  */
+
+  INTX_FTYPE_FX (h);
+  INTX_FTYPE_FX (n);
+  INTX_FTYPE_FX (l);
+  INTX_FTYPE_FX (ll);
+
+  INTX_FTYPE_FX (uh);
+  INTX_FTYPE_FX (un);
+  INTX_FTYPE_FX (ul);
+  INTX_FTYPE_FX (ull);
+
+  /* For fxbits builtins.  */
+
+  FX_FTYPE_INTX (h);
+  FX_FTYPE_INTX (n);
+  FX_FTYPE_INTX (l);
+  FX_FTYPE_INTX (ll);
+
+  FX_FTYPE_INTX (uh);
+  FX_FTYPE_INTX (un);
+  FX_FTYPE_INTX (ul);
+  FX_FTYPE_INTX (ull);
+
+
+#define DEF_BUILTIN(NAME, N_ARGS, TYPE, CODE, LIBNAME)                  \
+  {                                                                     \
+    int id = AVR_BUILTIN_ ## NAME;                                      \
+    const char *Name = "__builtin_avr_" #NAME;                          \
+    char *name = (char*) alloca (1 + strlen (Name));                    \
+                                                                        \
+    gcc_assert (id < AVR_BUILTIN_COUNT);                                \
+    avr_bdesc[id].fndecl                                                \
+      = add_builtin_function (avr_tolower (name, Name), TYPE, id,       \
+                              BUILT_IN_MD, LIBNAME, NULL_TREE);         \
+  }
+#include "builtins.def"
+#undef DEF_BUILTIN
+
+  avr_init_builtin_int24 ();
+}
+
+
+/* Subroutine of avr_expand_builtin to expand vanilla builtins
+   with non-void result and 1 ... 3 arguments.  */
+
+static rtx
+avr_default_expand_builtin (enum insn_code icode, tree exp, rtx target)
+{
+  rtx pat, xop[3];
+  int n_args = call_expr_nargs (exp);
+  machine_mode tmode = insn_data[icode].operand[0].mode;
+
+  gcc_assert (n_args >= 1 && n_args <= 3);
+
+  if (target == NULL_RTX
+      || GET_MODE (target) != tmode
+      || !insn_data[icode].operand[0].predicate (target, tmode))
+    {
+      target = gen_reg_rtx (tmode);
+    }
+
+  for (int n = 0; n < n_args; n++)
+    {
+      tree arg = CALL_EXPR_ARG (exp, n);
+      rtx op = expand_expr (arg, NULL_RTX, VOIDmode, EXPAND_NORMAL);
+      machine_mode opmode = GET_MODE (op);
+      machine_mode mode = insn_data[icode].operand[n + 1].mode;
+
+      if ((opmode == SImode || opmode == VOIDmode) && mode == HImode)
+        {
+          opmode = HImode;
+          op = gen_lowpart (HImode, op);
+        }
+
+      /* In case the insn wants input operands in modes different from
+         the result, abort.  */
+
+      gcc_assert (opmode == mode || opmode == VOIDmode);
+
+      if (!insn_data[icode].operand[n + 1].predicate (op, mode))
+        op = copy_to_mode_reg (mode, op);
+
+      xop[n] = op;
+    }
+
+  switch (n_args)
+    {
+    case 1: pat = GEN_FCN (icode) (target, xop[0]); break;
+    case 2: pat = GEN_FCN (icode) (target, xop[0], xop[1]); break;
+    case 3: pat = GEN_FCN (icode) (target, xop[0], xop[1], xop[2]); break;
+
+    default:
+      gcc_unreachable();
+    }
+
+  if (pat == NULL_RTX)
+    return NULL_RTX;
+
+  emit_insn (pat);
+
+  return target;
+}
+
+
+/* Implement `TARGET_EXPAND_BUILTIN'.  */
+/* Expand an expression EXP that calls a built-in function,
+   with result going to TARGET if that's convenient
+   (and in mode MODE if that's convenient).
+   SUBTARGET may be used as the target for computing one of EXP's operands.
+   IGNORE is nonzero if the value is to be ignored.  */
+
+static rtx
+avr_expand_builtin (tree exp, rtx target,
+                    rtx subtarget ATTRIBUTE_UNUSED,
+                    machine_mode mode ATTRIBUTE_UNUSED,
+                    int ignore)
+{
+  tree fndecl = TREE_OPERAND (CALL_EXPR_FN (exp), 0);
+  const char *bname = IDENTIFIER_POINTER (DECL_NAME (fndecl));
+  unsigned int id = DECL_MD_FUNCTION_CODE (fndecl);
+  const struct avr_builtin_description *d = &avr_bdesc[id];
+  tree arg0;
+  rtx op0;
+
+  gcc_assert (id < AVR_BUILTIN_COUNT);
+
+  switch (id)
+    {
+    case AVR_BUILTIN_NOP:
+      emit_insn (gen_nopv (GEN_INT (1)));
+      return 0;
+
+    case AVR_BUILTIN_DELAY_CYCLES:
+      {
+        arg0 = CALL_EXPR_ARG (exp, 0);
+        op0 = expand_expr (arg0, NULL_RTX, VOIDmode, EXPAND_NORMAL);
+
+        if (!CONST_INT_P (op0))
+          error ("%s expects a compile time integer constant", bname);
+        else
+          avr_expand_delay_cycles (op0);
+
+        return NULL_RTX;
+      }
+
+    case AVR_BUILTIN_NOPS:
+      {
+        arg0 = CALL_EXPR_ARG (exp, 0);
+        op0 = expand_expr (arg0, NULL_RTX, VOIDmode, EXPAND_NORMAL);
+
+        if (!CONST_INT_P (op0))
+          error ("%s expects a compile time integer constant", bname);
+        else
+          avr_expand_nops (op0);
+
+        return NULL_RTX;
+      }
+
+    case AVR_BUILTIN_INSERT_BITS:
+      {
+        arg0 = CALL_EXPR_ARG (exp, 0);
+        op0 = expand_expr (arg0, NULL_RTX, VOIDmode, EXPAND_NORMAL);
+
+        if (!CONST_INT_P (op0))
+          {
+            error ("%s expects a compile time long integer constant"
+                   " as first argument", bname);
+            return target;
+          }
+
+        break;
+      }
+
+    case AVR_BUILTIN_ROUNDHR:   case AVR_BUILTIN_ROUNDUHR:
+    case AVR_BUILTIN_ROUNDR:    case AVR_BUILTIN_ROUNDUR:
+    case AVR_BUILTIN_ROUNDLR:   case AVR_BUILTIN_ROUNDULR:
+    case AVR_BUILTIN_ROUNDLLR:  case AVR_BUILTIN_ROUNDULLR:
+
+    case AVR_BUILTIN_ROUNDHK:   case AVR_BUILTIN_ROUNDUHK:
+    case AVR_BUILTIN_ROUNDK:    case AVR_BUILTIN_ROUNDUK:
+    case AVR_BUILTIN_ROUNDLK:   case AVR_BUILTIN_ROUNDULK:
+    case AVR_BUILTIN_ROUNDLLK:  case AVR_BUILTIN_ROUNDULLK:
+
+      /* Warn about odd rounding.  Rounding points >= FBIT will have
+         no effect.  */
+
+      if (TREE_CODE (CALL_EXPR_ARG (exp, 1)) != INTEGER_CST)
+        break;
+
+      int rbit = (int) TREE_INT_CST_LOW (CALL_EXPR_ARG (exp, 1));
+
+      if (rbit >= (int) GET_MODE_FBIT (mode))
+        {
+          warning (OPT_Wextra, "rounding to %d bits has no effect for "
+                   "fixed-point value with %d fractional bits",
+                   rbit, GET_MODE_FBIT (mode));
+
+          return expand_expr (CALL_EXPR_ARG (exp, 0), NULL_RTX, mode,
+                              EXPAND_NORMAL);
+        }
+      else if (rbit <= - (int) GET_MODE_IBIT (mode))
+        {
+          warning (0, "rounding result will always be 0");
+          return CONST0_RTX (mode);
+        }
+
+      /* The rounding points RP satisfies now:  -IBIT < RP < FBIT.
+
+         TR 18037 only specifies results for  RP > 0.  However, the
+         remaining cases of  -IBIT < RP <= 0  can easily be supported
+         without any additional overhead.  */
+
+      break; /* round */
+    }
+
+  /* No fold found and no insn:  Call support function from libgcc.  */
+
+  if (d->icode == CODE_FOR_nothing
+      && DECL_ASSEMBLER_NAME (get_callee_fndecl (exp)) != NULL_TREE)
+    {
+      return expand_call (exp, target, ignore);
+    }
+
+  /* No special treatment needed: vanilla expand.  */
+
+  gcc_assert (d->icode != CODE_FOR_nothing);
+  gcc_assert (d->n_args == call_expr_nargs (exp));
+
+  if (d->n_args == 0)
+    {
+      emit_insn ((GEN_FCN (d->icode)) (target));
+      return NULL_RTX;
+    }
+
+  return avr_default_expand_builtin (d->icode, exp, target);
+}
+
+
+/* Helper for `avr_fold_builtin' that folds  absfx (FIXED_CST).  */
+
+static tree
+avr_fold_absfx (tree tval)
+{
+  if (FIXED_CST != TREE_CODE (tval))
+    return NULL_TREE;
+
+  /* Our fixed-points have no padding:  Use double_int payload directly.  */
+
+  FIXED_VALUE_TYPE fval = TREE_FIXED_CST (tval);
+  unsigned int bits = GET_MODE_BITSIZE (fval.mode);
+  double_int ival = fval.data.sext (bits);
+
+  if (!ival.is_negative())
+    return tval;
+
+  /* ISO/IEC TR 18037, 7.18a.6.2:  The absfx functions are saturating.  */
+
+  fval.data = (ival == double_int::min_value (bits, false).sext (bits))
+    ? double_int::max_value (bits, false)
+    : -ival;
+
+  return build_fixed (TREE_TYPE (tval), fval);
+}
+
+
+/* Implement `TARGET_FOLD_BUILTIN'.  */
+
+static tree
+avr_fold_builtin (tree fndecl, int n_args ATTRIBUTE_UNUSED, tree *arg,
+                  bool ignore ATTRIBUTE_UNUSED)
+{
+  unsigned int fcode = DECL_MD_FUNCTION_CODE (fndecl);
+  tree val_type = TREE_TYPE (TREE_TYPE (fndecl));
+
+  if (!optimize)
+    return NULL_TREE;
+
+  switch (fcode)
+    {
+    default:
+      break;
+
+    case AVR_BUILTIN_SWAP:
+      {
+        return fold_build2 (LROTATE_EXPR, val_type, arg[0],
+                            build_int_cst (val_type, 4));
+      }
+
+    case AVR_BUILTIN_ABSHR:
+    case AVR_BUILTIN_ABSR:
+    case AVR_BUILTIN_ABSLR:
+    case AVR_BUILTIN_ABSLLR:
+
+    case AVR_BUILTIN_ABSHK:
+    case AVR_BUILTIN_ABSK:
+    case AVR_BUILTIN_ABSLK:
+    case AVR_BUILTIN_ABSLLK:
+      /* GCC is not good with folding ABS for fixed-point.  Do it by hand.  */
+
+      return avr_fold_absfx (arg[0]);
+
+    case AVR_BUILTIN_BITSHR:    case AVR_BUILTIN_HRBITS:
+    case AVR_BUILTIN_BITSHK:    case AVR_BUILTIN_HKBITS:
+    case AVR_BUILTIN_BITSUHR:   case AVR_BUILTIN_UHRBITS:
+    case AVR_BUILTIN_BITSUHK:   case AVR_BUILTIN_UHKBITS:
+
+    case AVR_BUILTIN_BITSR:     case AVR_BUILTIN_RBITS:
+    case AVR_BUILTIN_BITSK:     case AVR_BUILTIN_KBITS:
+    case AVR_BUILTIN_BITSUR:    case AVR_BUILTIN_URBITS:
+    case AVR_BUILTIN_BITSUK:    case AVR_BUILTIN_UKBITS:
+
+    case AVR_BUILTIN_BITSLR:    case AVR_BUILTIN_LRBITS:
+    case AVR_BUILTIN_BITSLK:    case AVR_BUILTIN_LKBITS:
+    case AVR_BUILTIN_BITSULR:   case AVR_BUILTIN_ULRBITS:
+    case AVR_BUILTIN_BITSULK:   case AVR_BUILTIN_ULKBITS:
+
+    case AVR_BUILTIN_BITSLLR:   case AVR_BUILTIN_LLRBITS:
+    case AVR_BUILTIN_BITSLLK:   case AVR_BUILTIN_LLKBITS:
+    case AVR_BUILTIN_BITSULLR:  case AVR_BUILTIN_ULLRBITS:
+    case AVR_BUILTIN_BITSULLK:  case AVR_BUILTIN_ULLKBITS:
+
+      gcc_assert (TYPE_PRECISION (val_type)
+                  == TYPE_PRECISION (TREE_TYPE (arg[0])));
+
+      return build1 (VIEW_CONVERT_EXPR, val_type, arg[0]);
+
+    case AVR_BUILTIN_INSERT_BITS:
+      {
+        tree tbits = arg[1];
+        tree tval = arg[2];
+        tree tmap;
+        tree map_type = TREE_VALUE (TYPE_ARG_TYPES (TREE_TYPE (fndecl)));
+        unsigned int map;
+        bool changed = false;
+        avr_map_op_t best_g;
+
+        if (TREE_CODE (arg[0]) != INTEGER_CST)
+          {
+            /* No constant as first argument: Don't fold this and run into
+               error in avr_expand_builtin.  */
+
+            break;
+          }
+
+        tmap = wide_int_to_tree (map_type, wi::to_wide (arg[0]));
+        map = TREE_INT_CST_LOW (tmap);
+
+        if (TREE_CODE (tval) != INTEGER_CST
+	    && avr_map_metric (map, MAP_MASK_PREIMAGE_F) == 0)
+          {
+            /* There are no F in the map, i.e. 3rd operand is unused.
+               Replace that argument with some constant to render
+               respective input unused.  */
+
+            tval = build_int_cst (val_type, 0);
+            changed = true;
+          }
+
+        if (TREE_CODE (tbits) != INTEGER_CST
+	    && avr_map_metric (map, MAP_PREIMAGE_0_7) == 0)
+          {
+            /* Similar for the bits to be inserted. If they are unused,
+               we can just as well pass 0.  */
+
+            tbits = build_int_cst (val_type, 0);
+          }
+
+        if (TREE_CODE (tbits) == INTEGER_CST)
+          {
+            /* Inserting bits known at compile time is easy and can be
+               performed by AND and OR with appropriate masks.  */
+
+            int bits = TREE_INT_CST_LOW (tbits);
+            int mask_ior = 0, mask_and = 0xff;
+
+            for (size_t i = 0; i < 8; i++)
+              {
+                int mi = avr_map (map, i);
+
+                if (mi < 8)
+                  {
+                    if (bits & (1 << mi))     mask_ior |=  (1 << i);
+                    else                      mask_and &= ~(1 << i);
+                  }
+              }
+
+            tval = fold_build2 (BIT_IOR_EXPR, val_type, tval,
+                                build_int_cst (val_type, mask_ior));
+            return fold_build2 (BIT_AND_EXPR, val_type, tval,
+                                build_int_cst (val_type, mask_and));
+          }
+
+        if (changed)
+          return build_call_expr (fndecl, 3, tmap, tbits, tval);
+
+        /* If bits don't change their position we can use vanilla logic
+           to merge the two arguments.  */
+
+	if (avr_map_metric (map, MAP_NONFIXED_0_7) == 0)
+          {
+            int mask_f = avr_map_metric (map, MAP_MASK_PREIMAGE_F);
+            tree tres, tmask = build_int_cst (val_type, mask_f ^ 0xff);
+
+            tres = fold_build2 (BIT_XOR_EXPR, val_type, tbits, tval);
+            tres = fold_build2 (BIT_AND_EXPR, val_type, tres, tmask);
+            return fold_build2 (BIT_XOR_EXPR, val_type, tres, tval);
+          }
+
+        /* Try to decomposing map to reduce overall cost.  */
+
+        if (avr_log.builtin)
+          avr_edump ("\n%?: %x\n%?: ROL cost: ", map);
+
+        best_g = avr_map_op[0];
+        best_g.cost = 1000;
+
+        for (size_t i = 0; i < ARRAY_SIZE (avr_map_op); i++)
+          {
+            avr_map_op_t g
+              = avr_map_decompose (map, avr_map_op + i,
+                                   TREE_CODE (tval) == INTEGER_CST);
+
+            if (g.cost >= 0 && g.cost < best_g.cost)
+              best_g = g;
+          }
+
+        if (avr_log.builtin)
+          avr_edump ("\n");
+
+        if (best_g.arg == 0)
+          /* No optimization found */
+          break;
+
+        /* Apply operation G to the 2nd argument.  */
+
+        if (avr_log.builtin)
+          avr_edump ("%?: using OP(%s%d, %x) cost %d\n",
+                     best_g.str, best_g.arg, best_g.map, best_g.cost);
+
+        /* Do right-shifts arithmetically: They copy the MSB instead of
+           shifting in a non-usable value (0) as with logic right-shift.  */
+
+        tbits = fold_convert (signed_char_type_node, tbits);
+        tbits = fold_build2 (best_g.code, signed_char_type_node, tbits,
+                             build_int_cst (val_type, best_g.arg));
+        tbits = fold_convert (val_type, tbits);
+
+        /* Use map o G^-1 instead of original map to undo the effect of G.  */
+
+        tmap = wide_int_to_tree (map_type, best_g.map);
+
+        return build_call_expr (fndecl, 3, tmap, tbits, tval);
+      } /* AVR_BUILTIN_INSERT_BITS */
+    }
+
+  return NULL_TREE;
+}
+
+
+/* Worker function for `FLOAT_LIB_COMPARE_RETURNS_BOOL'.  */
+
+bool
+avr_float_lib_compare_returns_bool (machine_mode mode, enum rtx_code)
+{
+  if (mode == DFmode)
+    {
+#if WITH_DOUBLE_COMPARISON == 2
+      return true;
+#endif
+    }
+
+  // This is the GCC default and also what AVR-LibC implements.
+  return false;
+}
+
+
+
+/* Initialize the GCC target structure.  */
+
+#undef  TARGET_ASM_ALIGNED_HI_OP
+#define TARGET_ASM_ALIGNED_HI_OP "\t.word\t"
+#undef  TARGET_ASM_ALIGNED_SI_OP
+#define TARGET_ASM_ALIGNED_SI_OP "\t.long\t"
+#undef  TARGET_ASM_UNALIGNED_HI_OP
+#define TARGET_ASM_UNALIGNED_HI_OP "\t.word\t"
+#undef  TARGET_ASM_UNALIGNED_SI_OP
+#define TARGET_ASM_UNALIGNED_SI_OP "\t.long\t"
+#undef  TARGET_ASM_INTEGER
+#define TARGET_ASM_INTEGER avr_assemble_integer
+#undef  TARGET_ASM_FILE_START
+#define TARGET_ASM_FILE_START avr_file_start
+#undef  TARGET_ASM_FILE_END
+#define TARGET_ASM_FILE_END avr_file_end
+
+#undef  TARGET_ASM_FUNCTION_END_PROLOGUE
+#define TARGET_ASM_FUNCTION_END_PROLOGUE avr_asm_function_end_prologue
+#undef  TARGET_ASM_FUNCTION_BEGIN_EPILOGUE
+#define TARGET_ASM_FUNCTION_BEGIN_EPILOGUE avr_asm_function_begin_epilogue
+
+#undef  TARGET_FUNCTION_VALUE
+#define TARGET_FUNCTION_VALUE avr_function_value
+#undef  TARGET_LIBCALL_VALUE
+#define TARGET_LIBCALL_VALUE avr_libcall_value
+#undef  TARGET_FUNCTION_VALUE_REGNO_P
+#define TARGET_FUNCTION_VALUE_REGNO_P avr_function_value_regno_p
+
+#undef  TARGET_ATTRIBUTE_TABLE
+#define TARGET_ATTRIBUTE_TABLE avr_attribute_table
+#undef  TARGET_INSERT_ATTRIBUTES
+#define TARGET_INSERT_ATTRIBUTES avr_insert_attributes
+#undef  TARGET_SECTION_TYPE_FLAGS
+#define TARGET_SECTION_TYPE_FLAGS avr_section_type_flags
+
+#undef  TARGET_ASM_NAMED_SECTION
+#define TARGET_ASM_NAMED_SECTION avr_asm_named_section
+#undef  TARGET_ASM_INIT_SECTIONS
+#define TARGET_ASM_INIT_SECTIONS avr_asm_init_sections
+#undef  TARGET_ENCODE_SECTION_INFO
+#define TARGET_ENCODE_SECTION_INFO avr_encode_section_info
+#undef  TARGET_ASM_SELECT_SECTION
+#define TARGET_ASM_SELECT_SECTION avr_asm_select_section
+
+#undef  TARGET_ASM_FINAL_POSTSCAN_INSN
+#define TARGET_ASM_FINAL_POSTSCAN_INSN avr_asm_final_postscan_insn
+
+#undef  TARGET_REGISTER_MOVE_COST
+#define TARGET_REGISTER_MOVE_COST avr_register_move_cost
+#undef  TARGET_MEMORY_MOVE_COST
+#define TARGET_MEMORY_MOVE_COST avr_memory_move_cost
+#undef  TARGET_RTX_COSTS
+#define TARGET_RTX_COSTS avr_rtx_costs
+#undef  TARGET_ADDRESS_COST
+#define TARGET_ADDRESS_COST avr_address_cost
+#undef  TARGET_MACHINE_DEPENDENT_REORG
+#define TARGET_MACHINE_DEPENDENT_REORG avr_reorg
+#undef  TARGET_FUNCTION_ARG
+#define TARGET_FUNCTION_ARG avr_function_arg
+#undef  TARGET_FUNCTION_ARG_ADVANCE
+#define TARGET_FUNCTION_ARG_ADVANCE avr_function_arg_advance
+
+#undef  TARGET_SET_CURRENT_FUNCTION
+#define TARGET_SET_CURRENT_FUNCTION avr_set_current_function
+
+#undef  TARGET_RETURN_IN_MEMORY
+#define TARGET_RETURN_IN_MEMORY avr_return_in_memory
+
+#undef  TARGET_STRICT_ARGUMENT_NAMING
+#define TARGET_STRICT_ARGUMENT_NAMING hook_bool_CUMULATIVE_ARGS_true
+
+#undef TARGET_CONDITIONAL_REGISTER_USAGE
+#define TARGET_CONDITIONAL_REGISTER_USAGE avr_conditional_register_usage
+
+#undef  TARGET_HARD_REGNO_MODE_OK
+#define TARGET_HARD_REGNO_MODE_OK avr_hard_regno_mode_ok
+#undef  TARGET_HARD_REGNO_SCRATCH_OK
+#define TARGET_HARD_REGNO_SCRATCH_OK avr_hard_regno_scratch_ok
+#undef  TARGET_HARD_REGNO_CALL_PART_CLOBBERED
+#define TARGET_HARD_REGNO_CALL_PART_CLOBBERED \
+  avr_hard_regno_call_part_clobbered
+
+#undef  TARGET_CASE_VALUES_THRESHOLD
+#define TARGET_CASE_VALUES_THRESHOLD avr_case_values_threshold
+
+#undef  TARGET_FRAME_POINTER_REQUIRED
+#define TARGET_FRAME_POINTER_REQUIRED avr_frame_pointer_required_p
+#undef  TARGET_CAN_ELIMINATE
+#define TARGET_CAN_ELIMINATE avr_can_eliminate
+
+#undef  TARGET_ALLOCATE_STACK_SLOTS_FOR_ARGS
+#define TARGET_ALLOCATE_STACK_SLOTS_FOR_ARGS avr_allocate_stack_slots_for_args
+
+#undef TARGET_WARN_FUNC_RETURN
+#define TARGET_WARN_FUNC_RETURN avr_warn_func_return
+
+#undef  TARGET_CLASS_LIKELY_SPILLED_P
+#define TARGET_CLASS_LIKELY_SPILLED_P avr_class_likely_spilled_p
+
+#undef  TARGET_OPTION_OVERRIDE
+#define TARGET_OPTION_OVERRIDE avr_option_override
+
+#undef  TARGET_CANNOT_MODIFY_JUMPS_P
+#define TARGET_CANNOT_MODIFY_JUMPS_P avr_cannot_modify_jumps_p
+
+#undef  TARGET_FUNCTION_OK_FOR_SIBCALL
+#define TARGET_FUNCTION_OK_FOR_SIBCALL avr_function_ok_for_sibcall
+
+#undef  TARGET_INIT_BUILTINS
+#define TARGET_INIT_BUILTINS avr_init_builtins
+
+#undef  TARGET_BUILTIN_DECL
+#define TARGET_BUILTIN_DECL avr_builtin_decl
+
+#undef  TARGET_EXPAND_BUILTIN
+#define TARGET_EXPAND_BUILTIN avr_expand_builtin
+
+#undef  TARGET_FOLD_BUILTIN
+#define TARGET_FOLD_BUILTIN avr_fold_builtin
+
+#undef  TARGET_SCALAR_MODE_SUPPORTED_P
+#define TARGET_SCALAR_MODE_SUPPORTED_P avr_scalar_mode_supported_p
+
+#undef  TARGET_BUILD_BUILTIN_VA_LIST
+#define TARGET_BUILD_BUILTIN_VA_LIST avr_build_builtin_va_list
+
+#undef  TARGET_FIXED_POINT_SUPPORTED_P
+#define TARGET_FIXED_POINT_SUPPORTED_P hook_bool_void_true
+
+#undef  TARGET_CONVERT_TO_TYPE
+#define TARGET_CONVERT_TO_TYPE avr_convert_to_type
+
+#undef TARGET_LRA_P
+#define TARGET_LRA_P hook_bool_void_false
+
+#undef  TARGET_ADDR_SPACE_SUBSET_P
+#define TARGET_ADDR_SPACE_SUBSET_P avr_addr_space_subset_p
+
+#undef  TARGET_ADDR_SPACE_CONVERT
+#define TARGET_ADDR_SPACE_CONVERT avr_addr_space_convert
+
+#undef  TARGET_ADDR_SPACE_ADDRESS_MODE
+#define TARGET_ADDR_SPACE_ADDRESS_MODE avr_addr_space_address_mode
+
+#undef  TARGET_ADDR_SPACE_POINTER_MODE
+#define TARGET_ADDR_SPACE_POINTER_MODE avr_addr_space_pointer_mode
+
+#undef  TARGET_ADDR_SPACE_LEGITIMATE_ADDRESS_P
+#define TARGET_ADDR_SPACE_LEGITIMATE_ADDRESS_P  \
+  avr_addr_space_legitimate_address_p
+
+#undef  TARGET_ADDR_SPACE_LEGITIMIZE_ADDRESS
+#define TARGET_ADDR_SPACE_LEGITIMIZE_ADDRESS avr_addr_space_legitimize_address
+
+#undef  TARGET_ADDR_SPACE_DIAGNOSE_USAGE
+#define TARGET_ADDR_SPACE_DIAGNOSE_USAGE avr_addr_space_diagnose_usage
+
+#undef  TARGET_MODE_DEPENDENT_ADDRESS_P
+#define TARGET_MODE_DEPENDENT_ADDRESS_P avr_mode_dependent_address_p
+
+#undef  TARGET_PRINT_OPERAND
+#define TARGET_PRINT_OPERAND avr_print_operand
+#undef  TARGET_PRINT_OPERAND_ADDRESS
+#define TARGET_PRINT_OPERAND_ADDRESS avr_print_operand_address
+#undef  TARGET_PRINT_OPERAND_PUNCT_VALID_P
+#define TARGET_PRINT_OPERAND_PUNCT_VALID_P avr_print_operand_punct_valid_p
+
+#undef TARGET_USE_BY_PIECES_INFRASTRUCTURE_P
+#define TARGET_USE_BY_PIECES_INFRASTRUCTURE_P \
+  avr_use_by_pieces_infrastructure_p
+
+#undef  TARGET_LEGITIMATE_COMBINED_INSN
+#define TARGET_LEGITIMATE_COMBINED_INSN avr_legitimate_combined_insn
+
+#undef  TARGET_STARTING_FRAME_OFFSET
+#define TARGET_STARTING_FRAME_OFFSET avr_starting_frame_offset
+
+struct gcc_target targetm = TARGET_INITIALIZER;
+
+
+#include "gt-avr.h"
diff --git a/gcc-12.1.0/gcc/config/avr/avr.h b/gcc-12.1.0/gcc/config/avr/avr.h
index 1b948c6130c..0026a66883a 100644
--- a/gcc-12.1.0/gcc/config/avr/avr.h
+++ b/gcc-12.1.0/gcc/config/avr/avr.h
@@ -1,6 +1,6 @@
 /* Definitions of target machine for GNU compiler,
    for ATMEL AVR at90s8515, ATmega103/103L, ATmega603/603L microcontrollers.
-   Copyright (C) 1998-2022 Free Software Foundation, Inc.
+   Copyright (C) 1998-2021 Free Software Foundation, Inc.
    Contributed by Denis Chertykov (chertykov@gmail.com)
 
 This file is part of GCC.
@@ -155,7 +155,7 @@ FIXME: DRIVER_SELF_SPECS has changed.
 
 #define WCHAR_TYPE_SIZE 16
 
-#define FIRST_PSEUDO_REGISTER 37
+#define FIRST_PSEUDO_REGISTER 36
 
 #define GENERAL_REGNO_P(N)	IN_RANGE (N, 2, 31)
 #define GENERAL_REG_P(X)	(REG_P (X) && GENERAL_REGNO_P (REGNO (X)))
@@ -178,8 +178,7 @@ FIXME: DRIVER_SELF_SPECS has changed.
   0,0,/* r28 r29 */\
   0,0,/* r30 r31 */\
   1,1,/*  STACK */\
-  1,1, /* arg pointer */						\
-  1 /* CC */ }
+  1,1 /* arg pointer */  }
 
 #define CALL_USED_REGISTERS {			\
   1,1,/* r0 r1 */				\
@@ -199,8 +198,7 @@ FIXME: DRIVER_SELF_SPECS has changed.
     0,0,/* r28 r29 */				\
     1,1,/* r30 r31 */				\
     1,1,/*  STACK */				\
-    1,1, /* arg pointer */			\
-    1 /* CC */ }
+    1,1 /* arg pointer */  }
 
 #define REG_ALLOC_ORDER {			\
     24,25,					\
@@ -212,7 +210,7 @@ FIXME: DRIVER_SELF_SPECS has changed.
     28,29,					\
     17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,	\
     0,1,					\
-    32,33,34,35,36			\
+    32,33,34,35					\
     }
 
 #define ADJUST_REG_ALLOC_ORDER avr_adjust_reg_alloc_order()
@@ -232,7 +230,6 @@ enum reg_class {
   LD_REGS,			/* r16 - r31 */
   NO_LD_REGS,			/* r0 - r15 */
   GENERAL_REGS,			/* r0 - r31 */
-  CC_REG,			/* CC */
   ALL_REGS, LIM_REG_CLASSES
 };
 
@@ -253,7 +250,6 @@ enum reg_class {
 		   "LD_REGS",	/* r16 - r31 */			\
                    "NO_LD_REGS", /* r0 - r15 */                 \
 		   "GENERAL_REGS", /* r0 - r31 */		\
-		   "CC_REG", /* CC */		\
 		   "ALL_REGS" }
 
 #define REG_CLASS_CONTENTS {						\
@@ -274,8 +270,7 @@ enum reg_class {
      0x00000000},	/* LD_REGS, r16 - r31 */			\
   {0x0000ffff,0x00000000},	/* NO_LD_REGS  r0 - r15 */              \
   {0xffffffff,0x00000000},	/* GENERAL_REGS, r0 - r31 */		\
-  {0x00000000,0x00000010},	/* CC */				\
-  {0xffffffff,0x00000013}	/* ALL_REGS */				\
+  {0xffffffff,0x00000003}	/* ALL_REGS */				\
 }
 
 #define REGNO_REG_CLASS(R) avr_regno_reg_class(R)
@@ -321,7 +316,7 @@ enum reg_class {
 
 #define RETURN_ADDR_RTX(count, tem) avr_return_addr_rtx (count, tem)
 
-/* Don't use Push rounding. expr.cc: emit_single_push_insn is broken 
+/* Don't use Push rounding. expr.c: emit_single_push_insn is broken 
    for POST_DEC targets (PR27386).  */
 /*#define PUSH_ROUNDING(NPUSHED) (NPUSHED)*/
 
@@ -399,7 +394,7 @@ typedef struct avr_args
 #define SUPPORTS_INIT_PRIORITY 0
 
 /* We pretend jump tables are in text section because otherwise,
-   final.cc will switch to .rodata before jump tables and thereby
+   final.c will switch to .rodata before jump tables and thereby
    triggers __do_copy_data.  As we implement ASM_OUTPUT_ADDR_VEC,
    we still have full control over the jump tables themselves.  */
 #define JUMP_TABLES_IN_TEXT_SECTION 1
@@ -434,7 +429,7 @@ typedef struct avr_args
     "r8","r9","r10","r11","r12","r13","r14","r15",	\
     "r16","r17","r18","r19","r20","r21","r22","r23",	\
     "r24","r25","r26","r27","r28","r29","r30","r31",	\
-    "__SP_L__","__SP_H__","argL","argH", "cc"}
+    "__SP_L__","__SP_H__","argL","argH"}
 
 #define FINAL_PRESCAN_INSN(insn, operand, nop)  \
   avr_final_prescan_insn (insn, operand,nop)
@@ -489,6 +484,23 @@ typedef struct avr_args
 
 #define TRAMPOLINE_SIZE 4
 
+/* Store in cc_status the expressions
+   that the condition codes will describe
+   after execution of an instruction whose pattern is EXP.
+   Do not alter them if the instruction would not alter the cc's.  */
+
+#define NOTICE_UPDATE_CC(EXP, INSN) avr_notice_update_cc (EXP, INSN)
+
+/* The add insns don't set overflow in a usable way.  */
+#define CC_OVERFLOW_UNUSABLE 01000
+/* The mov,and,or,xor insns don't set carry.  That's ok though as the
+   Z bit is all we need when doing unsigned comparisons on the result of
+   these insns (since they're always with 0).  However, conditions.h has
+   CC_NO_OVERFLOW defined for this purpose.  Rename it to something more
+   understandable.  */
+#define CC_NO_CARRY CC_NO_OVERFLOW
+
+
 /* Output assembler code to FILE to increment profiler label # LABELNO
    for profiling a function entry.  */
 
diff --git a/gcc-12.1.0/gcc/config/avr/avr.md b/gcc-12.1.0/gcc/config/avr/avr.md
index efae7efb69b..478abc1182f 100644
--- a/gcc-12.1.0/gcc/config/avr/avr.md
+++ b/gcc-12.1.0/gcc/config/avr/avr.md
@@ -1,6 +1,6 @@
 ;;   Machine description for GNU compiler,
 ;;   for ATMEL AVR micro controllers.
-;;   Copyright (C) 1998-2022 Free Software Foundation, Inc.
+;;   Copyright (C) 1998-2021 Free Software Foundation, Inc.
 ;;   Contributed by Denis Chertykov (chertykov@gmail.com)
 
 ;; This file is part of GCC.
@@ -58,7 +58,6 @@
    (REG_Z       30)
    (REG_W       24)
    (REG_SP      32)
-   (REG_CC      36)
    (LPM_REGNO   0)      ; implicit target register of LPM
    (TMP_REGNO   0)      ; temporary register r0
    (ZERO_REGNO  1)      ; zero register r1
@@ -148,7 +147,7 @@
                        (const_int 2))]
         (const_int 2)))
 
-;; Lengths of several insns are adjusted in avr.cc:adjust_insn_length().
+;; Lengths of several insns are adjusted in avr.c:adjust_insn_length().
 ;; Following insn attribute tells if and how the adjustment has to be
 ;; done:
 ;;     no     No adjustment needed; attribute "length" is fine.
@@ -328,7 +327,7 @@
 ;; This avoids creating add/sub offsets in frame_pointer save/resore.
 ;; The 'null' receiver also avoids  problems with optimisation
 ;; not recognising incoming jmp and removing code that resets frame_pointer.
-;; The code derived from builtins.cc.
+;; The code derived from builtins.c.
 
 (define_expand "nonlocal_goto_receiver"
   [(set (reg:HI REG_Y)
@@ -346,7 +345,7 @@
 
 
 ;; Defining nonlocal_goto_receiver means we must also define this
-;; even though its function is identical to that in builtins.cc
+;; even though its function is identical to that in builtins.c
 
 (define_expand "nonlocal_goto"
   [(use (match_operand 0 "general_operand"))
@@ -460,8 +459,7 @@
   "reload_completed
    && frame_pointer_needed
    && !cfun->calls_alloca
-   && find_reg_note (insn, REG_ARGS_SIZE, const0_rtx)
-   && REGNO (operands[0]) != REG_Y"
+   && find_reg_note (insn, REG_ARGS_SIZE, const0_rtx)"
   [(set (reg:HI REG_SP)
         (reg:HI REG_Y))])
 
@@ -493,34 +491,19 @@
 ;; "load_psi_libgcc"
 ;; "load_si_libgcc"
 ;; "load_sf_libgcc"
-(define_insn_and_split "load_<mode>_libgcc"
+(define_insn "load_<mode>_libgcc"
   [(set (reg:MOVMODE 22)
         (match_operand:MOVMODE 0 "memory_operand" "m,m"))]
   "avr_load_libgcc_p (operands[0])
    && REG_P (XEXP (operands[0], 0))
    && REG_Z == REGNO (XEXP (operands[0], 0))"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:MOVMODE 22)
-                    (match_dup 0))
-              (clobber (reg:CC REG_CC))])]
-  ""
-  [(set_attr "isa" "rjmp,jmp")])
-
-(define_insn "*load_<mode>_libgcc"
-  [(set (reg:MOVMODE 22)
-        (match_operand:MOVMODE 0 "memory_operand" "m,m"))
-   (clobber (reg:CC REG_CC))]
-  "avr_load_libgcc_p (operands[0])
-   && REG_P (XEXP (operands[0], 0))
-   && REG_Z == REGNO (XEXP (operands[0], 0))
-   && reload_completed"
   {
     operands[0] = GEN_INT (GET_MODE_SIZE (<MODE>mode));
     return "%~call __load_%0";
   }
   [(set_attr "length" "1,2")
-   (set_attr "isa" "rjmp,jmp")])
+   (set_attr "isa" "rjmp,jmp")
+   (set_attr "cc" "clobber")])
 
 
 ;; "xload8qi_A"
@@ -608,7 +591,8 @@
   }
   [(set_attr "length" "4,4")
    (set_attr "adjust_len" "*,xload")
-   (set_attr "isa" "lpmx,lpm")])
+   (set_attr "isa" "lpmx,lpm")
+   (set_attr "cc" "none")])
 
 ;; R21:Z : 24-bit source address
 ;; R22   : 1-4 byte output
@@ -618,35 +602,21 @@
 ;; "xload_si_libgcc" "xload_sq_libgcc" "xload_usq_libgcc" "xload_sa_libgcc" "xload_usa_libgcc"
 ;; "xload_sf_libgcc"
 ;; "xload_psi_libgcc"
-
-(define_insn_and_split "xload_<mode>_libgcc"
+(define_insn "xload_<mode>_libgcc"
   [(set (reg:MOVMODE 22)
         (mem:MOVMODE (lo_sum:PSI (reg:QI 21)
                                  (reg:HI REG_Z))))
    (clobber (reg:QI 21))
    (clobber (reg:HI REG_Z))]
   "avr_xload_libgcc_p (<MODE>mode)"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:MOVMODE 22)
-              (mem:MOVMODE (lo_sum:PSI (reg:QI 21)
-                                       (reg:HI REG_Z))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*xload_<mode>_libgcc"
-  [(set (reg:MOVMODE 22)
-        (mem:MOVMODE (lo_sum:PSI (reg:QI 21)
-                                 (reg:HI REG_Z))))
-   (clobber (reg:CC REG_CC))]
-  "avr_xload_libgcc_p (<MODE>mode)
-   && reload_completed"
   {
     rtx x_bytes = GEN_INT (GET_MODE_SIZE (<MODE>mode));
 
     output_asm_insn ("%~call __xload_%0", &x_bytes);
     return "";
   }
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 
 ;; General move expanders
@@ -724,31 +694,19 @@
 ;; are call-saved registers, and most of LD_REGS are call-used registers,
 ;; so this may still be a win for registers live across function calls.
 
-(define_insn_and_split "mov<mode>_insn_split"
-  [(set (match_operand:ALL1 0 "nonimmediate_operand" "=r    ,d    ,Qm   ,r ,q,r,*r")
-        (match_operand:ALL1 1 "nox_general_operand"   "r Y00,n Ynn,r Y00,Qm,r,q,i"))]
-  "register_operand (operands[0], <MODE>mode)
-    || reg_or_0_operand (operands[1], <MODE>mode)"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (match_dup 1))
-              (clobber (reg:CC REG_CC))])])
-
 ;; "movqi_insn"
 ;; "movqq_insn" "movuqq_insn"
 (define_insn "mov<mode>_insn"
   [(set (match_operand:ALL1 0 "nonimmediate_operand" "=r    ,d    ,Qm   ,r ,q,r,*r")
-        (match_operand:ALL1 1 "nox_general_operand"   "r Y00,n Ynn,r Y00,Qm,r,q,i"))
-   (clobber (reg:CC REG_CC))]
-  "(register_operand (operands[0], <MODE>mode)
-    || reg_or_0_operand (operands[1], <MODE>mode))
-   && reload_completed"
+        (match_operand:ALL1 1 "nox_general_operand"   "r Y00,n Ynn,r Y00,Qm,r,q,i"))]
+  "register_operand (operands[0], <MODE>mode)
+    || reg_or_0_operand (operands[1], <MODE>mode)"
   {
     return output_movqi (insn, operands, NULL);
   }
   [(set_attr "length" "1,1,5,5,1,1,4")
-   (set_attr "adjust_len" "mov8")])
+   (set_attr "adjust_len" "mov8")
+   (set_attr "cc" "ldi,none,clobber,clobber,none,none,clobber")])
 
 ;; This is used in peephole2 to optimize loading immediate constants
 ;; if a scratch register from LD_REGS happens to be available.
@@ -758,26 +716,24 @@
 (define_insn "*reload_in<mode>"
   [(set (match_operand:ALL1 0 "register_operand"    "=l")
         (match_operand:ALL1 1 "const_operand"        "i"))
-   (clobber (match_operand:QI 2 "register_operand" "=&d"))
-   (clobber (reg:CC REG_CC))]
+   (clobber (match_operand:QI 2 "register_operand" "=&d"))]
   "reload_completed"
   "ldi %2,lo8(%1)
 	mov %0,%2"
-  [(set_attr "length" "2")])
+  [(set_attr "length" "2")
+   (set_attr "cc" "none")])
 
 (define_peephole2
   [(match_scratch:QI 2 "d")
-   (parallel [(set (match_operand:ALL1 0 "l_register_operand" "")
-                   (match_operand:ALL1 1 "const_operand" ""))
-              (clobber (reg:CC REG_CC))])]
+   (set (match_operand:ALL1 0 "l_register_operand" "")
+        (match_operand:ALL1 1 "const_operand" ""))]
   ; No need for a clobber reg for 0x0, 0x01 or 0xff
   "!satisfies_constraint_Y00 (operands[1])
    && !satisfies_constraint_Y01 (operands[1])
    && !satisfies_constraint_Ym1 (operands[1])"
   [(parallel [(set (match_dup 0)
                    (match_dup 1))
-              (clobber (match_dup 2))
-              (clobber (reg:CC REG_CC))])])
+              (clobber (match_dup 2))])])
 
 ;;============================================================================
 ;; move word (16 bit)
@@ -803,18 +759,17 @@
 	out %A0,%A1
 	out %A0,%A1\;out %B0,%B1"
   [(set_attr "length" "2,4,5,1,2")
-   (set_attr "isa" "no_xmega,no_xmega,no_xmega,*,xmega")])
+   (set_attr "isa" "no_xmega,no_xmega,no_xmega,*,xmega")
+   (set_attr "cc" "none")])
 
 (define_peephole2
   [(match_scratch:QI 2 "d")
-   (parallel [(set (match_operand:ALL2 0 "l_register_operand" "")
-                   (match_operand:ALL2 1 "const_or_immediate_operand" ""))
-              (clobber (reg:CC REG_CC))])]
+   (set (match_operand:ALL2 0 "l_register_operand" "")
+        (match_operand:ALL2 1 "const_or_immediate_operand" ""))]
   "operands[1] != CONST0_RTX (<MODE>mode)"
   [(parallel [(set (match_dup 0)
                    (match_dup 1))
-              (clobber (match_dup 2))
-              (clobber (reg:CC REG_CC))])])
+              (clobber (match_dup 2))])])
 
 ;; '*' because it is not used in rtl generation, only in above peephole
 ;; "*reload_inhi"
@@ -823,73 +778,55 @@
 (define_insn "*reload_in<mode>"
   [(set (match_operand:ALL2 0 "l_register_operand"  "=l")
         (match_operand:ALL2 1 "immediate_operand"    "i"))
-   (clobber (match_operand:QI 2 "register_operand" "=&d"))
-   (clobber (reg:CC REG_CC))]
+   (clobber (match_operand:QI 2 "register_operand" "=&d"))]
   "reload_completed"
   {
     return output_reload_inhi (operands, operands[2], NULL);
   }
   [(set_attr "length" "4")
-   (set_attr "adjust_len" "reload_in16")])
+   (set_attr "adjust_len" "reload_in16")
+   (set_attr "cc" "clobber")])
 
 ;; "*movhi"
 ;; "*movhq" "*movuhq"
 ;; "*movha" "*movuha"
-(define_insn_and_split "*mov<mode>_split"
+(define_insn "*mov<mode>"
   [(set (match_operand:ALL2 0 "nonimmediate_operand" "=r,r  ,r,m    ,d,*r,q,r")
         (match_operand:ALL2 1 "nox_general_operand"   "r,Y00,m,r Y00,i,i ,r,q"))]
   "register_operand (operands[0], <MODE>mode)
    || reg_or_0_operand (operands[1], <MODE>mode)"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (match_dup 1))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*mov<mode>"
-  [(set (match_operand:ALL2 0 "nonimmediate_operand" "=r,r  ,r,m    ,d,*r,q,r")
-        (match_operand:ALL2 1 "nox_general_operand"   "r,Y00,m,r Y00,i,i ,r,q"))
-   (clobber (reg:CC REG_CC))]
-  "(register_operand (operands[0], <MODE>mode)
-    || reg_or_0_operand (operands[1], <MODE>mode))
-   && reload_completed"
   {
     return output_movhi (insn, operands, NULL);
   }
   [(set_attr "length" "2,2,6,7,2,6,5,2")
-   (set_attr "adjust_len" "mov16")])
+   (set_attr "adjust_len" "mov16")
+   (set_attr "cc" "none,none,clobber,clobber,none,clobber,none,none")])
 
 (define_peephole2 ; movw
-  [(parallel [(set (match_operand:ALL1 0 "even_register_operand" "")
-                   (match_operand:ALL1 1 "even_register_operand" ""))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_operand:ALL1 2 "odd_register_operand" "")
-                   (match_operand:ALL1 3 "odd_register_operand" ""))
-              (clobber (reg:CC REG_CC))])]
+  [(set (match_operand:ALL1 0 "even_register_operand" "")
+        (match_operand:ALL1 1 "even_register_operand" ""))
+   (set (match_operand:ALL1 2 "odd_register_operand" "")
+        (match_operand:ALL1 3 "odd_register_operand" ""))]
   "AVR_HAVE_MOVW
    && REGNO (operands[0]) == REGNO (operands[2]) - 1
    && REGNO (operands[1]) == REGNO (operands[3]) - 1"
-  [(parallel [(set (match_dup 4)
-                   (match_dup 5))
-              (clobber (reg:CC REG_CC))])]
+  [(set (match_dup 4)
+        (match_dup 5))]
   {
     operands[4] = gen_rtx_REG (HImode, REGNO (operands[0]));
     operands[5] = gen_rtx_REG (HImode, REGNO (operands[1]));
   })
 
 (define_peephole2 ; movw_r
-  [(parallel [(set (match_operand:ALL1 0 "odd_register_operand" "")
-                   (match_operand:ALL1 1 "odd_register_operand" ""))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_operand:ALL1 2 "even_register_operand" "")
-                   (match_operand:ALL1 3 "even_register_operand" ""))
-              (clobber (reg:CC REG_CC))])]
+  [(set (match_operand:ALL1 0 "odd_register_operand" "")
+        (match_operand:ALL1 1 "odd_register_operand" ""))
+   (set (match_operand:ALL1 2 "even_register_operand" "")
+        (match_operand:ALL1 3 "even_register_operand" ""))]
   "AVR_HAVE_MOVW
    && REGNO (operands[2]) == REGNO (operands[0]) - 1
    && REGNO (operands[3]) == REGNO (operands[1]) - 1"
-  [(parallel [(set (match_dup 4)
-                   (match_dup 5))
-              (clobber (reg:CC REG_CC))])]
+  [(set (match_dup 4)
+        (match_dup 5))]
   {
     operands[4] = gen_rtx_REG (HImode, REGNO (operands[2]));
     operands[5] = gen_rtx_REG (HImode, REGNO (operands[3]));
@@ -907,10 +844,7 @@
   [(set (match_operand:HISI 0 "register_operand" "")
         (match_operand:HISI 1 "memory_operand" ""))]
   "reload_completed
-   && AVR_HAVE_LPMX
-   && avr_mem_flash_p (operands[1])
-   && REG_P (XEXP (operands[1], 0))
-   && !reg_overlap_mentioned_p (XEXP (operands[1], 0), operands[0])"
+   && AVR_HAVE_LPMX"
   [(set (match_dup 0)
         (match_dup 2))
    (set (match_dup 3)
@@ -919,6 +853,13 @@
   {
      rtx addr = XEXP (operands[1], 0);
 
+     if (!avr_mem_flash_p (operands[1])
+         || !REG_P (addr)
+         || reg_overlap_mentioned_p (addr, operands[0]))
+       {
+         FAIL;
+       }
+
     operands[2] = replace_equiv_address (operands[1],
                                          gen_rtx_POST_INC (Pmode, addr));
     operands[3] = addr;
@@ -930,70 +871,53 @@
 
 (define_peephole2 ; *reload_inpsi
   [(match_scratch:QI 2 "d")
-   (parallel [(set (match_operand:PSI 0 "l_register_operand" "")
-                   (match_operand:PSI 1 "immediate_operand" ""))
-              (clobber (reg:CC REG_CC))])
+   (set (match_operand:PSI 0 "l_register_operand" "")
+        (match_operand:PSI 1 "immediate_operand" ""))
    (match_dup 2)]
   "operands[1] != const0_rtx
    && operands[1] != constm1_rtx"
   [(parallel [(set (match_dup 0)
                    (match_dup 1))
-              (clobber (match_dup 2))
-              (clobber (reg:CC REG_CC))])])
+              (clobber (match_dup 2))])])
 
 ;; '*' because it is not used in rtl generation.
 (define_insn "*reload_inpsi"
   [(set (match_operand:PSI 0 "register_operand" "=r")
         (match_operand:PSI 1 "immediate_operand" "i"))
-   (clobber (match_operand:QI 2 "register_operand" "=&d"))
-   (clobber (reg:CC REG_CC))]
+   (clobber (match_operand:QI 2 "register_operand" "=&d"))]
   "reload_completed"
   {
     return avr_out_reload_inpsi (operands, operands[2], NULL);
   }
   [(set_attr "length" "6")
-   (set_attr "adjust_len" "reload_in24")])
+   (set_attr "adjust_len" "reload_in24")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*movpsi_split"
+(define_insn "*movpsi"
   [(set (match_operand:PSI 0 "nonimmediate_operand" "=r,r,r ,Qm,!d,r")
         (match_operand:PSI 1 "nox_general_operand"   "r,L,Qm,rL,i ,i"))]
   "register_operand (operands[0], PSImode)
    || register_operand (operands[1], PSImode)
    || const0_rtx == operands[1]"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (match_dup 1))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*movpsi"
-  [(set (match_operand:PSI 0 "nonimmediate_operand" "=r,r,r ,Qm,!d,r")
-        (match_operand:PSI 1 "nox_general_operand"   "r,L,Qm,rL,i ,i"))
-   (clobber (reg:CC REG_CC))]
-  "(register_operand (operands[0], PSImode)
-    || register_operand (operands[1], PSImode)
-    || const0_rtx == operands[1])
-   && reload_completed"
   {
     return avr_out_movpsi (insn, operands, NULL);
   }
   [(set_attr "length" "3,3,8,9,4,10")
-   (set_attr "adjust_len" "mov24")])
+   (set_attr "adjust_len" "mov24")
+   (set_attr "cc" "none,none,clobber,clobber,none,clobber")])
 
 ;;==========================================================================
 ;; move double word (32 bit)
 
 (define_peephole2 ; *reload_insi
   [(match_scratch:QI 2 "d")
-   (parallel [(set (match_operand:ALL4 0 "l_register_operand" "")
-                   (match_operand:ALL4 1 "immediate_operand" ""))
-              (clobber (reg:CC REG_CC))])
+   (set (match_operand:ALL4 0 "l_register_operand" "")
+        (match_operand:ALL4 1 "immediate_operand" ""))
    (match_dup 2)]
   "operands[1] != CONST0_RTX (<MODE>mode)"
   [(parallel [(set (match_dup 0)
                    (match_dup 1))
-              (clobber (match_dup 2))
-              (clobber (reg:CC REG_CC))])])
+              (clobber (match_dup 2))])])
 
 ;; '*' because it is not used in rtl generation.
 ;; "*reload_insi"
@@ -1002,94 +926,68 @@
 (define_insn "*reload_insi"
   [(set (match_operand:ALL4 0 "register_operand"   "=r")
         (match_operand:ALL4 1 "immediate_operand"   "n Ynn"))
-   (clobber (match_operand:QI 2 "register_operand" "=&d"))
-   (clobber (reg:CC REG_CC))]
+   (clobber (match_operand:QI 2 "register_operand" "=&d"))]
   "reload_completed"
   {
     return output_reload_insisf (operands, operands[2], NULL);
   }
   [(set_attr "length" "8")
-   (set_attr "adjust_len" "reload_in32")])
+   (set_attr "adjust_len" "reload_in32")
+   (set_attr "cc" "clobber")])
 
 
 ;; "*movsi"
 ;; "*movsq" "*movusq"
 ;; "*movsa" "*movusa"
-(define_insn_and_split "*mov<mode>_split"
+(define_insn "*mov<mode>"
   [(set (match_operand:ALL4 0 "nonimmediate_operand" "=r,r  ,r ,Qm   ,!d,r")
         (match_operand:ALL4 1 "nox_general_operand"   "r,Y00,Qm,r Y00,i ,i"))]
   "register_operand (operands[0], <MODE>mode)
    || reg_or_0_operand (operands[1], <MODE>mode)"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (match_dup 1))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*mov<mode>"
-  [(set (match_operand:ALL4 0 "nonimmediate_operand" "=r,r  ,r ,Qm   ,!d,r")
-        (match_operand:ALL4 1 "nox_general_operand"   "r,Y00,Qm,r Y00,i ,i"))
-   (clobber (reg:CC REG_CC))]
-  "(register_operand (operands[0], <MODE>mode)
-    || reg_or_0_operand (operands[1], <MODE>mode))
-   && reload_completed"
   {
     return output_movsisf (insn, operands, NULL);
   }
   [(set_attr "length" "4,4,8,9,4,10")
-   (set_attr "adjust_len" "mov32")])
+   (set_attr "adjust_len" "mov32")
+   (set_attr "cc" "none,none,clobber,clobber,none,clobber")])
 
 ;; fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
 ;; move floating point numbers (32 bit)
 
-(define_insn_and_split "*movsf_split"
+(define_insn "*movsf"
   [(set (match_operand:SF 0 "nonimmediate_operand" "=r,r,r ,Qm,!d,r")
         (match_operand:SF 1 "nox_general_operand"   "r,G,Qm,rG,F ,F"))]
   "register_operand (operands[0], SFmode)
    || reg_or_0_operand (operands[1], SFmode)"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (match_dup 1))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*movsf"
-  [(set (match_operand:SF 0 "nonimmediate_operand" "=r,r,r ,Qm,!d,r")
-        (match_operand:SF 1 "nox_general_operand"   "r,G,Qm,rG,F ,F"))
-   (clobber (reg:CC REG_CC))]
-  "(register_operand (operands[0], SFmode)
-    || reg_or_0_operand (operands[1], SFmode))
-   && reload_completed"
   {
     return output_movsisf (insn, operands, NULL);
   }
   [(set_attr "length" "4,4,8,9,4,10")
-   (set_attr "adjust_len" "mov32")])
+   (set_attr "adjust_len" "mov32")
+   (set_attr "cc" "none,none,clobber,clobber,none,clobber")])
 
 (define_peephole2 ; *reload_insf
   [(match_scratch:QI 2 "d")
-   (parallel [(set (match_operand:SF 0 "l_register_operand" "")
-                   (match_operand:SF 1 "const_double_operand" ""))
-              (clobber (reg:CC REG_CC))])
+   (set (match_operand:SF 0 "l_register_operand" "")
+        (match_operand:SF 1 "const_double_operand" ""))
    (match_dup 2)]
   "operands[1] != CONST0_RTX (SFmode)"
   [(parallel [(set (match_dup 0)
                    (match_dup 1))
-              (clobber (match_dup 2))
-              (clobber (reg:CC REG_CC))])])
+              (clobber (match_dup 2))])])
 
 ;; '*' because it is not used in rtl generation.
 (define_insn "*reload_insf"
   [(set (match_operand:SF 0 "register_operand" "=r")
         (match_operand:SF 1 "const_double_operand" "F"))
-   (clobber (match_operand:QI 2 "register_operand" "=&d"))
-   (clobber (reg:CC REG_CC))]
+   (clobber (match_operand:QI 2 "register_operand" "=&d"))]
   "reload_completed"
   {
     return output_reload_insisf (operands, operands[2], NULL);
   }
   [(set_attr "length" "8")
-   (set_attr "adjust_len" "reload_in32")])
+   (set_attr "adjust_len" "reload_in32")
+   (set_attr "cc" "clobber")])
 
 ;;=========================================================================
 ;; move string (like memcpy)
@@ -1117,7 +1015,7 @@
 
 ;; "cpymem_qi"
 ;; "cpymem_hi"
-(define_insn_and_split "cpymem_<mode>"
+(define_insn "cpymem_<mode>"
   [(set (mem:BLK (reg:HI REG_X))
         (mem:BLK (reg:HI REG_Z)))
    (unspec [(match_operand:QI 0 "const_int_operand" "n")]
@@ -1128,35 +1026,11 @@
    (clobber (reg:QI LPM_REGNO))
    (clobber (match_operand:QIHI 2 "register_operand" "=1"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (mem:BLK (reg:HI REG_X))
-                   (mem:BLK (reg:HI REG_Z)))
-              (unspec [(match_dup 0)]
-                      UNSPEC_CPYMEM)
-              (use (match_dup 1))
-              (clobber (reg:HI REG_X))
-              (clobber (reg:HI REG_Z))
-              (clobber (reg:QI LPM_REGNO))
-              (clobber (match_dup 2))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*cpymem_<mode>"
-  [(set (mem:BLK (reg:HI REG_X))
-        (mem:BLK (reg:HI REG_Z)))
-        (unspec [(match_operand:QI 0 "const_int_operand" "n")]
-                UNSPEC_CPYMEM)
-        (use (match_operand:QIHI 1 "register_operand" "<CPYMEM_r_d>"))
-        (clobber (reg:HI REG_X))
-        (clobber (reg:HI REG_Z))
-        (clobber (reg:QI LPM_REGNO))
-        (clobber (match_operand:QIHI 2 "register_operand" "=1"))
-        (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_cpymem (insn, operands, NULL);
   }
-  [(set_attr "adjust_len" "cpymem")])
+  [(set_attr "adjust_len" "cpymem")
+   (set_attr "cc" "clobber")])
 
 
 ;; $0    : Address Space
@@ -1167,8 +1041,7 @@
 
 ;; "cpymemx_qi"
 ;; "cpymemx_hi"
-
-(define_insn_and_split "cpymemx_<mode>"
+(define_insn "cpymemx_<mode>"
   [(set (mem:BLK (reg:HI REG_X))
         (mem:BLK (lo_sum:PSI (reg:QI 23)
                              (reg:HI REG_Z))))
@@ -1182,39 +1055,9 @@
    (clobber (reg:QI 23))
    (clobber (mem:QI (match_operand:QI 1 "io_address_operand" "n")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (mem:BLK (reg:HI REG_X))
-                   (mem:BLK (lo_sum:PSI (reg:QI 23)
-                                        (reg:HI REG_Z))))
-              (unspec [(match_dup 0)]
-                      UNSPEC_CPYMEM)
-              (use (reg:QIHI 24))
-              (clobber (reg:HI REG_X))
-              (clobber (reg:HI REG_Z))
-              (clobber (reg:QI LPM_REGNO))
-              (clobber (reg:HI 24))
-              (clobber (reg:QI 23))
-              (clobber (mem:QI (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*cpymemx_<mode>"
-  [(set (mem:BLK (reg:HI REG_X))
-        (mem:BLK (lo_sum:PSI (reg:QI 23)
-                             (reg:HI REG_Z))))
-   (unspec [(match_operand:QI 0 "const_int_operand" "n")]
-           UNSPEC_CPYMEM)
-   (use (reg:QIHI 24))
-   (clobber (reg:HI REG_X))
-   (clobber (reg:HI REG_Z))
-   (clobber (reg:QI LPM_REGNO))
-   (clobber (reg:HI 24))
-   (clobber (reg:QI 23))
-   (clobber (mem:QI (match_operand:QI 1 "io_address_operand" "n")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __movmemx_<mode>"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 
 ;; =%2 =%2 =%2 =%2 =%2 =%2 =%2 =%2 =%2 =%2 =%2 =%2 =%2 =%2 =%2 =%2 =%2 =%2
@@ -1248,7 +1091,7 @@
   })
 
 
-(define_insn_and_split "*clrmemqi_split"
+(define_insn "*clrmemqi"
   [(set (mem:BLK (match_operand:HI 0 "register_operand" "e"))
         (const_int 0))
    (use (match_operand:QI 1 "register_operand" "r"))
@@ -1256,30 +1099,12 @@
    (clobber (match_scratch:HI 3 "=0"))
    (clobber (match_scratch:QI 4 "=&1"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (mem:BLK (match_dup 0))
-                   (const_int 0))
-              (use (match_dup 1))
-              (use (match_dup 2))
-              (clobber (match_dup 3))
-              (clobber (match_dup 4))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*clrmemqi"
-  [(set (mem:BLK (match_operand:HI 0 "register_operand" "e"))
-        (const_int 0))
-   (use (match_operand:QI 1 "register_operand" "r"))
-   (use (match_operand:QI 2 "const_int_operand" "n"))
-   (clobber (match_scratch:HI 3 "=0"))
-   (clobber (match_scratch:QI 4 "=&1"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "0:\;st %a0+,__zero_reg__\;dec %1\;brne 0b"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "clobber")])
 
 
-(define_insn_and_split "*clrmemhi_split"
+(define_insn "*clrmemhi"
   [(set (mem:BLK (match_operand:HI 0 "register_operand" "e,e"))
         (const_int 0))
    (use (match_operand:HI 1 "register_operand" "!w,d"))
@@ -1287,30 +1112,11 @@
    (clobber (match_scratch:HI 3 "=0,0"))
    (clobber (match_scratch:HI 4 "=&1,&1"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (mem:BLK (match_dup 0))
-                   (const_int 0))
-              (use (match_dup 1))
-              (use (match_dup 2))
-              (clobber (match_dup 3))
-              (clobber (match_dup 4))
-              (clobber (reg:CC REG_CC))])])
-
-
-(define_insn "*clrmemhi"
-  [(set (mem:BLK (match_operand:HI 0 "register_operand" "e,e"))
-        (const_int 0))
-   (use (match_operand:HI 1 "register_operand" "!w,d"))
-   (use (match_operand:HI 2 "const_int_operand" "n,n"))
-   (clobber (match_scratch:HI 3 "=0,0"))
-   (clobber (match_scratch:HI 4 "=&1,&1"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "@
 	0:\;st %a0+,__zero_reg__\;sbiw %A1,1\;brne 0b
 	0:\;st %a0+,__zero_reg__\;subi %A1,1\;sbci %B1,0\;brne 0b"
-  [(set_attr "length" "3,4")])
+  [(set_attr "length" "3,4")
+   (set_attr "cc" "clobber,clobber")])
 
 (define_expand "strlenhi"
   [(set (match_dup 4)
@@ -1336,57 +1142,27 @@
     operands[4] = gen_reg_rtx (HImode);
   })
 
-(define_insn_and_split "*strlenhi_split"
+(define_insn "*strlenhi"
   [(set (match_operand:HI 0 "register_operand"                      "=e")
         (unspec:HI [(mem:BLK (match_operand:HI 1 "register_operand"  "0"))
                     (const_int 0)
                     (match_operand:HI 2 "immediate_operand"          "i")]
                    UNSPEC_STRLEN))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel
-      [(set (match_dup 0)
-            (unspec:HI [(mem:BLK (match_dup 1))
-                        (const_int 0)
-                        (match_dup 2)]
-                       UNSPEC_STRLEN))
-       (clobber (reg:CC REG_CC))])])
-
-(define_insn "*strlenhi"
-  [(set (match_operand:HI 0 "register_operand"                      "=e")
-        (unspec:HI [(mem:BLK (match_operand:HI 1 "register_operand"  "0"))
-                    (const_int 0)
-                    (match_operand:HI 2 "immediate_operand"          "i")]
-                   UNSPEC_STRLEN))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "0:\;ld __tmp_reg__,%a0+\;tst __tmp_reg__\;brne 0b"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "clobber")])
 
 ;+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 ; add bytes
 
 ;; "addqi3"
 ;; "addqq3" "adduqq3"
-(define_insn_and_split "add<mode>3"
+(define_insn "add<mode>3"
   [(set (match_operand:ALL1 0 "register_operand"            "=r,d    ,r  ,r  ,r  ,r")
         (plus:ALL1 (match_operand:ALL1 1 "register_operand" "%0,0    ,0  ,0  ,0  ,0")
                    (match_operand:ALL1 2 "nonmemory_operand" "r,n Ynn,Y01,Ym1,Y02,Ym2")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:ALL1 (match_dup 1)
-                              (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*add<mode>3"
-  [(set (match_operand:ALL1 0 "register_operand"            "=r,d    ,r  ,r  ,r  ,r")
-        (plus:ALL1 (match_operand:ALL1 1 "register_operand" "%0,0    ,0  ,0  ,0  ,0")
-                   (match_operand:ALL1 2 "nonmemory_operand" "r,n Ynn,Y01,Ym1,Y02,Ym2")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "@
 	add %0,%2
 	subi %0,lo8(-(%2))
@@ -1394,7 +1170,8 @@
 	dec %0
 	inc %0\;inc %0
 	dec %0\;dec %0"
-  [(set_attr "length" "1,1,1,1,2,2")])
+  [(set_attr "length" "1,1,1,1,2,2")
+   (set_attr "cc" "set_czn,set_czn,set_vzn,set_vzn,set_vzn,set_vzn")])
 
 ;; "addhi3"
 ;; "addhq3" "adduhq3"
@@ -1428,144 +1205,67 @@
   })
 
 
-(define_insn_and_split "*addhi3_zero_extend_split"
+(define_insn "*addhi3_zero_extend"
   [(set (match_operand:HI 0 "register_operand"                         "=r,*?r")
         (plus:HI (zero_extend:HI (match_operand:QI 1 "register_operand" "r  ,0"))
                  (match_operand:HI 2 "register_operand"                 "0  ,r")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:HI (zero_extend:HI (match_dup 1))
-                            (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*addhi3_zero_extend"
-  [(set (match_operand:HI 0 "register_operand"                         "=r,*?r")
-        (plus:HI (zero_extend:HI (match_operand:QI 1 "register_operand" "r  ,0"))
-                 (match_operand:HI 2 "register_operand"                 "0  ,r")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "@
 	add %A0,%1\;adc %B0,__zero_reg__
 	add %A0,%A2\;mov %B0,%B2\;adc %B0,__zero_reg__"
-  [(set_attr "length" "2,3")])
+  [(set_attr "length" "2,3")
+   (set_attr "cc" "set_n")])
 
-(define_insn_and_split "*addhi3_zero_extend1_split"
+(define_insn "*addhi3_zero_extend1"
   [(set (match_operand:HI 0 "register_operand"                         "=r")
         (plus:HI (match_operand:HI 1 "register_operand"                 "0")
                  (zero_extend:HI (match_operand:QI 2 "register_operand" "r"))))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:HI (match_dup 1)
-                            (zero_extend:HI (match_dup 2))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*addhi3_zero_extend1"
-  [(set (match_operand:HI 0 "register_operand"                         "=r")
-        (plus:HI (match_operand:HI 1 "register_operand"                 "0")
-                 (zero_extend:HI (match_operand:QI 2 "register_operand" "r"))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "add %A0,%2\;adc %B0,__zero_reg__"
-  [(set_attr "length" "2")])
+  [(set_attr "length" "2")
+   (set_attr "cc" "set_n")])
 
-(define_insn_and_split "*addhi3.sign_extend1_split"
+(define_insn "*addhi3.sign_extend1"
   [(set (match_operand:HI 0 "register_operand"                         "=r")
         (plus:HI (sign_extend:HI (match_operand:QI 1 "register_operand" "r"))
                  (match_operand:HI 2 "register_operand"                 "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel
-      [(set (match_dup 0)
-            (plus:HI
-              (sign_extend:HI (match_dup 1))
-              (match_dup 2)))
-       (clobber (reg:CC REG_CC))])])
-
-
-(define_insn "*addhi3.sign_extend1"
-  [(set (match_operand:HI 0 "register_operand"                         "=r")
-        (plus:HI (sign_extend:HI (match_operand:QI 1 "register_operand" "r"))
-                 (match_operand:HI 2 "register_operand"                 "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return reg_overlap_mentioned_p (operands[0], operands[1])
       ? "mov __tmp_reg__,%1\;add %A0,%1\;adc %B0,__zero_reg__\;sbrc __tmp_reg__,7\;dec %B0"
       : "add %A0,%1\;adc %B0,__zero_reg__\;sbrc %1,7\;dec %B0";
   }
-  [(set_attr "length" "5")])
+  [(set_attr "length" "5")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*addhi3_zero_extend.const_split"
+(define_insn "*addhi3_zero_extend.const"
   [(set (match_operand:HI 0 "register_operand"                         "=d")
         (plus:HI (zero_extend:HI (match_operand:QI 1 "register_operand" "0"))
                  (match_operand:HI 2 "const_m255_to_m1_operand"         "Cn8")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:HI (zero_extend:HI (match_dup 1))
-                            (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*addhi3_zero_extend.const"
-  [(set (match_operand:HI 0 "register_operand"                         "=d")
-        (plus:HI (zero_extend:HI (match_operand:QI 1 "register_operand" "0"))
-                 (match_operand:HI 2 "const_m255_to_m1_operand"         "Cn8")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "subi %A0,%n2\;sbc %B0,%B0"
-  [(set_attr "length" "2")])
+  [(set_attr "length" "2")
+   (set_attr "cc" "set_czn")])
 
-(define_insn_and_split "*usum_widenqihi3_split"
+(define_insn "*usum_widenqihi3"
   [(set (match_operand:HI 0 "register_operand"                          "=r")
         (plus:HI (zero_extend:HI (match_operand:QI 1 "register_operand"  "0"))
                  (zero_extend:HI (match_operand:QI 2 "register_operand"  "r"))))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:HI
-                     (zero_extend:HI (match_dup 1))
-                     (zero_extend:HI (match_dup 2))))
-              (clobber (reg:CC REG_CC))])])
-
-
-(define_insn "*usum_widenqihi3"
-  [(set (match_operand:HI 0 "register_operand"                          "=r")
-        (plus:HI (zero_extend:HI (match_operand:QI 1 "register_operand"  "0"))
-                 (zero_extend:HI (match_operand:QI 2 "register_operand"  "r"))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "add %A0,%2\;clr %B0\;rol %B0"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*udiff_widenqihi3_split"
+(define_insn "*udiff_widenqihi3"
   [(set (match_operand:HI 0 "register_operand"                           "=r")
         (minus:HI (zero_extend:HI (match_operand:QI 1 "register_operand"  "0"))
                   (zero_extend:HI (match_operand:QI 2 "register_operand"  "r"))))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (minus:HI (zero_extend:HI (match_dup 1))
-                             (zero_extend:HI (match_dup 2))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*udiff_widenqihi3"
-  [(set (match_operand:HI 0 "register_operand"                           "=r")
-        (minus:HI (zero_extend:HI (match_operand:QI 1 "register_operand"  "0"))
-                  (zero_extend:HI (match_operand:QI 2 "register_operand"  "r"))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "sub %A0,%2\;sbc %B0,%B0"
-  [(set_attr "length" "2")])
+  [(set_attr "length" "2")
+   (set_attr "cc" "set_czn")])
     
-(define_insn_and_split "*addhi3_sp"
+(define_insn "*addhi3_sp"
   [(set (match_operand:HI 1 "stack_register_operand"           "=q")
         (plus:HI (match_operand:HI 2 "stack_register_operand"   "q")
                  (match_operand:HI 0 "avr_sp_immediate_operand" "Csp")))]
@@ -1573,63 +1273,39 @@
   {
     return avr_out_addto_sp (operands, NULL);
   }
-  ""
-  [(const_int 0)]
-  {
-    /* Do not attempt to split this pattern. This FAIL is necessary
-       to prevent the splitter from matching *add<ALL2>3_split, splitting
-       it, and then failing later because constraints don't match, as split
-       does not look at constraints. */
-    FAIL;
-  }
   [(set_attr "length" "6")
    (set_attr "adjust_len" "addto_sp")])
 
 ;; "*addhi3"
 ;; "*addhq3" "*adduhq3"
 ;; "*addha3" "*adduha3"
-(define_insn_and_split "*add<mode>3_split"
+(define_insn "*add<mode>3"
   [(set (match_operand:ALL2 0 "register_operand"                   "=??r,d,!w    ,d")
         (plus:ALL2 (match_operand:ALL2 1 "register_operand"          "%0,0,0     ,0")
                    (match_operand:ALL2 2 "nonmemory_or_const_operand" "r,s,IJ YIJ,n Ynn")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:ALL2 (match_dup 1)
-                              (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*add<mode>3"
-  [(set (match_operand:ALL2 0 "register_operand"                   "=??r,d,!w    ,d")
-        (plus:ALL2 (match_operand:ALL2 1 "register_operand"          "%0,0,0     ,0")
-                   (match_operand:ALL2 2 "nonmemory_or_const_operand" "r,s,IJ YIJ,n Ynn")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_plus (insn, operands);
   }
   [(set_attr "length" "2")
-   (set_attr "adjust_len" "plus")])
+   (set_attr "adjust_len" "plus")
+   (set_attr "cc" "plus")])
 
 ;; Adding a constant to NO_LD_REGS might have lead to a reload of
 ;; that constant to LD_REGS.  We don't add a scratch to *addhi3
 ;; itself because that insn is special to reload.
 
 (define_peephole2 ; addhi3_clobber
-  [(parallel [(set (match_operand:ALL2 0 "d_register_operand" "")
-                   (match_operand:ALL2 1 "const_operand" ""))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_operand:ALL2 2 "l_register_operand" "")
-                   (plus:ALL2 (match_dup 2)
-                              (match_dup 0)))
-              (clobber (reg:CC REG_CC))])]
+  [(set (match_operand:ALL2 0 "d_register_operand" "")
+        (match_operand:ALL2 1 "const_operand" ""))
+   (set (match_operand:ALL2 2 "l_register_operand" "")
+        (plus:ALL2 (match_dup 2)
+                   (match_dup 0)))]
   "peep2_reg_dead_p (2, operands[0])"
   [(parallel [(set (match_dup 2)
                    (plus:ALL2 (match_dup 2)
                               (match_dup 1)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])]
+              (clobber (match_dup 3))])]
   {
     operands[3] = simplify_gen_subreg (QImode, operands[0], <MODE>mode, 0);
   })
@@ -1640,319 +1316,153 @@
 (define_peephole2 ; addhi3_clobber
   [(parallel [(set (match_operand:ALL2 0 "l_register_operand" "")
                    (match_operand:ALL2 1 "const_operand" ""))
-              (clobber (match_operand:QI 2 "d_register_operand" ""))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_operand:ALL2 3 "l_register_operand" "")
-                   (plus:ALL2 (match_dup 3)
-                              (match_dup 0)))
-              (clobber (reg:CC REG_CC))])]
+              (clobber (match_operand:QI 2 "d_register_operand" ""))])
+   (set (match_operand:ALL2 3 "l_register_operand" "")
+        (plus:ALL2 (match_dup 3)
+                   (match_dup 0)))]
   "peep2_reg_dead_p (2, operands[0])"
   [(parallel [(set (match_dup 3)
                    (plus:ALL2 (match_dup 3)
                               (match_dup 1)))
-              (clobber (match_dup 2))
-              (clobber (reg:CC REG_CC))])])
+              (clobber (match_dup 2))])])
 
 ;; "addhi3_clobber"
 ;; "addhq3_clobber" "adduhq3_clobber"
 ;; "addha3_clobber" "adduha3_clobber"
-(define_insn_and_split "add<mode>3_clobber"
+(define_insn "add<mode>3_clobber"
   [(set (match_operand:ALL2 0 "register_operand"            "=!w    ,d    ,r")
         (plus:ALL2 (match_operand:ALL2 1 "register_operand"  "%0    ,0    ,0")
                    (match_operand:ALL2 2 "const_operand"     "IJ YIJ,n Ynn,n Ynn")))
    (clobber (match_scratch:QI 3                             "=X     ,X    ,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:ALL2 (match_dup 1)
-                              (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*add<mode>3_clobber"
-  [(set (match_operand:ALL2 0 "register_operand"            "=!w    ,d    ,r")
-        (plus:ALL2 (match_operand:ALL2 1 "register_operand"  "%0    ,0    ,0")
-                   (match_operand:ALL2 2 "const_operand"     "IJ YIJ,n Ynn,n Ynn")))
-   (clobber (match_scratch:QI 3                             "=X     ,X    ,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_plus (insn, operands);
   }
   [(set_attr "length" "4")
-   (set_attr "adjust_len" "plus")])
+   (set_attr "adjust_len" "plus")
+   (set_attr "cc" "plus")])
 
 
 ;; "addsi3"
 ;; "addsq3" "addusq3"
 ;; "addsa3" "addusa3"
-(define_insn_and_split "add<mode>3"
+(define_insn "add<mode>3"
   [(set (match_operand:ALL4 0 "register_operand"          "=??r,d ,r")
         (plus:ALL4 (match_operand:ALL4 1 "register_operand" "%0,0 ,0")
                    (match_operand:ALL4 2 "nonmemory_operand" "r,i ,n Ynn")))
    (clobber (match_scratch:QI 3                             "=X,X ,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:ALL4 (match_dup 1)
-                              (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*add<mode>3"
-  [(set (match_operand:ALL4 0 "register_operand"          "=??r,d ,r")
-        (plus:ALL4 (match_operand:ALL4 1 "register_operand" "%0,0 ,0")
-                   (match_operand:ALL4 2 "nonmemory_operand" "r,i ,n Ynn")))
-   (clobber (match_scratch:QI 3                             "=X,X ,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_plus (insn, operands);
   }
   [(set_attr "length" "4")
-   (set_attr "adjust_len" "plus")])
+   (set_attr "adjust_len" "plus")
+   (set_attr "cc" "plus")])
 
-(define_insn_and_split "*addpsi3_zero_extend.qi_split"
+(define_insn "*addpsi3_zero_extend.qi"
   [(set (match_operand:PSI 0 "register_operand"                          "=r")
         (plus:PSI (zero_extend:PSI (match_operand:QI 1 "register_operand" "r"))
                   (match_operand:PSI 2 "register_operand"                 "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:PSI (zero_extend:PSI (match_dup 1))
-                             (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*addpsi3_zero_extend.qi"
-  [(set (match_operand:PSI 0 "register_operand"                          "=r")
-        (plus:PSI (zero_extend:PSI (match_operand:QI 1 "register_operand" "r"))
-                  (match_operand:PSI 2 "register_operand"                 "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "add %A0,%A1\;adc %B0,__zero_reg__\;adc %C0,__zero_reg__"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "set_n")])
 
-(define_insn_and_split "*addpsi3_zero_extend.hi_split"
+(define_insn "*addpsi3_zero_extend.hi"
   [(set (match_operand:PSI 0 "register_operand"                          "=r")
         (plus:PSI (zero_extend:PSI (match_operand:HI 1 "register_operand" "r"))
                   (match_operand:PSI 2 "register_operand"                 "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:PSI (zero_extend:PSI (match_dup 1))
-                             (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*addpsi3_zero_extend.hi"
-  [(set (match_operand:PSI 0 "register_operand"                          "=r")
-        (plus:PSI (zero_extend:PSI (match_operand:HI 1 "register_operand" "r"))
-                  (match_operand:PSI 2 "register_operand"                 "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "add %A0,%A1\;adc %B0,%B1\;adc %C0,__zero_reg__"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "set_n")])
 
-(define_insn_and_split "*addpsi3_sign_extend.hi_split"
+(define_insn "*addpsi3_sign_extend.hi"
   [(set (match_operand:PSI 0 "register_operand"                          "=r")
         (plus:PSI (sign_extend:PSI (match_operand:HI 1 "register_operand" "r"))
                   (match_operand:PSI 2 "register_operand"                 "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:PSI (sign_extend:PSI (match_dup 1))
-                             (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*addpsi3_sign_extend.hi"
-  [(set (match_operand:PSI 0 "register_operand"                          "=r")
-        (plus:PSI (sign_extend:PSI (match_operand:HI 1 "register_operand" "r"))
-                  (match_operand:PSI 2 "register_operand"                 "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "add %A0,%1\;adc %B0,%B1\;adc %C0,__zero_reg__\;sbrc %B1,7\;dec %C0"
-  [(set_attr "length" "5")])
+  [(set_attr "length" "5")
+   (set_attr "cc" "set_n")])
 
-(define_insn_and_split "*addsi3_zero_extend_split"
+(define_insn "*addsi3_zero_extend"
   [(set (match_operand:SI 0 "register_operand"                         "=r")
         (plus:SI (zero_extend:SI (match_operand:QI 1 "register_operand" "r"))
                  (match_operand:SI 2 "register_operand"                 "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:SI (zero_extend:SI (match_dup 1))
-                            (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*addsi3_zero_extend"
-  [(set (match_operand:SI 0 "register_operand"                         "=r")
-        (plus:SI (zero_extend:SI (match_operand:QI 1 "register_operand" "r"))
-                 (match_operand:SI 2 "register_operand"                 "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "add %A0,%1\;adc %B0,__zero_reg__\;adc %C0,__zero_reg__\;adc %D0,__zero_reg__"
-  [(set_attr "length" "4")])
+  [(set_attr "length" "4")
+   (set_attr "cc" "set_n")])
 
-(define_insn_and_split "*addsi3_zero_extend.hi_split"
+(define_insn "*addsi3_zero_extend.hi"
   [(set (match_operand:SI 0 "register_operand"                         "=r")
         (plus:SI (zero_extend:SI (match_operand:HI 1 "register_operand" "r"))
                  (match_operand:SI 2 "register_operand"                 "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:SI (zero_extend:SI (match_dup 1))
-                            (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*addsi3_zero_extend.hi"
-  [(set (match_operand:SI 0 "register_operand"                         "=r")
-        (plus:SI (zero_extend:SI (match_operand:HI 1 "register_operand" "r"))
-                 (match_operand:SI 2 "register_operand"                 "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "add %A0,%1\;adc %B0,%B1\;adc %C0,__zero_reg__\;adc %D0,__zero_reg__"
-  [(set_attr "length" "4")])
+  [(set_attr "length" "4")
+   (set_attr "cc" "set_n")])
 
-(define_insn_and_split "addpsi3"
+(define_insn "addpsi3"
   [(set (match_operand:PSI 0 "register_operand"         "=??r,d ,d,r")
         (plus:PSI (match_operand:PSI 1 "register_operand" "%0,0 ,0,0")
                   (match_operand:PSI 2 "nonmemory_operand" "r,s ,n,n")))
    (clobber (match_scratch:QI 3                           "=X,X ,X,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:PSI (match_dup 1)
-                             (match_dup 2)))
-              (clobber (match_dup 3 ))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*addpsi3"
-  [(set (match_operand:PSI 0 "register_operand"         "=??r,d ,d,r")
-        (plus:PSI (match_operand:PSI 1 "register_operand" "%0,0 ,0,0")
-                  (match_operand:PSI 2 "nonmemory_operand" "r,s ,n,n")))
-   (clobber (match_scratch:QI 3                           "=X,X ,X,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_plus (insn, operands);
   }
   [(set_attr "length" "3")
-   (set_attr "adjust_len" "plus")])
+   (set_attr "adjust_len" "plus")
+   (set_attr "cc" "plus")])
 
-(define_insn_and_split "subpsi3"
+(define_insn "subpsi3"
   [(set (match_operand:PSI 0 "register_operand"           "=r")
         (minus:PSI (match_operand:PSI 1 "register_operand" "0")
                    (match_operand:PSI 2 "register_operand" "r")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (minus:PSI (match_dup 1)
-                              (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*subpsi3"
-  [(set (match_operand:PSI 0 "register_operand"           "=r")
-        (minus:PSI (match_operand:PSI 1 "register_operand" "0")
-                   (match_operand:PSI 2 "register_operand" "r")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "sub %0,%2\;sbc %B0,%B2\;sbc %C0,%C2"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "set_czn")])
 
-(define_insn_and_split "*subpsi3_zero_extend.qi_split"
+(define_insn "*subpsi3_zero_extend.qi"
   [(set (match_operand:PSI 0 "register_operand"                           "=r")
         (minus:PSI (match_operand:SI 1 "register_operand"                  "0")
                    (zero_extend:PSI (match_operand:QI 2 "register_operand" "r"))))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (minus:PSI (match_dup 1)
-                              (zero_extend:PSI (match_dup 2))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*subpsi3_zero_extend.qi"
-  [(set (match_operand:PSI 0 "register_operand"                           "=r")
-        (minus:PSI (match_operand:SI 1 "register_operand"                  "0")
-                   (zero_extend:PSI (match_operand:QI 2 "register_operand" "r"))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "sub %A0,%2\;sbc %B0,__zero_reg__\;sbc %C0,__zero_reg__"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "set_czn")])
 
-(define_insn_and_split "*subpsi3_zero_extend.hi_split"
+(define_insn "*subpsi3_zero_extend.hi"
   [(set (match_operand:PSI 0 "register_operand"                           "=r")
         (minus:PSI (match_operand:PSI 1 "register_operand"                 "0")
                    (zero_extend:PSI (match_operand:HI 2 "register_operand" "r"))))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (minus:PSI (match_dup 1)
-                              (zero_extend:PSI (match_dup 2))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*subpsi3_zero_extend.hi"
-  [(set (match_operand:PSI 0 "register_operand"                           "=r")
-        (minus:PSI (match_operand:PSI 1 "register_operand"                 "0")
-                   (zero_extend:PSI (match_operand:HI 2 "register_operand" "r"))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "sub %A0,%2\;sbc %B0,%B2\;sbc %C0,__zero_reg__"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "set_czn")])
 
-(define_insn_and_split "*subpsi3_sign_extend.hi_split"
+(define_insn "*subpsi3_sign_extend.hi"
   [(set (match_operand:PSI 0 "register_operand"                           "=r")
         (minus:PSI (match_operand:PSI 1 "register_operand"                 "0")
                    (sign_extend:PSI (match_operand:HI 2 "register_operand" "r"))))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (minus:PSI (match_dup 1)
-                              (sign_extend:PSI (match_dup 2))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*subpsi3_sign_extend.hi"
-  [(set (match_operand:PSI 0 "register_operand"                           "=r")
-        (minus:PSI (match_operand:PSI 1 "register_operand"                 "0")
-                   (sign_extend:PSI (match_operand:HI 2 "register_operand" "r"))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "sub %A0,%A2\;sbc %B0,%B2\;sbc %C0,__zero_reg__\;sbrc %B2,7\;inc %C0"
-  [(set_attr "length" "5")])
+  [(set_attr "length" "5")
+   (set_attr "cc" "set_czn")])
 
 ;-----------------------------------------------------------------------------
 ; sub bytes
 
 ;; "subqi3"
 ;; "subqq3" "subuqq3"
-(define_insn_and_split "sub<mode>3"
+(define_insn "sub<mode>3"
   [(set (match_operand:ALL1 0 "register_operand"                    "=??r,d    ,r  ,r  ,r  ,r")
         (minus:ALL1 (match_operand:ALL1 1 "register_operand"           "0,0    ,0  ,0  ,0  ,0")
                     (match_operand:ALL1 2 "nonmemory_or_const_operand" "r,n Ynn,Y01,Ym1,Y02,Ym2")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (minus:ALL1 (match_dup 1)
-                               (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*sub<mode>3"
-  [(set (match_operand:ALL1 0 "register_operand"                    "=??r,d    ,r  ,r  ,r  ,r")
-        (minus:ALL1 (match_operand:ALL1 1 "register_operand"           "0,0    ,0  ,0  ,0  ,0")
-                    (match_operand:ALL1 2 "nonmemory_or_const_operand" "r,n Ynn,Y01,Ym1,Y02,Ym2")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "@
 	sub %0,%2
 	subi %0,lo8(%2)
@@ -1960,155 +1470,78 @@
 	inc %0
 	dec %0\;dec %0
 	inc %0\;inc %0"
-  [(set_attr "length" "1,1,1,1,2,2")])
+  [(set_attr "length" "1,1,1,1,2,2")
+   (set_attr "cc" "set_czn,set_czn,set_vzn,set_vzn,set_vzn,set_vzn")])
 
 ;; "subhi3"
 ;; "subhq3" "subuhq3"
 ;; "subha3" "subuha3"
-(define_insn_and_split "sub<mode>3"
+(define_insn "sub<mode>3"
   [(set (match_operand:ALL2 0 "register_operand"                    "=??r,d    ,*r")
         (minus:ALL2 (match_operand:ALL2 1 "register_operand"           "0,0    ,0")
                     (match_operand:ALL2 2 "nonmemory_or_const_operand" "r,i Ynn,Ynn")))
    (clobber (match_scratch:QI 3                                       "=X,X    ,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (minus:ALL2 (match_dup 1)
-                               (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*sub<mode>3"
-  [(set (match_operand:ALL2 0 "register_operand"                    "=??r,d    ,*r")
-        (minus:ALL2 (match_operand:ALL2 1 "register_operand"           "0,0    ,0")
-                    (match_operand:ALL2 2 "nonmemory_or_const_operand" "r,i Ynn,Ynn")))
-   (clobber (match_scratch:QI 3                                       "=X,X    ,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_plus (insn, operands);
   }
-  [(set_attr "adjust_len" "plus")])
+  [(set_attr "adjust_len" "plus")
+   (set_attr "cc" "plus")])
 
-(define_insn_and_split "*subhi3_zero_extend1_split"
+(define_insn "*subhi3_zero_extend1"
   [(set (match_operand:HI 0 "register_operand"                          "=r")
         (minus:HI (match_operand:HI 1 "register_operand"                 "0")
                   (zero_extend:HI (match_operand:QI 2 "register_operand" "r"))))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (minus:HI (match_dup 1)
-                             (zero_extend:HI (match_dup 2))))
-             (clobber (reg:CC REG_CC))])])
-
-(define_insn "*subhi3_zero_extend1"
-  [(set (match_operand:HI 0 "register_operand"                          "=r")
-        (minus:HI (match_operand:HI 1 "register_operand"                 "0")
-                  (zero_extend:HI (match_operand:QI 2 "register_operand" "r"))))
-  (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "sub %A0,%2\;sbc %B0,__zero_reg__"
-  [(set_attr "length" "2")])
+  [(set_attr "length" "2")
+   (set_attr "cc" "set_czn")])
 
-(define_insn_and_split "*subhi3.sign_extend2_split"
+(define_insn "*subhi3.sign_extend2"
   [(set (match_operand:HI 0 "register_operand"                          "=r")
         (minus:HI (match_operand:HI 1 "register_operand"                 "0")
                   (sign_extend:HI (match_operand:QI 2 "register_operand" "r"))))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                  (minus:HI (match_dup 1)
-                            (sign_extend:HI (match_dup 2))))
-              (clobber (reg:CC REG_CC))])])
-
-
-(define_insn "*subhi3.sign_extend2"
-  [(set (match_operand:HI 0 "register_operand"                          "=r")
-        (minus:HI (match_operand:HI 1 "register_operand"                 "0")
-                  (sign_extend:HI (match_operand:QI 2 "register_operand" "r"))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return reg_overlap_mentioned_p (operands[0], operands[2])
       ? "mov __tmp_reg__,%2\;sub %A0,%2\;sbc %B0,__zero_reg__\;sbrc __tmp_reg__,7\;inc %B0"
       : "sub %A0,%2\;sbc %B0,__zero_reg__\;sbrc %2,7\;inc %B0";
   }
-  [(set_attr "length" "5")])
+  [(set_attr "length" "5")
+   (set_attr "cc" "clobber")])
 
 ;; "subsi3"
 ;; "subsq3" "subusq3"
 ;; "subsa3" "subusa3"
-(define_insn_and_split "sub<mode>3"
+(define_insn "sub<mode>3"
   [(set (match_operand:ALL4 0 "register_operand"                    "=??r,d    ,r")
         (minus:ALL4 (match_operand:ALL4 1 "register_operand"           "0,0    ,0")
                     (match_operand:ALL4 2 "nonmemory_or_const_operand" "r,n Ynn,Ynn")))
    (clobber (match_scratch:QI 3                                       "=X,X    ,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (minus:ALL4 (match_dup 1)
-                               (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*sub<mode>3"
-  [(set (match_operand:ALL4 0 "register_operand"                    "=??r,d    ,r")
-        (minus:ALL4 (match_operand:ALL4 1 "register_operand"           "0,0    ,0")
-                    (match_operand:ALL4 2 "nonmemory_or_const_operand" "r,n Ynn,Ynn")))
-   (clobber (match_scratch:QI 3                                       "=X,X    ,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_plus (insn, operands);
   }
-  [(set_attr "adjust_len" "plus")])
+  [(set_attr "adjust_len" "plus")
+   (set_attr "cc" "plus")])
 
-(define_insn_and_split "*subsi3_zero_extend_split"
+(define_insn "*subsi3_zero_extend"
   [(set (match_operand:SI 0 "register_operand"                          "=r")
         (minus:SI (match_operand:SI 1 "register_operand"                 "0")
                   (zero_extend:SI (match_operand:QI 2 "register_operand" "r"))))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (minus:SI (match_dup 1)
-                             (zero_extend:SI (match_dup 2))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*subsi3_zero_extend"
-  [(set (match_operand:SI 0 "register_operand"                          "=r")
-        (minus:SI (match_operand:SI 1 "register_operand"                 "0")
-                  (zero_extend:SI (match_operand:QI 2 "register_operand" "r"))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "sub %A0,%2\;sbc %B0,__zero_reg__\;sbc %C0,__zero_reg__\;sbc %D0,__zero_reg__"
   [(set_attr "length" "4")
-   ])
+   (set_attr "cc" "set_czn")])
 
-(define_insn_and_split "*subsi3_zero_extend.hi_split"
+(define_insn "*subsi3_zero_extend.hi"
   [(set (match_operand:SI 0 "register_operand"                          "=r")
         (minus:SI (match_operand:SI 1 "register_operand"                 "0")
                   (zero_extend:SI (match_operand:HI 2 "register_operand" "r"))))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (minus:SI (match_dup 1)
-                             (zero_extend:SI (match_dup 2))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*subsi3_zero_extend.hi"
-  [(set (match_operand:SI 0 "register_operand"                          "=r")
-        (minus:SI (match_operand:SI 1 "register_operand"                 "0")
-                  (zero_extend:SI (match_operand:HI 2 "register_operand" "r"))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "sub %A0,%2\;sbc %B0,%B2\;sbc %C0,__zero_reg__\;sbc %D0,__zero_reg__"
-  [(set_attr "length" "4")])
+  [(set_attr "length" "4")
+   (set_attr "cc" "set_czn")])
 
 ;******************************************************************************
 ; mul
@@ -2126,28 +1559,16 @@
       }
   })
 
-(define_insn_and_split "*mulqi3_enh_split"
+(define_insn "*mulqi3_enh"
   [(set (match_operand:QI 0 "register_operand" "=r")
         (mult:QI (match_operand:QI 1 "register_operand" "r")
                  (match_operand:QI 2 "register_operand" "r")))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (mult:QI (match_dup 1)
-                            (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*mulqi3_enh"
-  [(set (match_operand:QI 0 "register_operand" "=r")
-        (mult:QI (match_operand:QI 1 "register_operand" "r")
-                 (match_operand:QI 2 "register_operand" "r")))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "mul %1,%2
 	mov %0,r0
 	clr r1"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "clobber")])
 
 (define_expand "mulqi3_call"
   [(set (reg:QI 24) (match_operand:QI 1 "register_operand" ""))
@@ -2160,392 +1581,189 @@
     avr_fix_inputs (operands, 1 << 2, regmask (QImode, 24));
   })
 
-(define_insn_and_split "*mulqi3_call_split"
+(define_insn "*mulqi3_call"
   [(set (reg:QI 24) (mult:QI (reg:QI 24) (reg:QI 22)))
    (clobber (reg:QI 22))]
   "!AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:QI 24) (mult:QI (reg:QI 24) (reg:QI 22)))
-              (clobber (reg:QI 22))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*mulqi3_call"
-  [(set (reg:QI 24) (mult:QI (reg:QI 24) (reg:QI 22)))
-   (clobber (reg:QI 22))
-   (clobber (reg:CC REG_CC))]
-  "!AVR_HAVE_MUL && reload_completed"
   "%~call __mulqi3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;; "umulqi3_highpart"
 ;; "smulqi3_highpart"
-
-(define_insn_and_split "<extend_su>mulqi3_highpart"
+(define_insn "<extend_su>mulqi3_highpart"
   [(set (match_operand:QI 0 "register_operand"                                       "=r")
         (truncate:QI
          (lshiftrt:HI (mult:HI (any_extend:HI (match_operand:QI 1 "register_operand" "<mul_r_d>"))
                                (any_extend:HI (match_operand:QI 2 "register_operand" "<mul_r_d>")))
                       (const_int 8))))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (truncate:QI
-                    (lshiftrt:HI (mult:HI (any_extend:HI (match_dup 1))
-                                          (any_extend:HI (match_dup 2)))
-                                 (const_int 8))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<extend_su>mulqi3_highpart"
-  [(set (match_operand:QI 0 "register_operand"                                       "=r")
-        (truncate:QI
-         (lshiftrt:HI (mult:HI (any_extend:HI (match_operand:QI 1 "register_operand" "<mul_r_d>"))
-                               (any_extend:HI (match_operand:QI 2 "register_operand" "<mul_r_d>")))
-                      (const_int 8))))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "mul<extend_s> %1,%2
 	mov %0,r1
 	clr __zero_reg__"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "clobber")])
 
 
 ;; Used when expanding div or mod inline for some special values
-(define_insn_and_split "*subqi3.ashiftrt7_split"
+(define_insn "*subqi3.ashiftrt7"
   [(set (match_operand:QI 0 "register_operand"                       "=r")
         (minus:QI (match_operand:QI 1 "register_operand"              "0")
                   (ashiftrt:QI (match_operand:QI 2 "register_operand" "r")
                                (const_int 7))))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (minus:QI (match_dup 1)
-                             (ashiftrt:QI (match_dup 2)
-                                          (const_int 7))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*subqi3.ashiftrt7"
-  [(set (match_operand:QI 0 "register_operand"                       "=r")
-        (minus:QI (match_operand:QI 1 "register_operand"              "0")
-                  (ashiftrt:QI (match_operand:QI 2 "register_operand" "r")
-                               (const_int 7))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "sbrc %2,7\;inc %0"
-  [(set_attr "length" "2")])
+  [(set_attr "length" "2")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*addqi3.lt0_split"
+(define_insn "*addqi3.lt0"
   [(set (match_operand:QI 0 "register_operand"                 "=r")
         (plus:QI (lt:QI (match_operand:QI 1 "register_operand"  "r")
                         (const_int 0))
                  (match_operand:QI 2 "register_operand"         "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:QI (lt:QI (match_dup 1)
-                                   (const_int 0))
-                            (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*addqi3.lt0"
-  [(set (match_operand:QI 0 "register_operand"                 "=r")
-        (plus:QI (lt:QI (match_operand:QI 1 "register_operand"  "r")
-                        (const_int 0))
-                 (match_operand:QI 2 "register_operand"         "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "sbrc %1,7\;inc %0"
-  [(set_attr "length" "2")])
+  [(set_attr "length" "2")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*addhi3.lt0_split"
+(define_insn "*addhi3.lt0"
   [(set (match_operand:HI 0 "register_operand"                   "=w,r")
         (plus:HI (lt:HI (match_operand:QI 1 "register_operand"    "r,r")
                         (const_int 0))
                  (match_operand:HI 2 "register_operand"           "0,0")))
    (clobber (match_scratch:QI 3                                  "=X,&1"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:HI (lt:HI (match_dup 1)
-                                   (const_int 0))
-                            (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*addhi3.lt0"
-  [(set (match_operand:HI 0 "register_operand"                   "=w,r")
-        (plus:HI (lt:HI (match_operand:QI 1 "register_operand"    "r,r")
-                        (const_int 0))
-                 (match_operand:HI 2 "register_operand"           "0,0")))
-   (clobber (match_scratch:QI 3                                  "=X,&1"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "@
 	sbrc %1,7\;adiw %0,1
 	lsl %1\;adc %A0,__zero_reg__\;adc %B0,__zero_reg__"
-  [(set_attr "length" "2,3")])
+  [(set_attr "length" "2,3")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*addpsi3.lt0_split"
+(define_insn "*addpsi3.lt0"
   [(set (match_operand:PSI 0 "register_operand"                         "=r")
         (plus:PSI (lshiftrt:PSI (match_operand:PSI 1 "register_operand"  "r")
                                 (const_int 23))
                  (match_operand:PSI 2 "register_operand"                 "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:PSI (lshiftrt:PSI (match_dup 1)
-                                           (const_int 23))
-                             (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*addpsi3.lt0"
-  [(set (match_operand:PSI 0 "register_operand"                         "=r")
-        (plus:PSI (lshiftrt:PSI (match_operand:PSI 1 "register_operand"  "r")
-                                (const_int 23))
-                 (match_operand:PSI 2 "register_operand"                 "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "mov __tmp_reg__,%C1\;lsl __tmp_reg__
 	adc %A0,__zero_reg__\;adc %B0,__zero_reg__\;adc %C0,__zero_reg__"
-  [(set_attr "length" "5")])
+  [(set_attr "length" "5")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*addsi3.lt0_split"
+(define_insn "*addsi3.lt0"
   [(set (match_operand:SI 0 "register_operand"                       "=r")
         (plus:SI (lshiftrt:SI (match_operand:SI 1 "register_operand"  "r")
                               (const_int 31))
                  (match_operand:SI 2 "register_operand"               "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:SI (lshiftrt:SI (match_dup 1)
-                                         (const_int 31))
-                            (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*addsi3.lt0"
-  [(set (match_operand:SI 0 "register_operand"                       "=r")
-        (plus:SI (lshiftrt:SI (match_operand:SI 1 "register_operand"  "r")
-                              (const_int 31))
-                 (match_operand:SI 2 "register_operand"               "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "mov __tmp_reg__,%D1\;lsl __tmp_reg__
 	adc %A0,__zero_reg__\;adc %B0,__zero_reg__\;adc %C0,__zero_reg__\;adc %D0,__zero_reg__"
-  [(set_attr "length" "6")])
+  [(set_attr "length" "6")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*umulqihi3.call_split"
+(define_insn "*umulqihi3.call"
   [(set (reg:HI 24)
         (mult:HI (zero_extend:HI (reg:QI 22))
                  (zero_extend:HI (reg:QI 24))))
    (clobber (reg:QI 21))
    (clobber (reg:HI 22))]
   "!AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 24)
-                   (mult:HI (zero_extend:HI (reg:QI 22))
-                   (zero_extend:HI (reg:QI 24))))
-              (clobber (reg:QI 21))
-              (clobber (reg:HI 22))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*umulqihi3.call"
-  [(set (reg:HI 24)
-        (mult:HI (zero_extend:HI (reg:QI 22))
-                 (zero_extend:HI (reg:QI 24))))
-   (clobber (reg:QI 21))
-   (clobber (reg:HI 22))
-   (clobber (reg:CC REG_CC))]
-  "!AVR_HAVE_MUL && reload_completed"
   "%~call __umulqihi3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;; "umulqihi3"
 ;; "mulqihi3"
-
-(define_insn_and_split "<extend_u>mulqihi3_split"
+(define_insn "<extend_u>mulqihi3"
   [(set (match_operand:HI 0 "register_operand"                         "=r")
         (mult:HI (any_extend:HI (match_operand:QI 1 "register_operand" "<mul_r_d>"))
                  (any_extend:HI (match_operand:QI 2 "register_operand" "<mul_r_d>"))))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (mult:HI (any_extend:HI (match_dup 1))
-                            (any_extend:HI (match_dup 2))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "<extend_u>mulqihi3"
-  [(set (match_operand:HI 0 "register_operand"                         "=r")
-        (mult:HI (any_extend:HI (match_operand:QI 1 "register_operand" "<mul_r_d>"))
-                 (any_extend:HI (match_operand:QI 2 "register_operand" "<mul_r_d>"))))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "mul<extend_s> %1,%2
 	movw %0,r0
 	clr __zero_reg__"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "usmulqihi3"
+(define_insn "usmulqihi3"
   [(set (match_operand:HI 0 "register_operand"                         "=r")
         (mult:HI (zero_extend:HI (match_operand:QI 1 "register_operand" "a"))
                  (sign_extend:HI (match_operand:QI 2 "register_operand" "a"))))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (mult:HI (zero_extend:HI (match_dup 1))
-                            (sign_extend:HI (match_dup 2))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*usmulqihi3"
-  [(set (match_operand:HI 0 "register_operand"                         "=r")
-        (mult:HI (zero_extend:HI (match_operand:QI 1 "register_operand" "a"))
-                 (sign_extend:HI (match_operand:QI 2 "register_operand" "a"))))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "mulsu %2,%1
 	movw %0,r0
 	clr __zero_reg__"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "clobber")])
 
 ;; Above insn is not canonicalized by insn combine, so here is a version with
 ;; operands swapped.
-(define_insn_and_split "*sumulqihi3_split"
-  [(set (match_operand:HI 0 "register_operand"                         "=r")
-        (mult:HI (sign_extend:HI (match_operand:QI 1 "register_operand" "a"))
-                 (zero_extend:HI (match_operand:QI 2 "register_operand" "a"))))]
-  "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (mult:HI (sign_extend:HI (match_dup 1))
-                            (zero_extend:HI (match_dup 2))))
-              (clobber (reg:CC REG_CC))])])
 
 (define_insn "*sumulqihi3"
   [(set (match_operand:HI 0 "register_operand"                         "=r")
         (mult:HI (sign_extend:HI (match_operand:QI 1 "register_operand" "a"))
-                 (zero_extend:HI (match_operand:QI 2 "register_operand" "a"))))
-    (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
+                 (zero_extend:HI (match_operand:QI 2 "register_operand" "a"))))]
+  "AVR_HAVE_MUL"
   "mulsu %1,%2
 	movw %0,r0
 	clr __zero_reg__"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "clobber")])
 
 ;; One-extend operand 1
 
-(define_insn_and_split "*osmulqihi3_split"
+(define_insn "*osmulqihi3"
   [(set (match_operand:HI 0 "register_operand"                                        "=&r")
         (mult:HI (not:HI (zero_extend:HI (not:QI (match_operand:QI 1 "register_operand" "a"))))
                  (sign_extend:HI (match_operand:QI 2 "register_operand"                 "a"))))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (mult:HI (not:HI (zero_extend:HI (not:QI (match_dup 1))))
-                            (sign_extend:HI (match_dup 2))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*osmulqihi3"
-  [(set (match_operand:HI 0 "register_operand"                                        "=&r")
-        (mult:HI (not:HI (zero_extend:HI (not:QI (match_operand:QI 1 "register_operand" "a"))))
-                 (sign_extend:HI (match_operand:QI 2 "register_operand"                 "a"))))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "mulsu %2,%1
 	movw %0,r0
 	sub %B0,%2
 	clr __zero_reg__"
-  [(set_attr "length" "4")])
+  [(set_attr "length" "4")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*oumulqihi3_split"
+(define_insn "*oumulqihi3"
   [(set (match_operand:HI 0 "register_operand"                                        "=&r")
         (mult:HI (not:HI (zero_extend:HI (not:QI (match_operand:QI 1 "register_operand" "r"))))
                  (zero_extend:HI (match_operand:QI 2 "register_operand"                 "r"))))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (mult:HI (not:HI (zero_extend:HI (not:QI (match_dup 1))))
-                            (zero_extend:HI (match_dup 2))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*oumulqihi3"
-  [(set (match_operand:HI 0 "register_operand"                                        "=&r")
-        (mult:HI (not:HI (zero_extend:HI (not:QI (match_operand:QI 1 "register_operand" "r"))))
-                 (zero_extend:HI (match_operand:QI 2 "register_operand"                 "r"))))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "mul %2,%1
 	movw %0,r0
 	sub %B0,%2
 	clr __zero_reg__"
-  [(set_attr "length" "4")])
+  [(set_attr "length" "4")
+   (set_attr "cc" "clobber")])
 
 ;******************************************************************************
 ; multiply-add/sub QI: $0 = $3 +/- $1*$2
 ;******************************************************************************
 
-(define_insn_and_split "*maddqi4_split"
+(define_insn "*maddqi4"
   [(set (match_operand:QI 0 "register_operand"                  "=r")
         (plus:QI (mult:QI (match_operand:QI 1 "register_operand" "r")
                           (match_operand:QI 2 "register_operand" "r"))
                  (match_operand:QI 3 "register_operand"          "0")))]
 
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:QI (mult:QI (match_dup 1)
-                                     (match_dup 2))
-                            (match_dup 3)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*maddqi4"
-  [(set (match_operand:QI 0 "register_operand"                  "=r")
-        (plus:QI (mult:QI (match_operand:QI 1 "register_operand" "r")
-                          (match_operand:QI 2 "register_operand" "r"))
-                 (match_operand:QI 3 "register_operand"          "0")))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "mul %1,%2
 	add %A0,r0
 	clr __zero_reg__"
-  [(set_attr "length" "4")])
+  [(set_attr "length" "4")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*msubqi4_split"
+(define_insn "*msubqi4"
   [(set (match_operand:QI 0 "register_operand"                   "=r")
         (minus:QI (match_operand:QI 3 "register_operand"          "0")
                   (mult:QI (match_operand:QI 1 "register_operand" "r")
                            (match_operand:QI 2 "register_operand" "r"))))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (minus:QI (match_dup 3)
-                             (mult:QI (match_dup 1)
-                                      (match_dup 2))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*msubqi4"
-  [(set (match_operand:QI 0 "register_operand"                   "=r")
-        (minus:QI (match_operand:QI 3 "register_operand"          "0")
-                  (mult:QI (match_operand:QI 1 "register_operand" "r")
-                           (match_operand:QI 2 "register_operand" "r"))))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "mul %1,%2
 	sub %A0,r0
 	clr __zero_reg__"
-  [(set_attr "length" "4")])
+  [(set_attr "length" "4")
+   (set_attr "cc" "clobber")])
 
 (define_insn_and_split "*maddqi4.const"
   [(set (match_operand:QI 0 "register_operand"                   "=r")
@@ -2603,87 +1821,42 @@
 
 ;; "*maddqihi4"
 ;; "*umaddqihi4"
-(define_insn_and_split "*<extend_u>maddqihi4_split"
+(define_insn "*<extend_u>maddqihi4"
   [(set (match_operand:HI 0 "register_operand"                                  "=r")
         (plus:HI (mult:HI (any_extend:HI (match_operand:QI 1 "register_operand" "<mul_r_d>"))
                           (any_extend:HI (match_operand:QI 2 "register_operand" "<mul_r_d>")))
                  (match_operand:HI 3 "register_operand"                         "0")))]
 
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:HI (mult:HI (any_extend:HI (match_dup 1))
-                                     (any_extend:HI (match_dup 2)))
-                            (match_dup 3)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<extend_u>maddqihi4"
-  [(set (match_operand:HI 0 "register_operand"                                  "=r")
-        (plus:HI (mult:HI (any_extend:HI (match_operand:QI 1 "register_operand" "<mul_r_d>"))
-                          (any_extend:HI (match_operand:QI 2 "register_operand" "<mul_r_d>")))
-                 (match_operand:HI 3 "register_operand"                         "0")))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "mul<extend_s> %1,%2
 	add %A0,r0
 	adc %B0,r1
 	clr __zero_reg__"
-  [(set_attr "length" "4")])
+  [(set_attr "length" "4")
+   (set_attr "cc" "clobber")])
 
 ;; "*msubqihi4"
 ;; "*umsubqihi4"
-(define_insn_and_split "*<extend_u>msubqihi4_split"
+(define_insn "*<extend_u>msubqihi4"
   [(set (match_operand:HI 0 "register_operand"                                  "=r")
         (minus:HI (match_operand:HI 3 "register_operand"                         "0")
                   (mult:HI (any_extend:HI (match_operand:QI 1 "register_operand" "<mul_r_d>"))
                            (any_extend:HI (match_operand:QI 2 "register_operand" "<mul_r_d>")))))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (minus:HI (match_dup 3)
-                             (mult:HI (any_extend:HI (match_dup 1))
-                                      (any_extend:HI (match_dup 2)))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<extend_u>msubqihi4"
-  [(set (match_operand:HI 0 "register_operand"                                  "=r")
-        (minus:HI (match_operand:HI 3 "register_operand"                         "0")
-                  (mult:HI (any_extend:HI (match_operand:QI 1 "register_operand" "<mul_r_d>"))
-                           (any_extend:HI (match_operand:QI 2 "register_operand" "<mul_r_d>")))))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "mul<extend_s> %1,%2
 	sub %A0,r0
 	sbc %B0,r1
 	clr __zero_reg__"
-  [(set_attr "length" "4")])
+  [(set_attr "length" "4")
+   (set_attr "cc" "clobber")])
 
 ;; "*usmaddqihi4"
 ;; "*sumaddqihi4"
-(define_insn_and_split "*<any_extend:extend_su><any_extend2:extend_su>msubqihi4_split"
-  [(set (match_operand:HI 0 "register_operand"                                  "=r")
-        (plus:HI (mult:HI (any_extend:HI  (match_operand:QI 1 "register_operand" "a"))
-                          (any_extend2:HI (match_operand:QI 2 "register_operand" "a")))
-                 (match_operand:HI 3 "register_operand"                          "0")))]
-  "AVR_HAVE_MUL
-   && reload_completed
-   && <any_extend:CODE> != <any_extend2:CODE>"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (plus:HI (mult:HI (any_extend:HI  (match_dup 1))
-                                     (any_extend2:HI (match_dup 2)))
-                            (match_dup 3)))
-              (clobber (reg:CC REG_CC))])])
-
 (define_insn "*<any_extend:extend_su><any_extend2:extend_su>msubqihi4"
   [(set (match_operand:HI 0 "register_operand"                                  "=r")
         (plus:HI (mult:HI (any_extend:HI  (match_operand:QI 1 "register_operand" "a"))
                           (any_extend2:HI (match_operand:QI 2 "register_operand" "a")))
-                 (match_operand:HI 3 "register_operand"                          "0")))
-   (clobber (reg:CC REG_CC))]
+                 (match_operand:HI 3 "register_operand"                          "0")))]
   "AVR_HAVE_MUL
    && reload_completed
    && <any_extend:CODE> != <any_extend2:CODE>"
@@ -2693,32 +1866,16 @@
 
     return "add %A0,r0\;adc %B0,r1\;clr __zero_reg__";
   }
-  [(set_attr "length" "4")])
+  [(set_attr "length" "4")
+   (set_attr "cc" "clobber")])
 
 ;; "*usmsubqihi4"
 ;; "*sumsubqihi4"
-(define_insn_and_split "*<any_extend:extend_su><any_extend2:extend_su>msubqihi4_split"
-  [(set (match_operand:HI 0 "register_operand"                                   "=r")
-        (minus:HI (match_operand:HI 3 "register_operand"                          "0")
-                  (mult:HI (any_extend:HI  (match_operand:QI 1 "register_operand" "a"))
-                           (any_extend2:HI (match_operand:QI 2 "register_operand" "a")))))]
-  "AVR_HAVE_MUL
-   && reload_completed
-   && <any_extend:CODE> != <any_extend2:CODE>"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (minus:HI (match_dup 3)
-                             (mult:HI (any_extend:HI  (match_dup 1))
-                                      (any_extend2:HI (match_dup 2)))))
-              (clobber (reg:CC REG_CC))])])
-
 (define_insn "*<any_extend:extend_su><any_extend2:extend_su>msubqihi4"
   [(set (match_operand:HI 0 "register_operand"                                   "=r")
         (minus:HI (match_operand:HI 3 "register_operand"                          "0")
                   (mult:HI (any_extend:HI  (match_operand:QI 1 "register_operand" "a"))
-                           (any_extend2:HI (match_operand:QI 2 "register_operand" "a")))))
-   (clobber (reg:CC REG_CC))]
+                           (any_extend2:HI (match_operand:QI 2 "register_operand" "a")))))]
   "AVR_HAVE_MUL
    && reload_completed
    && <any_extend:CODE> != <any_extend2:CODE>"
@@ -2728,7 +1885,8 @@
 
     return "sub %A0,r0\;sbc %B0,r1\;clr __zero_reg__";
   }
-  [(set_attr "length" "4")])
+  [(set_attr "length" "4")
+   (set_attr "cc" "clobber")])
 
 ;; Handle small constants
 
@@ -2972,28 +2130,17 @@
 ;; The EXTEND of $1 only appears in combine, we don't see it in expand so that
 ;; expand decides to use ASHIFT instead of MUL because ASHIFT costs are cheaper
 ;; at that time.  Fix that.
-(define_insn_and_split "*ashiftqihi2.signx.1_split"
-  [(set (match_operand:HI 0 "register_operand"                           "=r,*r")
-        (ashift:HI (sign_extend:HI (match_operand:QI 1 "register_operand" "0,r"))
-                   (const_int 1)))]
-  ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ashift:HI (sign_extend:HI (match_dup 1))
-                              (const_int 1)))
-              (clobber (reg:CC REG_CC))])])
 
 (define_insn "*ashiftqihi2.signx.1"
   [(set (match_operand:HI 0 "register_operand"                           "=r,*r")
         (ashift:HI (sign_extend:HI (match_operand:QI 1 "register_operand" "0,r"))
-                   (const_int 1)))
-   (clobber (reg:CC REG_CC)) ]
-  "reload_completed"
+                   (const_int 1)))]
+  ""
   "@
 	lsl %A0\;sbc %B0,%B0
 	mov %A0,%1\;lsl %A0\;sbc %B0,%B0"
-  [(set_attr "length" "2,3")])
+  [(set_attr "length" "2,3")
+   (set_attr "cc" "clobber")])
 
 (define_insn_and_split "*ashifthi3.signx.const"
   [(set (match_operand:HI 0 "register_operand"                           "=r")
@@ -3053,83 +2200,47 @@
 ; mul HI: $1 = sign-/zero-/one-extend, $2 = reg
 ;******************************************************************************
 
-(define_insn_and_split "mulsqihi3"
+(define_insn "mulsqihi3"
   [(set (match_operand:HI 0 "register_operand"                        "=&r")
         (mult:HI (sign_extend:HI (match_operand:QI 1 "register_operand" "a"))
                  (match_operand:HI 2 "register_operand"                 "a")))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (mult:HI (sign_extend:HI (match_dup 1))
-                            (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*mulsqihi3"
-  [(set (match_operand:HI 0 "register_operand"                        "=&r")
-        (mult:HI (sign_extend:HI (match_operand:QI 1 "register_operand" "a"))
-                 (match_operand:HI 2 "register_operand"                 "a")))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "mulsu %1,%A2
 	movw %0,r0
 	mul %1,%B2
 	add %B0,r0
 	clr __zero_reg__"
-  [(set_attr "length" "5")])
+  [(set_attr "length" "5")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "muluqihi3"
+(define_insn "muluqihi3"
   [(set (match_operand:HI 0 "register_operand"                        "=&r")
         (mult:HI (zero_extend:HI (match_operand:QI 1 "register_operand" "r"))
                  (match_operand:HI 2 "register_operand"                 "r")))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (mult:HI (zero_extend:HI (match_dup 1))
-                            (match_dup 2)))
-               (clobber (reg:CC REG_CC))])])
-
-(define_insn "*muluqihi3"
-  [(set (match_operand:HI 0 "register_operand"                        "=&r")
-        (mult:HI (zero_extend:HI (match_operand:QI 1 "register_operand" "r"))
-                 (match_operand:HI 2 "register_operand"                 "r")))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "mul %1,%A2
 	movw %0,r0
 	mul %1,%B2
 	add %B0,r0
 	clr __zero_reg__"
-  [(set_attr "length" "5")])
+  [(set_attr "length" "5")
+   (set_attr "cc" "clobber")])
 
 ;; one-extend operand 1
 
-(define_insn_and_split "muloqihi3"
+(define_insn "muloqihi3"
   [(set (match_operand:HI 0 "register_operand"                                        "=&r")
         (mult:HI (not:HI (zero_extend:HI (not:QI (match_operand:QI 1 "register_operand" "r"))))
                  (match_operand:HI 2 "register_operand"                                 "r")))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (mult:HI (not:HI (zero_extend:HI (not:QI (match_dup 1))))
-                            (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*muloqihi3"
-  [(set (match_operand:HI 0 "register_operand"                                        "=&r")
-        (mult:HI (not:HI (zero_extend:HI (not:QI (match_operand:QI 1 "register_operand" "r"))))
-                 (match_operand:HI 2 "register_operand"                                 "r")))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "mul %1,%A2
 	movw %0,r0
 	mul %1,%B2
 	add %B0,r0
 	sub %B0,%A2
 	clr __zero_reg__"
-  [(set_attr "length" "6")])
+  [(set_attr "length" "6")
+   (set_attr "cc" "clobber")])
 
 ;******************************************************************************
 
@@ -3177,30 +2288,18 @@
       operands[2] = force_reg (HImode, operands[2]);
   })
 
-(define_insn_and_split "*mulhi3_enh_split"
+(define_insn "*mulhi3_enh"
   [(set (match_operand:HI 0 "register_operand" "=&r")
         (mult:HI (match_operand:HI 1 "register_operand" "r")
                  (match_operand:HI 2 "register_operand" "r")))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (mult:HI (match_dup 1)
-                            (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*mulhi3_enh"
-  [(set (match_operand:HI 0 "register_operand" "=&r")
-        (mult:HI (match_operand:HI 1 "register_operand" "r")
-                 (match_operand:HI 2 "register_operand" "r")))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   {
     return REGNO (operands[1]) == REGNO (operands[2])
            ? "mul %A1,%A1\;movw %0,r0\;mul %A1,%B1\;add %B0,r0\;add %B0,r0\;clr r1"
            : "mul %A1,%A2\;movw %0,r0\;mul %A1,%B2\;add %B0,r0\;mul %B1,%A2\;add %B0,r0\;clr r1";
   }
-  [(set_attr "length" "7")])
+  [(set_attr "length" "7")
+   (set_attr "cc" "clobber")])
 
 (define_expand "mulhi3_call"
   [(set (reg:HI 24) (match_operand:HI 1 "register_operand" ""))
@@ -3216,26 +2315,14 @@
   })
 
 
-(define_insn_and_split "*mulhi3_call_split"
+(define_insn "*mulhi3_call"
   [(set (reg:HI 24) (mult:HI (reg:HI 24) (reg:HI 22)))
    (clobber (reg:HI 22))
    (clobber (reg:QI 21))]
   "!AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 24) (mult:HI (reg:HI 24) (reg:HI 22)))
-              (clobber (reg:HI 22))
-              (clobber (reg:QI 21))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*mulhi3_call"
-  [(set (reg:HI 24) (mult:HI (reg:HI 24) (reg:HI 22)))
-   (clobber (reg:HI 22))
-   (clobber (reg:QI 21))
-   (clobber (reg:CC REG_CC))]
-  "!AVR_HAVE_MUL && reload_completed"
   "%~call __mulhi3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;; To support widening multiplication with constant we postpone
 ;; expanding to the implicit library call until post combine and
@@ -3556,144 +2643,67 @@
     avr_fix_inputs (operands, 1 << 2, regmask (HImode, 18));
   })
 
-(define_insn_and_split "*mulsi3_call_split"
-  [(set (reg:SI 22)
-        (mult:SI (reg:SI 22)
-                 (reg:SI 18)))
-   (clobber (reg:HI 26))]
-  "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:SI 22)
-                   (mult:SI (reg:SI 22)
-                            (reg:SI 18)))
-              (clobber (reg:HI 26))
-              (clobber (reg:CC REG_CC))])])
 
 (define_insn "*mulsi3_call"
   [(set (reg:SI 22)
         (mult:SI (reg:SI 22)
                  (reg:SI 18)))
-   (clobber (reg:HI 26))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
+   (clobber (reg:HI 26))]
+  "AVR_HAVE_MUL"
   "%~call __mulsi3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;; "*mulhisi3_call"
 ;; "*umulhisi3_call"
-(define_insn_and_split "*<extend_u>mulhisi3_call_split"
+(define_insn "*<extend_u>mulhisi3_call"
   [(set (reg:SI 22)
         (mult:SI (any_extend:SI (reg:HI 18))
                  (any_extend:SI (reg:HI 26))))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:SI 22)
-                   (mult:SI (any_extend:SI (reg:HI 18))
-                            (any_extend:SI (reg:HI 26))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<extend_u>mulhisi3_call"
-  [(set (reg:SI 22)
-        (mult:SI (any_extend:SI (reg:HI 18))
-                 (any_extend:SI (reg:HI 26))))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "%~call __<extend_u>mulhisi3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;; "*umulhi3_highpart_call"
 ;; "*smulhi3_highpart_call"
-(define_insn_and_split "*<extend_su>mulhi3_highpart_call_split"
+(define_insn "*<extend_su>mulhi3_highpart_call"
   [(set (reg:HI 24)
         (truncate:HI (lshiftrt:SI (mult:SI (any_extend:SI (reg:HI 18))
                                            (any_extend:SI (reg:HI 26)))
                                   (const_int 16))))
    (clobber (reg:HI 22))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 24)
-                   (truncate:HI (lshiftrt:SI (mult:SI (any_extend:SI (reg:HI 18))
-                                                      (any_extend:SI (reg:HI 26)))
-                                             (const_int 16))))
-              (clobber (reg:HI 22))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*<extend_su>mulhi3_highpart_call"
-  [(set (reg:HI 24)
-        (truncate:HI (lshiftrt:SI (mult:SI (any_extend:SI (reg:HI 18))
-                                           (any_extend:SI (reg:HI 26)))
-                                  (const_int 16))))
-   (clobber (reg:HI 22))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "%~call __<extend_u>mulhisi3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*usmulhisi3_call_split"
+(define_insn "*usmulhisi3_call"
   [(set (reg:SI 22)
         (mult:SI (zero_extend:SI (reg:HI 18))
                  (sign_extend:SI (reg:HI 26))))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:SI 22)
-                   (mult:SI (zero_extend:SI (reg:HI 18))
-                            (sign_extend:SI (reg:HI 26))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*usmulhisi3_call"
-  [(set (reg:SI 22)
-        (mult:SI (zero_extend:SI (reg:HI 18))
-                 (sign_extend:SI (reg:HI 26))))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "%~call __usmulhisi3"
-  [(set_attr "type" "xcall")])
-
-(define_insn_and_split "*mul<extend_su>hisi3_call_split"
-  [(set (reg:SI 22)
-        (mult:SI (any_extend:SI (reg:HI 26))
-                 (reg:SI 18)))]
-  "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:SI 22)
-                   (mult:SI (any_extend:SI (reg:HI 26))
-                            (reg:SI 18)))
-              (clobber (reg:CC REG_CC))])])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 (define_insn "*mul<extend_su>hisi3_call"
   [(set (reg:SI 22)
-        (mult:SI (any_extend:SI (reg:HI 26))
-                 (reg:SI 18)))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
-  "%~call __mul<extend_su>hisi3"
-  [(set_attr "type" "xcall")])
-
-(define_insn_and_split "*mulohisi3_call_split"
-  [(set (reg:SI 22)
-        (mult:SI (not:SI (zero_extend:SI (not:HI (reg:HI 26))))
+        (mult:SI (any_extend:SI (reg:HI 26))
                  (reg:SI 18)))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:SI 22)
-                   (mult:SI (not:SI (zero_extend:SI (not:HI (reg:HI 26))))
-                            (reg:SI 18)))
-              (clobber (reg:CC REG_CC))])])
+  "%~call __mul<extend_su>hisi3"
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 (define_insn "*mulohisi3_call"
   [(set (reg:SI 22)
         (mult:SI (not:SI (zero_extend:SI (not:HI (reg:HI 26))))
-                 (reg:SI 18)))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
+                 (reg:SI 18)))]
+  "AVR_HAVE_MUL"
   "%~call __mulohisi3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ; / % / % / % / % / % / % / % / % / % / % / % / % / % / % / % / % / % / % / %
 ; divmod
@@ -3706,15 +2716,15 @@
 ;;    CSE has problems to operate on hard regs.
 ;;
 (define_insn_and_split "divmodqi4"
-  [(set (match_operand:QI 0 "pseudo_register_operand" "")
-        (div:QI (match_operand:QI 1 "pseudo_register_operand" "")
-                (match_operand:QI 2 "pseudo_register_operand" "")))
-   (set (match_operand:QI 3 "pseudo_register_operand" "")
-        (mod:QI (match_dup 1) (match_dup 2)))
-   (clobber (reg:QI 22))
-   (clobber (reg:QI 23))
-   (clobber (reg:QI 24))
-   (clobber (reg:QI 25))]
+  [(parallel [(set (match_operand:QI 0 "pseudo_register_operand" "")
+                   (div:QI (match_operand:QI 1 "pseudo_register_operand" "")
+                           (match_operand:QI 2 "pseudo_register_operand" "")))
+              (set (match_operand:QI 3 "pseudo_register_operand" "")
+                   (mod:QI (match_dup 1) (match_dup 2)))
+              (clobber (reg:QI 22))
+              (clobber (reg:QI 23))
+              (clobber (reg:QI 24))
+              (clobber (reg:QI 25))])]
   ""
   "this divmodqi4 pattern should have been splitted;"
   ""
@@ -3727,40 +2737,26 @@
    (set (match_dup 0) (reg:QI 24))
    (set (match_dup 3) (reg:QI 25))])
 
-(define_insn_and_split "*divmodqi4_call_split"
+(define_insn "*divmodqi4_call"
   [(set (reg:QI 24) (div:QI (reg:QI 24) (reg:QI 22)))
    (set (reg:QI 25) (mod:QI (reg:QI 24) (reg:QI 22)))
    (clobber (reg:QI 22))
    (clobber (reg:QI 23))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:QI 24) (div:QI (reg:QI 24) (reg:QI 22)))
-              (set (reg:QI 25) (mod:QI (reg:QI 24) (reg:QI 22)))
-              (clobber (reg:QI 22))
-              (clobber (reg:QI 23))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*divmodqi4_call"
-  [(set (reg:QI 24) (div:QI (reg:QI 24) (reg:QI 22)))
-   (set (reg:QI 25) (mod:QI (reg:QI 24) (reg:QI 22)))
-   (clobber (reg:QI 22))
-   (clobber (reg:QI 23))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __divmodqi4"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 (define_insn_and_split "udivmodqi4"
- [(set (match_operand:QI 0 "pseudo_register_operand" "")
-       (udiv:QI (match_operand:QI 1 "pseudo_register_operand" "")
-                (match_operand:QI 2 "pseudo_register_operand" "")))
-       (set (match_operand:QI 3 "pseudo_register_operand" "")
-            (umod:QI (match_dup 1) (match_dup 2)))
-       (clobber (reg:QI 22))
-       (clobber (reg:QI 23))
-       (clobber (reg:QI 24))
-       (clobber (reg:QI 25))]
+ [(parallel [(set (match_operand:QI 0 "pseudo_register_operand" "")
+                  (udiv:QI (match_operand:QI 1 "pseudo_register_operand" "")
+                           (match_operand:QI 2 "pseudo_register_operand" "")))
+             (set (match_operand:QI 3 "pseudo_register_operand" "")
+                  (umod:QI (match_dup 1) (match_dup 2)))
+             (clobber (reg:QI 22))
+             (clobber (reg:QI 23))
+             (clobber (reg:QI 24))
+             (clobber (reg:QI 25))])]
   ""
   "this udivmodqi4 pattern should have been splitted;"
   ""
@@ -3772,37 +2768,25 @@
    (set (match_dup 0) (reg:QI 24))
    (set (match_dup 3) (reg:QI 25))])
 
-(define_insn_and_split "*udivmodqi4_call_split"
+(define_insn "*udivmodqi4_call"
   [(set (reg:QI 24) (udiv:QI (reg:QI 24) (reg:QI 22)))
    (set (reg:QI 25) (umod:QI (reg:QI 24) (reg:QI 22)))
    (clobber (reg:QI 23))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:QI 24) (udiv:QI (reg:QI 24) (reg:QI 22)))
-              (set (reg:QI 25) (umod:QI (reg:QI 24) (reg:QI 22)))
-              (clobber (reg:QI 23))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*udivmodqi4_call"
-  [(set (reg:QI 24) (udiv:QI (reg:QI 24) (reg:QI 22)))
-   (set (reg:QI 25) (umod:QI (reg:QI 24) (reg:QI 22)))
-   (clobber (reg:QI 23))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __udivmodqi4"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 (define_insn_and_split "divmodhi4"
-  [(set (match_operand:HI 0 "pseudo_register_operand" "")
-        (div:HI (match_operand:HI 1 "pseudo_register_operand" "")
-                (match_operand:HI 2 "pseudo_register_operand" "")))
-   (set (match_operand:HI 3 "pseudo_register_operand" "")
-        (mod:HI (match_dup 1) (match_dup 2)))
-   (clobber (reg:QI 21))
-   (clobber (reg:HI 22))
-   (clobber (reg:HI 24))
-   (clobber (reg:HI 26))]
+  [(parallel [(set (match_operand:HI 0 "pseudo_register_operand" "")
+                   (div:HI (match_operand:HI 1 "pseudo_register_operand" "")
+                           (match_operand:HI 2 "pseudo_register_operand" "")))
+              (set (match_operand:HI 3 "pseudo_register_operand" "")
+                   (mod:HI (match_dup 1) (match_dup 2)))
+              (clobber (reg:QI 21))
+              (clobber (reg:HI 22))
+              (clobber (reg:HI 24))
+              (clobber (reg:HI 26))])]
   ""
   "this should have been splitted;"
   ""
@@ -3815,40 +2799,26 @@
    (set (match_dup 0) (reg:HI 22))
    (set (match_dup 3) (reg:HI 24))])
 
-(define_insn_and_split "*divmodhi4_call_split"
+(define_insn "*divmodhi4_call"
   [(set (reg:HI 22) (div:HI (reg:HI 24) (reg:HI 22)))
    (set (reg:HI 24) (mod:HI (reg:HI 24) (reg:HI 22)))
    (clobber (reg:HI 26))
    (clobber (reg:QI 21))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 22) (div:HI (reg:HI 24) (reg:HI 22)))
-              (set (reg:HI 24) (mod:HI (reg:HI 24) (reg:HI 22)))
-              (clobber (reg:HI 26))
-              (clobber (reg:QI 21))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*divmodhi4_call"
-  [(set (reg:HI 22) (div:HI (reg:HI 24) (reg:HI 22)))
-   (set (reg:HI 24) (mod:HI (reg:HI 24) (reg:HI 22)))
-   (clobber (reg:HI 26))
-   (clobber (reg:QI 21))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __divmodhi4"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 (define_insn_and_split "udivmodhi4"
-  [(set (match_operand:HI 0 "pseudo_register_operand" "")
-        (udiv:HI (match_operand:HI 1 "pseudo_register_operand" "")
-                 (match_operand:HI 2 "pseudo_register_operand" "")))
-   (set (match_operand:HI 3 "pseudo_register_operand" "")
-        (umod:HI (match_dup 1) (match_dup 2)))
-   (clobber (reg:QI 21))
-   (clobber (reg:HI 22))
-   (clobber (reg:HI 24))
-   (clobber (reg:HI 26))]
+  [(parallel [(set (match_operand:HI 0 "pseudo_register_operand" "")
+                   (udiv:HI (match_operand:HI 1 "pseudo_register_operand" "")
+                            (match_operand:HI 2 "pseudo_register_operand" "")))
+              (set (match_operand:HI 3 "pseudo_register_operand" "")
+                   (umod:HI (match_dup 1) (match_dup 2)))
+              (clobber (reg:QI 21))
+              (clobber (reg:HI 22))
+              (clobber (reg:HI 24))
+              (clobber (reg:HI 26))])]
   ""
   "this udivmodhi4 pattern should have been splitted.;"
   ""
@@ -3861,30 +2831,15 @@
    (set (match_dup 0) (reg:HI 22))
    (set (match_dup 3) (reg:HI 24))])
 
-(define_insn_and_split "*udivmodhi4_call_split"
+(define_insn "*udivmodhi4_call"
   [(set (reg:HI 22) (udiv:HI (reg:HI 24) (reg:HI 22)))
    (set (reg:HI 24) (umod:HI (reg:HI 24) (reg:HI 22)))
    (clobber (reg:HI 26))
    (clobber (reg:QI 21))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 22) (udiv:HI (reg:HI 24) (reg:HI 22)))
-              (set (reg:HI 24) (umod:HI (reg:HI 24) (reg:HI 22)))
-              (clobber (reg:HI 26))
-              (clobber (reg:QI 21))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*udivmodhi4_call"
-  [(set (reg:HI 22) (udiv:HI (reg:HI 24) (reg:HI 22)))
-   (set (reg:HI 24) (umod:HI (reg:HI 24) (reg:HI 22)))
-   (clobber (reg:HI 26))
-   (clobber (reg:QI 21))
-   (clobber (reg:CC REG_CC))
-   ]
-  "reload_completed"
   "%~call __udivmodhi4"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
 ;; 24-bit multiply
@@ -3915,24 +2870,11 @@
       DONE;
   })
 
-(define_insn_and_split "*umulqihipsi3_split"
+(define_insn "*umulqihipsi3"
   [(set (match_operand:PSI 0 "register_operand"                         "=&r")
         (mult:PSI (zero_extend:PSI (match_operand:QI 1 "register_operand" "r"))
                   (zero_extend:PSI (match_operand:HI 2 "register_operand" "r"))))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (mult:PSI (zero_extend:PSI (match_dup 1))
-                             (zero_extend:PSI (match_dup 2))))
-               (clobber (reg:CC REG_CC))])])
-
-(define_insn "*umulqihipsi3"
-  [(set (match_operand:PSI 0 "register_operand"                         "=&r")
-        (mult:PSI (zero_extend:PSI (match_operand:QI 1 "register_operand" "r"))
-                  (zero_extend:PSI (match_operand:HI 2 "register_operand" "r"))))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "mul %1,%A2
 	movw %A0,r0
 	mul %1,%B2
@@ -3940,26 +2882,14 @@
 	add %B0,r0
 	adc %C0,r1
 	clr __zero_reg__"
-  [(set_attr "length" "7")])
+  [(set_attr "length" "7")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*umulhiqipsi3_split"
+(define_insn "*umulhiqipsi3"
   [(set (match_operand:PSI 0 "register_operand"                         "=&r")
         (mult:PSI (zero_extend:PSI (match_operand:HI 2 "register_operand" "r"))
                   (zero_extend:PSI (match_operand:QI 1 "register_operand" "r"))))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (mult:PSI (zero_extend:PSI (match_dup 2))
-                             (zero_extend:PSI (match_dup 1))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*umulhiqipsi3"
-  [(set (match_operand:PSI 0 "register_operand"                         "=&r")
-        (mult:PSI (zero_extend:PSI (match_operand:HI 2 "register_operand" "r"))
-                  (zero_extend:PSI (match_operand:QI 1 "register_operand" "r"))))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "mul %1,%A2
 	movw %A0,r0
 	mul %1,%B2
@@ -3967,7 +2897,8 @@
 	mov %C0,r1
 	clr __zero_reg__
 	adc %C0,__zero_reg__"
-  [(set_attr "length" "7")])
+  [(set_attr "length" "7")
+   (set_attr "cc" "clobber")])
 
 (define_expand "mulsqipsi3"
   [(parallel [(set (match_operand:PSI 0 "pseudo_register_operand" "")
@@ -4032,28 +2963,16 @@
       }
   })
 
-(define_insn_and_split "*mulsqipsi3.libgcc_split"
+(define_insn "*mulsqipsi3.libgcc"
   [(set (reg:PSI 18)
         (mult:PSI (sign_extend:PSI (reg:QI 25))
                   (reg:PSI 22)))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:PSI 18)
-                   (mult:PSI (sign_extend:PSI (reg:QI 25))
-                             (reg:PSI 22)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*mulsqipsi3.libgcc"
-  [(set (reg:PSI 18)
-        (mult:PSI (sign_extend:PSI (reg:QI 25))
-                  (reg:PSI 22)))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "%~call __mulsqipsi3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*mulpsi3.libgcc_split"
+(define_insn "*mulpsi3.libgcc"
   [(set (reg:PSI 22)
         (mult:PSI (reg:PSI 22)
                   (reg:PSI 18)))
@@ -4061,27 +2980,9 @@
    (clobber (reg:QI 25))
    (clobber (reg:HI 26))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:PSI 22)
-                   (mult:PSI (reg:PSI 22)
-                             (reg:PSI 18)))
-              (clobber (reg:QI 21))
-              (clobber (reg:QI 25))
-              (clobber (reg:HI 26))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*mulpsi3.libgcc"
-  [(set (reg:PSI 22)
-        (mult:PSI (reg:PSI 22)
-                  (reg:PSI 18)))
-   (clobber (reg:QI 21))
-   (clobber (reg:QI 25))
-   (clobber (reg:HI 26))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "%~call __mulpsi3"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
@@ -4112,32 +3013,16 @@
    (set (match_dup 0) (reg:PSI 22))
    (set (match_dup 3) (reg:PSI 18))])
 
-(define_insn_and_split "*divmodpsi4_call_split"
+(define_insn "*divmodpsi4_call"
   [(set (reg:PSI 22) (div:PSI (reg:PSI 22) (reg:PSI 18)))
    (set (reg:PSI 18) (mod:PSI (reg:PSI 22) (reg:PSI 18)))
    (clobber (reg:QI 21))
    (clobber (reg:QI 25))
    (clobber (reg:QI 26))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:PSI 22) (div:PSI (reg:PSI 22) (reg:PSI 18)))
-              (set (reg:PSI 18) (mod:PSI (reg:PSI 22) (reg:PSI 18)))
-              (clobber (reg:QI 21))
-              (clobber (reg:QI 25))
-              (clobber (reg:QI 26))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*divmodpsi4_call"
-  [(set (reg:PSI 22) (div:PSI (reg:PSI 22) (reg:PSI 18)))
-   (set (reg:PSI 18) (mod:PSI (reg:PSI 22) (reg:PSI 18)))
-   (clobber (reg:QI 21))
-   (clobber (reg:QI 25))
-   (clobber (reg:QI 26))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __divmodpsi4"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 (define_insn_and_split "udivmodpsi4"
   [(parallel [(set (match_operand:PSI 0 "pseudo_register_operand" "")
@@ -4161,32 +3046,16 @@
    (set (match_dup 0) (reg:PSI 22))
    (set (match_dup 3) (reg:PSI 18))])
 
-(define_insn_and_split "*udivmodpsi4_call_split"
+(define_insn "*udivmodpsi4_call"
   [(set (reg:PSI 22) (udiv:PSI (reg:PSI 22) (reg:PSI 18)))
    (set (reg:PSI 18) (umod:PSI (reg:PSI 22) (reg:PSI 18)))
    (clobber (reg:QI 21))
    (clobber (reg:QI 25))
    (clobber (reg:QI 26))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:PSI 22) (udiv:PSI (reg:PSI 22) (reg:PSI 18)))
-              (set (reg:PSI 18) (umod:PSI (reg:PSI 22) (reg:PSI 18)))
-              (clobber (reg:QI 21))
-              (clobber (reg:QI 25))
-              (clobber (reg:QI 26))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*udivmodpsi4_call"
-  [(set (reg:PSI 22) (udiv:PSI (reg:PSI 22) (reg:PSI 18)))
-   (set (reg:PSI 18) (umod:PSI (reg:PSI 22) (reg:PSI 18)))
-   (clobber (reg:QI 21))
-   (clobber (reg:QI 25))
-   (clobber (reg:QI 26))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __udivmodpsi4"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
 
@@ -4212,29 +3081,15 @@
    (set (match_dup 0) (reg:SI 18))
    (set (match_dup 3) (reg:SI 22))])
 
-(define_insn_and_split "*divmodsi4_call_split"
+(define_insn "*divmodsi4_call"
   [(set (reg:SI 18) (div:SI (reg:SI 22) (reg:SI 18)))
    (set (reg:SI 22) (mod:SI (reg:SI 22) (reg:SI 18)))
    (clobber (reg:HI 26))
    (clobber (reg:HI 30))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:SI 18) (div:SI (reg:SI 22) (reg:SI 18)))
-              (set (reg:SI 22) (mod:SI (reg:SI 22) (reg:SI 18)))
-              (clobber (reg:HI 26))
-              (clobber (reg:HI 30))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*divmodsi4_call"
-  [(set (reg:SI 18) (div:SI (reg:SI 22) (reg:SI 18)))
-   (set (reg:SI 22) (mod:SI (reg:SI 22) (reg:SI 18)))
-   (clobber (reg:HI 26))
-   (clobber (reg:HI 30))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __divmodsi4"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 (define_insn_and_split "udivmodsi4"
   [(parallel [(set (match_operand:SI 0 "pseudo_register_operand" "")
@@ -4258,78 +3113,37 @@
    (set (match_dup 0) (reg:SI 18))
    (set (match_dup 3) (reg:SI 22))])
 
-(define_insn_and_split "*udivmodsi4_call_split"
+(define_insn "*udivmodsi4_call"
   [(set (reg:SI 18) (udiv:SI (reg:SI 22) (reg:SI 18)))
    (set (reg:SI 22) (umod:SI (reg:SI 22) (reg:SI 18)))
    (clobber (reg:HI 26))
    (clobber (reg:HI 30))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:SI 18) (udiv:SI (reg:SI 22) (reg:SI 18)))
-              (set (reg:SI 22) (umod:SI (reg:SI 22) (reg:SI 18)))
-              (clobber (reg:HI 26))
-              (clobber (reg:HI 30))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*udivmodsi4_call"
-  [(set (reg:SI 18) (udiv:SI (reg:SI 22) (reg:SI 18)))
-   (set (reg:SI 22) (umod:SI (reg:SI 22) (reg:SI 18)))
-   (clobber (reg:HI 26))
-   (clobber (reg:HI 30))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __udivmodsi4"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
 ; and
 
-(define_insn_and_split "andqi3"
+(define_insn "andqi3"
   [(set (match_operand:QI 0 "register_operand"       "=??r,d,*l")
         (and:QI (match_operand:QI 1 "register_operand" "%0,0,0")
                 (match_operand:QI 2 "nonmemory_operand" "r,i,Ca1")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (and:QI (match_dup 1)
-                           (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*andqi3"
-  [(set (match_operand:QI 0 "register_operand"       "=??r,d,*l")
-        (and:QI (match_operand:QI 1 "register_operand" "%0,0,0")
-                (match_operand:QI 2 "nonmemory_operand" "r,i,Ca1")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "@
 	and %0,%2
 	andi %0,lo8(%2)
 	* return avr_out_bitop (insn, operands, NULL);"
-  [(set_attr "length" "1,1,2")])
+  [(set_attr "length" "1,1,2")
+   (set_attr "cc" "set_zn,set_zn,none")])
 
-(define_insn_and_split "andhi3"
+(define_insn "andhi3"
   [(set (match_operand:HI 0 "register_operand"       "=??r,d,d,r  ,r")
         (and:HI (match_operand:HI 1 "register_operand" "%0,0,0,0  ,0")
                 (match_operand:HI 2 "nonmemory_operand" "r,s,n,Ca2,n")))
    (clobber (match_scratch:QI 3                        "=X,X,X,X  ,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (and:HI (match_dup 1)
-                           (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*andhi3"
-  [(set (match_operand:HI 0 "register_operand"       "=??r,d,d,r  ,r")
-        (and:HI (match_operand:HI 1 "register_operand" "%0,0,0,0  ,0")
-                (match_operand:HI 2 "nonmemory_operand" "r,s,n,Ca2,n")))
-   (clobber (match_scratch:QI 3                        "=X,X,X,X  ,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     if (which_alternative == 0)
       return "and %A0,%A2\;and %B0,%B2";
@@ -4339,29 +3153,15 @@
     return avr_out_bitop (insn, operands, NULL);
   }
   [(set_attr "length" "2,2,2,4,4")
-   (set_attr "adjust_len" "*,*,out_bitop,out_bitop,out_bitop")])
+   (set_attr "adjust_len" "*,*,out_bitop,out_bitop,out_bitop")
+   (set_attr "cc" "set_n,set_n,clobber,clobber,clobber")])
 
-(define_insn_and_split "andpsi3"
+(define_insn "andpsi3"
   [(set (match_operand:PSI 0 "register_operand"        "=??r,d,r  ,r")
         (and:PSI (match_operand:PSI 1 "register_operand" "%0,0,0  ,0")
                  (match_operand:PSI 2 "nonmemory_operand" "r,n,Ca3,n")))
    (clobber (match_scratch:QI 3                          "=X,X,X  ,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (and:PSI (match_dup 1)
-                            (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*andpsi3"
-  [(set (match_operand:PSI 0 "register_operand"        "=??r,d,r  ,r")
-        (and:PSI (match_operand:PSI 1 "register_operand" "%0,0,0  ,0")
-                 (match_operand:PSI 2 "nonmemory_operand" "r,n,Ca3,n")))
-   (clobber (match_scratch:QI 3                          "=X,X,X  ,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     if (which_alternative == 0)
       return "and %A0,%A2" CR_TAB
@@ -4371,29 +3171,15 @@
     return avr_out_bitop (insn, operands, NULL);
   }
   [(set_attr "length" "3,3,6,6")
-   (set_attr "adjust_len" "*,out_bitop,out_bitop,out_bitop")])
+   (set_attr "adjust_len" "*,out_bitop,out_bitop,out_bitop")
+   (set_attr "cc" "set_n,clobber,clobber,clobber")])
 
-(define_insn_and_split "andsi3"
+(define_insn "andsi3"
   [(set (match_operand:SI 0 "register_operand"       "=??r,d,r  ,r")
         (and:SI (match_operand:SI 1 "register_operand" "%0,0,0  ,0")
                 (match_operand:SI 2 "nonmemory_operand" "r,n,Ca4,n")))
    (clobber (match_scratch:QI 3                        "=X,X,X  ,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (and:SI (match_dup 1)
-                           (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*andsi3"
-  [(set (match_operand:SI 0 "register_operand"       "=??r,d,r  ,r")
-        (and:SI (match_operand:SI 1 "register_operand" "%0,0,0  ,0")
-                (match_operand:SI 2 "nonmemory_operand" "r,n,Ca4,n")))
-   (clobber (match_scratch:QI 3                        "=X,X,X  ,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     if (which_alternative == 0)
       return "and %0,%2"   CR_TAB
@@ -4404,20 +3190,18 @@
     return avr_out_bitop (insn, operands, NULL);
   }
   [(set_attr "length" "4,4,8,8")
-   (set_attr "adjust_len" "*,out_bitop,out_bitop,out_bitop")])
+   (set_attr "adjust_len" "*,out_bitop,out_bitop,out_bitop")
+   (set_attr "cc" "set_n,clobber,clobber,clobber")])
 
 (define_peephole2 ; andi
-  [(parallel [(set (match_operand:QI 0 "d_register_operand" "")
-                   (and:QI (match_dup 0)
-                           (match_operand:QI 1 "const_int_operand" "")))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 0)
-                   (and:QI (match_dup 0)
-                           (match_operand:QI 2 "const_int_operand" "")))
-              (clobber (reg:CC REG_CC))])]
-  ""
-  [(parallel [(set (match_dup 0) (and:QI (match_dup 0) (match_dup 1)))
-              (clobber (reg:CC REG_CC))])]
+  [(set (match_operand:QI 0 "d_register_operand" "")
+        (and:QI (match_dup 0)
+                (match_operand:QI 1 "const_int_operand" "")))
+   (set (match_dup 0)
+        (and:QI (match_dup 0)
+                (match_operand:QI 2 "const_int_operand" "")))]
+  ""
+  [(set (match_dup 0) (and:QI (match_dup 0) (match_dup 1)))]
   {
     operands[1] = GEN_INT (INTVAL (operands[1]) & INTVAL (operands[2]));
   })
@@ -4425,51 +3209,24 @@
 ;;|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
 ;; ior
 
-(define_insn_and_split "iorqi3"
+(define_insn "iorqi3"
   [(set (match_operand:QI 0 "register_operand"       "=??r,d,*l")
         (ior:QI (match_operand:QI 1 "register_operand" "%0,0,0")
                 (match_operand:QI 2 "nonmemory_operand" "r,i,Co1")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ior:QI (match_dup 1)
-                           (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*iorqi3"
-  [(set (match_operand:QI 0 "register_operand"       "=??r,d,*l")
-        (ior:QI (match_operand:QI 1 "register_operand" "%0,0,0")
-                (match_operand:QI 2 "nonmemory_operand" "r,i,Co1")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "@
 	or %0,%2
 	ori %0,lo8(%2)
         * return avr_out_bitop (insn, operands, NULL);"
-  [(set_attr "length" "1,1,2")])
+  [(set_attr "length" "1,1,2")
+   (set_attr "cc" "set_zn,set_zn,none")])
 
-(define_insn_and_split "iorhi3"
+(define_insn "iorhi3"
   [(set (match_operand:HI 0 "register_operand"       "=??r,d,d,r  ,r")
         (ior:HI (match_operand:HI 1 "register_operand" "%0,0,0,0  ,0")
                 (match_operand:HI 2 "nonmemory_operand" "r,s,n,Co2,n")))
    (clobber (match_scratch:QI 3                        "=X,X,X,X  ,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ior:HI (match_dup 1)
-                           (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*iorhi3"
-  [(set (match_operand:HI 0 "register_operand"       "=??r,d,d,r  ,r")
-        (ior:HI (match_operand:HI 1 "register_operand" "%0,0,0,0  ,0")
-                (match_operand:HI 2 "nonmemory_operand" "r,s,n,Co2,n")))
-   (clobber (match_scratch:QI 3                        "=X,X,X,X  ,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     if (which_alternative == 0)
       return "or %A0,%A2\;or %B0,%B2";
@@ -4479,29 +3236,15 @@
     return avr_out_bitop (insn, operands, NULL);
   }
   [(set_attr "length" "2,2,2,4,4")
-   (set_attr "adjust_len" "*,*,out_bitop,out_bitop,out_bitop")])
+   (set_attr "adjust_len" "*,*,out_bitop,out_bitop,out_bitop")
+   (set_attr "cc" "set_n,set_n,clobber,clobber,clobber")])
 
-(define_insn_and_split "iorpsi3"
+(define_insn "iorpsi3"
   [(set (match_operand:PSI 0 "register_operand"        "=??r,d,r  ,r")
         (ior:PSI (match_operand:PSI 1 "register_operand" "%0,0,0  ,0")
                  (match_operand:PSI 2 "nonmemory_operand" "r,n,Co3,n")))
    (clobber (match_scratch:QI 3                          "=X,X,X  ,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ior:PSI (match_dup 1)
-                            (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*iorpsi3"
-  [(set (match_operand:PSI 0 "register_operand"        "=??r,d,r  ,r")
-        (ior:PSI (match_operand:PSI 1 "register_operand" "%0,0,0  ,0")
-                 (match_operand:PSI 2 "nonmemory_operand" "r,n,Co3,n")))
-   (clobber (match_scratch:QI 3                          "=X,X,X  ,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     if (which_alternative == 0)
       return "or %A0,%A2" CR_TAB
@@ -4511,29 +3254,15 @@
     return avr_out_bitop (insn, operands, NULL);
   }
   [(set_attr "length" "3,3,6,6")
-   (set_attr "adjust_len" "*,out_bitop,out_bitop,out_bitop")])
+   (set_attr "adjust_len" "*,out_bitop,out_bitop,out_bitop")
+   (set_attr "cc" "set_n,clobber,clobber,clobber")])
 
-(define_insn_and_split "iorsi3"
+(define_insn "iorsi3"
   [(set (match_operand:SI 0 "register_operand"       "=??r,d,r  ,r")
         (ior:SI (match_operand:SI 1 "register_operand" "%0,0,0  ,0")
                 (match_operand:SI 2 "nonmemory_operand" "r,n,Co4,n")))
    (clobber (match_scratch:QI 3                        "=X,X,X  ,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ior:SI (match_dup 1)
-                           (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*iorsi3"
-  [(set (match_operand:SI 0 "register_operand"       "=??r,d,r  ,r")
-        (ior:SI (match_operand:SI 1 "register_operand" "%0,0,0  ,0")
-                (match_operand:SI 2 "nonmemory_operand" "r,n,Co4,n")))
-   (clobber (match_scratch:QI 3                        "=X,X,X  ,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     if (which_alternative == 0)
       return "or %0,%2"   CR_TAB
@@ -4544,53 +3273,27 @@
     return avr_out_bitop (insn, operands, NULL);
   }
   [(set_attr "length" "4,4,8,8")
-   (set_attr "adjust_len" "*,out_bitop,out_bitop,out_bitop")])
-
-;;^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
-;; xor
-
-(define_insn_and_split "xorqi3"
-  [(set (match_operand:QI 0 "register_operand" "=r")
-        (xor:QI (match_operand:QI 1 "register_operand" "%0")
-                (match_operand:QI 2 "register_operand" "r")))]
-  ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (xor:QI (match_dup 1)
-                           (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
+   (set_attr "adjust_len" "*,out_bitop,out_bitop,out_bitop")
+   (set_attr "cc" "set_n,clobber,clobber,clobber")])
 
-(define_insn "*xorqi3"
+;;^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+;; xor
+
+(define_insn "xorqi3"
   [(set (match_operand:QI 0 "register_operand" "=r")
         (xor:QI (match_operand:QI 1 "register_operand" "%0")
-                (match_operand:QI 2 "register_operand" "r")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
+                (match_operand:QI 2 "register_operand" "r")))]
+  ""
   "eor %0,%2"
-  [(set_attr "length" "1")])
+  [(set_attr "length" "1")
+   (set_attr "cc" "set_zn")])
 
-(define_insn_and_split "xorhi3"
+(define_insn "xorhi3"
   [(set (match_operand:HI 0 "register_operand"       "=??r,r  ,r")
         (xor:HI (match_operand:HI 1 "register_operand" "%0,0  ,0")
                 (match_operand:HI 2 "nonmemory_operand" "r,Cx2,n")))
    (clobber (match_scratch:QI 3                        "=X,X  ,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (xor:HI (match_dup 1)
-                           (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*xorhi3"
-  [(set (match_operand:HI 0 "register_operand"       "=??r,r  ,r")
-        (xor:HI (match_operand:HI 1 "register_operand" "%0,0  ,0")
-                (match_operand:HI 2 "nonmemory_operand" "r,Cx2,n")))
-   (clobber (match_scratch:QI 3                        "=X,X  ,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     if (which_alternative == 0)
       return "eor %A0,%A2\;eor %B0,%B2";
@@ -4598,29 +3301,15 @@
     return avr_out_bitop (insn, operands, NULL);
   }
   [(set_attr "length" "2,2,4")
-   (set_attr "adjust_len" "*,out_bitop,out_bitop")])
+   (set_attr "adjust_len" "*,out_bitop,out_bitop")
+   (set_attr "cc" "set_n,clobber,clobber")])
 
-(define_insn_and_split "xorpsi3"
+(define_insn "xorpsi3"
   [(set (match_operand:PSI 0 "register_operand"        "=??r,r  ,r")
         (xor:PSI (match_operand:PSI 1 "register_operand" "%0,0  ,0")
                  (match_operand:PSI 2 "nonmemory_operand" "r,Cx3,n")))
    (clobber (match_scratch:QI 3                          "=X,X  ,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (xor:PSI (match_dup 1)
-                            (match_dup 2)))
-                   (clobber (match_dup 3))
-                   (clobber (reg:CC REG_CC))])])
-
-(define_insn "*xorpsi3"
-  [(set (match_operand:PSI 0 "register_operand"        "=??r,r  ,r")
-        (xor:PSI (match_operand:PSI 1 "register_operand" "%0,0  ,0")
-                 (match_operand:PSI 2 "nonmemory_operand" "r,Cx3,n")))
-   (clobber (match_scratch:QI 3                          "=X,X  ,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     if (which_alternative == 0)
       return "eor %A0,%A2" CR_TAB
@@ -4630,29 +3319,15 @@
     return avr_out_bitop (insn, operands, NULL);
   }
   [(set_attr "length" "3,6,6")
-   (set_attr "adjust_len" "*,out_bitop,out_bitop")])
+   (set_attr "adjust_len" "*,out_bitop,out_bitop")
+   (set_attr "cc" "set_n,clobber,clobber")])
 
-(define_insn_and_split "xorsi3"
+(define_insn "xorsi3"
   [(set (match_operand:SI 0 "register_operand"       "=??r,r  ,r")
         (xor:SI (match_operand:SI 1 "register_operand" "%0,0  ,0")
                 (match_operand:SI 2 "nonmemory_operand" "r,Cx4,n")))
    (clobber (match_scratch:QI 3                        "=X,X  ,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (xor:SI (match_dup 1)
-                           (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*xorsi3"
-  [(set (match_operand:SI 0 "register_operand"       "=??r,r  ,r")
-        (xor:SI (match_operand:SI 1 "register_operand" "%0,0  ,0")
-                (match_operand:SI 2 "nonmemory_operand" "r,Cx4,n")))
-   (clobber (match_scratch:QI 3                        "=X,X  ,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     if (which_alternative == 0)
       return "eor %0,%2"   CR_TAB
@@ -4663,7 +3338,8 @@
     return avr_out_bitop (insn, operands, NULL);
   }
   [(set_attr "length" "4,8,8")
-   (set_attr "adjust_len" "*,out_bitop,out_bitop")])
+   (set_attr "adjust_len" "*,out_bitop,out_bitop")
+   (set_attr "cc" "set_n,clobber,clobber")])
 
 
 (define_split
@@ -4748,24 +3424,11 @@
         (rotate:QI (match_operand:QI 1 "register_operand" "")
                    (const_int 4)))])
 
-(define_insn_and_split "*rotlqi3_split"
+(define_insn "*rotlqi3"
   [(set (match_operand:QI 0 "register_operand"               "=r,r,r  ,r  ,r  ,r  ,r  ,r")
         (rotate:QI (match_operand:QI 1 "register_operand"     "0,0,0  ,0  ,0  ,0  ,0  ,0")
                    (match_operand:QI 2 "const_0_to_7_operand" "P,K,C03,C04,C05,C06,C07,L")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (rotate:QI (match_dup 1)
-                              (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*rotlqi3"
-  [(set (match_operand:QI 0 "register_operand"               "=r,r,r  ,r  ,r  ,r  ,r  ,r")
-        (rotate:QI (match_operand:QI 1 "register_operand"     "0,0,0  ,0  ,0  ,0  ,0  ,0")
-                   (match_operand:QI 2 "const_0_to_7_operand" "P,K,C03,C04,C05,C06,C07,L")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "@
 	lsl %0\;adc %0,__zero_reg__
 	lsl %0\;adc %0,__zero_reg__\;lsl %0\;adc %0,__zero_reg__
@@ -4775,7 +3438,8 @@
 	swap %0\;lsl %0\;adc %0,__zero_reg__\;lsl %0\;adc %0,__zero_reg__
 	bst %0,0\;ror %0\;bld %0,7
 	" ; empty
-  [(set_attr "length" "2,4,4,1,3,5,3,0")])
+  [(set_attr "length" "2,4,4,1,3,5,3,0")
+   (set_attr "cc" "set_n,set_n,clobber,none,set_n,set_n,clobber,none")])
 
 ;; Split all rotates of HI,SI and PSImode registers where rotation is by
 ;; a whole number of bytes.  The split creates the appropriate moves and
@@ -4823,131 +3487,59 @@
       FAIL;
   })
 
-(define_insn_and_split "*rotlhi2.1_split"
+(define_insn "*rotlhi2.1"
   [(set (match_operand:HI 0 "register_operand"           "=r")
         (rotate:HI (match_operand:HI 1 "register_operand" "0")
                    (const_int 1)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (rotate:HI (match_dup 1)
-                              (const_int 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*rotlhi2.1"
-  [(set (match_operand:HI 0 "register_operand"           "=r")
-        (rotate:HI (match_operand:HI 1 "register_operand" "0")
-                   (const_int 1)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "lsl %A0\;rol %B0\;adc %A0,__zero_reg__"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*rotlhi2.15_split"
+(define_insn "*rotlhi2.15"
   [(set (match_operand:HI 0 "register_operand"           "=r")
         (rotate:HI (match_operand:HI 1 "register_operand" "0")
                    (const_int 15)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (rotate:HI (match_dup 1)
-                              (const_int 15)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*rotlhi2.15"
-  [(set (match_operand:HI 0 "register_operand"           "=r")
-        (rotate:HI (match_operand:HI 1 "register_operand" "0")
-                   (const_int 15)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "bst %A0,0\;ror %B0\;ror %A0\;bld %B0,7"
-  [(set_attr "length" "4")])
+  [(set_attr "length" "4")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*rotlpsi2.1_split"
+(define_insn "*rotlpsi2.1"
   [(set (match_operand:PSI 0 "register_operand"            "=r")
         (rotate:PSI (match_operand:PSI 1 "register_operand" "0")
                     (const_int 1)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (rotate:PSI (match_dup 1)
-                               (const_int 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*rotlpsi2.1"
-  [(set (match_operand:PSI 0 "register_operand"            "=r")
-        (rotate:PSI (match_operand:PSI 1 "register_operand" "0")
-                    (const_int 1)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "lsl %A0\;rol %B0\;rol %C0\;adc %A0,__zero_reg__"
-  [(set_attr "length" "4")])
+  [(set_attr "length" "4")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*rotlpsi2.23_split"
+(define_insn "*rotlpsi2.23"
   [(set (match_operand:PSI 0 "register_operand"            "=r")
         (rotate:PSI (match_operand:PSI 1 "register_operand" "0")
                     (const_int 23)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (rotate:PSI (match_dup 1)
-                               (const_int 23)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*rotlpsi2.23"
-  [(set (match_operand:PSI 0 "register_operand"            "=r")
-        (rotate:PSI (match_operand:PSI 1 "register_operand" "0")
-                    (const_int 23)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "bst %A0,0\;ror %C0\;ror %B0\;ror %A0\;bld %C0,7"
-  [(set_attr "length" "5")])
+  [(set_attr "length" "5")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*rotlsi2.1_split"
+(define_insn "*rotlsi2.1"
   [(set (match_operand:SI 0 "register_operand"           "=r")
         (rotate:SI (match_operand:SI 1 "register_operand" "0")
                    (const_int 1)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (rotate:SI (match_dup 1)
-                              (const_int 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*rotlsi2.1"
-  [(set (match_operand:SI 0 "register_operand"           "=r")
-        (rotate:SI (match_operand:SI 1 "register_operand" "0")
-                   (const_int 1)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "lsl %A0\;rol %B0\;rol %C0\;rol %D0\;adc %A0,__zero_reg__"
-  [(set_attr "length" "5")])
+  [(set_attr "length" "5")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*rotlsi2.31_split"
+(define_insn "*rotlsi2.31"
   [(set (match_operand:SI 0 "register_operand"           "=r")
         (rotate:SI (match_operand:SI 1 "register_operand" "0")
                    (const_int 31)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (rotate:SI (match_dup 1)
-                              (const_int 31)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*rotlsi2.31"
-  [(set (match_operand:SI 0 "register_operand"           "=r")
-        (rotate:SI (match_operand:SI 1 "register_operand" "0")
-                   (const_int 31)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "bst %A0,0\;ror %D0\;ror %C0\;ror %B0\;ror %A0\;bld %D0,7"
-  [(set_attr "length" "6")])
+  [(set_attr "length" "6")
+   (set_attr "cc" "clobber")])
 
 ;; Overlapping non-HImode registers often (but not always) need a scratch.
 ;; The best we can do is use early clobber alternative "#&r" so that
@@ -5052,53 +3644,29 @@
 
 ;; "*ashlqi3"
 ;; "*ashlqq3"  "*ashluqq3"
-(define_insn_and_split "*ashl<mode>3_split"
+(define_insn "*ashl<mode>3"
   [(set (match_operand:ALL1 0 "register_operand"              "=r,r,r,r,!d,r,r")
         (ashift:ALL1 (match_operand:ALL1 1 "register_operand"  "0,0,0,0,0 ,0,0")
                      (match_operand:QI 2 "nop_general_operand" "r,L,P,K,n ,n,Qm")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ashift:ALL1 (match_dup 1)
-                                (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*ashl<mode>3"
-  [(set (match_operand:ALL1 0 "register_operand"              "=r,r,r,r,!d,r,r")
-        (ashift:ALL1 (match_operand:ALL1 1 "register_operand"  "0,0,0,0,0 ,0,0")
-                     (match_operand:QI 2 "nop_general_operand" "r,L,P,K,n ,n,Qm")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return ashlqi3_out (insn, operands, NULL);
   }
   [(set_attr "length" "5,0,1,2,4,6,9")
-   (set_attr "adjust_len" "ashlqi")])
+   (set_attr "adjust_len" "ashlqi")
+   (set_attr "cc" "clobber,none,set_czn,set_czn,set_czn,set_czn,clobber")])
 
-(define_insn_and_split "ashl<mode>3"
+(define_insn "ashl<mode>3"
   [(set (match_operand:ALL2 0 "register_operand"              "=r,r,r,r,r,r,r")
         (ashift:ALL2 (match_operand:ALL2 1 "register_operand"  "0,0,0,r,0,0,0")
                      (match_operand:QI 2 "nop_general_operand" "r,L,P,O,K,n,Qm")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ashift:ALL2 (match_dup 1)
-                                (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*ashl<mode>3"
-  [(set (match_operand:ALL2 0 "register_operand"              "=r,r,r,r,r,r,r")
-        (ashift:ALL2 (match_operand:ALL2 1 "register_operand"  "0,0,0,r,0,0,0")
-                     (match_operand:QI 2 "nop_general_operand" "r,L,P,O,K,n,Qm")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return ashlhi3_out (insn, operands, NULL);
   }
   [(set_attr "length" "6,0,2,2,4,10,10")
-   (set_attr "adjust_len" "ashlhi")])
+   (set_attr "adjust_len" "ashlhi")
+   (set_attr "cc" "clobber,none,set_n,clobber,set_n,clobber,clobber")])
 
 
 ;; Insns like the following are generated when (implicitly) extending 8-bit shifts
@@ -5163,15 +3731,13 @@
 ;; No need to compute it, map to 8-bit shift.
 
 (define_peephole2
-  [(parallel [(set (match_operand:HI 0 "register_operand" "")
-                   (ashift:HI (match_dup 0)
-                              (match_operand:QI 1 "register_operand" "")))
-              (clobber (reg:CC REG_CC))])]
+  [(set (match_operand:HI 0 "register_operand" "")
+        (ashift:HI (match_dup 0)
+                   (match_operand:QI 1 "register_operand" "")))]
   ""
-  [(parallel [(set (match_dup 2)
-                   (ashift:QI (match_dup 2)
-                              (match_dup 1)))
-              (clobber (reg:CC REG_CC))])
+  [(set (match_dup 2)
+        (ashift:QI (match_dup 2)
+                   (match_dup 1)))
    (clobber (match_dup 3))]
   {
     operands[3] = simplify_gen_subreg (QImode, operands[0], HImode, 1);
@@ -5186,172 +3752,114 @@
 ;; "ashlsi3"
 ;; "ashlsq3"  "ashlusq3"
 ;; "ashlsa3"  "ashlusa3"
-(define_insn_and_split "ashl<mode>3"
+(define_insn "ashl<mode>3"
   [(set (match_operand:ALL4 0 "register_operand"                "=r,r,r,r,r,r,r")
         (ashift:ALL4 (match_operand:ALL4 1 "register_operand"    "0,0,0,r,0,0,0")
                      (match_operand:QI 2 "nop_general_operand"   "r,L,P,O,K,n,Qm")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ashift:ALL4 (match_dup 1)
-                                (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*ashl<mode>3"
-  [(set (match_operand:ALL4 0 "register_operand"                "=r,r,r,r,r,r,r")
-        (ashift:ALL4 (match_operand:ALL4 1 "register_operand"    "0,0,0,r,0,0,0")
-                     (match_operand:QI 2 "nop_general_operand"   "r,L,P,O,K,n,Qm")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return ashlsi3_out (insn, operands, NULL);
   }
   [(set_attr "length" "8,0,4,4,8,10,12")
-   (set_attr "adjust_len" "ashlsi")])
+   (set_attr "adjust_len" "ashlsi")
+   (set_attr "cc" "clobber,none,set_n,clobber,set_n,clobber,clobber")])
 
 ;; Optimize if a scratch register from LD_REGS happens to be available.
 
 (define_peephole2 ; ashlqi3_l_const4
-  [(parallel [(set (match_operand:ALL1 0 "l_register_operand" "")
-                   (ashift:ALL1 (match_dup 0)
-                                (const_int 4)))
-              (clobber (reg:CC REG_CC))])
+  [(set (match_operand:ALL1 0 "l_register_operand" "")
+        (ashift:ALL1 (match_dup 0)
+                     (const_int 4)))
    (match_scratch:QI 1 "d")]
   ""
-  [(parallel [(set (match_dup 2) (rotate:QI (match_dup 2) (const_int 4)))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 1) (const_int -16))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 2) (and:QI (match_dup 2) (match_dup 1)))
-              (clobber (reg:CC REG_CC))])]
+  [(set (match_dup 2) (rotate:QI (match_dup 2) (const_int 4)))
+   (set (match_dup 1) (const_int -16))
+   (set (match_dup 2) (and:QI (match_dup 2) (match_dup 1)))]
   {
     operands[2] = avr_to_int_mode (operands[0]);
   })
 
 (define_peephole2 ; ashlqi3_l_const5
-  [(parallel [(set (match_operand:ALL1 0 "l_register_operand" "")
-                   (ashift:ALL1 (match_dup 0)
-                                (const_int 5)))
-              (clobber (reg:CC REG_CC))])
+  [(set (match_operand:ALL1 0 "l_register_operand" "")
+        (ashift:ALL1 (match_dup 0)
+                     (const_int 5)))
    (match_scratch:QI 1 "d")]
   ""
-  [(parallel [(set (match_dup 2) (rotate:QI (match_dup 2) (const_int 4)))
-                   (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 2) (ashift:QI (match_dup 2) (const_int 1)))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 1) (const_int -32))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 2) (and:QI (match_dup 2) (match_dup 1)))
-              (clobber (reg:CC REG_CC))])]
+  [(set (match_dup 2) (rotate:QI (match_dup 2) (const_int 4)))
+   (set (match_dup 2) (ashift:QI (match_dup 2) (const_int 1)))
+   (set (match_dup 1) (const_int -32))
+   (set (match_dup 2) (and:QI (match_dup 2) (match_dup 1)))]
   {
     operands[2] = avr_to_int_mode (operands[0]);
   })
 
 (define_peephole2 ; ashlqi3_l_const6
-  [(parallel [(set (match_operand:ALL1 0 "l_register_operand" "")
-                   (ashift:ALL1 (match_dup 0)
-                                (const_int 6)))
-              (clobber (reg:CC REG_CC))])
+  [(set (match_operand:ALL1 0 "l_register_operand" "")
+        (ashift:ALL1 (match_dup 0)
+                     (const_int 6)))
    (match_scratch:QI 1 "d")]
   ""
-  [(parallel [(set (match_dup 2) (rotate:QI (match_dup 2) (const_int 4)))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 2) (ashift:QI (match_dup 2) (const_int 2)))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 1) (const_int -64))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 2) (and:QI (match_dup 2) (match_dup 1)))
-              (clobber (reg:CC REG_CC))])]
+  [(set (match_dup 2) (rotate:QI (match_dup 2) (const_int 4)))
+   (set (match_dup 2) (ashift:QI (match_dup 2) (const_int 2)))
+   (set (match_dup 1) (const_int -64))
+   (set (match_dup 2) (and:QI (match_dup 2) (match_dup 1)))]
   {
     operands[2] = avr_to_int_mode (operands[0]);
   })
 
 (define_peephole2
   [(match_scratch:QI 3 "d")
-   (parallel [(set (match_operand:ALL2 0 "register_operand" "")
-                   (ashift:ALL2 (match_operand:ALL2 1 "register_operand" "")
-                                (match_operand:QI 2 "const_int_operand" "")))
-              (clobber (reg:CC REG_CC))])]
+   (set (match_operand:ALL2 0 "register_operand" "")
+        (ashift:ALL2 (match_operand:ALL2 1 "register_operand" "")
+                     (match_operand:QI 2 "const_int_operand" "")))]
   ""
   [(parallel [(set (match_dup 0)
                    (ashift:ALL2 (match_dup 1)
                                 (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
+              (clobber (match_dup 3))])])
 
 ;; "*ashlhi3_const"
 ;; "*ashlhq3_const"  "*ashluhq3_const"
 ;; "*ashlha3_const"  "*ashluha3_const"
-(define_insn_and_split "*ashl<mode>3_const_split"
-  [(set (match_operand:ALL2 0 "register_operand"              "=r,r,r,r,r")
-        (ashift:ALL2 (match_operand:ALL2 1 "register_operand"  "0,0,r,0,0")
-                     (match_operand:QI 2 "const_int_operand"   "L,P,O,K,n")))
-   (clobber (match_scratch:QI 3                               "=X,X,X,X,&d"))]
-  "reload_completed"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ashift:ALL2 (match_dup 1)
-                                (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
 (define_insn "*ashl<mode>3_const"
   [(set (match_operand:ALL2 0 "register_operand"              "=r,r,r,r,r")
         (ashift:ALL2 (match_operand:ALL2 1 "register_operand"  "0,0,r,0,0")
                      (match_operand:QI 2 "const_int_operand"   "L,P,O,K,n")))
-   (clobber (match_scratch:QI 3                               "=X,X,X,X,&d"))
-   (clobber (reg:CC REG_CC))]
+   (clobber (match_scratch:QI 3                               "=X,X,X,X,&d"))]
   "reload_completed"
   {
     return ashlhi3_out (insn, operands, NULL);
   }
   [(set_attr "length" "0,2,2,4,10")
-   (set_attr "adjust_len" "ashlhi")])
+   (set_attr "adjust_len" "ashlhi")
+   (set_attr "cc" "none,set_n,clobber,set_n,clobber")])
 
 (define_peephole2
   [(match_scratch:QI 3 "d")
-   (parallel [(set (match_operand:ALL4 0 "register_operand" "")
-                   (ashift:ALL4 (match_operand:ALL4 1 "register_operand" "")
-                                (match_operand:QI 2 "const_int_operand" "")))
-              (clobber (reg:CC REG_CC))])]
+   (set (match_operand:ALL4 0 "register_operand" "")
+        (ashift:ALL4 (match_operand:ALL4 1 "register_operand" "")
+                     (match_operand:QI 2 "const_int_operand" "")))]
   ""
   [(parallel [(set (match_dup 0)
                    (ashift:ALL4 (match_dup 1)
                                 (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
+              (clobber (match_dup 3))])])
 
 ;; "*ashlsi3_const"
 ;; "*ashlsq3_const"  "*ashlusq3_const"
 ;; "*ashlsa3_const"  "*ashlusa3_const"
-(define_insn_and_split "*ashl<mode>3_const_split"
-  [(set (match_operand:ALL4 0 "register_operand"              "=r,r,r,r")
-        (ashift:ALL4 (match_operand:ALL4 1 "register_operand"  "0,0,r,0")
-                     (match_operand:QI 2 "const_int_operand"   "L,P,O,n")))
-   (clobber (match_scratch:QI 3                               "=X,X,X,&d"))]
-  "reload_completed"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ashift:ALL4 (match_dup 1)
-                                (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
 (define_insn "*ashl<mode>3_const"
   [(set (match_operand:ALL4 0 "register_operand"              "=r,r,r,r")
         (ashift:ALL4 (match_operand:ALL4 1 "register_operand"  "0,0,r,0")
                      (match_operand:QI 2 "const_int_operand"   "L,P,O,n")))
-   (clobber (match_scratch:QI 3                               "=X,X,X,&d"))
-   (clobber (reg:CC REG_CC))]
+   (clobber (match_scratch:QI 3                               "=X,X,X,&d"))]
   "reload_completed"
   {
     return ashlsi3_out (insn, operands, NULL);
   }
   [(set_attr "length" "0,4,4,10")
-   (set_attr "adjust_len" "ashlsi")])
+   (set_attr "adjust_len" "ashlsi")
+   (set_attr "cc" "none,set_n,clobber,clobber")])
 
 (define_expand "ashlpsi3"
   [(parallel [(set (match_operand:PSI 0 "register_operand"             "")
@@ -5380,228 +3888,132 @@
       }
   })
 
-(define_insn_and_split "*ashlpsi3_split"
+(define_insn "*ashlpsi3"
   [(set (match_operand:PSI 0 "register_operand"             "=r,r,r,r")
         (ashift:PSI (match_operand:PSI 1 "register_operand"  "0,0,r,0")
                     (match_operand:QI 2 "nonmemory_operand"  "r,P,O,n")))
    (clobber (match_scratch:QI 3                             "=X,X,X,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ashift:PSI (match_dup 1)
-                               (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*ashlpsi3"
-  [(set (match_operand:PSI 0 "register_operand"             "=r,r,r,r")
-        (ashift:PSI (match_operand:PSI 1 "register_operand"  "0,0,r,0")
-                    (match_operand:QI 2 "nonmemory_operand"  "r,P,O,n")))
-   (clobber (match_scratch:QI 3                             "=X,X,X,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_ashlpsi3 (insn, operands, NULL);
   }
-  [(set_attr "adjust_len" "ashlpsi")])
+  [(set_attr "adjust_len" "ashlpsi")
+   (set_attr "cc" "clobber")])
 
 ;; >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >>
 ;; arithmetic shift right
 
 ;; "ashrqi3"
 ;; "ashrqq3"  "ashruqq3"
-(define_insn_and_split "ashr<mode>3"
+(define_insn "ashr<mode>3"
   [(set (match_operand:ALL1 0 "register_operand"                  "=r,r,r,r,r          ,r      ,r")
         (ashiftrt:ALL1 (match_operand:ALL1 1 "register_operand"    "0,0,0,0,0          ,0      ,0")
                        (match_operand:QI 2 "nop_general_operand"   "r,L,P,K,C03 C04 C05,C06 C07,Qm")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ashiftrt:ALL1 (match_dup 1)
-                                  (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*ashr<mode>3"
-  [(set (match_operand:ALL1 0 "register_operand"                  "=r,r,r,r,r          ,r      ,r")
-        (ashiftrt:ALL1 (match_operand:ALL1 1 "register_operand"    "0,0,0,0,0          ,0      ,0")
-                       (match_operand:QI 2 "nop_general_operand"   "r,L,P,K,C03 C04 C05,C06 C07,Qm")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return ashrqi3_out (insn, operands, NULL);
   }
   [(set_attr "length" "5,0,1,2,5,4,9")
-   (set_attr "adjust_len" "ashrqi")])
+   (set_attr "adjust_len" "ashrqi")
+   (set_attr "cc" "clobber,none,set_czn,set_czn,set_czn,clobber,clobber")])
 
 ;; "ashrhi3"
 ;; "ashrhq3"  "ashruhq3"
 ;; "ashrha3"  "ashruha3"
-(define_insn_and_split "ashr<mode>3"
+(define_insn "ashr<mode>3"
   [(set (match_operand:ALL2 0 "register_operand"                "=r,r,r,r,r,r,r")
         (ashiftrt:ALL2 (match_operand:ALL2 1 "register_operand"  "0,0,0,r,0,0,0")
                        (match_operand:QI 2 "nop_general_operand" "r,L,P,O,K,n,Qm")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_operand:ALL2 0 "register_operand"                "=r,r,r,r,r,r,r")
-                   (ashiftrt:ALL2 (match_operand:ALL2 1 "register_operand"  "0,0,0,r,0,0,0")
-                                  (match_operand:QI 2 "nop_general_operand" "r,L,P,O,K,n,Qm")))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*ashr<mode>3"
-  [(set (match_operand:ALL2 0 "register_operand"                "=r,r,r,r,r,r,r")
-        (ashiftrt:ALL2 (match_operand:ALL2 1 "register_operand"  "0,0,0,r,0,0,0")
-                       (match_operand:QI 2 "nop_general_operand" "r,L,P,O,K,n,Qm")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return ashrhi3_out (insn, operands, NULL);
   }
   [(set_attr "length" "6,0,2,4,4,10,10")
-   (set_attr "adjust_len" "ashrhi")])
+   (set_attr "adjust_len" "ashrhi")
+   (set_attr "cc" "clobber,none,clobber,set_n,clobber,clobber,clobber")])
 
-(define_insn_and_split "ashrpsi3"
+(define_insn "ashrpsi3"
   [(set (match_operand:PSI 0 "register_operand"                 "=r,r,r,r,r")
         (ashiftrt:PSI (match_operand:PSI 1 "register_operand"    "0,0,0,r,0")
                       (match_operand:QI 2 "nonmemory_operand"    "r,P,K,O,n")))
    (clobber (match_scratch:QI 3                                 "=X,X,X,X,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ashiftrt:PSI (match_dup 1)
-                                 (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*ashrpsi3"
-  [(set (match_operand:PSI 0 "register_operand"                 "=r,r,r,r,r")
-        (ashiftrt:PSI (match_operand:PSI 1 "register_operand"    "0,0,0,r,0")
-                      (match_operand:QI 2 "nonmemory_operand"    "r,P,K,O,n")))
-   (clobber (match_scratch:QI 3                                 "=X,X,X,X,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_ashrpsi3 (insn, operands, NULL);
   }
-  [(set_attr "adjust_len" "ashrpsi")])
+  [(set_attr "adjust_len" "ashrpsi")
+   (set_attr "cc" "clobber")])
 
 ;; "ashrsi3"
 ;; "ashrsq3"  "ashrusq3"
 ;; "ashrsa3"  "ashrusa3"
-(define_insn_and_split "ashr<mode>3"
+(define_insn "ashr<mode>3"
   [(set (match_operand:ALL4 0 "register_operand"                  "=r,r,r,r,r,r,r")
         (ashiftrt:ALL4 (match_operand:ALL4 1 "register_operand"    "0,0,0,r,0,0,0")
                        (match_operand:QI 2 "nop_general_operand"   "r,L,P,O,K,n,Qm")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ashiftrt:ALL4 (match_dup 1)
-                                  (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*ashr<mode>3"
-  [(set (match_operand:ALL4 0 "register_operand"                  "=r,r,r,r,r,r,r")
-        (ashiftrt:ALL4 (match_operand:ALL4 1 "register_operand"    "0,0,0,r,0,0,0")
-                       (match_operand:QI 2 "nop_general_operand"   "r,L,P,O,K,n,Qm")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return ashrsi3_out (insn, operands, NULL);
   }
   [(set_attr "length" "8,0,4,6,8,10,12")
-   (set_attr "adjust_len" "ashrsi")])
+   (set_attr "adjust_len" "ashrsi")
+   (set_attr "cc" "clobber,none,clobber,set_n,clobber,clobber,clobber")])
 
 ;; Optimize if a scratch register from LD_REGS happens to be available.
 
 (define_peephole2
   [(match_scratch:QI 3 "d")
-   (parallel [(set (match_operand:ALL2 0 "register_operand" "")
-                   (ashiftrt:ALL2 (match_operand:ALL2 1 "register_operand" "")
-                                  (match_operand:QI 2 "const_int_operand" "")))
-              (clobber (reg:CC REG_CC))])]
+   (set (match_operand:ALL2 0 "register_operand" "")
+        (ashiftrt:ALL2 (match_operand:ALL2 1 "register_operand" "")
+                       (match_operand:QI 2 "const_int_operand" "")))]
   ""
   [(parallel [(set (match_dup 0)
                    (ashiftrt:ALL2 (match_dup 1)
                                   (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
+              (clobber (match_dup 3))])])
 
 ;; "*ashrhi3_const"
 ;; "*ashrhq3_const"  "*ashruhq3_const"
 ;; "*ashrha3_const"  "*ashruha3_const"
-(define_insn_and_split "*ashr<mode>3_const_split"
-  [(set (match_operand:ALL2 0 "register_operand"                "=r,r,r,r,r")
-        (ashiftrt:ALL2 (match_operand:ALL2 1 "register_operand"  "0,0,r,0,0")
-                       (match_operand:QI 2 "const_int_operand"   "L,P,O,K,n")))
-   (clobber (match_scratch:QI 3                                 "=X,X,X,X,&d"))]
-  "reload_completed"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ashiftrt:ALL2 (match_dup 1)
-                                  (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
 (define_insn "*ashr<mode>3_const"
   [(set (match_operand:ALL2 0 "register_operand"                "=r,r,r,r,r")
         (ashiftrt:ALL2 (match_operand:ALL2 1 "register_operand"  "0,0,r,0,0")
                        (match_operand:QI 2 "const_int_operand"   "L,P,O,K,n")))
-   (clobber (match_scratch:QI 3                                 "=X,X,X,X,&d"))
-   (clobber (reg:CC REG_CC))]
+   (clobber (match_scratch:QI 3                                 "=X,X,X,X,&d"))]
   "reload_completed"
   {
     return ashrhi3_out (insn, operands, NULL);
   }
   [(set_attr "length" "0,2,4,4,10")
-   (set_attr "adjust_len" "ashrhi")])
+   (set_attr "adjust_len" "ashrhi")
+   (set_attr "cc" "none,clobber,set_n,clobber,clobber")])
 
 (define_peephole2
   [(match_scratch:QI 3 "d")
-   (parallel [(set (match_operand:ALL4 0 "register_operand" "")
-                   (ashiftrt:ALL4 (match_operand:ALL4 1 "register_operand" "")
-                                  (match_operand:QI 2 "const_int_operand" "")))
-              (clobber (reg:CC REG_CC))])]
+   (set (match_operand:ALL4 0 "register_operand" "")
+        (ashiftrt:ALL4 (match_operand:ALL4 1 "register_operand" "")
+                       (match_operand:QI 2 "const_int_operand" "")))]
   ""
   [(parallel [(set (match_dup 0)
                    (ashiftrt:ALL4 (match_dup 1)
                                   (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
+              (clobber (match_dup 3))])])
 
 ;; "*ashrsi3_const"
 ;; "*ashrsq3_const"  "*ashrusq3_const"
 ;; "*ashrsa3_const"  "*ashrusa3_const"
-(define_insn_and_split "*ashr<mode>3_const_split"
-  [(set (match_operand:ALL4 0 "register_operand"                "=r,r,r,r")
-        (ashiftrt:ALL4 (match_operand:ALL4 1 "register_operand"  "0,0,r,0")
-                       (match_operand:QI 2 "const_int_operand"   "L,P,O,n")))
-   (clobber (match_scratch:QI 3                                 "=X,X,X,&d"))]
-  "reload_completed"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (ashiftrt:ALL4 (match_dup 1)
-                                  (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
 (define_insn "*ashr<mode>3_const"
   [(set (match_operand:ALL4 0 "register_operand"                "=r,r,r,r")
         (ashiftrt:ALL4 (match_operand:ALL4 1 "register_operand"  "0,0,r,0")
                        (match_operand:QI 2 "const_int_operand"   "L,P,O,n")))
-   (clobber (match_scratch:QI 3                                 "=X,X,X,&d"))
-   (clobber (reg:CC REG_CC))]
+   (clobber (match_scratch:QI 3                                 "=X,X,X,&d"))]
   "reload_completed"
   {
     return ashrsi3_out (insn, operands, NULL);
   }
   [(set_attr "length" "0,4,4,10")
-   (set_attr "adjust_len" "ashrsi")])
+   (set_attr "adjust_len" "ashrsi")
+   (set_attr "cc" "none,clobber,set_n,clobber")])
 
 ;; >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >> >>
 ;; logical shift right
@@ -5655,499 +4067,281 @@
 ;; "*lshrqi3"
 ;; "*lshrqq3"
 ;; "*lshruqq3"
-(define_insn_and_split "*lshr<mode>3_split"
+(define_insn "*lshr<mode>3"
   [(set (match_operand:ALL1 0 "register_operand"                  "=r,r,r,r,!d,r,r")
         (lshiftrt:ALL1 (match_operand:ALL1 1 "register_operand"    "0,0,0,0,0 ,0,0")
                        (match_operand:QI 2 "nop_general_operand"   "r,L,P,K,n ,n,Qm")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (lshiftrt:ALL1 (match_dup 1)
-                                  (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*lshr<mode>3"
-  [(set (match_operand:ALL1 0 "register_operand"                  "=r,r,r,r,!d,r,r")
-        (lshiftrt:ALL1 (match_operand:ALL1 1 "register_operand"    "0,0,0,0,0 ,0,0")
-                       (match_operand:QI 2 "nop_general_operand"   "r,L,P,K,n ,n,Qm")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return lshrqi3_out (insn, operands, NULL);
   }
   [(set_attr "length" "5,0,1,2,4,6,9")
-   (set_attr "adjust_len" "lshrqi")])
+   (set_attr "adjust_len" "lshrqi")
+   (set_attr "cc" "clobber,none,set_czn,set_czn,set_czn,set_czn,clobber")])
 
 ;; "lshrhi3"
 ;; "lshrhq3"  "lshruhq3"
 ;; "lshrha3"  "lshruha3"
-(define_insn_and_split "lshr<mode>3"
+(define_insn "lshr<mode>3"
   [(set (match_operand:ALL2 0 "register_operand"                "=r,r,r,r,r,r,r")
         (lshiftrt:ALL2 (match_operand:ALL2 1 "register_operand"    "0,0,0,r,0,0,0")
                        (match_operand:QI 2 "nop_general_operand" "r,L,P,O,K,n,Qm")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (lshiftrt:ALL2 (match_dup 1)
-                                  (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*lshr<mode>3"
-  [(set (match_operand:ALL2 0 "register_operand"                "=r,r,r,r,r,r,r")
-        (lshiftrt:ALL2 (match_operand:ALL2 1 "register_operand"    "0,0,0,r,0,0,0")
-                       (match_operand:QI 2 "nop_general_operand" "r,L,P,O,K,n,Qm")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return lshrhi3_out (insn, operands, NULL);
-  }
-  [(set_attr "length" "6,0,2,2,4,10,10")
-   (set_attr "adjust_len" "lshrhi")])
-
-(define_insn_and_split "lshrpsi3"
-  [(set (match_operand:PSI 0 "register_operand"                 "=r,r,r,r,r")
-        (lshiftrt:PSI (match_operand:PSI 1 "register_operand"    "0,0,r,0,0")
-                      (match_operand:QI 2 "nonmemory_operand"    "r,P,O,K,n")))
-   (clobber (match_scratch:QI 3                                 "=X,X,X,X,&d"))]
-  ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (lshiftrt:PSI (match_dup 1)
-                                 (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
+  }
+  [(set_attr "length" "6,0,2,2,4,10,10")
+   (set_attr "adjust_len" "lshrhi")
+   (set_attr "cc" "clobber,none,clobber,clobber,clobber,clobber,clobber")])
 
-(define_insn "*lshrpsi3"
+(define_insn "lshrpsi3"
   [(set (match_operand:PSI 0 "register_operand"                 "=r,r,r,r,r")
         (lshiftrt:PSI (match_operand:PSI 1 "register_operand"    "0,0,r,0,0")
                       (match_operand:QI 2 "nonmemory_operand"    "r,P,O,K,n")))
-   (clobber (match_scratch:QI 3                                 "=X,X,X,X,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
+   (clobber (match_scratch:QI 3                                 "=X,X,X,X,&d"))]
+  ""
   {
     return avr_out_lshrpsi3 (insn, operands, NULL);
   }
-  [(set_attr "adjust_len" "lshrpsi")])
+  [(set_attr "adjust_len" "lshrpsi")
+   (set_attr "cc" "clobber")])
 
 ;; "lshrsi3"
 ;; "lshrsq3"  "lshrusq3"
 ;; "lshrsa3"  "lshrusa3"
-(define_insn_and_split "lshr<mode>3"
+(define_insn "lshr<mode>3"
   [(set (match_operand:ALL4 0 "register_operand"                  "=r,r,r,r,r,r,r")
         (lshiftrt:ALL4 (match_operand:ALL4 1 "register_operand"    "0,0,0,r,0,0,0")
                        (match_operand:QI 2 "nop_general_operand"   "r,L,P,O,K,n,Qm")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (lshiftrt:ALL4 (match_dup 1)
-                                  (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*lshr<mode>3"
-  [(set (match_operand:ALL4 0 "register_operand"                  "=r,r,r,r,r,r,r")
-        (lshiftrt:ALL4 (match_operand:ALL4 1 "register_operand"    "0,0,0,r,0,0,0")
-                       (match_operand:QI 2 "nop_general_operand"   "r,L,P,O,K,n,Qm")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return lshrsi3_out (insn, operands, NULL);
   }
   [(set_attr "length" "8,0,4,4,8,10,12")
-   (set_attr "adjust_len" "lshrsi")])
+   (set_attr "adjust_len" "lshrsi")
+   (set_attr "cc" "clobber,none,clobber,clobber,clobber,clobber,clobber")])
 
 ;; Optimize if a scratch register from LD_REGS happens to be available.
 
 (define_peephole2 ; lshrqi3_l_const4
-  [(parallel [(set (match_operand:ALL1 0 "l_register_operand" "")
-                   (lshiftrt:ALL1 (match_dup 0)
-                                  (const_int 4)))
-              (clobber (reg:CC REG_CC))])
+  [(set (match_operand:ALL1 0 "l_register_operand" "")
+        (lshiftrt:ALL1 (match_dup 0)
+                       (const_int 4)))
    (match_scratch:QI 1 "d")]
   ""
-  [(parallel [(set (match_dup 2) (rotate:QI (match_dup 2) (const_int 4)))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 1) (const_int 15))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 2) (and:QI (match_dup 2) (match_dup 1)))
-              (clobber (reg:CC REG_CC))])]
+  [(set (match_dup 2) (rotate:QI (match_dup 2) (const_int 4)))
+   (set (match_dup 1) (const_int 15))
+   (set (match_dup 2) (and:QI (match_dup 2) (match_dup 1)))]
   {
     operands[2] = avr_to_int_mode (operands[0]);
   })
 
 (define_peephole2 ; lshrqi3_l_const5
-  [(parallel [(set (match_operand:ALL1 0 "l_register_operand" "")
-                   (lshiftrt:ALL1 (match_dup 0)
-                                  (const_int 5)))
-              (clobber (reg:CC REG_CC))])
+  [(set (match_operand:ALL1 0 "l_register_operand" "")
+        (lshiftrt:ALL1 (match_dup 0)
+                       (const_int 5)))
    (match_scratch:QI 1 "d")]
   ""
-  [(parallel [(set (match_dup 2) (rotate:QI (match_dup 2) (const_int 4)))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 2) (lshiftrt:QI (match_dup 2) (const_int 1)))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 1) (const_int 7))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 2) (and:QI (match_dup 2) (match_dup 1)))
-              (clobber (reg:CC REG_CC))])]
+  [(set (match_dup 2) (rotate:QI (match_dup 2) (const_int 4)))
+   (set (match_dup 2) (lshiftrt:QI (match_dup 2) (const_int 1)))
+   (set (match_dup 1) (const_int 7))
+   (set (match_dup 2) (and:QI (match_dup 2) (match_dup 1)))]
   {
     operands[2] = avr_to_int_mode (operands[0]);
   })
 
 (define_peephole2 ; lshrqi3_l_const6
-  [(parallel [(set (match_operand:ALL1 0 "l_register_operand" "")
-                   (lshiftrt:ALL1 (match_dup 0)
-                                  (const_int 6)))
-              (clobber (reg:CC REG_CC))])
+  [(set (match_operand:ALL1 0 "l_register_operand" "")
+        (lshiftrt:ALL1 (match_dup 0)
+                       (const_int 6)))
    (match_scratch:QI 1 "d")]
   ""
-  [(parallel [(set (match_dup 2) (rotate:QI (match_dup 2) (const_int 4)))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 2) (lshiftrt:QI (match_dup 2) (const_int 2)))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 1) (const_int 3))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 2) (and:QI (match_dup 2) (match_dup 1)))
-              (clobber (reg:CC REG_CC))])]
+  [(set (match_dup 2) (rotate:QI (match_dup 2) (const_int 4)))
+   (set (match_dup 2) (lshiftrt:QI (match_dup 2) (const_int 2)))
+   (set (match_dup 1) (const_int 3))
+   (set (match_dup 2) (and:QI (match_dup 2) (match_dup 1)))]
   {
     operands[2] = avr_to_int_mode (operands[0]);
   })
 
 (define_peephole2
   [(match_scratch:QI 3 "d")
-   (parallel [(set (match_operand:ALL2 0 "register_operand" "")
-                   (lshiftrt:ALL2 (match_operand:ALL2 1 "register_operand" "")
-                                  (match_operand:QI 2 "const_int_operand" "")))
-              (clobber (reg:CC REG_CC))])]
+   (set (match_operand:ALL2 0 "register_operand" "")
+        (lshiftrt:ALL2 (match_operand:ALL2 1 "register_operand" "")
+                       (match_operand:QI 2 "const_int_operand" "")))]
   ""
   [(parallel [(set (match_dup 0)
                    (lshiftrt:ALL2 (match_dup 1)
                                   (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
+              (clobber (match_dup 3))])])
 
 ;; "*lshrhi3_const"
 ;; "*lshrhq3_const"  "*lshruhq3_const"
 ;; "*lshrha3_const"  "*lshruha3_const"
-(define_insn_and_split "*lshr<mode>3_const_split"
-  [(set (match_operand:ALL2 0 "register_operand"                "=r,r,r,r,r")
-        (lshiftrt:ALL2 (match_operand:ALL2 1 "register_operand"  "0,0,r,0,0")
-                       (match_operand:QI 2 "const_int_operand"   "L,P,O,K,n")))
-   (clobber (match_scratch:QI 3                                 "=X,X,X,X,&d"))]
-  "reload_completed"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (lshiftrt:ALL2 (match_dup 1)
-                                  (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
 (define_insn "*lshr<mode>3_const"
   [(set (match_operand:ALL2 0 "register_operand"                "=r,r,r,r,r")
         (lshiftrt:ALL2 (match_operand:ALL2 1 "register_operand"  "0,0,r,0,0")
                        (match_operand:QI 2 "const_int_operand"   "L,P,O,K,n")))
-   (clobber (match_scratch:QI 3                                 "=X,X,X,X,&d"))
-   (clobber (reg:CC REG_CC))]
+   (clobber (match_scratch:QI 3                                 "=X,X,X,X,&d"))]
   "reload_completed"
   {
     return lshrhi3_out (insn, operands, NULL);
   }
   [(set_attr "length" "0,2,2,4,10")
-   (set_attr "adjust_len" "lshrhi")])
+   (set_attr "adjust_len" "lshrhi")
+   (set_attr "cc" "none,clobber,clobber,clobber,clobber")])
 
 (define_peephole2
   [(match_scratch:QI 3 "d")
-   (parallel [(set (match_operand:ALL4 0 "register_operand" "")
-                   (lshiftrt:ALL4 (match_operand:ALL4 1 "register_operand" "")
-                                  (match_operand:QI 2 "const_int_operand" "")))
-              (clobber (reg:CC REG_CC))])]
+   (set (match_operand:ALL4 0 "register_operand" "")
+        (lshiftrt:ALL4 (match_operand:ALL4 1 "register_operand" "")
+                       (match_operand:QI 2 "const_int_operand" "")))]
   ""
   [(parallel [(set (match_dup 0)
                    (lshiftrt:ALL4 (match_dup 1)
                                   (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
+              (clobber (match_dup 3))])])
 
 ;; "*lshrsi3_const"
 ;; "*lshrsq3_const"  "*lshrusq3_const"
 ;; "*lshrsa3_const"  "*lshrusa3_const"
-(define_insn_and_split "*lshr<mode>3_const_split"
-  [(set (match_operand:ALL4 0 "register_operand"               "=r,r,r,r")
-        (lshiftrt:ALL4 (match_operand:ALL4 1 "register_operand" "0,0,r,0")
-                       (match_operand:QI 2 "const_int_operand"  "L,P,O,n")))
-   (clobber (match_scratch:QI 3                                "=X,X,X,&d"))]
-  "reload_completed"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (lshiftrt:ALL4 (match_dup 1)
-                                  (match_dup 2)))
-              (clobber (match_dup 3))
-              (clobber (reg:CC REG_CC))])])
-
 (define_insn "*lshr<mode>3_const"
   [(set (match_operand:ALL4 0 "register_operand"               "=r,r,r,r")
         (lshiftrt:ALL4 (match_operand:ALL4 1 "register_operand" "0,0,r,0")
                        (match_operand:QI 2 "const_int_operand"  "L,P,O,n")))
-   (clobber (match_scratch:QI 3                                "=X,X,X,&d"))
-   (clobber (reg:CC REG_CC))]
+   (clobber (match_scratch:QI 3                                "=X,X,X,&d"))]
   "reload_completed"
   {
     return lshrsi3_out (insn, operands, NULL);
   }
   [(set_attr "length" "0,4,4,10")
-   (set_attr "adjust_len" "lshrsi")])
+   (set_attr "adjust_len" "lshrsi")
+   (set_attr "cc" "none,clobber,clobber,clobber")])
 
 ;; abs(x) abs(x) abs(x) abs(x) abs(x) abs(x) abs(x) abs(x) abs(x) abs(x) abs(x)
 ;; abs
 
-(define_insn_and_split "absqi2"
+(define_insn "absqi2"
   [(set (match_operand:QI 0 "register_operand" "=r")
         (abs:QI (match_operand:QI 1 "register_operand" "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (abs:QI (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*absqi2"
-  [(set (match_operand:QI 0 "register_operand" "=r")
-        (abs:QI (match_operand:QI 1 "register_operand" "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "sbrc %0,7
 	neg %0"
-  [(set_attr "length" "2")])
+  [(set_attr "length" "2")
+   (set_attr "cc" "clobber")])
 
 
-(define_insn_and_split "abssf2"
+(define_insn "abssf2"
   [(set (match_operand:SF 0 "register_operand" "=d,r")
         (abs:SF (match_operand:SF 1 "register_operand" "0,0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (abs:SF (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*abssf2"
-  [(set (match_operand:SF 0 "register_operand" "=d,r")
-        (abs:SF (match_operand:SF 1 "register_operand" "0,0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "@
 	andi %D0,0x7f
 	clt\;bld %D0,7"
-  [(set_attr "length" "1,2")])
+  [(set_attr "length" "1,2")
+   (set_attr "cc" "set_n,clobber")])
 
 ;; 0 - x  0 - x  0 - x  0 - x  0 - x  0 - x  0 - x  0 - x  0 - x  0 - x  0 - x
 ;; neg
 
-(define_insn_and_split "negqi2"
+(define_insn "negqi2"
   [(set (match_operand:QI 0 "register_operand" "=r")
         (neg:QI (match_operand:QI 1 "register_operand" "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (neg:QI (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*negqi2"
-  [(set (match_operand:QI 0 "register_operand" "=r")
-        (neg:QI (match_operand:QI 1 "register_operand" "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "neg %0"
-  [(set_attr "length" "1")])
+  [(set_attr "length" "1")
+   (set_attr "cc" "set_vzn")])
 
-(define_insn_and_split "*negqihi2_split"
+(define_insn "*negqihi2"
   [(set (match_operand:HI 0 "register_operand"                        "=r")
         (neg:HI (sign_extend:HI (match_operand:QI 1 "register_operand" "0"))))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (neg:HI (sign_extend:HI (match_dup 1))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*negqihi2"
-  [(set (match_operand:HI 0 "register_operand"                        "=r")
-        (neg:HI (sign_extend:HI (match_operand:QI 1 "register_operand" "0"))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "clr %B0\;neg %A0\;brge .+2\;com %B0"
-  [(set_attr "length" "4")])
+  [(set_attr "length" "4")
+   (set_attr "cc" "set_n")])
 
-(define_insn_and_split "neghi2"
+(define_insn "neghi2"
   [(set (match_operand:HI 0 "register_operand"        "=r,&r")
         (neg:HI (match_operand:HI 1 "register_operand" "0,r")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (neg:HI (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*neghi2"
-  [(set (match_operand:HI 0 "register_operand"        "=r,&r")
-        (neg:HI (match_operand:HI 1 "register_operand" "0,r")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "@
 	neg %B0\;neg %A0\;sbc %B0,__zero_reg__
 	clr %A0\;clr %B0\;sub %A0,%A1\;sbc %B0,%B1"
-  [(set_attr "length" "3,4")])
+  [(set_attr "length" "3,4")
+   (set_attr "cc" "set_czn")])
 
-(define_insn_and_split "negpsi2"
+(define_insn "negpsi2"
   [(set (match_operand:PSI 0 "register_operand"        "=!d,r,&r")
         (neg:PSI (match_operand:PSI 1 "register_operand" "0,0,r")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (neg:PSI (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*negpsi2"
-  [(set (match_operand:PSI 0 "register_operand"        "=!d,r,&r")
-        (neg:PSI (match_operand:PSI 1 "register_operand" "0,0,r")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "@
 	com %C0\;com %B0\;neg %A0\;sbci %B0,-1\;sbci %C0,-1
 	com %C0\;com %B0\;com %A0\;adc %A0,__zero_reg__\;adc %B0,__zero_reg__\;adc %C0,__zero_reg__
 	clr %A0\;clr %B0\;clr %C0\;sub %A0,%A1\;sbc %B0,%B1\;sbc %C0,%C1"
-  [(set_attr "length" "5,6,6")])
+  [(set_attr "length" "5,6,6")
+   (set_attr "cc" "set_czn,set_n,set_czn")])
 
-(define_insn_and_split "negsi2"
+(define_insn "negsi2"
   [(set (match_operand:SI 0 "register_operand"       "=!d,r,&r,&r")
         (neg:SI (match_operand:SI 1 "register_operand" "0,0,r ,r")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (neg:SI (match_dup 1)))
-              (clobber (reg:CC REG_CC))])]
-  ""
-  [(set_attr "isa" "*,*,mov,movw")])
-
-(define_insn "*negsi2"
-  [(set (match_operand:SI 0 "register_operand"       "=!d,r,&r,&r")
-        (neg:SI (match_operand:SI 1 "register_operand" "0,0,r ,r")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "@
 	com %D0\;com %C0\;com %B0\;neg %A0\;sbci %B0,lo8(-1)\;sbci %C0,lo8(-1)\;sbci %D0,lo8(-1)
 	com %D0\;com %C0\;com %B0\;com %A0\;adc %A0,__zero_reg__\;adc %B0,__zero_reg__\;adc %C0,__zero_reg__\;adc %D0,__zero_reg__
 	clr %A0\;clr %B0\;clr %C0\;clr %D0\;sub %A0,%A1\;sbc %B0,%B1\;sbc %C0,%C1\;sbc %D0,%D1
 	clr %A0\;clr %B0\;movw %C0,%A0\;sub %A0,%A1\;sbc %B0,%B1\;sbc %C0,%C1\;sbc %D0,%D1"
   [(set_attr "length" "7,8,8,7")
-   (set_attr "isa"    "*,*,mov,movw")])
+   (set_attr "isa"    "*,*,mov,movw")
+   (set_attr "cc" "set_czn,set_n,set_czn,set_czn")])
 
-(define_insn_and_split "negsf2"
+(define_insn "negsf2"
   [(set (match_operand:SF 0 "register_operand" "=d,r")
 	(neg:SF (match_operand:SF 1 "register_operand" "0,0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-	               (neg:SF (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*negsf2"
-  [(set (match_operand:SF 0 "register_operand" "=d,r")
-	(neg:SF (match_operand:SF 1 "register_operand" "0,0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "@
 	subi %D0,0x80
 	bst %D0,7\;com %D0\;bld %D0,7\;com %D0"
-  [(set_attr "length" "1,4")])
+  [(set_attr "length" "1,4")
+   (set_attr "cc" "set_n,set_n")])
 
 ;; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
 ;; not
 
-(define_insn_and_split "one_cmplqi2"
+(define_insn "one_cmplqi2"
   [(set (match_operand:QI 0 "register_operand" "=r")
         (not:QI (match_operand:QI 1 "register_operand" "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (not:QI (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*one_cmplqi2"
-  [(set (match_operand:QI 0 "register_operand" "=r")
-        (not:QI (match_operand:QI 1 "register_operand" "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "com %0"
-  [(set_attr "length" "1")])
+  [(set_attr "length" "1")
+   (set_attr "cc" "set_czn")])
 
-(define_insn_and_split "one_cmplhi2"
+(define_insn "one_cmplhi2"
   [(set (match_operand:HI 0 "register_operand" "=r")
         (not:HI (match_operand:HI 1 "register_operand" "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (not:HI (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*one_cmplhi2"
-  [(set (match_operand:HI 0 "register_operand" "=r")
-        (not:HI (match_operand:HI 1 "register_operand" "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "com %0
 	com %B0"
-  [(set_attr "length" "2")])
+  [(set_attr "length" "2")
+   (set_attr "cc" "set_n")])
 
-(define_insn_and_split "one_cmplpsi2"
+(define_insn "one_cmplpsi2"
   [(set (match_operand:PSI 0 "register_operand" "=r")
         (not:PSI (match_operand:PSI 1 "register_operand" "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (not:PSI (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*one_cmplpsi2"
-  [(set (match_operand:PSI 0 "register_operand" "=r")
-        (not:PSI (match_operand:PSI 1 "register_operand" "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "com %0\;com %B0\;com %C0"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "set_n")])
 
-(define_insn_and_split "one_cmplsi2"
+(define_insn "one_cmplsi2"
   [(set (match_operand:SI 0 "register_operand" "=r")
         (not:SI (match_operand:SI 1 "register_operand" "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (not:SI (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*one_cmplsi2"
-  [(set (match_operand:SI 0 "register_operand" "=r")
-        (not:SI (match_operand:SI 1 "register_operand" "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "com %0
 	com %B0
 	com %C0
 	com %D0"
-  [(set_attr "length" "4")])
+  [(set_attr "length" "4")
+   (set_attr "cc" "set_n")])
 
 ;; xx<---x xx<---x xx<---x xx<---x xx<---x xx<---x xx<---x xx<---x xx<---x
 ;; sign extend
@@ -6159,131 +4353,71 @@
 ;; multiplication.  There is no need for combine to propagate hard registers,
 ;; register allocation can do it just as well.
 
-(define_insn_and_split "extendqihi2"
+(define_insn "extendqihi2"
   [(set (match_operand:HI 0 "register_operand" "=r,r")
         (sign_extend:HI (match_operand:QI 1 "combine_pseudo_register_operand" "0,*r")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (sign_extend:HI (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*extendqihi2"
-  [(set (match_operand:HI 0 "register_operand" "=r,r")
-        (sign_extend:HI (match_operand:QI 1 "combine_pseudo_register_operand" "0,*r")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_sign_extend (insn, operands, NULL);
   }
   [(set_attr "length" "3,4")
-   (set_attr "adjust_len" "sext")])
+   (set_attr "adjust_len" "sext")
+   (set_attr "cc" "set_n")])
 
-(define_insn_and_split "extendqipsi2"
+(define_insn "extendqipsi2"
   [(set (match_operand:PSI 0 "register_operand" "=r,r")
         (sign_extend:PSI (match_operand:QI 1 "combine_pseudo_register_operand" "0,*r")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (sign_extend:PSI (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*extendqipsi2"
-  [(set (match_operand:PSI 0 "register_operand" "=r,r")
-        (sign_extend:PSI (match_operand:QI 1 "combine_pseudo_register_operand" "0,*r")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_sign_extend (insn, operands, NULL);
   }
   [(set_attr "length" "4,5")
-   (set_attr "adjust_len" "sext")])
+   (set_attr "adjust_len" "sext")
+   (set_attr "cc" "set_n")])
 
-(define_insn_and_split "extendqisi2"
+(define_insn "extendqisi2"
   [(set (match_operand:SI 0 "register_operand" "=r,r")
         (sign_extend:SI (match_operand:QI 1 "combine_pseudo_register_operand" "0,*r")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (sign_extend:SI (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*extendqisi2"
-  [(set (match_operand:SI 0 "register_operand" "=r,r")
-        (sign_extend:SI (match_operand:QI 1 "combine_pseudo_register_operand" "0,*r")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_sign_extend (insn, operands, NULL);
   }
   [(set_attr "length" "5,6")
-   (set_attr "adjust_len" "sext")])
+   (set_attr "adjust_len" "sext")
+   (set_attr "cc" "set_n")])
 
-(define_insn_and_split "extendhipsi2"
+(define_insn "extendhipsi2"
   [(set (match_operand:PSI 0 "register_operand"                               "=r,r")
         (sign_extend:PSI (match_operand:HI 1 "combine_pseudo_register_operand" "0,*r")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (sign_extend:PSI (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*extendhipsi2"
-  [(set (match_operand:PSI 0 "register_operand"                               "=r,r")
-        (sign_extend:PSI (match_operand:HI 1 "combine_pseudo_register_operand" "0,*r")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_sign_extend (insn, operands, NULL);
   }
   [(set_attr "length" "3,5")
-   (set_attr "adjust_len" "sext")])
+   (set_attr "adjust_len" "sext")
+   (set_attr "cc" "set_n")])
 
-(define_insn_and_split "extendhisi2"
+(define_insn "extendhisi2"
   [(set (match_operand:SI 0 "register_operand"                               "=r,r")
         (sign_extend:SI (match_operand:HI 1 "combine_pseudo_register_operand" "0,*r")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (sign_extend:SI (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*extendhisi2"
-  [(set (match_operand:SI 0 "register_operand"                               "=r,r")
-        (sign_extend:SI (match_operand:HI 1 "combine_pseudo_register_operand" "0,*r")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_sign_extend (insn, operands, NULL);
   }
   [(set_attr "length" "4,6")
-   (set_attr "adjust_len" "sext")])
+   (set_attr "adjust_len" "sext")
+   (set_attr "cc" "set_n")])
 
-(define_insn_and_split "extendpsisi2"
+(define_insn "extendpsisi2"
   [(set (match_operand:SI 0 "register_operand"                                "=r")
         (sign_extend:SI (match_operand:PSI 1 "combine_pseudo_register_operand" "0")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (sign_extend:SI (match_dup 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*extendpsisi2"
-  [(set (match_operand:SI 0 "register_operand"                                "=r")
-        (sign_extend:SI (match_operand:PSI 1 "combine_pseudo_register_operand" "0")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_sign_extend (insn, operands, NULL);
   }
   [(set_attr "length" "3")
-   (set_attr "adjust_len" "sext")])
+   (set_attr "adjust_len" "sext")
+   (set_attr "cc" "set_n")])
 
 ;; xx<---x xx<---x xx<---x xx<---x xx<---x xx<---x xx<---x xx<---x xx<---x
 ;; zero extend
@@ -6451,133 +4585,145 @@
 
 ; Optimize negated tests into reverse compare if overflow is undefined.
 (define_insn "*negated_tstqi"
-  [(set (reg:CC REG_CC)
-        (compare:CC (neg:QI (match_operand:QI 0 "register_operand" "r"))
+  [(set (cc0)
+        (compare (neg:QI (match_operand:QI 0 "register_operand" "r"))
                  (const_int 0)))]
-  "reload_completed && !flag_wrapv && !flag_trapv"
+  "!flag_wrapv && !flag_trapv"
   "cp __zero_reg__,%0"
-  [(set_attr "length" "1")])
+  [(set_attr "cc" "compare")
+   (set_attr "length" "1")])
 
 (define_insn "*reversed_tstqi"
-  [(set (reg:CC REG_CC)
-        (compare:CC (const_int 0)
+  [(set (cc0)
+        (compare (const_int 0)
                  (match_operand:QI 0 "register_operand" "r")))]
-  "reload_completed"
+  ""
   "cp __zero_reg__,%0"
-[(set_attr "length" "2")])
+[(set_attr "cc" "compare")
+ (set_attr "length" "2")])
 
 (define_insn "*negated_tsthi"
-  [(set (reg:CC REG_CC)
-        (compare:CC (neg:HI (match_operand:HI 0 "register_operand" "r"))
+  [(set (cc0)
+        (compare (neg:HI (match_operand:HI 0 "register_operand" "r"))
                  (const_int 0)))]
-  "reload_completed && !flag_wrapv && !flag_trapv"
+  "!flag_wrapv && !flag_trapv"
   "cp __zero_reg__,%A0
 	cpc __zero_reg__,%B0"
-[(set_attr "length" "2")])
+[(set_attr "cc" "compare")
+ (set_attr "length" "2")])
 
 ;; Leave here the clobber used by the cmphi pattern for simplicity, even
 ;; though it is unused, because this pattern is synthesized by avr_reorg.
 (define_insn "*reversed_tsthi"
-  [(set (reg:CC REG_CC)
-        (compare:CC (const_int 0)
+  [(set (cc0)
+        (compare (const_int 0)
                  (match_operand:HI 0 "register_operand" "r")))
    (clobber (match_scratch:QI 1 "=X"))]
-  "reload_completed"
+  ""
   "cp __zero_reg__,%A0
 	cpc __zero_reg__,%B0"
-[(set_attr "length" "2")])
+[(set_attr "cc" "compare")
+ (set_attr "length" "2")])
 
 (define_insn "*negated_tstpsi"
-  [(set (reg:CC REG_CC)
-        (compare:CC (neg:PSI (match_operand:PSI 0 "register_operand" "r"))
+  [(set (cc0)
+        (compare (neg:PSI (match_operand:PSI 0 "register_operand" "r"))
                  (const_int 0)))]
-  "reload_completed && !flag_wrapv && !flag_trapv"
+  "!flag_wrapv && !flag_trapv"
   "cp __zero_reg__,%A0\;cpc __zero_reg__,%B0\;cpc __zero_reg__,%C0"
-  [(set_attr "length" "3")])
+  [(set_attr "cc" "compare")
+   (set_attr "length" "3")])
 
 (define_insn "*reversed_tstpsi"
-  [(set (reg:CC REG_CC)
-        (compare:CC (const_int 0)
+  [(set (cc0)
+        (compare (const_int 0)
                  (match_operand:PSI 0 "register_operand" "r")))
    (clobber (match_scratch:QI 1 "=X"))]
-  "reload_completed"
+  ""
   "cp __zero_reg__,%A0\;cpc __zero_reg__,%B0\;cpc __zero_reg__,%C0"
-  [(set_attr "length" "3")])
+  [(set_attr "cc" "compare")
+   (set_attr "length" "3")])
 
 (define_insn "*negated_tstsi"
-  [(set (reg:CC REG_CC)
-        (compare:CC (neg:SI (match_operand:SI 0 "register_operand" "r"))
+  [(set (cc0)
+        (compare (neg:SI (match_operand:SI 0 "register_operand" "r"))
                  (const_int 0)))]
-  "reload_completed && !flag_wrapv && !flag_trapv"
+  "!flag_wrapv && !flag_trapv"
   "cp __zero_reg__,%A0
 	cpc __zero_reg__,%B0
 	cpc __zero_reg__,%C0
 	cpc __zero_reg__,%D0"
-  [(set_attr "length" "4")])
+  [(set_attr "cc" "compare")
+   (set_attr "length" "4")])
 
 ;; "*reversed_tstsi"
 ;; "*reversed_tstsq" "*reversed_tstusq"
 ;; "*reversed_tstsa" "*reversed_tstusa"
 (define_insn "*reversed_tst<mode>"
-  [(set (reg:CC REG_CC)
-        (compare:CC (match_operand:ALL4 0 "const0_operand"   "Y00")
+  [(set (cc0)
+        (compare (match_operand:ALL4 0 "const0_operand"   "Y00")
                  (match_operand:ALL4 1 "register_operand" "r")))
    (clobber (match_scratch:QI 2 "=X"))]
-  "reload_completed"
+  ""
   "cp __zero_reg__,%A1
 	cpc __zero_reg__,%B1
 	cpc __zero_reg__,%C1
 	cpc __zero_reg__,%D1"
-  [(set_attr "length" "4")])
+  [(set_attr "cc" "compare")
+   (set_attr "length" "4")])
 
 
 ;; "cmpqi3"
 ;; "cmpqq3" "cmpuqq3"
 (define_insn "cmp<mode>3"
-  [(set (reg:CC REG_CC)
-        (compare:CC (match_operand:ALL1 0 "register_operand"  "r  ,r,d")
+  [(set (cc0)
+        (compare (match_operand:ALL1 0 "register_operand"  "r  ,r,d")
                  (match_operand:ALL1 1 "nonmemory_operand" "Y00,r,i")))]
-  "reload_completed"
+  ""
   "@
 	tst %0
 	cp %0,%1
 	cpi %0,lo8(%1)"
-  [(set_attr "length" "1,1,1")])
+  [(set_attr "cc" "compare,compare,compare")
+   (set_attr "length" "1,1,1")])
 
 (define_insn "*cmpqi_sign_extend"
-  [(set (reg:CC REG_CC)
-        (compare:CC (sign_extend:HI (match_operand:QI 0 "register_operand" "d"))
+  [(set (cc0)
+        (compare (sign_extend:HI (match_operand:QI 0 "register_operand" "d"))
                  (match_operand:HI 1 "s8_operand"                       "n")))]
-  "reload_completed"
+  ""
   "cpi %0,lo8(%1)"
-  [(set_attr "length" "1")])
+  [(set_attr "cc" "compare")
+   (set_attr "length" "1")])
 
 
 (define_insn "*cmphi.zero-extend.0"
-  [(set (reg:CC REG_CC)
-        (compare:CC (zero_extend:HI (match_operand:QI 0 "register_operand" "r"))
+  [(set (cc0)
+        (compare (zero_extend:HI (match_operand:QI 0 "register_operand" "r"))
                  (match_operand:HI 1 "register_operand" "r")))]
-  "reload_completed"
+  ""
   "cp %0,%A1\;cpc __zero_reg__,%B1"
-  [(set_attr "length" "2")])
+  [(set_attr "cc" "compare")
+   (set_attr "length" "2")])
 
 (define_insn "*cmphi.zero-extend.1"
-  [(set (reg:CC REG_CC)
-        (compare:CC (match_operand:HI 0 "register_operand" "r")
+  [(set (cc0)
+        (compare (match_operand:HI 0 "register_operand" "r")
                  (zero_extend:HI (match_operand:QI 1 "register_operand" "r"))))]
-  "reload_completed"
+  ""
   "cp %A0,%1\;cpc %B0,__zero_reg__"
-  [(set_attr "length" "2")])
+  [(set_attr "cc" "compare")
+   (set_attr "length" "2")])
 
 ;; "cmphi3"
 ;; "cmphq3" "cmpuhq3"
 ;; "cmpha3" "cmpuha3"
 (define_insn "cmp<mode>3"
-  [(set (reg:CC REG_CC)
-        (compare:CC (match_operand:ALL2 0 "register_operand"  "!w  ,r  ,r,d ,r  ,d,r")
+  [(set (cc0)
+        (compare (match_operand:ALL2 0 "register_operand"  "!w  ,r  ,r,d ,r  ,d,r")
                  (match_operand:ALL2 1 "nonmemory_operand"  "Y00,Y00,r,s ,s  ,M,n Ynn")))
    (clobber (match_scratch:QI 2                            "=X  ,X  ,X,&d,&d ,X,&d"))]
-  "reload_completed"
+  ""
   {
     switch (which_alternative)
       {
@@ -6603,15 +4749,16 @@
 
     return avr_out_compare (insn, operands, NULL);
   }
-  [(set_attr "length" "1,2,2,3,4,2,4")
+  [(set_attr "cc" "compare")
+   (set_attr "length" "1,2,2,3,4,2,4")
    (set_attr "adjust_len" "tsthi,tsthi,*,*,*,compare,compare")])
 
 (define_insn "*cmppsi"
-  [(set (reg:CC REG_CC)
-        (compare:CC (match_operand:PSI 0 "register_operand"  "r,r,d ,r  ,d,r")
+  [(set (cc0)
+        (compare (match_operand:PSI 0 "register_operand"  "r,r,d ,r  ,d,r")
                  (match_operand:PSI 1 "nonmemory_operand" "L,r,s ,s  ,M,n")))
    (clobber (match_scratch:QI 2                          "=X,X,&d,&d ,X,&d"))]
-  "reload_completed"
+  ""
   {
     switch (which_alternative)
       {
@@ -6632,18 +4779,19 @@
 
     return avr_out_compare (insn, operands, NULL);
   }
-  [(set_attr "length" "3,3,5,6,3,7")
+  [(set_attr "cc" "compare")
+   (set_attr "length" "3,3,5,6,3,7")
    (set_attr "adjust_len" "tstpsi,*,*,*,compare,compare")])
 
 ;; "*cmpsi"
 ;; "*cmpsq" "*cmpusq"
 ;; "*cmpsa" "*cmpusa"
 (define_insn "*cmp<mode>"
-  [(set (reg:CC REG_CC)
-        (compare:CC (match_operand:ALL4 0 "register_operand"  "r  ,r ,d,r ,r")
+  [(set (cc0)
+        (compare (match_operand:ALL4 0 "register_operand"  "r  ,r ,d,r ,r")
                  (match_operand:ALL4 1 "nonmemory_operand" "Y00,r ,M,M ,n Ynn")))
    (clobber (match_scratch:QI 2                           "=X  ,X ,X,&d,&d"))]
-  "reload_completed"
+  ""
   {
     if (0 == which_alternative)
       return avr_out_tstsi (insn, operands, NULL);
@@ -6652,7 +4800,8 @@
 
     return avr_out_compare (insn, operands, NULL);
   }
-  [(set_attr "length" "4,4,4,5,8")
+  [(set_attr "cc" "compare")
+   (set_attr "length" "4,4,4,5,8")
    (set_attr "adjust_len" "tstsi,*,compare,compare,compare")])
 
 
@@ -6661,120 +4810,40 @@
 ;; ----------------------------------------------------------------------
 ;; Conditional jump instructions
 
+;; "cbranchqi4"
+;; "cbranchqq4"  "cbranchuqq4"
 (define_expand "cbranch<mode>4"
-  [(set (pc)
-        (if_then_else (match_operator 0 "ordered_comparison_operator"
-                        [(match_operand:ALL1 1 "register_operand" "")
-                         (match_operand:ALL1 2 "nonmemory_operand" "")])
+  [(set (cc0)
+        (compare (match_operand:ALL1 1 "register_operand" "")
+                 (match_operand:ALL1 2 "nonmemory_operand" "")))
+   (set (pc)
+        (if_then_else
+         (match_operator 0 "ordered_comparison_operator" [(cc0)
+                                                          (const_int 0)])
          (label_ref (match_operand 3 "" ""))
          (pc)))])
 
+;; "cbranchhi4"  "cbranchhq4"  "cbranchuhq4"  "cbranchha4"  "cbranchuha4"
+;; "cbranchsi4"  "cbranchsq4"  "cbranchusq4"  "cbranchsa4"  "cbranchusa4"
+;; "cbranchpsi4"
 (define_expand "cbranch<mode>4"
-  [(parallel
-     [(set (pc)
-           (if_then_else
-             (match_operator 0 "ordered_comparison_operator"
-               [(match_operand:ORDERED234 1 "register_operand" "")
-                (match_operand:ORDERED234 2 "nonmemory_operand" "")])
-             (label_ref (match_operand 3 "" ""))
-             (pc)))
-      (clobber (match_scratch:QI 4 ""))])])
-
-;; "*cbranchqi4"
-;; "*cbranchqq4"  "*cbranchuqq4"
-(define_insn_and_split "*cbranch<mode>4"
-  [(set (pc)
-        (if_then_else (match_operator 0 "ordered_comparison_operator"
-                        [(match_operand:ALL1 1 "register_operand" "r  ,r,d")
-                         (match_operand:ALL1 2 "nonmemory_operand" "Y00,r,i")])
+  [(parallel [(set (cc0)
+                   (compare (match_operand:ORDERED234 1 "register_operand" "")
+                            (match_operand:ORDERED234 2 "nonmemory_operand" "")))
+              (clobber (match_scratch:QI 4 ""))])
+   (set (pc)
+        (if_then_else
+         (match_operator 0 "ordered_comparison_operator" [(cc0)
+                                                          (const_int 0)])
          (label_ref (match_operand 3 "" ""))
-         (pc)))]
-   ""
-   "#"
-   "reload_completed"
-   [(set (reg:CC REG_CC)
-                    (compare:CC (match_dup 1) (match_dup 2)))
-    (set (pc)
-         (if_then_else (match_op_dup 0
-                         [(reg:CC REG_CC) (const_int 0)])
-                       (label_ref (match_dup 3))
-                       (pc)))]
-   "")
-
-;; "*cbranchsi4"  "*cbranchsq4"  "*cbranchusq4"  "*cbranchsa4"  "*cbranchusa4"
-(define_insn_and_split "*cbranch<mode>4"
-  [(set (pc)
-           (if_then_else
-             (match_operator 0 "ordered_comparison_operator"
-               [(match_operand:ALL4 1 "register_operand" "r  ,r ,d,r ,r")
-                (match_operand:ALL4 2 "nonmemory_operand" "Y00,r ,M,M ,n Ynn")])
-             (label_ref (match_operand 3 "" ""))
-             (pc)))
-   (clobber (match_scratch:QI 4 "=X  ,X ,X,&d,&d"))]
-   ""
-   "#"
-   "reload_completed"
-   [(parallel [(set (reg:CC REG_CC)
-                    (compare:CC (match_dup 1) (match_dup 2)))
-               (clobber (match_dup 4))])
-    (set (pc)
-         (if_then_else (match_op_dup 0
-                         [(reg:CC REG_CC) (const_int 0)])
-                       (label_ref (match_dup 3))
-                       (pc)))]
-   "")
-
-;; "*cbranchpsi4"
-(define_insn_and_split "*cbranchpsi4"
-  [(set (pc)
-           (if_then_else
-             (match_operator 0 "ordered_comparison_operator"
-               [(match_operand:PSI 1 "register_operand" "r,r,d ,r  ,d,r")
-                (match_operand:PSI 2 "nonmemory_operand" "L,r,s ,s  ,M,n")])
-             (label_ref (match_operand 3 "" ""))
-             (pc)))
-   (clobber (match_scratch:QI 4 "=X,X,&d,&d ,X,&d"))]
-   ""
-   "#"
-   "reload_completed"
-   [(parallel [(set (reg:CC REG_CC)
-                    (compare:CC (match_dup 1) (match_dup 2)))
-               (clobber (match_dup 4))])
-    (set (pc)
-         (if_then_else (match_op_dup 0
-                         [(reg:CC REG_CC) (const_int 0)])
-                       (label_ref (match_dup 3))
-                       (pc)))]
-   "")
-
-;; "*cbranchhi4"  "*cbranchhq4"  "*cbranchuhq4"  "*cbranchha4"  "*cbranchuha4"
-(define_insn_and_split "*cbranch<mode>4"
-  [(set (pc)
-           (if_then_else
-             (match_operator 0 "ordered_comparison_operator"
-               [(match_operand:ALL2 1 "register_operand" "!w  ,r  ,r,d ,r  ,d,r")
-                (match_operand:ALL2 2 "nonmemory_operand" "Y00,Y00,r,s ,s  ,M,n Ynn")])
-             (label_ref (match_operand 3 "" ""))
-             (pc)))
-   (clobber (match_scratch:QI 4 "=X  ,X  ,X,&d,&d ,X,&d"))]
-   ""
-   "#"
-   "reload_completed"
-   [(parallel [(set (reg:CC REG_CC)
-                    (compare:CC (match_dup 1) (match_dup 2)))
-               (clobber (match_dup 4))])
-    (set (pc)
-         (if_then_else (match_op_dup 0
-                         [(reg:CC REG_CC) (const_int 0)])
-                       (label_ref (match_dup 3))
-                       (pc)))]
-   "")
+         (pc)))])
+
 
 ;; Test a single bit in a QI/HI/SImode register.
 ;; Combine will create zero extract patterns for single bit tests.
 ;; permit any mode in source pattern by using VOIDmode.
 
-(define_insn_and_split "*sbrx_branch<mode>_split"
+(define_insn "*sbrx_branch<mode>"
   [(set (pc)
         (if_then_else
          (match_operator 0 "eqne_operator"
@@ -6786,33 +4855,6 @@
          (label_ref (match_operand 3 "" ""))
          (pc)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (pc)
-                   (if_then_else
-                    (match_op_dup 0
-                                  [(zero_extract:QIDI
-                                    (match_dup 1)
-                                    (const_int 1)
-                                    (match_dup 2))
-                                   (const_int 0)])
-                    (label_ref (match_dup 3))
-                    (pc)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*sbrx_branch<mode>"
-  [(set (pc)
-        (if_then_else
-         (match_operator 0 "eqne_operator"
-                         [(zero_extract:QIDI
-                           (match_operand:VOID 1 "register_operand" "r")
-                           (const_int 1)
-                           (match_operand 2 "const_int_operand" "n"))
-                          (const_int 0)])
-         (label_ref (match_operand 3 "" ""))
-         (pc)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_sbxx_branch (insn, operands);
   }
@@ -6822,13 +4864,14 @@
                       (const_int 2)
                       (if_then_else (match_test "!AVR_HAVE_JMP_CALL")
                                     (const_int 2)
-                                    (const_int 4))))])
+                                    (const_int 4))))
+   (set_attr "cc" "clobber")])
 
 ;; Same test based on bitwise AND.  Keep this in case gcc changes patterns.
 ;; or for old peepholes.
 ;; Fixme - bitwise Mask will not work for DImode
 
-(define_insn_and_split "*sbrx_and_branch<mode>_split"
+(define_insn "*sbrx_and_branch<mode>"
   [(set (pc)
         (if_then_else
          (match_operator 0 "eqne_operator"
@@ -6839,31 +4882,6 @@
          (label_ref (match_operand 3 "" ""))
          (pc)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (pc)
-                   (if_then_else
-                   (match_op_dup 0
-                                 [(and:QISI
-                                   (match_dup 1)
-                                   (match_dup 2))
-                                  (const_int 0)])
-                   (label_ref (match_dup 3))
-                   (pc)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*sbrx_and_branch<mode>"
-  [(set (pc)
-        (if_then_else
-         (match_operator 0 "eqne_operator"
-                         [(and:QISI
-                           (match_operand:QISI 1 "register_operand" "r")
-                           (match_operand:QISI 2 "single_one_operand" "n"))
-                          (const_int 0)])
-         (label_ref (match_operand 3 "" ""))
-         (pc)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     HOST_WIDE_INT bitnumber;
     bitnumber = exact_log2 (GET_MODE_MASK (<MODE>mode) & INTVAL (operands[2]));
@@ -6876,101 +4894,90 @@
                       (const_int 2)
                       (if_then_else (match_test "!AVR_HAVE_JMP_CALL")
                                     (const_int 2)
-                                    (const_int 4))))])
+                                    (const_int 4))))
+   (set_attr "cc" "clobber")])
 
 ;; Convert sign tests to bit 7/15/31 tests that match the above insns.
 (define_peephole2
-  [(set (reg:CC REG_CC) (compare:CC (match_operand:QI 0 "register_operand" "")
+  [(set (cc0) (compare (match_operand:QI 0 "register_operand" "")
                        (const_int 0)))
-   (parallel [(set (pc) (if_then_else (ge (reg:CC REG_CC) (const_int 0))
-                                      (label_ref (match_operand 1 "" ""))
-                                      (pc)))
-              (clobber (reg:CC REG_CC))])]
-  ""
-  [(parallel [(set (pc) (if_then_else (eq (zero_extract:HI (match_dup 0)
-                                                           (const_int 1)
-                                                           (const_int 7))
-                                          (const_int 0))
-                                      (label_ref (match_dup 1))
-                                      (pc)))
-              (clobber (reg:CC REG_CC))])])
+   (set (pc) (if_then_else (ge (cc0) (const_int 0))
+                           (label_ref (match_operand 1 "" ""))
+                           (pc)))]
+  ""
+  [(set (pc) (if_then_else (eq (zero_extract:HI (match_dup 0)
+                                                (const_int 1)
+                                                (const_int 7))
+                               (const_int 0))
+                           (label_ref (match_dup 1))
+                           (pc)))])
 
 (define_peephole2
-  [(set (reg:CC REG_CC) (compare:CC (match_operand:QI 0 "register_operand" "")
+  [(set (cc0) (compare (match_operand:QI 0 "register_operand" "")
                        (const_int 0)))
-   (parallel [(set (pc) (if_then_else (lt (reg:CC REG_CC) (const_int 0))
-                                      (label_ref (match_operand 1 "" ""))
-                                      (pc)))
-              (clobber (reg:CC REG_CC))])]
-  ""
-  [(parallel [(set (pc) (if_then_else (ne (zero_extract:HI (match_dup 0)
-                                                           (const_int 1)
-                                                           (const_int 7))
-                                          (const_int 0))
-                                      (label_ref (match_dup 1))
-                                      (pc)))
-              (clobber (reg:CC REG_CC))])])
+   (set (pc) (if_then_else (lt (cc0) (const_int 0))
+                           (label_ref (match_operand 1 "" ""))
+                           (pc)))]
+  ""
+  [(set (pc) (if_then_else (ne (zero_extract:HI (match_dup 0)
+                                                (const_int 1)
+                                                (const_int 7))
+                               (const_int 0))
+                           (label_ref (match_dup 1))
+                           (pc)))])
 
 (define_peephole2
-  [(parallel [(set (reg:CC REG_CC) (compare:CC (match_operand:HI 0 "register_operand" "")
+  [(parallel [(set (cc0) (compare (match_operand:HI 0 "register_operand" "")
                                   (const_int 0)))
               (clobber (match_operand:HI 2 ""))])
-   (parallel [(set (pc) (if_then_else (ge (reg:CC REG_CC) (const_int 0))
-                                      (label_ref (match_operand 1 "" ""))
-                                      (pc)))
-              (clobber (reg:CC REG_CC))])]
+   (set (pc) (if_then_else (ge (cc0) (const_int 0))
+                           (label_ref (match_operand 1 "" ""))
+                           (pc)))]
   ""
-  [(parallel [(set (pc) (if_then_else (eq (and:HI (match_dup 0) (const_int -32768))
-                                          (const_int 0))
-                                      (label_ref (match_dup 1))
-                                      (pc)))
-              (clobber (reg:CC REG_CC))])])
+  [(set (pc) (if_then_else (eq (and:HI (match_dup 0) (const_int -32768))
+                               (const_int 0))
+                           (label_ref (match_dup 1))
+                           (pc)))])
 
 (define_peephole2
-  [(parallel [(set (reg:CC REG_CC) (compare:CC (match_operand:HI 0 "register_operand" "")
+  [(parallel [(set (cc0) (compare (match_operand:HI 0 "register_operand" "")
                                   (const_int 0)))
               (clobber (match_operand:HI 2 ""))])
-   (parallel [(set (pc) (if_then_else (lt (reg:CC REG_CC) (const_int 0))
-                                      (label_ref (match_operand 1 "" ""))
-                                      (pc)))
-              (clobber (reg:CC REG_CC))])]
+   (set (pc) (if_then_else (lt (cc0) (const_int 0))
+                           (label_ref (match_operand 1 "" ""))
+                           (pc)))]
   ""
-  [(parallel [(set (pc) (if_then_else (ne (and:HI (match_dup 0) (const_int -32768))
-                                          (const_int 0))
-                                      (label_ref (match_dup 1))
-                                      (pc)))
-              (clobber (reg:CC REG_CC))])])
+  [(set (pc) (if_then_else (ne (and:HI (match_dup 0) (const_int -32768))
+                               (const_int 0))
+                           (label_ref (match_dup 1))
+                           (pc)))])
 
 (define_peephole2
-  [(parallel [(set (reg:CC REG_CC) (compare:CC (match_operand:SI 0 "register_operand" "")
+  [(parallel [(set (cc0) (compare (match_operand:SI 0 "register_operand" "")
                                   (const_int 0)))
               (clobber (match_operand:SI 2 ""))])
-   (parallel [(set (pc) (if_then_else (ge (reg:CC REG_CC) (const_int 0))
-                                      (label_ref (match_operand 1 "" ""))
-                                      (pc)))
-              (clobber (reg:CC REG_CC))])]
-  ""
-  [(parallel [(set (pc) (if_then_else (eq (and:SI (match_dup 0) (match_dup 2))
-                                          (const_int 0))
-                                      (label_ref (match_dup 1))
-                                      (pc)))
-              (clobber (reg:CC REG_CC))])]
+   (set (pc) (if_then_else (ge (cc0) (const_int 0))
+                           (label_ref (match_operand 1 "" ""))
+                           (pc)))]
+  ""
+  [(set (pc) (if_then_else (eq (and:SI (match_dup 0) (match_dup 2))
+                               (const_int 0))
+                           (label_ref (match_dup 1))
+                           (pc)))]
   "operands[2] = gen_int_mode (-2147483647 - 1, SImode);")
 
 (define_peephole2
-  [(parallel [(set (reg:CC REG_CC) (compare:CC (match_operand:SI 0 "register_operand" "")
+  [(parallel [(set (cc0) (compare (match_operand:SI 0 "register_operand" "")
                                   (const_int 0)))
               (clobber (match_operand:SI 2 ""))])
-   (parallel [(set (pc) (if_then_else (lt (reg:CC REG_CC) (const_int 0))
-                                      (label_ref (match_operand 1 "" ""))
-                                      (pc)))
-              (clobber (reg:CC REG_CC))])]
-  ""
-  [(parallel [(set (pc) (if_then_else (ne (and:SI (match_dup 0) (match_dup 2))
-                                          (const_int 0))
-                                      (label_ref (match_dup 1))
-                                      (pc)))
-              (clobber (reg:CC REG_CC))])]
+   (set (pc) (if_then_else (lt (cc0) (const_int 0))
+                           (label_ref (match_operand 1 "" ""))
+                           (pc)))]
+  ""
+  [(set (pc) (if_then_else (ne (and:SI (match_dup 0) (match_dup 2))
+                               (const_int 0))
+                           (label_ref (match_dup 1))
+                           (pc)))]
   "operands[2] = gen_int_mode (-2147483647 - 1, SImode);")
 
 ;; ************************************************************************
@@ -6978,37 +4985,19 @@
 ;;  Compare with 0 (test) jumps
 ;; ************************************************************************
 
-(define_insn_and_split "branch"
+(define_insn "branch"
   [(set (pc)
         (if_then_else (match_operator 1 "simple_comparison_operator"
-                                      [(reg:CC REG_CC)
+                                      [(cc0)
                                        (const_int 0)])
                       (label_ref (match_operand 0 "" ""))
                       (pc)))]
-  "reload_completed"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (pc)
-                   (if_then_else (match_op_dup 1
-                                               [(reg:CC REG_CC)
-                                                (const_int 0)])
-                                 (label_ref (match_dup 0))
-                                 (pc)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*branch"
-  [(set (pc)
-        (if_then_else (match_operator 1 "simple_comparison_operator"
-                                      [(reg:CC REG_CC)
-                                       (const_int 0)])
-                      (label_ref (match_operand 0 "" ""))
-                      (pc)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
+  ""
   {
     return ret_cond_branch (operands[1], avr_jump_mode (operands[0], insn), 0);
   }
-  [(set_attr "type" "branch")])
+  [(set_attr "type" "branch")
+   (set_attr "cc" "clobber")])
 
 
 ;; Same as above but wrap SET_SRC so that this branch won't be transformed
@@ -7017,120 +5006,66 @@
 (define_insn "branch_unspec"
   [(set (pc)
         (unspec [(if_then_else (match_operator 1 "simple_comparison_operator"
-                                               [(reg:CC REG_CC)
+                                               [(cc0)
                                                 (const_int 0)])
                                (label_ref (match_operand 0 "" ""))
                                (pc))
-                 ] UNSPEC_IDENTITY))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
+                 ] UNSPEC_IDENTITY))]
+  ""
   {
     return ret_cond_branch (operands[1], avr_jump_mode (operands[0], insn), 0);
   }
-  [(set_attr "type" "branch")])
+  [(set_attr "type" "branch")
+   (set_attr "cc" "none")])
 
 ;; ****************************************************************
-;; AVR does not have following conditional jumps: LE,LEU,GT,GTU.
-;; Convert them all to proper jumps.
-;; ****************************************************************/
-
-(define_insn_and_split "difficult_branch"
-  [(set (pc)
-        (if_then_else (match_operator 1 "difficult_comparison_operator"
-                        [(reg:CC REG_CC)
-                         (const_int 0)])
-                      (label_ref (match_operand 0 "" ""))
-                      (pc)))]
-  "reload_completed"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (pc)
-                   (if_then_else (match_op_dup 1
-                                   [(reg:CC REG_CC)
-                                    (const_int 0)])
-                                 (label_ref (match_dup 0))
-                                 (pc)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*difficult_branch"
+;; AVR does not have following conditional jumps: LE,LEU,GT,GTU.
+;; Convert them all to proper jumps.
+;; ****************************************************************/
+
+(define_insn "difficult_branch"
   [(set (pc)
         (if_then_else (match_operator 1 "difficult_comparison_operator"
-                        [(reg:CC REG_CC)
+                        [(cc0)
                          (const_int 0)])
                       (label_ref (match_operand 0 "" ""))
-                      (pc)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
+                      (pc)))]
+  ""
   {
     return ret_cond_branch (operands[1], avr_jump_mode (operands[0], insn), 0);
   }
-  [(set_attr "type" "branch1")])
+  [(set_attr "type" "branch1")
+   (set_attr "cc" "clobber")])
 
 ;; revers branch
 
-(define_insn_and_split "rvbranch"
+(define_insn "rvbranch"
   [(set (pc)
         (if_then_else (match_operator 1 "simple_comparison_operator"
-                                      [(reg:CC REG_CC)
+                                      [(cc0)
                                        (const_int 0)])
                       (pc)
                       (label_ref (match_operand 0 "" ""))))]
-  "reload_completed"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (pc)
-                   (if_then_else (match_op_dup 1
-                                               [(reg:CC REG_CC)
-                                                (const_int 0)])
-                                 (pc)
-                                 (label_ref (match_dup 0))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*rvbranch"
-  [(set (pc)
-        (if_then_else (match_operator 1 "simple_comparison_operator"
-                                      [(reg:CC REG_CC)
-                                       (const_int 0)])
-                      (pc)
-                      (label_ref (match_operand 0 "" ""))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
+  ""
   {
     return ret_cond_branch (operands[1], avr_jump_mode (operands[0], insn), 1);
   }
-  [(set_attr "type" "branch1")])
+  [(set_attr "type" "branch1")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "difficult_rvbranch"
+(define_insn "difficult_rvbranch"
   [(set (pc)
         (if_then_else (match_operator 1 "difficult_comparison_operator"
-                                      [(reg:CC REG_CC)
+                                      [(cc0)
                                        (const_int 0)])
                       (pc)
                       (label_ref (match_operand 0 "" ""))))]
-  "reload_completed"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (pc)
-                   (if_then_else (match_op_dup 1
-                                               [(reg:CC REG_CC)
-                                                (const_int 0)])
-                                 (pc)
-                                 (label_ref (match_dup 0))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*difficult_rvbranch"
-  [(set (pc)
-        (if_then_else (match_operator 1 "difficult_comparison_operator"
-                                      [(reg:CC REG_CC)
-                                       (const_int 0)])
-                      (pc)
-                      (label_ref (match_operand 0 "" ""))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
+  ""
   {
     return ret_cond_branch (operands[1], avr_jump_mode (operands[0], insn), 1);
   }
-  [(set_attr "type" "branch")])
+  [(set_attr "type" "branch")
+   (set_attr "cc" "clobber")])
 
 ;; **************************************************************************
 ;; Unconditional and other jump instructions.
@@ -7152,7 +5087,8 @@
                       (if_then_else (and (ge (minus (pc) (match_dup 0)) (const_int -2047))
                                          (le (minus (pc) (match_dup 0)) (const_int 2047)))
                                     (const_int 1)
-                                    (const_int 2))))])
+                                    (const_int 2))))
+   (set_attr "cc" "none")])
 
 ;; call
 
@@ -7200,7 +5136,8 @@
     %~call %x0
     %!ijmp
     %~jmp %x0"
-  [(set_attr "length" "1,*,1,*")
+  [(set_attr "cc" "clobber")
+   (set_attr "length" "1,*,1,*")
    (set_attr "adjust_len" "*,call,*,call")])
 
 (define_insn "call_value_insn"
@@ -7216,14 +5153,16 @@
     %~call %x1
     %!ijmp
     %~jmp %x1"
-  [(set_attr "length" "1,*,1,*")
+  [(set_attr "cc" "clobber")
+   (set_attr "length" "1,*,1,*")
    (set_attr "adjust_len" "*,call,*,call")])
 
 (define_insn "nop"
   [(const_int 0)]
   ""
   "nop"
-  [(set_attr "length" "1")])
+  [(set_attr "cc" "none")
+   (set_attr "length" "1")])
 
 ; indirect jump
 
@@ -7250,7 +5189,8 @@
 	push %A0\;push %B0\;ret
 	eijmp"
   [(set_attr "length" "1,2,1,3,1")
-   (set_attr "isa" "rjmp,jmp,ijmp,ijmp,eijmp")])
+   (set_attr "isa" "rjmp,jmp,ijmp,ijmp,eijmp")
+   (set_attr "cc" "none")])
 
 ;; table jump
 ;; For entries in jump table see avr_output_addr_vec.
@@ -7258,7 +5198,7 @@
 ;; Table made from
 ;;    "rjmp .L<n>"   instructions for <= 8K devices
 ;;    ".word gs(.L<n>)" addresses for >  8K devices
-(define_insn_and_split "*tablejump_split"
+(define_insn "*tablejump"
   [(set (pc)
         (unspec:HI [(match_operand:HI 0 "register_operand" "!z,*r,z")]
                    UNSPEC_INDEX_JMP))
@@ -7266,35 +5206,15 @@
    (clobber (match_dup 0))
    (clobber (const_int 0))]
   "!AVR_HAVE_EIJMP_EICALL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (pc)
-                   (unspec:HI [(match_dup 0)]
-                              UNSPEC_INDEX_JMP))
-              (use (label_ref (match_dup 1)))
-              (clobber (match_dup 0))
-              (clobber (const_int 0))
-              (clobber (reg:CC REG_CC))])]
-  ""
-  [(set_attr "isa" "rjmp,rjmp,jmp")])
-
-(define_insn "*tablejump"
-  [(set (pc)
-        (unspec:HI [(match_operand:HI 0 "register_operand" "!z,*r,z")]
-                   UNSPEC_INDEX_JMP))
-   (use (label_ref (match_operand 1 "" "")))
-   (clobber (match_dup 0))
-   (clobber (const_int 0))
-   (clobber (reg:CC REG_CC))]
-  "!AVR_HAVE_EIJMP_EICALL && reload_completed"
   "@
 	ijmp
 	push %A0\;push %B0\;ret
 	jmp __tablejump2__"
   [(set_attr "length" "1,3,2")
-   (set_attr "isa" "rjmp,rjmp,jmp")])
+   (set_attr "isa" "rjmp,rjmp,jmp")
+   (set_attr "cc" "none,none,clobber")])
 
-(define_insn_and_split "*tablejump.3byte-pc_split"
+(define_insn "*tablejump.3byte-pc"
   [(set (pc)
         (unspec:HI [(reg:HI REG_Z)]
                    UNSPEC_INDEX_JMP))
@@ -7302,31 +5222,10 @@
    (clobber (reg:HI REG_Z))
    (clobber (reg:QI 24))]
   "AVR_HAVE_EIJMP_EICALL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (pc)
-                   (unspec:HI [(reg:HI REG_Z)]
-                              UNSPEC_INDEX_JMP))
-              (use (label_ref (match_dup 0)))
-              (clobber (reg:HI REG_Z))
-              (clobber (reg:QI 24))
-              (clobber (reg:CC REG_CC))])]
-  ""
-  [(set_attr "isa" "eijmp")])
-
-
-(define_insn "*tablejump.3byte-pc"
-  [(set (pc)
-        (unspec:HI [(reg:HI REG_Z)]
-                   UNSPEC_INDEX_JMP))
-   (use (label_ref (match_operand 0 "" "")))
-   (clobber (reg:HI REG_Z))
-   (clobber (reg:QI 24))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_EIJMP_EICALL && reload_completed"
   "clr r24\;subi r30,pm_lo8(-(%0))\;sbci r31,pm_hi8(-(%0))\;sbci r24,pm_hh8(-(%0))\;jmp __tablejump2__"
   [(set_attr "length" "6")
-   (set_attr "isa" "eijmp")])
+   (set_attr "isa" "eijmp")
+   (set_attr "cc" "clobber")])
 
 
 ;; FIXME: casesi comes up with an SImode switch value $0 which
@@ -7355,14 +5254,17 @@
                    (plus:SI (match_operand:SI 0 "register_operand")
                             (match_operand:SI 1 "const_int_operand")))
               (clobber (scratch:QI))])
-
-   (parallel [(set (pc)
-                   (if_then_else (gtu (match_dup 5)
-                                      (match_operand:SI 2 "const_int_operand"))
-                                 (label_ref (match_operand 4))
-                                 (pc)))
+   (parallel [(set (cc0)
+                   (compare (match_dup 5)
+                            (match_operand:SI 2 "const_int_operand")))
               (clobber (scratch:QI))])
 
+   (set (pc)
+        (if_then_else (gtu (cc0)
+                           (const_int 0))
+                      (label_ref (match_operand 4))
+                      (pc)))
+
    (set (match_dup 7)
         (match_dup 6))
 
@@ -7410,14 +5312,17 @@
                    (plus:SI (match_dup 0)
                             (match_operand:SI 1 "const_int_operand")))
               (clobber (scratch:QI))])
-
-   (parallel [(set (pc)
-                   (if_then_else (gtu (match_dup 5)
-                                      (match_operand:SI 2 "const_int_operand"))
-                                 (label_ref (match_operand 4))
-                                 (pc)))
+   (parallel [(set (cc0)
+                   (compare (match_dup 5)
+                            (match_operand:SI 2 "const_int_operand")))
               (clobber (scratch:QI))])
 
+   (set (pc)
+        (if_then_else (gtu (cc0)
+                           (const_int 0))
+                      (label_ref (match_operand 4))
+                      (pc)))
+
    (set (match_operand:HI 7 "register_operand")
         (match_operand:HI 6))
 
@@ -7433,6 +5338,15 @@
 
 
 ;; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+;; This instruction sets Z flag
+
+(define_insn "sez"
+  [(set (cc0) (const_int 0))]
+  ""
+  "sez"
+  [(set_attr "length" "1")
+   (set_attr "cc" "compare")])
+
 ;; Clear/set/test a single bit in I/O address space.
 
 (define_insn "*cbi"
@@ -7444,7 +5358,8 @@
     operands[2] = GEN_INT (exact_log2 (~INTVAL (operands[1]) & 0xff));
     return "cbi %i0,%2";
   }
-  [(set_attr "length" "1")])
+  [(set_attr "length" "1")
+   (set_attr "cc" "none")])
 
 (define_insn "*sbi"
   [(set (mem:QI (match_operand 0 "low_io_address_operand" "i"))
@@ -7455,10 +5370,11 @@
     operands[2] = GEN_INT (exact_log2 (INTVAL (operands[1]) & 0xff));
     return "sbi %i0,%2";
   }
-  [(set_attr "length" "1")])
+  [(set_attr "length" "1")
+   (set_attr "cc" "none")])
 
 ;; Lower half of the I/O space - use sbic/sbis directly.
-(define_insn_and_split "*sbix_branch_split"
+(define_insn "*sbix_branch"
   [(set (pc)
         (if_then_else
          (match_operator 0 "eqne_operator"
@@ -7470,33 +5386,6 @@
          (label_ref (match_operand 3 "" ""))
          (pc)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (pc)
-                   (if_then_else
-                    (match_operator 0 "eqne_operator"
-                                    [(zero_extract:QIHI
-                                      (mem:QI (match_dup 1))
-                                      (const_int 1)
-                                      (match_dup 2))
-                                     (const_int 0)])
-                    (label_ref (match_dup 3))
-                    (pc)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*sbix_branch"
-  [(set (pc)
-        (if_then_else
-         (match_operator 0 "eqne_operator"
-                         [(zero_extract:QIHI
-                           (mem:QI (match_operand 1 "low_io_address_operand" "i"))
-                           (const_int 1)
-                           (match_operand 2 "const_int_operand" "n"))
-                          (const_int 0)])
-         (label_ref (match_operand 3 "" ""))
-         (pc)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_sbxx_branch (insn, operands);
   }
@@ -7506,10 +5395,11 @@
                       (const_int 2)
                       (if_then_else (match_test "!AVR_HAVE_JMP_CALL")
                                     (const_int 2)
-                                    (const_int 4))))])
+                                    (const_int 4))))
+   (set_attr "cc" "clobber")])
 
 ;; Tests of bit 7 are pessimized to sign tests, so we need this too...
-(define_insn_and_split "*sbix_branch_bit7_split"
+(define_insn "*sbix_branch_bit7"
   [(set (pc)
         (if_then_else
          (match_operator 0 "gelt_operator"
@@ -7518,27 +5408,6 @@
          (label_ref (match_operand 2 "" ""))
          (pc)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (pc)
-                   (if_then_else
-                    (match_operator 0 "gelt_operator"
-                                    [(mem:QI (match_dup 1))
-                                     (const_int 0)])
-                    (label_ref (match_dup 2))
-                    (pc)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*sbix_branch_bit7"
-  [(set (pc)
-        (if_then_else
-         (match_operator 0 "gelt_operator"
-                         [(mem:QI (match_operand 1 "low_io_address_operand" "i"))
-                          (const_int 0)])
-         (label_ref (match_operand 2 "" ""))
-         (pc)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     operands[3] = operands[2];
     operands[2] = GEN_INT (7);
@@ -7550,10 +5419,11 @@
                       (const_int 2)
                       (if_then_else (match_test "!AVR_HAVE_JMP_CALL")
                                     (const_int 2)
-                                    (const_int 4))))])
+                                    (const_int 4))))
+   (set_attr "cc" "clobber")])
 
 ;; Upper half of the I/O space - read port to __tmp_reg__ and use sbrc/sbrs.
-(define_insn_and_split "*sbix_branch_tmp_split"
+(define_insn "*sbix_branch_tmp"
   [(set (pc)
         (if_then_else
          (match_operator 0 "eqne_operator"
@@ -7565,33 +5435,6 @@
          (label_ref (match_operand 3 "" ""))
          (pc)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (pc)
-                   (if_then_else
-                    (match_operator 0 "eqne_operator"
-                                    [(zero_extract:QIHI
-                                      (mem:QI (match_dup 1))
-                                      (const_int 1)
-                                      (match_dup 2))
-                                     (const_int 0)])
-                    (label_ref (match_dup 3))
-                    (pc)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*sbix_branch_tmp"
-  [(set (pc)
-        (if_then_else
-         (match_operator 0 "eqne_operator"
-                         [(zero_extract:QIHI
-                           (mem:QI (match_operand 1 "high_io_address_operand" "n"))
-                           (const_int 1)
-                           (match_operand 2 "const_int_operand" "n"))
-                          (const_int 0)])
-         (label_ref (match_operand 3 "" ""))
-         (pc)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_sbxx_branch (insn, operands);
   }
@@ -7601,9 +5444,10 @@
                       (const_int 3)
                       (if_then_else (match_test "!AVR_HAVE_JMP_CALL")
                                     (const_int 3)
-                                    (const_int 5))))])
+                                    (const_int 5))))
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*sbix_branch_tmp_bit7_split"
+(define_insn "*sbix_branch_tmp_bit7"
   [(set (pc)
         (if_then_else
          (match_operator 0 "gelt_operator"
@@ -7612,27 +5456,6 @@
          (label_ref (match_operand 2 "" ""))
          (pc)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (pc)
-                   (if_then_else
-                    (match_operator 0 "gelt_operator"
-                                    [(mem:QI (match_dup 1))
-                                     (const_int 0)])
-                    (label_ref (match_dup 2))
-                    (pc)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*sbix_branch_tmp_bit7"
-  [(set (pc)
-        (if_then_else
-         (match_operator 0 "gelt_operator"
-                         [(mem:QI (match_operand 1 "high_io_address_operand" "n"))
-                          (const_int 0)])
-         (label_ref (match_operand 2 "" ""))
-         (pc)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     operands[3] = operands[2];
     operands[2] = GEN_INT (7);
@@ -7644,7 +5467,8 @@
                       (const_int 3)
                       (if_then_else (match_test "!AVR_HAVE_JMP_CALL")
                                     (const_int 3)
-                                    (const_int 5))))])
+                                    (const_int 5))))
+   (set_attr "cc" "clobber")])
 
 ;; ************************* Peepholes ********************************
 
@@ -7652,22 +5476,21 @@
   [(parallel [(set (match_operand:SI 0 "d_register_operand" "")
                    (plus:SI (match_dup 0)
                             (const_int -1)))
-              (clobber (scratch:QI))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (reg:CC REG_CC)
-                   (compare:CC (match_dup 0)
+              (clobber (scratch:QI))])
+   (parallel [(set (cc0)
+                   (compare (match_dup 0)
                             (const_int -1)))
               (clobber (match_operand:QI 1 "d_register_operand" ""))])
-   (parallel [(set (pc)
-                   (if_then_else (eqne (reg:CC REG_CC)
-                                       (const_int 0))
-                                 (label_ref (match_operand 2 "" ""))
-                                 (pc)))
-              (clobber (reg:CC REG_CC))])]
+   (set (pc)
+        (if_then_else (eqne (cc0)
+                            (const_int 0))
+                      (label_ref (match_operand 2 "" ""))
+                      (pc)))]
   ""
   {
     const char *op;
     int jump_mode;
+    CC_STATUS_INIT;
     if (test_hard_reg_class (ADDW_REGS, operands[0]))
       output_asm_insn ("sbiw %0,1" CR_TAB
                        "sbc %C0,__zero_reg__" CR_TAB
@@ -7694,24 +5517,23 @@
   })
 
 (define_peephole ; "*dec-and-branchhi!=-1"
-  [(parallel [(set (match_operand:HI 0 "d_register_operand" "")
-                   (plus:HI (match_dup 0)
-                            (const_int -1)))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (reg:CC REG_CC)
-                   (compare:CC (match_dup 0)
+  [(set (match_operand:HI 0 "d_register_operand" "")
+        (plus:HI (match_dup 0)
+                 (const_int -1)))
+   (parallel [(set (cc0)
+                   (compare (match_dup 0)
                             (const_int -1)))
               (clobber (match_operand:QI 1 "d_register_operand" ""))])
-   (parallel [(set (pc)
-                   (if_then_else (eqne (reg:CC REG_CC)
-                                       (const_int 0))
-                                 (label_ref (match_operand 2 "" ""))
-                                 (pc)))
-              (clobber (reg:CC REG_CC))])]
+   (set (pc)
+        (if_then_else (eqne (cc0)
+                            (const_int 0))
+                      (label_ref (match_operand 2 "" ""))
+                      (pc)))]
   ""
   {
     const char *op;
     int jump_mode;
+    CC_STATUS_INIT;
     if (test_hard_reg_class (ADDW_REGS, operands[0]))
       output_asm_insn ("sbiw %0,1", operands);
     else
@@ -7738,22 +5560,21 @@
   [(parallel [(set (match_operand:HI 0 "d_register_operand" "")
                    (plus:HI (match_dup 0)
                             (const_int -1)))
-              (clobber (scratch:QI))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (reg:CC REG_CC)
-                   (compare:CC (match_dup 0)
+              (clobber (scratch:QI))])
+   (parallel [(set (cc0)
+                   (compare (match_dup 0)
                             (const_int -1)))
               (clobber (match_operand:QI 1 "d_register_operand" ""))])
-   (parallel [(set (pc)
-                   (if_then_else (eqne (reg:CC REG_CC)
-                                       (const_int 0))
-                                 (label_ref (match_operand 2 "" ""))
-                                 (pc)))
-              (clobber (reg:CC REG_CC))])]
+   (set (pc)
+        (if_then_else (eqne (cc0)
+                            (const_int 0))
+                      (label_ref (match_operand 2 "" ""))
+                      (pc)))]
   ""
   {
     const char *op;
     int jump_mode;
+    CC_STATUS_INIT;
     if (test_hard_reg_class (ADDW_REGS, operands[0]))
       output_asm_insn ("sbiw %0,1", operands);
     else
@@ -7780,22 +5601,21 @@
   [(parallel [(set (match_operand:HI 0 "l_register_operand" "")
                    (plus:HI (match_dup 0)
                             (const_int -1)))
-              (clobber (match_operand:QI 3 "d_register_operand" ""))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (reg:CC REG_CC)
-                   (compare:CC (match_dup 0)
+              (clobber (match_operand:QI 3 "d_register_operand" ""))])
+   (parallel [(set (cc0)
+                   (compare (match_dup 0)
                             (const_int -1)))
               (clobber (match_operand:QI 1 "d_register_operand" ""))])
-   (parallel [(set (pc)
-                   (if_then_else (eqne (reg:CC REG_CC)
-                                       (const_int 0))
-                                 (label_ref (match_operand 2 "" ""))
-                                 (pc)))
-              (clobber (reg:CC REG_CC))])]
+   (set (pc)
+        (if_then_else (eqne (cc0)
+                            (const_int 0))
+                      (label_ref (match_operand 2 "" ""))
+                      (pc)))]
   ""
   {
     const char *op;
     int jump_mode;
+    CC_STATUS_INIT;
     output_asm_insn ("ldi %3,1"   CR_TAB
                      "sub %A0,%3" CR_TAB
                      "sbc %B0,__zero_reg__", operands);
@@ -7816,23 +5636,24 @@
   })
 
 (define_peephole ; "*dec-and-branchqi!=-1"
-  [(parallel [(set (match_operand:QI 0 "d_register_operand" "")
-                   (plus:QI (match_dup 0)
-                            (const_int -1)))
-              (clobber (reg:CC REG_CC))])
-   (set (reg:CC REG_CC)
-        (compare:CC (match_dup 0)
+  [(set (match_operand:QI 0 "d_register_operand" "")
+        (plus:QI (match_dup 0)
                  (const_int -1)))
-   (parallel [(set (pc)
-                   (if_then_else (eqne (reg:CC REG_CC)
-                                       (const_int 0))
-                                 (label_ref (match_operand 1 "" ""))
-                                 (pc)))
-              (clobber (reg:CC REG_CC))])]
+   (set (cc0)
+        (compare (match_dup 0)
+                 (const_int -1)))
+   (set (pc)
+        (if_then_else (eqne (cc0)
+                            (const_int 0))
+                      (label_ref (match_operand 1 "" ""))
+                      (pc)))]
   ""
   {
     const char *op;
     int jump_mode;
+    CC_STATUS_INIT;
+    cc_status.value1 = operands[0];
+    cc_status.flags |= CC_OVERFLOW_UNUSABLE;
 
     output_asm_insn ("subi %A0,1", operands);
 
@@ -7853,15 +5674,14 @@
 
 
 (define_peephole ; "*cpse.eq"
-  [(set (reg:CC REG_CC)
-        (compare:CC (match_operand:ALL1 1 "register_operand" "r,r")
+  [(set (cc0)
+        (compare (match_operand:ALL1 1 "register_operand" "r,r")
                  (match_operand:ALL1 2 "reg_or_0_operand" "r,Y00")))
-   (parallel [(set (pc)
-                   (if_then_else (eq (reg:CC REG_CC)
-                                     (const_int 0))
-                                 (label_ref (match_operand 0 "" ""))
-                                 (pc)))
-              (clobber (reg:CC REG_CC))])]
+   (set (pc)
+        (if_then_else (eq (cc0)
+                          (const_int 0))
+                      (label_ref (match_operand 0 "" ""))
+                      (pc)))]
   "jump_over_one_insn_p (insn, operands[0])"
   "@
 	cpse %1,%2
@@ -7889,15 +5709,14 @@
 ;; and thus longer and slower and not easy to be rolled back.
 
 (define_peephole ; "*cpse.ne"
-  [(set (reg:CC REG_CC)
-        (compare:CC (match_operand:ALL1 1 "register_operand" "")
+  [(set (cc0)
+        (compare (match_operand:ALL1 1 "register_operand" "")
                  (match_operand:ALL1 2 "reg_or_0_operand" "")))
-   (parallel [(set (pc)
-                   (if_then_else (ne (reg:CC REG_CC)
-                                     (const_int 0))
-                                 (label_ref (match_operand 0 "" ""))
-                                 (pc)))
-              (clobber (reg:CC REG_CC))])]
+   (set (pc)
+        (if_then_else (ne (cc0)
+                          (const_int 0))
+                      (label_ref (match_operand 0 "" ""))
+                      (pc)))]
   "!AVR_HAVE_JMP_CALL
    || !TARGET_SKIP_BUG"
   {
@@ -7917,7 +5736,8 @@
         (mem:QI (pre_inc:HI (reg:HI REG_SP))))]
   ""
   "pop %0"
-  [(set_attr "length" "1")])
+  [(set_attr "cc" "none")
+   (set_attr "length" "1")])
 
 ;; Enable Interrupts
 (define_expand "enable_interrupt"
@@ -7950,7 +5770,8 @@
   "@
 	cli
 	sei"
-  [(set_attr "length" "1")])
+  [(set_attr "length" "1")
+   (set_attr "cc" "none")])
 
 ;;  Library prologue saves
 (define_insn "call_prologue_saves"
@@ -7960,14 +5781,14 @@
         (minus:HI (reg:HI REG_SP)
                   (match_operand:HI 1 "immediate_operand" "i,i")))
    (use (reg:HI REG_X))
-   (clobber (reg:HI REG_Z))
-   (clobber (reg:CC REG_CC))]
+   (clobber (reg:HI REG_Z))]
   ""
   "ldi r30,lo8(gs(1f))
 	ldi r31,hi8(gs(1f))
 	%~jmp __prologue_saves__+((18 - %0) * 2)
 1:"
   [(set_attr "length" "5,6")
+   (set_attr "cc" "clobber")
    (set_attr "isa" "rjmp,jmp")])
 
 ;  epilogue  restores using library
@@ -7979,12 +5800,12 @@
    (set (reg:HI REG_SP)
         (plus:HI (reg:HI REG_Y)
                  (match_dup 0)))
-   (clobber (reg:QI REG_Z))
-   (clobber (reg:CC REG_CC))]
+   (clobber (reg:QI REG_Z))]
   ""
   "ldi r30, lo8(%0)
 	%~jmp __epilogue_restores__ + ((18 - %0) * 2)"
   [(set_attr "length" "2,3")
+   (set_attr "cc" "clobber")
    (set_attr "isa" "rjmp,jmp")])
 
 
@@ -7998,8 +5819,7 @@
                    (unspec_volatile:HI [(reg:HI REG_SP)] UNSPECV_GASISR))
               (set (match_dup 2)
                    (unspec_volatile:BLK [(match_dup 2)]
-                                        UNSPECV_MEMORY_BARRIER))
-              (clobber (reg:CC REG_CC))])]
+                                        UNSPECV_MEMORY_BARRIER))])]
   "avr_gasisr_prologues"
   {
     operands[2] = gen_rtx_MEM (BLKmode, gen_rtx_SCRATCH (Pmode));
@@ -8013,11 +5833,11 @@
    (set (reg:HI REG_SP)
         (unspec_volatile:HI [(reg:HI REG_SP)] UNSPECV_GASISR))
    (set (match_operand:BLK 2)
-        (unspec_volatile:BLK [(match_dup 2)] UNSPECV_MEMORY_BARRIER))
-   (clobber (reg:CC REG_CC))]
+        (unspec_volatile:BLK [(match_dup 2)] UNSPECV_MEMORY_BARRIER))]
   "avr_gasisr_prologues"
   "__gcc_isr %0"
-  [(set_attr "length" "6,5")])
+  [(set_attr "length" "6,5")
+   (set_attr "cc" "clobber")])
 
 
 ; return
@@ -8025,7 +5845,8 @@
   [(return)]
   "reload_completed && avr_simple_epilogue ()"
   "ret"
-  [(set_attr "length" "1")])
+  [(set_attr "cc" "none")
+   (set_attr "length" "1")])
 
 (define_insn "return_from_epilogue"
   [(return)]
@@ -8034,7 +5855,8 @@
    && !(cfun->machine->is_interrupt || cfun->machine->is_signal)
    && !cfun->machine->is_naked"
   "ret"
-  [(set_attr "length" "1")])
+  [(set_attr "cc" "none")
+   (set_attr "length" "1")])
 
 (define_insn "return_from_interrupt_epilogue"
   [(return)]
@@ -8043,7 +5865,8 @@
    && (cfun->machine->is_interrupt || cfun->machine->is_signal)
    && !cfun->machine->is_naked"
   "reti"
-  [(set_attr "length" "1")])
+  [(set_attr "cc" "none")
+   (set_attr "length" "1")])
 
 (define_insn "return_from_naked_epilogue"
   [(return)]
@@ -8051,7 +5874,8 @@
    && cfun->machine
    && cfun->machine->is_naked"
   ""
-  [(set_attr "length" "0")])
+  [(set_attr "cc" "none")
+   (set_attr "length" "0")])
 
 (define_expand "prologue"
   [(const_int 0)]
@@ -8080,7 +5904,7 @@
 ;; Some instructions resp. instruction sequences available
 ;; via builtins.
 
-(define_insn_and_split "delay_cycles_1"
+(define_insn "delay_cycles_1"
   [(unspec_volatile [(match_operand:QI 0 "const_int_operand" "n")
                      (const_int 1)]
                     UNSPECV_DELAY_CYCLES)
@@ -8088,31 +5912,13 @@
 	(unspec_volatile:BLK [(match_dup 1)] UNSPECV_MEMORY_BARRIER))
    (clobber (match_scratch:QI 2 "=&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(unspec_volatile [(match_dup 0)
-                                (const_int 1)]
-                               UNSPECV_DELAY_CYCLES)
-              (set (match_dup 1)
-               (unspec_volatile:BLK [(match_dup 1)] UNSPECV_MEMORY_BARRIER))
-              (clobber (match_dup 2))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*delay_cycles_1"
-  [(unspec_volatile [(match_operand:QI 0 "const_int_operand" "n")
-                     (const_int 1)]
-                    UNSPECV_DELAY_CYCLES)
-   (set (match_operand:BLK 1 "" "")
-	(unspec_volatile:BLK [(match_dup 1)] UNSPECV_MEMORY_BARRIER))
-   (clobber (match_scratch:QI 2 "=&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "ldi %2,lo8(%0)
 1:	dec %2
 	brne 1b"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "delay_cycles_2"
+(define_insn "delay_cycles_2"
   [(unspec_volatile [(match_operand:HI 0 "const_int_operand" "n,n")
                      (const_int 2)]
                     UNSPECV_DELAY_CYCLES)
@@ -8120,34 +5926,14 @@
 	(unspec_volatile:BLK [(match_dup 1)] UNSPECV_MEMORY_BARRIER))
    (clobber (match_scratch:HI 2 "=&w,&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(unspec_volatile [(match_dup 0)
-                                (const_int 2)]
-                               UNSPECV_DELAY_CYCLES)
-              (set (match_dup 1)
-               (unspec_volatile:BLK [(match_dup 1)] UNSPECV_MEMORY_BARRIER))
-              (clobber (match_dup 2))
-              (clobber (reg:CC REG_CC))])]
-  ""
-  [(set_attr "isa" "no_tiny,tiny")])
-
-(define_insn "*delay_cycles_2"
-  [(unspec_volatile [(match_operand:HI 0 "const_int_operand" "n,n")
-                     (const_int 2)]
-                    UNSPECV_DELAY_CYCLES)
-   (set (match_operand:BLK 1 "" "")
-	(unspec_volatile:BLK [(match_dup 1)] UNSPECV_MEMORY_BARRIER))
-   (clobber (match_scratch:HI 2 "=&w,&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "@
 	ldi %A2,lo8(%0)\;ldi %B2,hi8(%0)\n1:	sbiw %A2,1\;brne 1b
 	ldi %A2,lo8(%0)\;ldi %B2,hi8(%0)\n1:	subi %A2,1\;sbci %B2,0\;brne 1b"
   [(set_attr "length" "4,5")
-   (set_attr "isa" "no_tiny,tiny")])
+   (set_attr "isa" "no_tiny,tiny")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "delay_cycles_3"
+(define_insn "delay_cycles_3"
   [(unspec_volatile [(match_operand:SI 0 "const_int_operand" "n")
                      (const_int 3)]
                     UNSPECV_DELAY_CYCLES)
@@ -8157,29 +5943,6 @@
    (clobber (match_scratch:QI 3 "=&d"))
    (clobber (match_scratch:QI 4 "=&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(unspec_volatile [(match_dup 0)
-                                (const_int 3)]
-                               UNSPECV_DELAY_CYCLES)
-              (set (match_dup 1)
-               (unspec_volatile:BLK [(match_dup 1)] UNSPECV_MEMORY_BARRIER))
-              (clobber (match_dup 2))
-              (clobber (match_dup 3))
-              (clobber (match_dup 4))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*delay_cycles_3"
-  [(unspec_volatile [(match_operand:SI 0 "const_int_operand" "n")
-                     (const_int 3)]
-                    UNSPECV_DELAY_CYCLES)
-   (set (match_operand:BLK 1 "" "")
-	(unspec_volatile:BLK [(match_dup 1)] UNSPECV_MEMORY_BARRIER))
-   (clobber (match_scratch:QI 2 "=&d"))
-   (clobber (match_scratch:QI 3 "=&d"))
-   (clobber (match_scratch:QI 4 "=&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "ldi %2,lo8(%0)
 	ldi %3,hi8(%0)
 	ldi %4,hlo8(%0)
@@ -8187,9 +5950,10 @@
 	sbci %3,0
 	sbci %4,0
 	brne 1b"
-  [(set_attr "length" "7")])
+  [(set_attr "length" "7")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "delay_cycles_4"
+(define_insn "delay_cycles_4"
   [(unspec_volatile [(match_operand:SI 0 "const_int_operand" "n")
                      (const_int 4)]
                     UNSPECV_DELAY_CYCLES)
@@ -8200,31 +5964,6 @@
    (clobber (match_scratch:QI 4 "=&d"))
    (clobber (match_scratch:QI 5 "=&d"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(unspec_volatile [(match_dup 0)
-                                (const_int 4)]
-                               UNSPECV_DELAY_CYCLES)
-              (set (match_dup 1)
-               (unspec_volatile:BLK [(match_dup 1)] UNSPECV_MEMORY_BARRIER))
-              (clobber (match_dup 2))
-              (clobber (match_dup 3))
-              (clobber (match_dup 4))
-              (clobber (match_dup 5))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*delay_cycles_4"
-  [(unspec_volatile [(match_operand:SI 0 "const_int_operand" "n")
-                     (const_int 4)]
-                    UNSPECV_DELAY_CYCLES)
-   (set (match_operand:BLK 1 "" "")
-	(unspec_volatile:BLK [(match_dup 1)] UNSPECV_MEMORY_BARRIER))
-   (clobber (match_scratch:QI 2 "=&d"))
-   (clobber (match_scratch:QI 3 "=&d"))
-   (clobber (match_scratch:QI 4 "=&d"))
-   (clobber (match_scratch:QI 5 "=&d"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "ldi %2,lo8(%0)
 	ldi %3,hi8(%0)
 	ldi %4,hlo8(%0)
@@ -8234,39 +5973,24 @@
 	sbci %4,0
 	sbci %5,0
 	brne 1b"
-  [(set_attr "length" "9")])
+  [(set_attr "length" "9")
+   (set_attr "cc" "clobber")])
 
 
 ;; __builtin_avr_insert_bits
 
-(define_insn_and_split "insert_bits"
+(define_insn "insert_bits"
   [(set (match_operand:QI 0 "register_operand"              "=r  ,d  ,r")
         (unspec:QI [(match_operand:SI 1 "const_int_operand"  "C0f,Cxf,C0f")
                     (match_operand:QI 2 "register_operand"   "r  ,r  ,r")
                     (match_operand:QI 3 "nonmemory_operand"  "n  ,0  ,0")]
                    UNSPEC_INSERT_BITS))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (unspec:QI [(match_dup 1)
-                               (match_dup 2)
-                               (match_dup 3)]
-                              UNSPEC_INSERT_BITS))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*insert_bits"
-  [(set (match_operand:QI 0 "register_operand"              "=r  ,d  ,r")
-        (unspec:QI [(match_operand:SI 1 "const_int_operand"  "C0f,Cxf,C0f")
-                    (match_operand:QI 2 "register_operand"   "r  ,r  ,r")
-                    (match_operand:QI 3 "nonmemory_operand"  "n  ,0  ,0")]
-                   UNSPEC_INSERT_BITS))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_insert_bits (operands, NULL);
   }
-  [(set_attr "adjust_len" "insert_bits")])
+  [(set_attr "adjust_len" "insert_bits")
+   (set_attr "cc" "clobber")])
 
 
 ;; __builtin_avr_flash_segment
@@ -8277,31 +6001,17 @@
   [(set (match_operand:QI 0 "register_operand" "")
         (subreg:QI (match_operand:PSI 1 "register_operand" "")
                    2))
+   (set (cc0)
+        (compare (match_dup 0)
+                 (const_int 0)))
    (set (pc)
-        (if_then_else (ge (match_dup 0)
+        (if_then_else (ge (cc0)
                           (const_int 0))
                       (label_ref (match_operand 2 "" ""))
                       (pc)))
    (set (match_dup 0)
         (const_int -1))])
 
-(define_insn_and_split "*flash_segment1"
-  [(set (pc)
-        (if_then_else (ge (match_operand:QI 0 "register_operand" "")
-                          (const_int 0))
-         (label_ref (match_operand 1 "" ""))
-         (pc)))]
-   ""
-   "#"
-   "reload_completed"
-   [(set (reg:CC REG_CC)
-         (compare:CC (match_dup 0) (const_int 0)))
-    (set (pc)
-         (if_then_else (ge (reg:CC REG_CC) (const_int 0))
-                       (label_ref (match_dup 1))
-                       (pc)))]
-   "")
-
 (define_expand "flash_segment"
   [(parallel [(match_operand:QI 0 "register_operand" "")
               (match_operand:PSI 1 "register_operand" "")])]
@@ -8382,59 +6092,29 @@
     operands[2] = gen_reg_rtx (HImode);
   })
 
-(define_insn_and_split "*parityhi2.libgcc_split"
+(define_insn "*parityhi2.libgcc"
   [(set (reg:HI 24)
         (parity:HI (reg:HI 24)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 24)
-                   (parity:HI (reg:HI 24)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*parityhi2.libgcc"
-  [(set (reg:HI 24)
-        (parity:HI (reg:HI 24)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __parityhi2"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*parityqihi2.libgcc_split"
+(define_insn "*parityqihi2.libgcc"
   [(set (reg:HI 24)
         (zero_extend:HI (parity:QI (reg:QI 24))))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 24)
-                   (zero_extend:HI (parity:QI (reg:QI 24))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*parityqihi2.libgcc"
-  [(set (reg:HI 24)
-        (zero_extend:HI (parity:QI (reg:QI 24))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __parityqi2"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*paritysihi2.libgcc_split"
+(define_insn "*paritysihi2.libgcc"
   [(set (reg:HI 24)
         (truncate:HI (parity:SI (reg:SI 22))))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 24)
-                   (truncate:HI (parity:SI (reg:SI 22))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*paritysihi2.libgcc"
-  [(set (reg:HI 24)
-        (truncate:HI (parity:SI (reg:SI 22))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __paritysi2"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 
 ;; Popcount
@@ -8463,59 +6143,29 @@
     operands[2] = gen_reg_rtx (HImode);
   })
 
-(define_insn_and_split "*popcounthi2.libgcc_split"
-  [(set (reg:HI 24)
-        (popcount:HI (reg:HI 24)))]
-  ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 24)
-                   (popcount:HI (reg:HI 24)))
-              (clobber (reg:CC REG_CC))])])
-
 (define_insn "*popcounthi2.libgcc"
   [(set (reg:HI 24)
-        (popcount:HI (reg:HI 24)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
+        (popcount:HI (reg:HI 24)))]
+  ""
   "%~call __popcounthi2"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*popcountsi2.libgcc_split"
+(define_insn "*popcountsi2.libgcc"
   [(set (reg:HI 24)
         (truncate:HI (popcount:SI (reg:SI 22))))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 24)
-                   (truncate:HI (popcount:SI (reg:SI 22))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*popcountsi2.libgcc"
-  [(set (reg:HI 24)
-        (truncate:HI (popcount:SI (reg:SI 22))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __popcountsi2"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*popcountqi2.libgcc_split"
+(define_insn "*popcountqi2.libgcc"
   [(set (reg:QI 24)
         (popcount:QI (reg:QI 24)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:QI 24)
-                   (popcount:QI (reg:QI 24)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*popcountqi2.libgcc"
-  [(set (reg:QI 24)
-        (popcount:QI (reg:QI 24)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __popcountqi2"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 (define_insn_and_split "*popcountqihi2.libgcc"
   [(set (reg:HI 24)
@@ -8554,47 +6204,23 @@
     operands[2] = gen_reg_rtx (HImode);
   })
 
-(define_insn_and_split "*clzhi2.libgcc_split"
+(define_insn "*clzhi2.libgcc"
   [(set (reg:HI 24)
         (clz:HI (reg:HI 24)))
    (clobber (reg:QI 26))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 24)
-                   (clz:HI (reg:HI 24)))
-              (clobber (reg:QI 26))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*clzhi2.libgcc"
-  [(set (reg:HI 24)
-        (clz:HI (reg:HI 24)))
-   (clobber (reg:QI 26))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __clzhi2"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*clzsihi2.libgcc_split"
+(define_insn "*clzsihi2.libgcc"
   [(set (reg:HI 24)
         (truncate:HI (clz:SI (reg:SI 22))))
    (clobber (reg:QI 26))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 24)
-                   (truncate:HI (clz:SI (reg:SI 22))))
-              (clobber (reg:QI 26))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*clzsihi2.libgcc"
-  [(set (reg:HI 24)
-        (truncate:HI (clz:SI (reg:SI 22))))
-   (clobber (reg:QI 26))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __clzsi2"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;; Count Trailing Zeros
 
@@ -8623,50 +6249,24 @@
     operands[2] = gen_reg_rtx (HImode);
   })
 
-(define_insn_and_split "*ctzhi2.libgcc_split"
+(define_insn "*ctzhi2.libgcc"
   [(set (reg:HI 24)
         (ctz:HI (reg:HI 24)))
    (clobber (reg:QI 26))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 24)
-                   (ctz:HI (reg:HI 24)))
-              (clobber (reg:QI 26))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*ctzhi2.libgcc"
-  [(set (reg:HI 24)
-        (ctz:HI (reg:HI 24)))
-   (clobber (reg:QI 26))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __ctzhi2"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*ctzsihi2.libgcc_split"
+(define_insn "*ctzsihi2.libgcc"
   [(set (reg:HI 24)
         (truncate:HI (ctz:SI (reg:SI 22))))
    (clobber (reg:QI 22))
    (clobber (reg:QI 26))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 24)
-                   (truncate:HI (ctz:SI (reg:SI 22))))
-              (clobber (reg:QI 22))
-              (clobber (reg:QI 26))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*ctzsihi2.libgcc"
-  [(set (reg:HI 24)
-        (truncate:HI (ctz:SI (reg:SI 22))))
-   (clobber (reg:QI 22))
-   (clobber (reg:QI 26))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __ctzsi2"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;; Find First Set
 
@@ -8695,50 +6295,24 @@
     operands[2] = gen_reg_rtx (HImode);
   })
 
-(define_insn_and_split "*ffshi2.libgcc_split"
+(define_insn "*ffshi2.libgcc"
   [(set (reg:HI 24)
         (ffs:HI (reg:HI 24)))
    (clobber (reg:QI 26))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 24)
-                   (ffs:HI (reg:HI 24)))
-              (clobber (reg:QI 26))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*ffshi2.libgcc"
-  [(set (reg:HI 24)
-        (ffs:HI (reg:HI 24)))
-   (clobber (reg:QI 26))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __ffshi2"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*ffssihi2.libgcc_split"
+(define_insn "*ffssihi2.libgcc"
   [(set (reg:HI 24)
         (truncate:HI (ffs:SI (reg:SI 22))))
    (clobber (reg:QI 22))
    (clobber (reg:QI 26))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 24)
-                   (truncate:HI (ffs:SI (reg:SI 22))))
-              (clobber (reg:QI 22))
-              (clobber (reg:QI 26))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*ffssihi2.libgcc"
-  [(set (reg:HI 24)
-        (truncate:HI (ffs:SI (reg:SI 22))))
-   (clobber (reg:QI 22))
-   (clobber (reg:QI 26))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __ffssi2"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;; Copysign
 
@@ -8749,7 +6323,8 @@
                    UNSPEC_COPYSIGN))]
   ""
   "bst %D2,7\;bld %D0,7"
-  [(set_attr "length" "2")])
+  [(set_attr "length" "2")
+   (set_attr "cc" "none")])
 
 ;; Swap Bytes (change byte-endianness)
 
@@ -8761,23 +6336,13 @@
    (set (match_operand:SI 0 "register_operand" "")
         (reg:SI 22))])
 
-(define_insn_and_split "*bswapsi2.libgcc_split"
+(define_insn "*bswapsi2.libgcc"
   [(set (reg:SI 22)
         (bswap:SI (reg:SI 22)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:SI 22)
-                   (bswap:SI (reg:SI 22)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*bswapsi2.libgcc"
-  [(set (reg:SI 22)
-        (bswap:SI (reg:SI 22)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "%~call __bswapsi2"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 
 ;; CPU instructions
@@ -8804,7 +6369,8 @@
   "@
 	nop
 	rjmp ."
-  [(set_attr "length" "1")])
+  [(set_attr "length" "1")
+   (set_attr "cc" "none")])
 
 ;; SLEEP
 (define_expand "sleep"
@@ -8824,7 +6390,8 @@
 	(unspec_volatile:BLK [(match_dup 0)] UNSPECV_MEMORY_BARRIER))]
   ""
   "sleep"
-  [(set_attr "length" "1")])
+  [(set_attr "length" "1")
+   (set_attr "cc" "none")])
 
 ;; WDR
 (define_expand "wdr"
@@ -8844,7 +6411,8 @@
 	(unspec_volatile:BLK [(match_dup 0)] UNSPECV_MEMORY_BARRIER))]
   ""
   "wdr"
-  [(set_attr "length" "1")])
+  [(set_attr "length" "1")
+   (set_attr "cc" "none")])
 
 ;; FMUL
 (define_expand "fmul"
@@ -8868,55 +6436,27 @@
     avr_fix_inputs (operands, 1 << 2, regmask (QImode, 24));
   })
 
-(define_insn_and_split "fmul_insn"
+(define_insn "fmul_insn"
   [(set (match_operand:HI 0 "register_operand" "=r")
         (unspec:HI [(match_operand:QI 1 "register_operand" "a")
                     (match_operand:QI 2 "register_operand" "a")]
                    UNSPEC_FMUL))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (unspec:HI [(match_dup 1)
-                               (match_dup 2)]
-                              UNSPEC_FMUL))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*fmul_insn"
-  [(set (match_operand:HI 0 "register_operand" "=r")
-        (unspec:HI [(match_operand:QI 1 "register_operand" "a")
-                    (match_operand:QI 2 "register_operand" "a")]
-                   UNSPEC_FMUL))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "fmul %1,%2
 	movw %0,r0
 	clr __zero_reg__"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*fmul.call_split"
+(define_insn "*fmul.call"
   [(set (reg:HI 22)
         (unspec:HI [(reg:QI 24)
                     (reg:QI 25)] UNSPEC_FMUL))
    (clobber (reg:HI 24))]
   "!AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 22)
-                   (unspec:HI [(reg:QI 24)
-                               (reg:QI 25)] UNSPEC_FMUL))
-              (clobber (reg:HI 24))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*fmul.call"
-  [(set (reg:HI 22)
-        (unspec:HI [(reg:QI 24)
-                    (reg:QI 25)] UNSPEC_FMUL))
-   (clobber (reg:HI 24))
-   (clobber (reg:CC REG_CC))]
-  "!AVR_HAVE_MUL && reload_completed"
   "%~call __fmul"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;; FMULS
 (define_expand "fmuls"
@@ -8940,55 +6480,27 @@
     avr_fix_inputs (operands, 1 << 2, regmask (QImode, 24));
   })
 
-(define_insn_and_split "fmuls_insn"
+(define_insn "fmuls_insn"
   [(set (match_operand:HI 0 "register_operand" "=r")
         (unspec:HI [(match_operand:QI 1 "register_operand" "a")
                     (match_operand:QI 2 "register_operand" "a")]
                    UNSPEC_FMULS))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (unspec:HI [(match_dup 1)
-                               (match_dup 2)]
-                              UNSPEC_FMULS))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*fmuls_insn"
-  [(set (match_operand:HI 0 "register_operand" "=r")
-        (unspec:HI [(match_operand:QI 1 "register_operand" "a")
-                    (match_operand:QI 2 "register_operand" "a")]
-                   UNSPEC_FMULS))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "fmuls %1,%2
 	movw %0,r0
 	clr __zero_reg__"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*fmuls.call_split"
+(define_insn "*fmuls.call"
   [(set (reg:HI 22)
         (unspec:HI [(reg:QI 24)
                     (reg:QI 25)] UNSPEC_FMULS))
    (clobber (reg:HI 24))]
   "!AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 22)
-                   (unspec:HI [(reg:QI 24)
-                               (reg:QI 25)] UNSPEC_FMULS))
-              (clobber (reg:HI 24))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*fmuls.call"
-  [(set (reg:HI 22)
-        (unspec:HI [(reg:QI 24)
-                    (reg:QI 25)] UNSPEC_FMULS))
-   (clobber (reg:HI 24))
-   (clobber (reg:CC REG_CC))]
-  "!AVR_HAVE_MUL && reload_completed"
   "%~call __fmuls"
-  [(set_attr "type" "xcall")])
+  [(set_attr "type" "xcall")
+   (set_attr "cc" "clobber")])
 
 ;; FMULSU
 (define_expand "fmulsu"
@@ -9012,56 +6524,27 @@
     avr_fix_inputs (operands, 1 << 2, regmask (QImode, 24));
   })
 
-(define_insn_and_split "fmulsu_insn"
+(define_insn "fmulsu_insn"
   [(set (match_operand:HI 0 "register_operand" "=r")
         (unspec:HI [(match_operand:QI 1 "register_operand" "a")
                     (match_operand:QI 2 "register_operand" "a")]
                    UNSPEC_FMULSU))]
   "AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (unspec:HI [(match_dup 1)
-                               (match_dup 2)]
-                              UNSPEC_FMULSU))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*fmulsu_insn"
-  [(set (match_operand:HI 0 "register_operand" "=r")
-        (unspec:HI [(match_operand:QI 1 "register_operand" "a")
-                    (match_operand:QI 2 "register_operand" "a")]
-                   UNSPEC_FMULSU))
-   (clobber (reg:CC REG_CC))]
-  "AVR_HAVE_MUL && reload_completed"
   "fmulsu %1,%2
 	movw %0,r0
 	clr __zero_reg__"
-  [(set_attr "length" "3")])
+  [(set_attr "length" "3")
+   (set_attr "cc" "clobber")])
 
-(define_insn_and_split "*fmulsu.call_split"
+(define_insn "*fmulsu.call"
   [(set (reg:HI 22)
         (unspec:HI [(reg:QI 24)
                     (reg:QI 25)] UNSPEC_FMULSU))
    (clobber (reg:HI 24))]
   "!AVR_HAVE_MUL"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (reg:HI 22)
-                   (unspec:HI [(reg:QI 24)
-                               (reg:QI 25)] UNSPEC_FMULSU))
-              (clobber (reg:HI 24))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*fmulsu.call"
-  [(set (reg:HI 22)
-        (unspec:HI [(reg:QI 24)
-                    (reg:QI 25)] UNSPEC_FMULSU))
-   (clobber (reg:HI 24))
-   (clobber (reg:CC REG_CC))]
-  "!AVR_HAVE_MUL && reload_completed"
   "%~call __fmulsu"
   [(set_attr "type" "xcall")
-   ])
+   (set_attr "cc" "clobber")])
 
 
 ;; Some combiner patterns dealing with bits.
@@ -9078,7 +6561,8 @@
   "INTVAL(operands[4]) == exact_log2 (~INTVAL(operands[2]) & GET_MODE_MASK (QImode))
    && INTVAL(operands[4]) == exact_log2 (INTVAL(operands[5]) & GET_MODE_MASK (QImode))"
   "bst %3,0\;bld %0,%4"
-  [(set_attr "length" "2")])
+  [(set_attr "length" "2")
+   (set_attr "cc" "none")])
 
 ;; Move bit $3.0 into bit $0.$4
 ;; Variation of above. Unfortunately, there is no canonicalized representation
@@ -9093,7 +6577,8 @@
                            (match_operand:QI 4 "const_0_to_7_operand"      "n"))))]
   "INTVAL(operands[4]) == exact_log2 (~INTVAL(operands[2]) & GET_MODE_MASK (QImode))"
   "bst %3,0\;bld %0,%4"
-  [(set_attr "length" "2")])
+  [(set_attr "length" "2")
+   (set_attr "cc" "none")])
 
 ;; Move bit $3.0 into bit $0.0.
 ;; For bit 0, combiner generates slightly different pattern.
@@ -9105,7 +6590,8 @@
                         (const_int 1))))]
   "0 == exact_log2 (~INTVAL(operands[2]) & GET_MODE_MASK (QImode))"
   "bst %3,0\;bld %0,0"
-  [(set_attr "length" "2")])
+  [(set_attr "length" "2")
+   (set_attr "cc" "none")])
 
 ;; Move bit $2.0 into bit $0.7.
 ;; For bit 7, combiner generates slightly different pattern
@@ -9117,7 +6603,8 @@
                            (const_int 7))))]
   ""
   "bst %2,0\;bld %0,7"
-  [(set_attr "length" "2")])
+  [(set_attr "length" "2")
+   (set_attr "cc" "none")])
 
 ;; Combiner transforms above four pattern into ZERO_EXTRACT if it sees MEM
 ;; and input/output match.  We provide a special pattern for this, because
@@ -9133,7 +6620,8 @@
 	cbi %i0,%1
 	sbi %i0,%1
 	sbrc %2,0\;sbi %i0,%1\;sbrs %2,0\;cbi %i0,%1"
-  [(set_attr "length" "1,1,4")])
+  [(set_attr "length" "1,1,4")
+   (set_attr "cc" "none")])
 
 (define_insn "*insv.not.io"
   [(set (zero_extract:QI (mem:QI (match_operand 0 "low_io_address_operand" "i"))
@@ -9142,7 +6630,8 @@
         (not:QI (match_operand:QI 2 "register_operand"                     "r")))]
   ""
   "sbrs %2,0\;sbi %i0,%1\;sbrc %2,0\;cbi %i0,%1"
-  [(set_attr "length" "4")])
+  [(set_attr "length" "4")
+   (set_attr "cc" "none")])
 
 ;; The insv expander.
 ;; We only support 1-bit inserts
@@ -9159,34 +6648,20 @@
 ;; complicated.
 
 ;; Insert bit $2.0 into $0.$1
-(define_insn_and_split "*insv.reg_split"
+(define_insn "*insv.reg"
   [(set (zero_extract:QI (match_operand:QI 0 "register_operand"    "+r,d,d,l,l")
                          (const_int 1)
                          (match_operand:QI 1 "const_0_to_7_operand" "n,n,n,n,n"))
         (match_operand:QI 2 "nonmemory_operand"                     "r,L,P,L,P"))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (zero_extract:QI (match_dup 0)
-                                    (const_int 1)
-                                    (match_dup 1))
-                   (match_dup 2))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*insv.reg"
-  [(set (zero_extract:QI (match_operand:QI 0 "register_operand"    "+r,d,d,l,l")
-                         (const_int 1)
-                         (match_operand:QI 1 "const_0_to_7_operand" "n,n,n,n,n"))
-        (match_operand:QI 2 "nonmemory_operand"                     "r,L,P,L,P"))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "@
 	bst %2,0\;bld %0,%1
 	andi %0,lo8(~(1<<%1))
 	ori %0,lo8(1<<%1)
 	clt\;bld %0,%1
 	set\;bld %0,%1"
-  [(set_attr "length" "2,1,1,2,2")])
+  [(set_attr "length" "2,1,1,2,2")
+   (set_attr "cc" "none,set_zn,set_zn,none,none")])
 
 ;; Insert bit $2.$3 into $0.$1
 (define_insn "*insv.extract"
@@ -9198,7 +6673,8 @@
                         (match_operand:QI 3 "const_0_to_7_operand"  "n")))]
   ""
   "bst %2,%3\;bld %0,%1"
-  [(set_attr "length" "2")])
+  [(set_attr "length" "2")
+   (set_attr "cc" "none")])
 
 ;; Insert bit $2.$3 into $0.$1
 (define_insn "*insv.shiftrt"
@@ -9209,128 +6685,67 @@
                         (match_operand:QI 3 "const_0_to_7_operand"  "n")))]
   ""
   "bst %2,%3\;bld %0,%1"
-  [(set_attr "length" "2")])
+  [(set_attr "length" "2")
+   (set_attr "cc" "none")])
 
 ;; Same, but with a NOT inverting the source bit.
 ;; Insert bit ~$2.$3 into $0.$1
-(define_insn_and_split "*insv.not-shiftrt_split"
+(define_insn "*insv.not-shiftrt"
   [(set (zero_extract:QI (match_operand:QI 0 "register_operand"           "+r")
                          (const_int 1)
                          (match_operand:QI 1 "const_0_to_7_operand"        "n"))
         (not:QI (any_shiftrt:QI (match_operand:QI 2 "register_operand"     "r")
                                 (match_operand:QI 3 "const_0_to_7_operand" "n"))))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (zero_extract:QI (match_dup 0)
-                                    (const_int 1)
-                                    (match_dup 1))
-                   (not:QI (any_shiftrt:QI (match_dup 2)
-                                           (match_dup 3))))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*insv.not-shiftrt"
-  [(set (zero_extract:QI (match_operand:QI 0 "register_operand"           "+r")
-                         (const_int 1)
-                         (match_operand:QI 1 "const_0_to_7_operand"        "n"))
-        (not:QI (any_shiftrt:QI (match_operand:QI 2 "register_operand"     "r")
-                                (match_operand:QI 3 "const_0_to_7_operand" "n"))))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_insert_notbit (insn, operands, NULL_RTX, NULL);
   }
-  [(set_attr "adjust_len" "insv_notbit")])
+  [(set_attr "adjust_len" "insv_notbit")
+   (set_attr "cc" "clobber")])
 
 ;; Insert bit ~$2.0 into $0.$1
-(define_insn_and_split "*insv.xor1-bit.0_split"
+(define_insn "*insv.xor1-bit.0"
   [(set (zero_extract:QI (match_operand:QI 0 "register_operand"    "+r")
                          (const_int 1)
                          (match_operand:QI 1 "const_0_to_7_operand" "n"))
         (xor:QI (match_operand:QI 2 "register_operand"              "r")
                 (const_int 1)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (zero_extract:QI (match_dup 0)
-                                    (const_int 1)
-                                    (match_dup 1))
-                   (xor:QI (match_dup 2)
-                           (const_int 1)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*insv.xor1-bit.0"
-  [(set (zero_extract:QI (match_operand:QI 0 "register_operand"    "+r")
-                         (const_int 1)
-                         (match_operand:QI 1 "const_0_to_7_operand" "n"))
-        (xor:QI (match_operand:QI 2 "register_operand"              "r")
-                (const_int 1)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_insert_notbit (insn, operands, const0_rtx, NULL);
   }
-  [(set_attr "adjust_len" "insv_notbit_0")])
+  [(set_attr "adjust_len" "insv_notbit_0")
+   (set_attr "cc" "clobber")])
 
 ;; Insert bit ~$2.0 into $0.$1
-(define_insn_and_split "*insv.not-bit.0_split"
+(define_insn "*insv.not-bit.0"
   [(set (zero_extract:QI (match_operand:QI 0 "register_operand"    "+r")
                          (const_int 1)
                          (match_operand:QI 1 "const_0_to_7_operand" "n"))
         (not:QI (match_operand:QI 2 "register_operand"              "r")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (zero_extract:QI (match_dup 0)
-                                    (const_int 1)
-                                    (match_dup 1))
-                   (not:QI (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*insv.not-bit.0"
-  [(set (zero_extract:QI (match_operand:QI 0 "register_operand"    "+r")
-                         (const_int 1)
-                         (match_operand:QI 1 "const_0_to_7_operand" "n"))
-        (not:QI (match_operand:QI 2 "register_operand"              "r")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_insert_notbit (insn, operands, const0_rtx, NULL);
   }
-  [(set_attr "adjust_len" "insv_notbit_0")])
+  [(set_attr "adjust_len" "insv_notbit_0")
+   (set_attr "cc" "clobber")])
 
 ;; Insert bit ~$2.7 into $0.$1
-(define_insn_and_split "*insv.not-bit.7_split"
+(define_insn "*insv.not-bit.7"
   [(set (zero_extract:QI (match_operand:QI 0 "register_operand"    "+r")
                          (const_int 1)
                          (match_operand:QI 1 "const_0_to_7_operand" "n"))
         (ge:QI (match_operand:QI 2 "register_operand"               "r")
                (const_int 0)))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (zero_extract:QI (match_dup 0)
-                                    (const_int 1)
-                                    (match_dup 1))
-                   (ge:QI (match_dup 2)
-                          (const_int 0)))
-               (clobber (reg:CC REG_CC))])])
-
-(define_insn "*insv.not-bit.7"
-  [(set (zero_extract:QI (match_operand:QI 0 "register_operand"    "+r")
-                         (const_int 1)
-                         (match_operand:QI 1 "const_0_to_7_operand" "n"))
-        (ge:QI (match_operand:QI 2 "register_operand"               "r")
-               (const_int 0)))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   {
     return avr_out_insert_notbit (insn, operands, GEN_INT (7), NULL);
   }
-  [(set_attr "adjust_len" "insv_notbit_7")])
+  [(set_attr "adjust_len" "insv_notbit_7")
+   (set_attr "cc" "clobber")])
 
 ;; Insert bit ~$2.$3 into $0.$1
-(define_insn_and_split "*insv.xor-extract_split"
+(define_insn "*insv.xor-extract"
   [(set (zero_extract:QI (match_operand:QI 0 "register_operand"        "+r")
                          (const_int 1)
                          (match_operand:QI 1 "const_0_to_7_operand"     "n"))
@@ -9339,31 +6754,11 @@
                         (const_int 1)
                         (match_operand:QI 3 "const_0_to_7_operand"      "n")))]
   "INTVAL (operands[4]) & (1 << INTVAL (operands[3]))"
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (zero_extract:QI (match_dup 0)
-                                    (const_int 1)
-                                    (match_dup 1))
-                   (any_extract:QI (xor:QI (match_dup 2)
-                                           (match_dup 4))
-                                   (const_int 1)
-                                   (match_dup 3)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*insv.xor-extract"
-  [(set (zero_extract:QI (match_operand:QI 0 "register_operand"        "+r")
-                         (const_int 1)
-                         (match_operand:QI 1 "const_0_to_7_operand"     "n"))
-        (any_extract:QI (xor:QI (match_operand:QI 2 "register_operand"  "r")
-                                (match_operand:QI 4 "const_int_operand" "n"))
-                        (const_int 1)
-                        (match_operand:QI 3 "const_0_to_7_operand"      "n")))
-   (clobber (reg:CC REG_CC))]
-  "INTVAL (operands[4]) & (1 << INTVAL (operands[3])) && reload_completed"
   {
     return avr_out_insert_notbit (insn, operands, NULL_RTX, NULL);
   }
-  [(set_attr "adjust_len" "insv_notbit")])
+  [(set_attr "adjust_len" "insv_notbit")
+   (set_attr "cc" "clobber")])
 
 
 ;; Some combine patterns that try to fix bad code when a value is composed
@@ -9476,17 +6871,14 @@
 
 
 (define_peephole2
-  [(parallel [(set (match_operand:QI 0 "register_operand")
-                   (const_int 0))
-              (clobber (reg:CC REG_CC))])
-   (parallel [(set (match_dup 0)
-                   (ior:QI (match_dup 0)
-                           (match_operand:QI 1 "register_operand")))
-              (clobber (reg:CC REG_CC))])]
+  [(set (match_operand:QI 0 "register_operand")
+        (const_int 0))
+   (set (match_dup 0)
+        (ior:QI (match_dup 0)
+                (match_operand:QI 1 "register_operand")))]
   ""
-  [(parallel [(set (match_dup 0)
-                   (match_dup 1))
-              (clobber (reg:CC REG_CC))])])
+  [(set (match_dup 0)
+        (match_dup 1))])
 
 
 (define_expand "extzv"
@@ -9495,34 +6887,20 @@
                          (match_operand:QI 2 "const1_operand" "")
                          (match_operand:QI 3 "const_0_to_7_operand" "")))])
 
-(define_insn_and_split "*extzv_split"
+(define_insn "*extzv"
   [(set (match_operand:QI 0 "register_operand"                   "=*d,*d,*d,*d,r")
         (zero_extract:QI (match_operand:QI 1 "register_operand"     "0,r,0,0,r")
                          (const_int 1)
                          (match_operand:QI 2 "const_0_to_7_operand" "L,L,P,C04,n")))]
   ""
-  "#"
-  "&& reload_completed"
-  [(parallel [(set (match_dup 0)
-                   (zero_extract:QI (match_dup 1)
-                                    (const_int 1)
-                                    (match_dup 2)))
-              (clobber (reg:CC REG_CC))])])
-
-(define_insn "*extzv"
-  [(set (match_operand:QI 0 "register_operand"                   "=*d,*d,*d,*d,r")
-        (zero_extract:QI (match_operand:QI 1 "register_operand"     "0,r,0,0,r")
-                         (const_int 1)
-                         (match_operand:QI 2 "const_0_to_7_operand" "L,L,P,C04,n")))
-   (clobber (reg:CC REG_CC))]
-  "reload_completed"
   "@
 	andi %0,1
 	mov %0,%1\;andi %0,1
 	lsr %0\;andi %0,1
 	swap %0\;andi %0,1
 	bst %1,%2\;clr %0\;bld %0,0"
-  [(set_attr "length" "1,2,2,2,3")])
+  [(set_attr "length" "1,2,2,2,3")
+   (set_attr "cc" "set_zn,set_zn,set_zn,set_zn,clobber")])
 
 (define_insn_and_split "*extzv.qihi1"
   [(set (match_operand:HI 0 "register_operand"                     "=r")
diff --git a/gcc-12.1.0/gcc/config/avr/avr.opt b/gcc-12.1.0/gcc/config/avr/avr.opt
index fdb1daee95a..e86473443de 100644
--- a/gcc-12.1.0/gcc/config/avr/avr.opt
+++ b/gcc-12.1.0/gcc/config/avr/avr.opt
@@ -1,6 +1,6 @@
 ; Options for the ATMEL AVR port of the compiler.
 
-; Copyright (C) 2005-2022 Free Software Foundation, Inc.
+; Copyright (C) 2005-2021 Free Software Foundation, Inc.
 ;
 ; This file is part of GCC.
 ;
diff --git a/gcc-12.1.0/gcc/config/avr/avrlibc.h b/gcc-12.1.0/gcc/config/avr/avrlibc.h
index 03a1dd15805..068f6c374ef 100644
--- a/gcc-12.1.0/gcc/config/avr/avrlibc.h
+++ b/gcc-12.1.0/gcc/config/avr/avrlibc.h
@@ -1,6 +1,6 @@
 /* Definitions of target machine for the GNU compiler collection
    for Atmel AVR micro controller if configured for AVR-Libc.
-   Copyright (C) 2012-2022 Free Software Foundation, Inc.
+   Copyright (C) 2012-2021 Free Software Foundation, Inc.
    Contributed by Georg-Johann Lay (avr@gjlay.de)
 
 This file is part of GCC.
diff --git a/gcc-12.1.0/gcc/config/avr/builtins.def b/gcc-12.1.0/gcc/config/avr/builtins.def
index 8ed70c45d18..4e4b440d59e 100644
--- a/gcc-12.1.0/gcc/config/avr/builtins.def
+++ b/gcc-12.1.0/gcc/config/avr/builtins.def
@@ -1,4 +1,4 @@
-/* Copyright (C) 2012-2022 Free Software Foundation, Inc.
+/* Copyright (C) 2012-2021 Free Software Foundation, Inc.
 
    This file is part of GCC.
 
@@ -25,9 +25,9 @@
    NAME:    `__builtin_avr_name' will be the user-level name of the builtin.
             `AVR_BUILTIN_NAME' will be the internal builtin's id.
    N_ARGS:  Number of input arguments.  If special treatment is needed,
-            set to -1 and handle it by hand, see avr.cc:avr_expand_builtin().
+            set to -1 and handle it by hand, see avr.c:avr_expand_builtin().
    TYPE:    A tree node describing the prototype of the built-in.
-   ICODE:   Name of attached insn or expander.  If special treatment in avr.cc
+   ICODE:   Name of attached insn or expander.  If special treatment in avr.c
             is needed to expand the built-in, use `nothing'.
    LIBNAME: Name of the attached implementation in libgcc which is used if
             the builtin cannot be folded away and there is no insn.  */
diff --git a/gcc-12.1.0/gcc/config/avr/constraints.md b/gcc-12.1.0/gcc/config/avr/constraints.md
index 57397d1469b..f653ee4627c 100644
--- a/gcc-12.1.0/gcc/config/avr/constraints.md
+++ b/gcc-12.1.0/gcc/config/avr/constraints.md
@@ -1,5 +1,5 @@
 ;; Constraint definitions for ATMEL AVR micro controllers.
-;; Copyright (C) 2006-2022 Free Software Foundation, Inc.
+;; Copyright (C) 2006-2021 Free Software Foundation, Inc.
 ;;
 ;; This file is part of GCC.
 ;;
diff --git a/gcc-12.1.0/gcc/config/avr/driver-avr.c b/gcc-12.1.0/gcc/config/avr/driver-avr.c
new file mode 100644
index 00000000000..b840c7d87c8
--- /dev/null
+++ b/gcc-12.1.0/gcc/config/avr/driver-avr.c
@@ -0,0 +1,167 @@
+/* Subroutines for the gcc driver.
+   Copyright (C) 2009-2021 Free Software Foundation, Inc.
+   Contributed by Georg-Johann Lay <avr@gjlay.de>
+
+This file is part of GCC.
+
+GCC is free software; you can redistribute it and/or modify
+it under the terms of the GNU General Public License as published by
+the Free Software Foundation; either version 3, or (at your option)
+any later version.
+
+GCC is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with GCC; see the file COPYING3.  If not see
+<http://www.gnu.org/licenses/>.  */
+
+#define IN_TARGET_CODE 1
+
+#include "config.h"
+#include "system.h"
+#include "coretypes.h"
+#include "diagnostic.h"
+#include "tm.h"
+
+// Remove -nodevicelib and -nodevicespecs from the command line if not needed.
+#define X_NODEVLIB "%<nodevicelib %<nodevicespecs"
+
+static const char dir_separator_str[] = { DIR_SEPARATOR, 0 };
+
+
+/* Implement spec function `device-specs-file.
+
+   Validate mcu name given with -mmcu option. Compose
+   -specs=<specs-file-name>%s. If everything went well then argv[0] is the
+   inflated (absolute) first device-specs directory and argv[1] is a device
+   or core name as supplied by -mmcu=*. When building GCC the path might be
+   relative.  */
+
+const char*
+avr_devicespecs_file (int argc, const char **argv)
+{
+  const char *mmcu = NULL;
+
+#ifdef DEBUG_SPECS
+  if (verbose_flag)
+    fnotice (stderr, "Running spec function '%s' with %d args\n\n",
+             __FUNCTION__, argc);
+#endif
+
+  switch (argc)
+    {
+    case 0:
+      fatal_error (input_location,
+                   "bad usage of spec function %qs", "device-specs-file");
+      return X_NODEVLIB;
+
+    case 1:
+      if (strcmp ("device-specs", argv[0]) == 0)
+        {
+          /* FIXME:  This means "device-specs%s" from avr.h:DRIVER_SELF_SPECS
+             has not been resolved to a path.  That case can occur when the
+             c++ testsuite is run from the build directory.  DejaGNU's
+             libgloss.exp:get_multilibs runs $compiler without -B, i.e.runs
+             xgcc without specifying a prefix.  Without any prefix, there is
+             no means to find out where the specs files might be located.
+             get_multilibs runs xgcc --print-multi-lib, hence we don't actually
+             need information form a specs file and may skip it here.  */
+          return X_NODEVLIB;
+        }
+
+      mmcu = AVR_MMCU_DEFAULT;
+      break;
+
+    default:
+      mmcu = argv[1];
+
+      // Allow specifying the same MCU more than once.
+
+      for (int i = 2; i < argc; i++)
+	if (strcmp (mmcu, argv[i]) != 0)
+          {
+            error ("specified option %qs more than once", "-mmcu");
+            return X_NODEVLIB;
+          }
+
+      break;
+    }
+
+  // Filter out silly -mmcu= arguments like "foo bar".
+
+  for (const char *s = mmcu; *s; s++)
+    if (!ISALNUM (*s)
+        && '-' != *s
+        && '_' != *s)
+      {
+        error ("strange device name %qs after %qs: bad character %qc",
+               mmcu, "-mmcu=", *s);
+        return X_NODEVLIB;
+      }
+
+  return concat ("%{!nodevicespecs:-specs=device-specs", dir_separator_str,
+				 "specs-", mmcu, "%s} %<nodevicespecs"
+#if defined (WITH_AVRLIBC)
+                 " %{mmcu=avr*:" X_NODEVLIB "} %{!mmcu=*:" X_NODEVLIB "}",
+#else
+                 " " X_NODEVLIB,
+#endif
+                 NULL);
+}
+
+
+/* Re-build the -mdouble= and -mlong-double= options.  This is needed
+   because these options are not independent of each other.  */
+
+const char*
+avr_double_lib (int argc, const char **argv)
+{
+#if defined (WITH_DOUBLE64)
+  int dbl = 64;
+#elif defined (WITH_DOUBLE32)
+  int dbl = 32;
+#else
+#error "align this with config.gcc"
+#endif
+
+#if defined (WITH_LONG_DOUBLE64)
+  int ldb = 64;
+#elif defined (WITH_LONG_DOUBLE32)
+  int ldb = 32;
+#else
+#error "align this with config.gcc"
+#endif
+
+  for (int i = 0; i < argc; i++)
+    {
+      if (strcmp (argv[i], "mdouble=32") == 0)
+        {
+          dbl = 32;
+#ifdef HAVE_LONG_DOUBLE_IS_DOUBLE
+          ldb = dbl;
+#endif
+        }
+      else if (strcmp (argv[i], "mdouble=64") == 0)
+        {
+          ldb = dbl = 64;
+        }
+      else if (strcmp (argv[i], "mlong-double=32") == 0)
+        {
+          ldb = dbl = 32;
+        }
+      else if (strcmp (argv[i], "mlong-double=64") == 0)
+        {
+          ldb = 64;
+#ifdef HAVE_LONG_DOUBLE_IS_DOUBLE
+          dbl = ldb;
+#endif
+        }
+    }
+
+  return concat (" %<mdouble=* -mdouble=", dbl == 32 ? "32" : "64",
+                 " %<mlong-double=* -mlong-double=", ldb == 32 ? "32" : "64",
+                 NULL);
+}
diff --git a/gcc-12.1.0/gcc/config/avr/elf.h b/gcc-12.1.0/gcc/config/avr/elf.h
index eb1a70a917b..2f0eb0de775 100644
--- a/gcc-12.1.0/gcc/config/avr/elf.h
+++ b/gcc-12.1.0/gcc/config/avr/elf.h
@@ -1,4 +1,4 @@
-/* Copyright (C) 2011-2022 Free Software Foundation, Inc.
+/* Copyright (C) 2011-2021 Free Software Foundation, Inc.
    Contributed by Georg-Johann Lay (avr@gjlay.de)
 
    This file is part of GCC.
@@ -22,6 +22,9 @@
 
 #undef PCC_BITFIELD_TYPE_MATTERS
 
+#undef PREFERRED_DEBUGGING_TYPE
+#define PREFERRED_DEBUGGING_TYPE DBX_DEBUG
+
 #undef MAX_OFILE_ALIGNMENT
 #define MAX_OFILE_ALIGNMENT (32768 * 8)
 
diff --git a/gcc-12.1.0/gcc/config/avr/gen-avr-mmcu-specs.c b/gcc-12.1.0/gcc/config/avr/gen-avr-mmcu-specs.c
new file mode 100644
index 00000000000..b9e935bab66
--- /dev/null
+++ b/gcc-12.1.0/gcc/config/avr/gen-avr-mmcu-specs.c
@@ -0,0 +1,323 @@
+/* Copyright (C) 1998-2021 Free Software Foundation, Inc.
+   Contributed by Joern Rennecke
+
+   This file is part of GCC.
+
+   GCC is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 3, or (at your option)
+   any later version.
+   
+   GCC is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+   
+   You should have received a copy of the GNU General Public License
+   along with GCC; see the file COPYING3.  If not see
+   <http://www.gnu.org/licenses/>.  */
+
+#include <stdlib.h>
+#include <stdio.h>
+#include <string.h>
+
+#define IN_TARGET_CODE 1
+
+#include "config.h"
+
+#define IN_GEN_AVR_MMCU_TEXI
+
+#include "avr-devices.c"
+
+// Get rid of "defaults.h".  We just need tm.h for `WITH_AVRLIBC' and
+// and `WITH_RTEMS'.  */
+#define GCC_DEFAULTS_H
+
+#include "tm.h"
+
+// Mimic the include order as specified in config.gcc::tm_file.
+
+#include "specs.h"
+
+#if defined (WITH_AVRLIBC)
+#include "avrlibc.h"
+#endif
+
+
+#define SPECFILE_DOC_URL                                \
+  "https://gcc.gnu.org/onlinedocs/gcc/Spec-Files.html"
+
+#define SPECFILE_USAGE_URL                              \
+  "https://gcc.gnu.org/gcc-5/changes.html"
+
+
+static const char header[] =
+  "#\n"
+  "# Generated by   : ./gcc-12.1.0/gcc/config/avr/gen-avr-mmcu-specs.c\n"
+  "# Generated from : ./gcc/config/gcc.c\n"
+  "#                  ./gcc-12.1.0/gcc/config/avr/specs.h\n"
+#if defined (WITH_AVRLIBC)
+  "#                  ./gcc-12.1.0/gcc/config/avr/avrlibc.h\n"
+#endif
+  "# Used by        : avr-gcc compiler driver\n"
+  "# Used for       : building command options for sub-processes\n"
+  "#\n"
+  "# See <" SPECFILE_DOC_URL ">\n"
+  "# for a documentation of spec files.\n"
+  "\n";
+
+static const char help_copy_paste[] =
+  "# If you intend to use an existing device specs file as a starting point\n"
+  "# for a new device spec file, make sure you are copying from a specs\n"
+  "# file for a device from the same core architecture and SP width.\n"
+  "# See <" SPECFILE_USAGE_URL "> for a description\n"
+  "# of how to use such own spec files.\n";
+
+#if defined (WITH_AVRLIBC)
+static const char help_dev_lib_name[] =
+  "# AVR-LibC's avr/io.h uses the device specifying macro to determine\n"
+  "# the name of the device header.  For example, -mmcu=atmega8a triggers\n"
+  "# the definition of __AVR_ATmega8A__ and avr/io.h includes the device\n"
+  "# header 'iom8a.h' by means of:\n"
+  "#\n"
+  "#     ...\n"
+  "#     #elif defined (__AVR_ATmega8A__)\n"
+  "#     #  include <avr/iom8a.h>\n"
+  "#     #elif ...\n"
+  "# \n"
+  "# If no device macro is defined, AVR-LibC uses __AVR_DEV_LIB_NAME__\n"
+  "# as fallback to determine the name of the device header as\n"
+  "#\n"
+  "#     \"avr/io\" + __AVR_DEV_LIB_NAME__ + \".h\"\n"
+  "#\n"
+  "# If you provide your own specs file for a device not yet known to\n"
+  "# AVR-LibC, you can now define the hook macro __AVR_DEV_LIB_NAME__\n"
+  "# as needed so that\n"
+  "#\n"
+  "#     #include <avr/io.h>\n"
+  "#\n"
+  "# will include the desired device header.  For ATmega8A the supplement\n"
+  "# to *cpp_avrlibc would read\n"
+  "#\n"
+  "#     -D__AVR_DEV_LIB_NAME__=m8a\n"
+  "\n";
+#endif // WITH_AVRLIBC
+
+static void
+print_mcu (const avr_mcu_t *mcu)
+{
+  const char *sp8_spec;
+  const char *rcall_spec;
+  const avr_mcu_t *arch_mcu;
+  const avr_arch_t *arch;
+  enum avr_arch_id arch_id = mcu->arch_id;
+
+  for (arch_mcu = mcu; arch_mcu->macro; )
+    arch_mcu--;
+  if (arch_mcu->arch_id != arch_id)
+    exit (EXIT_FAILURE);
+
+  arch = &avr_arch_types[arch_id];
+
+  char name[100];
+  if (snprintf (name, sizeof name, "specs-%s", mcu->name) >= (int) sizeof name)
+   exit (EXIT_FAILURE);
+
+  FILE *f = fopen (name ,"w");
+
+  bool absdata = (mcu->dev_attribute & AVR_ISA_LDS) != 0;
+  bool errata_skip = (mcu->dev_attribute & AVR_ERRATA_SKIP) != 0;
+  bool rmw = (mcu->dev_attribute & AVR_ISA_RMW) != 0;
+  bool sp8 = (mcu->dev_attribute & AVR_SHORT_SP) != 0;
+  bool rcall = (mcu->dev_attribute & AVR_ISA_RCALL);
+  bool is_arch = mcu->macro == NULL;
+  bool is_device = ! is_arch;
+  int flash_pm_offset = 0;
+
+  if (arch->flash_pm_offset
+      && mcu->flash_pm_offset
+      && mcu->flash_pm_offset != arch->flash_pm_offset)
+    {
+      flash_pm_offset = mcu->flash_pm_offset;
+    }
+
+  if (is_arch
+      && (ARCH_AVR2 == arch_id
+          || ARCH_AVR25 == arch_id))
+    {
+      // Leave "avr2" and "avr25" alone.  These two architectures are
+      // the only ones that mix devices with 8-bit SP and 16-bit SP.
+      sp8_spec = "";
+    }
+  else
+    {
+      sp8_spec = sp8 ? "-msp8" :"%<msp8";
+    }
+
+  if (is_arch
+      && ARCH_AVRXMEGA3 == arch_id)
+    {
+      // Leave "avrxmega3" alone.  This architectures is the only one
+      // that mixes devices with and without JMP / CALL.
+      rcall_spec = "";
+    }
+  else
+    {
+      rcall_spec = rcall ? "-mshort-calls" : "%<mshort-calls";
+    }
+
+  fprintf (f, "#\n"
+           "# Auto-generated specs for AVR ");
+  if (is_arch)
+    fprintf (f, "core architecture %s\n", arch->name);
+  else
+    fprintf (f, "device %s (core %s, %d-bit SP%s)\n", mcu->name,
+             arch->name, sp8 ? 8 : 16, rcall ? ", short-calls" : "");
+  fprintf (f, "%s\n", header);
+
+  if (is_device)
+    fprintf (f, "%s\n", help_copy_paste);
+
+#if defined (WITH_AVRLIBC)
+  // AVR-LibC specific.  See avrlibc.h for the specs using them as subspecs.
+
+  if (is_device)
+    {
+      fprintf (f, "*avrlibc_startfile:\n");
+      fprintf (f, "\tcrt%s.o%%s", mcu->name);
+      fprintf (f, "\n\n");
+
+      fprintf (f, "*avrlibc_devicelib:\n");
+      fprintf (f, "\t%%{!nodevicelib:-l%s}", mcu->name);
+      fprintf (f, "\n\n");
+    }
+#endif  // WITH_AVRLIBC
+
+  // avr-gcc specific specs for the compilation / the compiler proper.
+
+  int n_flash = 1 + (mcu->flash_size - 1) / 0x10000;
+
+  fprintf (f, "*cc1_n_flash:\n"
+           "\t%%{!mn-flash=*:-mn-flash=%d}\n\n", n_flash);
+
+  fprintf (f, "*cc1_rmw:\n%s\n\n", rmw
+           ? "\t%{!mno-rmw: -mrmw}"
+           : "\t%{mrmw}");
+
+  fprintf (f, "*cc1_errata_skip:\n%s\n\n", errata_skip
+           ? "\t%{!mno-skip-bug: -mskip-bug}"
+           : "\t%{!mskip-bug: -mno-skip-bug}");
+
+  fprintf (f, "*cc1_absdata:\n%s\n\n", absdata
+           ? "\t%{!mno-absdata: -mabsdata}"
+           : "\t%{mabsdata}");
+
+  // avr-gcc specific specs for assembling / the assembler.
+
+  fprintf (f, "*asm_arch:\n\t-mmcu=%s\n\n", arch->name);
+
+#ifdef HAVE_AS_AVR_MLINK_RELAX_OPTION
+  fprintf (f, "*asm_relax:\n\t%s\n\n", ASM_RELAX_SPEC);
+#endif // have avr-as --mlink-relax
+
+#ifdef HAVE_AS_AVR_MRMW_OPTION
+  fprintf (f, "*asm_rmw:\n%s\n\n", rmw
+           ? "\t%{!mno-rmw: -mrmw}"
+           : "\t%{mrmw}");
+#endif // have avr-as -mrmw
+
+#ifdef HAVE_AS_AVR_MGCCISR_OPTION
+  fprintf (f, "*asm_gccisr:\n%s\n\n",
+           "\t%{!mno-gas-isr-prologues: -mgcc-isr}");
+#endif // have avr-as -mgcc-isr
+
+  fprintf (f, "*asm_errata_skip:\n%s\n\n", errata_skip
+           ? "\t%{mno-skip-bug}"
+           : "\t%{!mskip-bug: -mno-skip-bug}");
+
+  // avr-specific specs for linking / the linker.
+
+  int wrap_k =
+    mcu->flash_size == 0x2000 ? 8
+    : mcu->flash_size == 0x4000 ? 16
+    : mcu->flash_size == 0x8000 ? 32
+    : mcu->flash_size == 0x10000 ? 64
+    : 0;
+
+  fprintf (f, "*link_pmem_wrap:\n");
+  if (wrap_k == 8)
+    fprintf (f, "\t%%{!mno-pmem-wrap-around: --pmem-wrap-around=8k}");
+  else if (wrap_k > 8)
+    fprintf (f, "\t%%{mpmem-wrap-around: --pmem-wrap-around=%dk}", wrap_k);
+  fprintf (f, "\n\n");
+
+  fprintf (f, "*link_relax:\n\t%s\n\n", LINK_RELAX_SPEC);
+
+  fprintf (f, "*link_arch:\n\t%s", LINK_ARCH_SPEC);
+  if (is_device
+      && flash_pm_offset)
+    fprintf (f, " --defsym=__RODATA_PM_OFFSET__=0x%x", flash_pm_offset);
+  fprintf (f, "\n\n");
+
+  if (is_device)
+    {
+      fprintf (f, "*link_data_start:\n");
+      if (mcu->data_section_start
+          != arch->default_data_section_start)
+        fprintf (f, "\t%%{!Tdata:-Tdata 0x%lX}",
+                 0x800000UL + mcu->data_section_start);
+      fprintf (f, "\n\n");
+
+      fprintf (f, "*link_text_start:\n");
+      if (mcu->text_section_start != 0x0)
+        fprintf (f, "\t%%{!Ttext:-Ttext 0x%lX}", 0UL + mcu->text_section_start);
+      fprintf (f, "\n\n");
+    }
+
+  // Specs known to GCC.
+
+  if (is_device)
+    {
+      fprintf (f, "*self_spec:\n");
+      fprintf (f, "\t%%{!mmcu=avr*: %%<mmcu=* -mmcu=%s} ", arch->name);
+      fprintf (f, "%s ", rcall_spec);
+      fprintf (f, "%s\n\n", sp8_spec);
+
+#if defined (WITH_AVRLIBC)
+      fprintf (f, "%s\n", help_dev_lib_name);
+
+      fprintf (f, "*cpp_avrlibc:\n");
+      fprintf (f, "\t-D__AVR_DEVICE_NAME__=%s", mcu->name);
+      fprintf (f, "\n\n");
+#endif // WITH_AVRLIBC
+
+      fprintf (f, "*cpp_mcu:\n");
+      fprintf (f, "\t-D%s", mcu->macro);
+      if (flash_pm_offset)
+	{
+	  fprintf (f, " -U__AVR_PM_BASE_ADDRESS__");
+	  fprintf (f, " -D__AVR_PM_BASE_ADDRESS__=0x%x", flash_pm_offset);
+	}
+      fprintf (f, "\n\n");
+
+      fprintf (f, "*cpp:\n");
+      fprintf (f, "\t%%(cpp_mcu)");
+#if defined (WITH_AVRLIBC)
+      fprintf (f, " %%(cpp_avrlibc)");
+#endif // WITH_AVRLIBC
+      fprintf (f, "\n\n");
+    }
+
+  fprintf (f, "# End of file\n");
+
+  fclose (f);
+}
+
+
+int main (void)
+{
+  for (const avr_mcu_t *mcu = avr_mcu_types; mcu->name; mcu++)
+    print_mcu (mcu);
+
+  return EXIT_SUCCESS;
+}
diff --git a/gcc-12.1.0/gcc/config/avr/gen-avr-mmcu-texi.c b/gcc-12.1.0/gcc/config/avr/gen-avr-mmcu-texi.c
new file mode 100644
index 00000000000..29252a52f3b
--- /dev/null
+++ b/gcc-12.1.0/gcc/config/avr/gen-avr-mmcu-texi.c
@@ -0,0 +1,202 @@
+/* Copyright (C) 2012-2021 Free Software Foundation, Inc.
+   Contributed by Georg-Johann Lay (avr@gjlay.de)
+
+   This file is part of GCC.
+
+   GCC is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 3, or (at your option)
+   any later version.
+   
+   GCC is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+   
+   You should have received a copy of the GNU General Public License
+   along with GCC; see the file COPYING3.  If not see
+   <http://www.gnu.org/licenses/>.  */
+
+#include <stdlib.h>
+#include <stdio.h>
+#include <string.h>
+
+#define IN_GEN_AVR_MMCU_TEXI
+
+#include "avr-devices.c"
+
+static const avr_mcu_t*
+mcus[sizeof avr_mcu_types / sizeof avr_mcu_types[0]];
+
+static int letter (char c)
+{
+  return c >= 'a' && c <= 'z';
+}
+
+static int digit (char c)
+{
+  return c >= '0' && c <= '9';
+}
+
+static int
+str_prefix_p (const char *str, const char *prefix)
+{
+  return strncmp (str, prefix, strlen (prefix)) == 0;
+}
+
+
+/* Used by string comparator to group MCUs by their
+   name prefix like "attiny" or "atmega".  */
+
+static int
+c_prefix (const char *str)
+{
+  static const char *const prefixes[] =
+    {
+      "attiny", "atmega", "atxmega", "ata", "at90"
+    };
+
+  int i, n = (int) (sizeof (prefixes) / sizeof (*prefixes));
+
+  for (i = 0; i < n; i++)
+    if (str_prefix_p (str, prefixes[i]))
+      return i;
+
+  return n;
+}
+
+
+/* If A starts a group of digits, return their value as a number.  */
+
+static int
+c_number (const char *a)
+{
+  int val = 0;
+
+  if (digit (*a) && ! digit (*(a-1)))
+    {
+      while (digit (*a))
+	val = 10 * val + (*a++) - '0';
+    }
+
+  return val;
+}
+
+
+/* Compare two MCUs and order them for easy lookup.  */
+
+static int
+comparator (const void *va, const void *vb)
+{
+  const avr_mcu_t *mcu_a = *(const avr_mcu_t* const*) va;
+  const avr_mcu_t *mcu_b = *(const avr_mcu_t* const*) vb;
+  const char *a = mcu_a->name;
+  const char *b = mcu_b->name;
+
+  // First, group MCUs according to their pure-letter prefix.
+
+  int c = c_prefix (a) - c_prefix (b);
+  if (c)
+    return c;
+
+  // Second, if their prefixes are the same, group according to
+  // their flash size.
+
+  c = (int) mcu_a->flash_size - (int) mcu_b->flash_size;
+  if (c)
+    return c;
+
+  // Third, group according to aligned groups of digits.
+
+  while (*a && *b)
+    {
+      c = c_number (a) - c_number (b);
+      if (c)
+	return c;
+
+      if (*a != *b)
+	return *a - *b;
+      
+      a++;
+      b++;
+    }
+
+  return *a - *b;
+} 
+
+static void
+print_mcus (size_t n_mcus)
+{
+  int duplicate = 0;
+  size_t i;
+    
+  if (!n_mcus)
+    return;
+    
+  qsort (mcus, n_mcus, sizeof (avr_mcu_t*), comparator);
+
+  printf ("@*@var{mcu}@tie{}=");
+
+  for (i = 0; i < n_mcus; i++)
+    {
+      printf (" @code{%s}%s", mcus[i]->name, i == n_mcus-1 ? ".\n\n" : ",");
+
+      if (i && !strcmp (mcus[i]->name, mcus[i-1]->name))
+	{
+	  // Sanity-check: Fail on devices that are present more than once.
+
+	  duplicate = 1;
+	  fprintf (stderr, "error: duplicate device: %s\n", mcus[i]->name);
+	}
+    }
+
+  if (duplicate)
+    exit (1);
+}
+
+int main (void)
+{
+  enum avr_arch_id arch_id = ARCH_UNKNOWN;
+  size_t i, n_mcus = 0;
+  const avr_mcu_t *mcu;
+
+  printf ("@c Copyright (C) 2012-2021 Free Software Foundation, Inc.\n");
+  printf ("@c This is part of the GCC manual.\n");
+  printf ("@c For copying conditions, see the file "
+	  "gcc/doc/include/fdl.texi.\n\n");
+
+  printf ("@c This file is generated automatically using\n");
+  printf ("@c gcc-12.1.0/gcc/config/avr/gen-avr-mmcu-texi.c from:\n");
+  printf ("@c	 gcc-12.1.0/gcc/config/avr/avr-arch.h\n");
+  printf ("@c	 gcc-12.1.0/gcc/config/avr/avr-devices.c\n");
+  printf ("@c	 gcc-12.1.0/gcc/config/avr/avr-mcus.def\n\n");
+
+  printf ("@c Please do not edit manually.\n\n");
+
+  printf ("@table @code\n\n");
+
+  for (mcu = avr_mcu_types; mcu->name; mcu++)
+    {
+      if (mcu->macro == NULL)
+	{
+	  arch_id = mcu->arch_id;
+
+	  // Start a new architecture:	Flush the MCUs collected so far.
+	  print_mcus (n_mcus);
+	  n_mcus = 0;
+
+	  for (i = 0; i < sizeof (avr_texinfo) / sizeof (*avr_texinfo); i++)
+	    if (arch_id == avr_texinfo[i].arch_id)
+	      printf ("@item %s\n%s\n", mcu->name, avr_texinfo[i].texinfo);
+	}
+      else if (arch_id == (enum avr_arch_id) mcu->arch_id)
+	{
+	  mcus[n_mcus++] = mcu;
+	}
+    }
+
+  print_mcus (n_mcus);
+  printf ("@end table\n");
+
+  return EXIT_SUCCESS;
+}
diff --git a/gcc-12.1.0/gcc/config/avr/genmultilib.awk b/gcc-12.1.0/gcc/config/avr/genmultilib.awk
index 25a1f4f6684..efe41ddb560 100644
--- a/gcc-12.1.0/gcc/config/avr/genmultilib.awk
+++ b/gcc-12.1.0/gcc/config/avr/genmultilib.awk
@@ -1,4 +1,4 @@
-# Copyright (C) 2011-2022 Free Software Foundation, Inc.
+# Copyright (C) 2011-2021 Free Software Foundation, Inc.
 #
 # This file is part of GCC.
 #
@@ -67,16 +67,6 @@ BEGIN {
 
     dir_long_double = "long-double"   (96 - with_long_double)
     opt_long_double = "mlong-double=" (96 - with_long_double)
-
-    if (with_multilib_list != "")
-    {
-	split(with_multilib_list, multilib_list, ",")
-
-	for (i in multilib_list)
-	{
-	    multilibs[multilib_list[i]] = 1
-	}
-    }
 }
 
 ##################################################################
@@ -147,9 +137,6 @@ BEGIN {
 	if (core == "avr1")
 	    next
 
-	if (with_multilib_list != "" && !(core in multilibs))
-	    next
-
 	option[core] = "mmcu=" core
 
 	m_options  = m_options m_sep option[core]
@@ -163,9 +150,6 @@ BEGIN {
     if (core == "avr1")
 	next
 
-    if (with_multilib_list != "" && !(core in multilibs))
-	next
-
     opts = option[core]
 
     # split device specific feature list
diff --git a/gcc-12.1.0/gcc/config/avr/predicates.md b/gcc-12.1.0/gcc/config/avr/predicates.md
index c7f417d405c..0b9a97df61b 100644
--- a/gcc-12.1.0/gcc/config/avr/predicates.md
+++ b/gcc-12.1.0/gcc/config/avr/predicates.md
@@ -1,5 +1,5 @@
 ;; Predicate definitions for ATMEL AVR micro controllers.
-;; Copyright (C) 2006-2022 Free Software Foundation, Inc.
+;; Copyright (C) 2006-2021 Free Software Foundation, Inc.
 ;;
 ;; This file is part of GCC.
 ;;
diff --git a/gcc-12.1.0/gcc/config/avr/specs.h b/gcc-12.1.0/gcc/config/avr/specs.h
index b50ab407c6d..a0e09cbcda2 100644
--- a/gcc-12.1.0/gcc/config/avr/specs.h
+++ b/gcc-12.1.0/gcc/config/avr/specs.h
@@ -1,6 +1,6 @@
 /* Specs definitions for Atmel AVR back end.
 
-   Copyright (C) 2012-2022 Free Software Foundation, Inc.
+   Copyright (C) 2012-2021 Free Software Foundation, Inc.
    Contributed by Georg-Johann Lay (avr@gjlay.de)
 
 This file is part of GCC.
diff --git a/gcc-12.1.0/gcc/config/avr/stdfix.h b/gcc-12.1.0/gcc/config/avr/stdfix.h
index 4469d7c17d7..79c20fc9bef 100644
--- a/gcc-12.1.0/gcc/config/avr/stdfix.h
+++ b/gcc-12.1.0/gcc/config/avr/stdfix.h
@@ -1,4 +1,4 @@
-/* Copyright (C) 2007-2022 Free Software Foundation, Inc.
+/* Copyright (C) 2007-2021 Free Software Foundation, Inc.
 
    This file is part of GCC.
 
diff --git a/gcc-12.1.0/gcc/config/avr/t-avr b/gcc-12.1.0/gcc/config/avr/t-avr
index d7b1751b3b6..06a0a3a7618 100644
--- a/gcc-12.1.0/gcc/config/avr/t-avr
+++ b/gcc-12.1.0/gcc/config/avr/t-avr
@@ -1,4 +1,4 @@
-# Copyright (C) 2000-2022 Free Software Foundation, Inc.
+# Copyright (C) 2000-2021 Free Software Foundation, Inc.
 #
 # This file is part of GCC.
 #
@@ -40,22 +40,22 @@ endif
 
 PASSES_EXTRA += $(srcdir)/config/avr/avr-passes.def
 
-driver-avr.o: $(srcdir)/config/avr/driver-avr.cc \
+driver-avr.o: $(srcdir)/config/avr/driver-avr.c \
   $(CONFIG_H) $(SYSTEM_H) coretypes.h \
   $(srcdir)/config/avr/avr-arch.h $(TM_H)
 	$(COMPILER) -c $(ALL_COMPILERFLAGS) $(ALL_CPPFLAGS) $(INCLUDES) $<
 
-avr-devices.o: $(srcdir)/config/avr/avr-devices.cc \
+avr-devices.o: $(srcdir)/config/avr/avr-devices.c \
   $(srcdir)/config/avr/avr-mcus.def \
   $(srcdir)/config/avr/avr-arch.h \
   $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H)
 	$(COMPILER) -c $(ALL_COMPILERFLAGS) $(ALL_CPPFLAGS) $(INCLUDES) $<
 
-avr-c.o: $(srcdir)/config/avr/avr-c.cc \
+avr-c.o: $(srcdir)/config/avr/avr-c.c \
   $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(TREE_H) $(C_COMMON_H)
 	$(COMPILER) -c $(ALL_COMPILERFLAGS) $(ALL_CPPFLAGS) $(INCLUDES) $<
 
-avr-log.o: $(srcdir)/config/avr/avr-log.cc \
+avr-log.o: $(srcdir)/config/avr/avr-log.c \
   $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(TREE_H) $(INPUT_H) dumpfile.h
 	$(COMPILER) -c $(ALL_COMPILERFLAGS) $(ALL_CPPFLAGS) $(INCLUDES) $<
 
@@ -81,13 +81,13 @@ AVR_MCUS = $(srcdir)/config/avr/avr-mcus.def
 avr-mcus: $(srcdir)/doc/avr-mmcu.texi ; @true
 
 # Make sure that native -mmcu= support is in sync with -mmcu= documentation.
-gen-avr-mmcu-texi$(build_exeext): $(srcdir)/config/avr/gen-avr-mmcu-texi.cc \
-  $(AVR_MCUS) $(srcdir)/config/avr/avr-devices.cc \
+gen-avr-mmcu-texi$(build_exeext): $(srcdir)/config/avr/gen-avr-mmcu-texi.c \
+  $(AVR_MCUS) $(srcdir)/config/avr/avr-devices.c \
   $(srcdir)/config/avr/avr-arch.h
-	$(CXX_FOR_BUILD) $(CXXFLAGS_FOR_BUILD) $< -o $@
+	$(CC_FOR_BUILD) $(CFLAGS_FOR_BUILD) $< -o $@
 
-gen-avr-mmcu-specs$(build_exeext): $(srcdir)/config/avr/gen-avr-mmcu-specs.cc \
-  $(AVR_MCUS) $(srcdir)/config/avr/avr-devices.cc \
+gen-avr-mmcu-specs$(build_exeext): $(srcdir)/config/avr/gen-avr-mmcu-specs.c \
+  $(AVR_MCUS) $(srcdir)/config/avr/avr-devices.c \
   $(srcdir)/config/avr/avr-arch.h $(TM_H)
 	$(CXX_FOR_BUILD) $(CXXFLAGS_FOR_BUILD) $< -o $@ $(INCLUDES)
 
@@ -127,7 +127,6 @@ t-multilib-avr: $(srcdir)/config/avr/genmultilib.awk \
 		-v HAVE_LONG_DOUBLE64=$(HAVE_LONG_DOUBLE64) 		\
 		-v with_double=$(WITH_DOUBLE) 				\
 		-v with_long_double=$(WITH_LONG_DOUBLE)			\
-		-v with_multilib_list=$(TM_MULTILIB_CONFIG)		\
 		-f $< $< $(AVR_MCUS) > $@
 
 include t-multilib-avr
